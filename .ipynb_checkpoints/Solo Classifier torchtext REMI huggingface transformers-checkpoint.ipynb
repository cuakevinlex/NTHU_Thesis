{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193a1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:1\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "print(dev)\n",
    "device = torch.device(dev)\n",
    "print(device)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022889aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# dataset folder\n",
    "source_folder = \"solo_classification_REMI_dataset_unbalanced\"\n",
    "# where it saves the weights\n",
    "destination_folder = \"solo_classification_transformer_REMI_weights_huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715a9def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-73db8496d3ef46d9\n",
      "Reusing dataset csv (/home/tonistark23/.cache/huggingface/datasets/csv/default-73db8496d3ef46d9/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5d42ed5cbe4ae4a0f299e598ae9747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "pop_dataset = load_dataset(\"csv\", data_files={'train': source_folder+\"/train.csv\", 'valid': source_folder+\"/val.csv\", 'test': source_folder+\"/test.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea16dda4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c63548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/tonistark23/.cache/huggingface/datasets/csv/default-73db8496d3ef46d9/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-6702da6344414444.arrow\n",
      "Loading cached processed dataset at /home/tonistark23/.cache/huggingface/datasets/csv/default-73db8496d3ef46d9/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-7dc0409cd7727ee7.arrow\n",
      "Loading cached processed dataset at /home/tonistark23/.cache/huggingface/datasets/csv/default-73db8496d3ef46d9/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-d4942841be577805.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"melody\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = pop_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0709ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset=tokenized_dataset[\"train\"]\n",
    "full_eval_dataset=tokenized_dataset[\"valid\"]\n",
    "full_test_dataset=tokenized_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64139cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b77620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "# training_args = TrainingArguments(\n",
    "#     do_predict=True,\n",
    "#     overwrite_output_dir=True,\n",
    "#     do_train=True,\n",
    "#     num_train_epochs=1,\n",
    "#     per_device_train_batch_size = 8,\n",
    "#     logging_steps=10,\n",
    "#     learning_rate=5e-5,\n",
    "#     warmup_steps=100,\n",
    "#     save_steps=50\n",
    "# )\n",
    "training_args=TrainingArguments('test_trainer')\n",
    "print(training_args.device)\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args, train_dataset=full_train_dataset, eval_dataset=full_eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99427ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d8407f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True)\n",
    "fields = [('labels', label_field), ('notes', text_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='val.csv', test='test.csv',\n",
    "                                           format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "test_iter = BucketIterator(test, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "\n",
    "# Vocabulary\n",
    "\n",
    "text_field.build_vocab(train, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e54a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(text_field.vocab)\n",
    "emsize = 200\n",
    "d_hid = 64\n",
    "nlayers = 2 \n",
    "nhead = 8\n",
    "dropout = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa477d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  7, 30,  ..., 41, 44,  2],\n",
      "        [ 4,  7, 30,  ..., 22, 31, 49],\n",
      "        [ 4,  7, 30,  ..., 51, 43, 78],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 41, 27,  3],\n",
      "        [ 4,  7, 30,  ..., 22, 29, 61],\n",
      "        [ 4,  7, 58,  ..., 14, 54, 89],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4, 28, 67,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  67,  40,   2],\n",
      "        [  4,   7,  30,  ...,  38,  84,   1],\n",
      "        [  4,   7, 186,  ...,  83,  46,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  24,  27,   2],\n",
      "        [  4,   7,  30,  ...,  48, 172,   1],\n",
      "        [  4,   7,  58,  ...,  23,   6,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  53,  55,   5],\n",
      "        [  4,   7,  58,  ...,  51,  43, 116],\n",
      "        [  4,   7,  58,  ...,  14,  23,   3],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,  84,   1,   1],\n",
      "        [  4,   7,  58,  ...,  61,   1,   1],\n",
      "        [  4,   7,  30,  ...,   2,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  54, 103],\n",
      "        [  4,   7,  30,  ...,  24,  79,  90],\n",
      "        [  4,   7,  58,  ...,  24,  63,  49],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  11,  30,  94],\n",
      "        [  4,   7,  30,  ...,  53, 167,  74],\n",
      "        [  4,   7,  30,  ...,   5,   1,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ...,  8, 62,  2],\n",
      "        [ 4,  7, 30,  ..., 14, 54,  2],\n",
      "        [ 4,  7, 58,  ..., 43, 46,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ...,  8, 35,  5],\n",
      "        [ 4, 16, 12,  ..., 76, 50,  2],\n",
      "        [ 4,  7, 58,  ..., 41, 47, 46],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 32, 44,  3],\n",
      "        [ 4,  7, 58,  ..., 22, 55, 90],\n",
      "        [ 4,  7, 30,  ..., 15, 70, 46],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 15, 47,  5],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  12,  57, 153],\n",
      "        [  4,   7,  58,  ...,   8,  31, 205],\n",
      "        [  4,   7,  58,  ...,  24,  62,   5],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   8,  39,  49],\n",
      "        [  4,   7,  30,  ...,  59,  50,  49],\n",
      "        [  4,   7,  58,  ...,  15,  39, 120],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   9,  23,   5],\n",
      "        [  4,   7,  58,  ...,  32,  70,  91],\n",
      "        [  4,   7,  58,  ...,   8,  40,  61]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  15,  44, 205],\n",
      "        [  4,   7,  58,  ...,  38, 171,   1],\n",
      "        [  4,   7,  58,  ...,  50,   3,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7, 186,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  14,  27,   2],\n",
      "        [  4,   7,  30,  ...,  16,  30, 124],\n",
      "        [  4,   7,  58,  ...,  17, 128,   3],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   9,  35,   6],\n",
      "        [  4,   7,  30,  ...,  41,  52,   2],\n",
      "        [  4,   7,  58,  ...,  12,  56,   2],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  27,   2,   1],\n",
      "        [  4,   7,  58,  ...,  55,  90,   1],\n",
      "        [  4,   7,  30,  ...,  82, 116,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  24,  38, 127],\n",
      "        [  4,   7,  30,  ...,  12,  29,   6],\n",
      "        [  4,   7,  30,  ...,  10,  55,   2],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  57,   3,   1],\n",
      "        [  4,   7,  30,  ...,  62,  74,   1],\n",
      "        [  4,   7,  30,  ...,  40, 138,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  29,   6],\n",
      "        [  4,   7,  30,  ...,  31,  46,   1],\n",
      "        [  4,   7,  30,  ...,  82, 116,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  31, 127],\n",
      "        [  4,   7,  58,  ...,  12,  38,   2],\n",
      "        [  4,   7,  58,  ...,   9,  43, 153],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  15,  39,   3],\n",
      "        [  4,   7,  58,  ...,  10,  23,  46],\n",
      "        [  4,   7,  30,  ...,  17,  52, 164],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 22, 27,  3],\n",
      "        [ 4,  7, 30,  ..., 17, 52,  6],\n",
      "        [ 4,  7, 30,  ..., 41, 52,  5],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ..., 85,  1,  1],\n",
      "        [ 4,  7, 30,  ..., 89,  1,  1],\n",
      "        [ 4,  7, 30,  ..., 78,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  59,  35,   3],\n",
      "        [  4,   7,  30,  ...,   8,  52,   3],\n",
      "        [  4,   7,  30,  ...,  41,  23, 105],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  66,   2,   1],\n",
      "        [  4,   7,  30,  ...,  74,   1,   1],\n",
      "        [  4,   7,  58,  ...,  72,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   8,  35, 116],\n",
      "        [  4,   7,  58,  ...,   8,  40,   5],\n",
      "        [  4,   7,  30,  ...,  24,  52,  49],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  22,  35,  49],\n",
      "        [  4,   7,  58,  ...,  67,  50,   3],\n",
      "        [  4,   7,  30,  ...,  12,  43,   3]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  22,  29,   2],\n",
      "        [  4,   7,  58,  ...,  41,  35,  45],\n",
      "        [  4,   7,  30,  ...,  50, 116,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 24, 50,  6],\n",
      "        [ 4,  7, 30,  ..., 50,  2,  1],\n",
      "        [ 4,  7, 30,  ..., 23,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  32,  43,  46],\n",
      "        [  4,   7,  58,  ...,   9,  23, 120],\n",
      "        [  4,   7,  58,  ...,  35,  46,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   9,  29, 138],\n",
      "        [  4,   7,  30,  ...,  17,  82,   2],\n",
      "        [  4,   7,  58,  ...,   8,  68, 118],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 38, 84],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 67, 60,  2],\n",
      "        [ 4,  7, 30,  ..., 15, 23,  6],\n",
      "        [ 4,  7, 30,  ..., 10, 60,  2],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  15,  44, 115],\n",
      "        [  4,   7,  58,  ...,  24,  35,  91],\n",
      "        [  4,   7,  58,  ...,   8,  31,  89],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  41,  43, 105],\n",
      "        [  4,   7,  30,  ...,   8,  39,  89],\n",
      "        [  4,   7,  58,  ...,  41,  57,  45],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 24, 31,  6],\n",
      "        [ 4,  7, 30,  ..., 32, 40, 96],\n",
      "        [ 4,  7, 30,  ..., 22, 35, 45],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   8,  40, 105],\n",
      "        [  4,   7,  58,  ...,  32,  38,  69],\n",
      "        [  4,   7,  30,  ...,  43,   3,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  63,   3],\n",
      "        [  4,   7,  58,  ...,   8,  35,  46],\n",
      "        [  4,   7,  58,  ...,  32,  62, 138],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   8,  44, 127],\n",
      "        [  4,   7,  30,  ...,   8,  29, 115],\n",
      "        [  4,   7,  30,  ...,  51,  23,  46]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  41,  31,   2],\n",
      "        [  4,   7,  58,  ...,  31, 118,   1],\n",
      "        [  4,   7,  58,  ...,  35,  89,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,  40,   3,   1],\n",
      "        [  4,   7,  30,  ...,  56, 118,   1],\n",
      "        [  4,   7,  58,  ...,  52,   3,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 48,  3],\n",
      "        [ 4,  7, 30,  ..., 15, 43, 45],\n",
      "        [ 4,  7, 30,  ..., 17, 39,  6],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  65,  43,   3],\n",
      "        [  4,   7,  30,  ...,  14,  47,  49],\n",
      "        [  4,   7, 186,  ...,  17,  54, 120],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 22, 35,  6],\n",
      "        [ 4,  7, 30,  ..., 14, 97,  3],\n",
      "        [ 4,  7, 30,  ..., 32, 27,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 24, 82, 84],\n",
      "        [ 4,  7, 58,  ...,  3,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 12, 63, 46],\n",
      "        [ 4,  7, 30,  ..., 75,  3,  1],\n",
      "        [ 4,  7, 30,  ..., 54,  2,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  2,  1,  1],\n",
      "        [ 4,  7, 30,  ..., 69,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  40, 153],\n",
      "        [  4,   7,  30,  ...,   8,  47, 119],\n",
      "        [  4,   7,  30,  ...,  12,  31,  46],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  53,  27, 116],\n",
      "        [  4,   7,  58,  ...,  14,  40, 116],\n",
      "        [  4,   7,  30,  ...,   8,  23,  89],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 35,  6],\n",
      "        [ 4,  7, 30,  ..., 22, 23, 90],\n",
      "        [ 4,  7, 30,  ...,  8, 55, 45],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,  13,  59,  ...,  17,  47, 171],\n",
      "        [  4,   7,  58,  ...,  10,  27, 116],\n",
      "        [  4,   7,  30,  ...,  22,  48,   3],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  16,  30, 102],\n",
      "        [  4,   7,  30,  ...,  10,  55,   2],\n",
      "        [  4,   7,  30,  ...,  53,  38,  84],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 17, 44, 45],\n",
      "        [ 4,  7, 58,  ..., 70, 61,  1],\n",
      "        [ 4,  7, 58,  ..., 52,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  22,  38,  72],\n",
      "        [  4,   7,  30,  ...,  40, 105,   1],\n",
      "        [  4,   7,  30,  ...,  43,  49,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  15,  39,  45],\n",
      "        [  4,   7,  30,  ...,  15,  39,  45],\n",
      "        [  4,   7,  30,  ...,   8,  62,   2],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,  68, 116,   1],\n",
      "        [  4,   7,  30,  ...,  29, 118,   1],\n",
      "        [  4,   7,  30,  ...,  35, 191,   1]], device='cuda:0')\n",
      "tensor([[  4,   7, 186,  ...,  32,  27, 119],\n",
      "        [  4,   7,  30,  ...,   8,  55, 153],\n",
      "        [  4,   7,  58,  ...,  54, 198,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,  11,  17,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 12, 52,  2],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for (labels, (notes, notes_len)), _ in (train_iter):\n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82eec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4d0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, 2)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.mean(dim=1)\n",
    "        output = self.decoder(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32976625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load Functions https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0\n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c88beb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Step [50/25000], Train Loss: 0.6645, Valid Loss: 0.6447\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.632446134347275\n",
      "Epoch [2/500], Step [100/25000], Train Loss: 0.6461, Valid Loss: 0.6469\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [3/500], Step [150/25000], Train Loss: 0.6401, Valid Loss: 0.6492\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [4/500], Step [200/25000], Train Loss: 0.6387, Valid Loss: 0.6448\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [5/500], Step [250/25000], Train Loss: 0.6352, Valid Loss: 0.6351\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [6/500], Step [300/25000], Train Loss: 0.6323, Valid Loss: 0.6208\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [7/500], Step [350/25000], Train Loss: 0.6296, Valid Loss: 0.6042\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [8/500], Step [400/25000], Train Loss: 0.6256, Valid Loss: 0.5916\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [9/500], Step [450/25000], Train Loss: 0.6209, Valid Loss: 0.5699\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.670468948035488\n",
      "Epoch [10/500], Step [500/25000], Train Loss: 0.6111, Valid Loss: 0.5485\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6717363751584284\n",
      "Epoch [11/500], Step [550/25000], Train Loss: 0.5993, Valid Loss: 0.5341\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6711026615969582\n",
      "Epoch [12/500], Step [600/25000], Train Loss: 0.5783, Valid Loss: 0.5340\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.7129277566539924\n",
      "Epoch [13/500], Step [650/25000], Train Loss: 0.5575, Valid Loss: 0.5372\n",
      "Epoch Accuracy: 0.7636248415716096\n",
      "Epoch [14/500], Step [700/25000], Train Loss: 0.5449, Valid Loss: 0.5246\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.811787072243346\n",
      "Epoch [15/500], Step [750/25000], Train Loss: 0.5334, Valid Loss: 0.5164\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8136882129277566\n",
      "Epoch [16/500], Step [800/25000], Train Loss: 0.5266, Valid Loss: 0.5183\n",
      "Epoch Accuracy: 0.8200253485424588\n",
      "Epoch [17/500], Step [850/25000], Train Loss: 0.5245, Valid Loss: 0.5077\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8003802281368821\n",
      "Epoch [18/500], Step [900/25000], Train Loss: 0.5197, Valid Loss: 0.5136\n",
      "Epoch Accuracy: 0.8067173637515843\n",
      "Epoch [19/500], Step [950/25000], Train Loss: 0.5162, Valid Loss: 0.5131\n",
      "Epoch Accuracy: 0.8193916349809885\n",
      "Epoch [20/500], Step [1000/25000], Train Loss: 0.5136, Valid Loss: 0.5093\n",
      "Epoch Accuracy: 0.8149556400506971\n",
      "Epoch [21/500], Step [1050/25000], Train Loss: 0.5106, Valid Loss: 0.5137\n",
      "Epoch Accuracy: 0.8086185044359949\n",
      "Epoch [22/500], Step [1100/25000], Train Loss: 0.5085, Valid Loss: 0.5077\n",
      "Epoch Accuracy: 0.8092522179974652\n",
      "Epoch [23/500], Step [1150/25000], Train Loss: 0.5085, Valid Loss: 0.5085\n",
      "Epoch Accuracy: 0.8060836501901141\n",
      "Epoch [24/500], Step [1200/25000], Train Loss: 0.5073, Valid Loss: 0.5100\n",
      "Epoch Accuracy: 0.8130544993662865\n",
      "Epoch [25/500], Step [1250/25000], Train Loss: 0.5048, Valid Loss: 0.5073\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8067173637515843\n",
      "Epoch [26/500], Step [1300/25000], Train Loss: 0.5018, Valid Loss: 0.5101\n",
      "Epoch Accuracy: 0.8181242078580482\n",
      "Epoch [27/500], Step [1350/25000], Train Loss: 0.5009, Valid Loss: 0.5049\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.820659062103929\n",
      "Epoch [28/500], Step [1400/25000], Train Loss: 0.4993, Valid Loss: 0.5088\n",
      "Epoch Accuracy: 0.8181242078580482\n",
      "Epoch [29/500], Step [1450/25000], Train Loss: 0.4972, Valid Loss: 0.4971\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8219264892268695\n",
      "Epoch [30/500], Step [1500/25000], Train Loss: 0.4960, Valid Loss: 0.4900\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8174904942965779\n",
      "Epoch [31/500], Step [1550/25000], Train Loss: 0.4937, Valid Loss: 0.4790\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8326996197718631\n",
      "Epoch [32/500], Step [1600/25000], Train Loss: 0.4971, Valid Loss: 0.4942\n",
      "Epoch Accuracy: 0.8212927756653993\n",
      "Epoch [33/500], Step [1650/25000], Train Loss: 0.4888, Valid Loss: 0.4765\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8250950570342205\n",
      "Epoch [34/500], Step [1700/25000], Train Loss: 0.4891, Valid Loss: 0.4773\n",
      "Epoch Accuracy: 0.8269961977186312\n",
      "Epoch [35/500], Step [1750/25000], Train Loss: 0.4858, Valid Loss: 0.4749\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8346007604562737\n",
      "Epoch [36/500], Step [1800/25000], Train Loss: 0.4814, Valid Loss: 0.4823\n",
      "Epoch Accuracy: 0.8396704689480355\n",
      "Epoch [37/500], Step [1850/25000], Train Loss: 0.4796, Valid Loss: 0.4720\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8339670468948035\n",
      "Epoch [38/500], Step [1900/25000], Train Loss: 0.4801, Valid Loss: 0.4861\n",
      "Epoch Accuracy: 0.8365019011406845\n",
      "Epoch [39/500], Step [1950/25000], Train Loss: 0.4763, Valid Loss: 0.4810\n",
      "Epoch Accuracy: 0.8428390367553865\n",
      "Epoch [40/500], Step [2000/25000], Train Loss: 0.4752, Valid Loss: 0.4823\n",
      "Epoch Accuracy: 0.8422053231939164\n",
      "Epoch [41/500], Step [2050/25000], Train Loss: 0.4719, Valid Loss: 0.4666\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8536121673003803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/500], Step [2100/25000], Train Loss: 0.4716, Valid Loss: 0.4791\n",
      "Epoch Accuracy: 0.8479087452471483\n",
      "Epoch [43/500], Step [2150/25000], Train Loss: 0.4674, Valid Loss: 0.4663\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8466413181242078\n",
      "Epoch [44/500], Step [2200/25000], Train Loss: 0.4696, Valid Loss: 0.4720\n",
      "Epoch Accuracy: 0.8447401774397972\n",
      "Epoch [45/500], Step [2250/25000], Train Loss: 0.4667, Valid Loss: 0.4692\n",
      "Epoch Accuracy: 0.8567807351077313\n",
      "Epoch [46/500], Step [2300/25000], Train Loss: 0.4655, Valid Loss: 0.4624\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.85297845373891\n",
      "Epoch [47/500], Step [2350/25000], Train Loss: 0.4656, Valid Loss: 0.4678\n",
      "Epoch Accuracy: 0.8479087452471483\n",
      "Epoch [48/500], Step [2400/25000], Train Loss: 0.4610, Valid Loss: 0.4619\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.861850443599493\n",
      "Epoch [49/500], Step [2450/25000], Train Loss: 0.4635, Valid Loss: 0.4683\n",
      "Epoch Accuracy: 0.858681875792142\n",
      "Epoch [50/500], Step [2500/25000], Train Loss: 0.4601, Valid Loss: 0.4640\n",
      "Epoch Accuracy: 0.8542458808618505\n",
      "Epoch [51/500], Step [2550/25000], Train Loss: 0.4565, Valid Loss: 0.4672\n",
      "Epoch Accuracy: 0.861850443599493\n",
      "Epoch [52/500], Step [2600/25000], Train Loss: 0.4572, Valid Loss: 0.4663\n",
      "Epoch Accuracy: 0.861850443599493\n",
      "Epoch [53/500], Step [2650/25000], Train Loss: 0.4526, Valid Loss: 0.4766\n",
      "Epoch Accuracy: 0.861850443599493\n",
      "Epoch [54/500], Step [2700/25000], Train Loss: 0.4545, Valid Loss: 0.4626\n",
      "Epoch Accuracy: 0.8656527249683144\n",
      "Epoch [55/500], Step [2750/25000], Train Loss: 0.4520, Valid Loss: 0.4594\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8713561470215463\n",
      "Epoch [56/500], Step [2800/25000], Train Loss: 0.4509, Valid Loss: 0.4601\n",
      "Epoch Accuracy: 0.8681875792141952\n",
      "Epoch [57/500], Step [2850/25000], Train Loss: 0.4523, Valid Loss: 0.4594\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.870722433460076\n",
      "Epoch [58/500], Step [2900/25000], Train Loss: 0.4495, Valid Loss: 0.4671\n",
      "Epoch Accuracy: 0.867553865652725\n",
      "Epoch [59/500], Step [2950/25000], Train Loss: 0.4486, Valid Loss: 0.4553\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8694550063371356\n",
      "Epoch [60/500], Step [3000/25000], Train Loss: 0.4433, Valid Loss: 0.4502\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8814955640050697\n",
      "Epoch [61/500], Step [3050/25000], Train Loss: 0.4465, Valid Loss: 0.4591\n",
      "Epoch Accuracy: 0.8745247148288974\n",
      "Epoch [62/500], Step [3100/25000], Train Loss: 0.4410, Valid Loss: 0.4605\n",
      "Epoch Accuracy: 0.8795944233206591\n",
      "Epoch [63/500], Step [3150/25000], Train Loss: 0.4436, Valid Loss: 0.4419\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8738910012674271\n",
      "Epoch [64/500], Step [3200/25000], Train Loss: 0.4419, Valid Loss: 0.4550\n",
      "Epoch Accuracy: 0.8783269961977186\n",
      "Epoch [65/500], Step [3250/25000], Train Loss: 0.4398, Valid Loss: 0.4819\n",
      "Epoch Accuracy: 0.876425855513308\n",
      "Epoch [66/500], Step [3300/25000], Train Loss: 0.4385, Valid Loss: 0.4545\n",
      "Epoch Accuracy: 0.8840304182509505\n",
      "Epoch [67/500], Step [3350/25000], Train Loss: 0.4365, Valid Loss: 0.4509\n",
      "Epoch Accuracy: 0.8859315589353612\n",
      "Epoch [68/500], Step [3400/25000], Train Loss: 0.4336, Valid Loss: 0.4449\n",
      "Epoch Accuracy: 0.8891001267427123\n",
      "Epoch [69/500], Step [3450/25000], Train Loss: 0.4367, Valid Loss: 0.4419\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8878326996197718\n",
      "Epoch [70/500], Step [3500/25000], Train Loss: 0.4338, Valid Loss: 0.4492\n",
      "Epoch Accuracy: 0.8840304182509505\n",
      "Epoch [71/500], Step [3550/25000], Train Loss: 0.4289, Valid Loss: 0.4444\n",
      "Epoch Accuracy: 0.8884664131812421\n",
      "Epoch [72/500], Step [3600/25000], Train Loss: 0.4289, Valid Loss: 0.4418\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8986058301647655\n",
      "Epoch [73/500], Step [3650/25000], Train Loss: 0.4276, Valid Loss: 0.4441\n",
      "Epoch Accuracy: 0.9005069708491762\n",
      "Epoch [74/500], Step [3700/25000], Train Loss: 0.4268, Valid Loss: 0.4555\n",
      "Epoch Accuracy: 0.8884664131812421\n",
      "Epoch [75/500], Step [3750/25000], Train Loss: 0.4263, Valid Loss: 0.4386\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8916349809885932\n",
      "Epoch [76/500], Step [3800/25000], Train Loss: 0.4267, Valid Loss: 0.4467\n",
      "Epoch Accuracy: 0.8922686945500634\n",
      "Epoch [77/500], Step [3850/25000], Train Loss: 0.4231, Valid Loss: 0.4300\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.903041825095057\n",
      "Epoch [78/500], Step [3900/25000], Train Loss: 0.4243, Valid Loss: 0.4362\n",
      "Epoch Accuracy: 0.8948035487959443\n",
      "Epoch [79/500], Step [3950/25000], Train Loss: 0.4234, Valid Loss: 0.4349\n",
      "Epoch Accuracy: 0.9017743979721166\n",
      "Epoch [80/500], Step [4000/25000], Train Loss: 0.4240, Valid Loss: 0.4357\n",
      "Epoch Accuracy: 0.8979721166032953\n",
      "Epoch [81/500], Step [4050/25000], Train Loss: 0.4246, Valid Loss: 0.4381\n",
      "Epoch Accuracy: 0.8960709759188846\n",
      "Epoch [82/500], Step [4100/25000], Train Loss: 0.4216, Valid Loss: 0.4275\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.903041825095057\n",
      "Epoch [83/500], Step [4150/25000], Train Loss: 0.4211, Valid Loss: 0.4505\n",
      "Epoch Accuracy: 0.899873257287706\n",
      "Epoch [84/500], Step [4200/25000], Train Loss: 0.4203, Valid Loss: 0.4360\n",
      "Epoch Accuracy: 0.9017743979721166\n",
      "Epoch [85/500], Step [4250/25000], Train Loss: 0.4172, Valid Loss: 0.4380\n",
      "Epoch Accuracy: 0.9100126742712294\n",
      "Epoch [86/500], Step [4300/25000], Train Loss: 0.4212, Valid Loss: 0.4449\n",
      "Epoch Accuracy: 0.8992395437262357\n",
      "Epoch [87/500], Step [4350/25000], Train Loss: 0.4158, Valid Loss: 0.4397\n",
      "Epoch Accuracy: 0.9036755386565273\n",
      "Epoch [88/500], Step [4400/25000], Train Loss: 0.4167, Valid Loss: 0.4358\n",
      "Epoch Accuracy: 0.9055766793409379\n",
      "Epoch [89/500], Step [4450/25000], Train Loss: 0.4177, Valid Loss: 0.4398\n",
      "Epoch Accuracy: 0.9036755386565273\n",
      "Epoch [90/500], Step [4500/25000], Train Loss: 0.4145, Valid Loss: 0.4444\n",
      "Epoch Accuracy: 0.9074778200253485\n",
      "Epoch [91/500], Step [4550/25000], Train Loss: 0.4121, Valid Loss: 0.4296\n",
      "Epoch Accuracy: 0.9119138149556401\n",
      "Epoch [92/500], Step [4600/25000], Train Loss: 0.4170, Valid Loss: 0.4365\n",
      "Epoch Accuracy: 0.9011406844106464\n",
      "Epoch [93/500], Step [4650/25000], Train Loss: 0.4110, Valid Loss: 0.4316\n",
      "Epoch Accuracy: 0.9112801013941698\n",
      "Epoch [94/500], Step [4700/25000], Train Loss: 0.4128, Valid Loss: 0.4335\n",
      "Epoch Accuracy: 0.908745247148289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/500], Step [4750/25000], Train Loss: 0.4101, Valid Loss: 0.4323\n",
      "Epoch Accuracy: 0.9125475285171103\n",
      "Epoch [96/500], Step [4800/25000], Train Loss: 0.4167, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.9043092522179975\n",
      "Epoch [97/500], Step [4850/25000], Train Loss: 0.4109, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.9119138149556401\n",
      "Epoch [98/500], Step [4900/25000], Train Loss: 0.4137, Valid Loss: 0.4284\n",
      "Epoch Accuracy: 0.9049429657794676\n",
      "Epoch [99/500], Step [4950/25000], Train Loss: 0.4125, Valid Loss: 0.4284\n",
      "Epoch Accuracy: 0.9055766793409379\n",
      "Epoch [100/500], Step [5000/25000], Train Loss: 0.4100, Valid Loss: 0.4323\n",
      "Epoch Accuracy: 0.9112801013941698\n",
      "Epoch [101/500], Step [5050/25000], Train Loss: 0.4084, Valid Loss: 0.4356\n",
      "Epoch Accuracy: 0.9106463878326996\n",
      "Epoch [102/500], Step [5100/25000], Train Loss: 0.4109, Valid Loss: 0.4320\n",
      "Epoch Accuracy: 0.9068441064638784\n",
      "Epoch [103/500], Step [5150/25000], Train Loss: 0.4073, Valid Loss: 0.4325\n",
      "Epoch Accuracy: 0.9131812420785805\n",
      "Epoch [104/500], Step [5200/25000], Train Loss: 0.4095, Valid Loss: 0.4373\n",
      "Epoch Accuracy: 0.9074778200253485\n",
      "Epoch [105/500], Step [5250/25000], Train Loss: 0.4084, Valid Loss: 0.4347\n",
      "Epoch Accuracy: 0.9112801013941698\n",
      "Epoch [106/500], Step [5300/25000], Train Loss: 0.4047, Valid Loss: 0.4285\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [107/500], Step [5350/25000], Train Loss: 0.4066, Valid Loss: 0.4307\n",
      "Epoch Accuracy: 0.908745247148289\n",
      "Epoch [108/500], Step [5400/25000], Train Loss: 0.4047, Valid Loss: 0.4415\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [109/500], Step [5450/25000], Train Loss: 0.4039, Valid Loss: 0.4197\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [110/500], Step [5500/25000], Train Loss: 0.4036, Valid Loss: 0.4219\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [111/500], Step [5550/25000], Train Loss: 0.4052, Valid Loss: 0.4221\n",
      "Epoch Accuracy: 0.9157160963244614\n",
      "Epoch [112/500], Step [5600/25000], Train Loss: 0.4053, Valid Loss: 0.4192\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9157160963244614\n",
      "Epoch [113/500], Step [5650/25000], Train Loss: 0.4033, Valid Loss: 0.4314\n",
      "Epoch Accuracy: 0.9144486692015209\n",
      "Epoch [114/500], Step [5700/25000], Train Loss: 0.4041, Valid Loss: 0.4201\n",
      "Epoch Accuracy: 0.9150823827629911\n",
      "Epoch [115/500], Step [5750/25000], Train Loss: 0.4040, Valid Loss: 0.4233\n",
      "Epoch Accuracy: 0.9150823827629911\n",
      "Epoch [116/500], Step [5800/25000], Train Loss: 0.4011, Valid Loss: 0.4200\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [117/500], Step [5850/25000], Train Loss: 0.4048, Valid Loss: 0.4175\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9125475285171103\n",
      "Epoch [118/500], Step [5900/25000], Train Loss: 0.4013, Valid Loss: 0.4189\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [119/500], Step [5950/25000], Train Loss: 0.4027, Valid Loss: 0.4227\n",
      "Epoch Accuracy: 0.9144486692015209\n",
      "Epoch [120/500], Step [6000/25000], Train Loss: 0.4021, Valid Loss: 0.4297\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [121/500], Step [6050/25000], Train Loss: 0.4005, Valid Loss: 0.4138\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [122/500], Step [6100/25000], Train Loss: 0.4024, Valid Loss: 0.4172\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [123/500], Step [6150/25000], Train Loss: 0.4027, Valid Loss: 0.4139\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [124/500], Step [6200/25000], Train Loss: 0.3997, Valid Loss: 0.4197\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [125/500], Step [6250/25000], Train Loss: 0.4023, Valid Loss: 0.4245\n",
      "Epoch Accuracy: 0.9150823827629911\n",
      "Epoch [126/500], Step [6300/25000], Train Loss: 0.4015, Valid Loss: 0.4219\n",
      "Epoch Accuracy: 0.9195183776932826\n",
      "Epoch [127/500], Step [6350/25000], Train Loss: 0.4011, Valid Loss: 0.4179\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [128/500], Step [6400/25000], Train Loss: 0.3969, Valid Loss: 0.4212\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [129/500], Step [6450/25000], Train Loss: 0.3995, Valid Loss: 0.4274\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [130/500], Step [6500/25000], Train Loss: 0.4001, Valid Loss: 0.4281\n",
      "Epoch Accuracy: 0.9195183776932826\n",
      "Epoch [131/500], Step [6550/25000], Train Loss: 0.4008, Valid Loss: 0.4220\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [132/500], Step [6600/25000], Train Loss: 0.3978, Valid Loss: 0.4228\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [133/500], Step [6650/25000], Train Loss: 0.4012, Valid Loss: 0.4216\n",
      "Epoch Accuracy: 0.9157160963244614\n",
      "Epoch [134/500], Step [6700/25000], Train Loss: 0.3973, Valid Loss: 0.4205\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [135/500], Step [6750/25000], Train Loss: 0.3992, Valid Loss: 0.4222\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [136/500], Step [6800/25000], Train Loss: 0.4006, Valid Loss: 0.4165\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [137/500], Step [6850/25000], Train Loss: 0.3943, Valid Loss: 0.4237\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [138/500], Step [6900/25000], Train Loss: 0.3957, Valid Loss: 0.4162\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [139/500], Step [6950/25000], Train Loss: 0.3985, Valid Loss: 0.4221\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [140/500], Step [7000/25000], Train Loss: 0.3960, Valid Loss: 0.4312\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [141/500], Step [7050/25000], Train Loss: 0.3970, Valid Loss: 0.4189\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [142/500], Step [7100/25000], Train Loss: 0.3941, Valid Loss: 0.4297\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [143/500], Step [7150/25000], Train Loss: 0.3954, Valid Loss: 0.4165\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [144/500], Step [7200/25000], Train Loss: 0.3938, Valid Loss: 0.4329\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [145/500], Step [7250/25000], Train Loss: 0.3977, Valid Loss: 0.4196\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [146/500], Step [7300/25000], Train Loss: 0.3983, Valid Loss: 0.4376\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [147/500], Step [7350/25000], Train Loss: 0.3943, Valid Loss: 0.4151\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [148/500], Step [7400/25000], Train Loss: 0.3930, Valid Loss: 0.4185\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [149/500], Step [7450/25000], Train Loss: 0.3943, Valid Loss: 0.4150\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [150/500], Step [7500/25000], Train Loss: 0.3964, Valid Loss: 0.4190\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [151/500], Step [7550/25000], Train Loss: 0.3932, Valid Loss: 0.4237\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [152/500], Step [7600/25000], Train Loss: 0.3946, Valid Loss: 0.4292\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [153/500], Step [7650/25000], Train Loss: 0.3956, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [154/500], Step [7700/25000], Train Loss: 0.3924, Valid Loss: 0.4289\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [155/500], Step [7750/25000], Train Loss: 0.3975, Valid Loss: 0.4188\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [156/500], Step [7800/25000], Train Loss: 0.3936, Valid Loss: 0.4243\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [157/500], Step [7850/25000], Train Loss: 0.3914, Valid Loss: 0.4191\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [158/500], Step [7900/25000], Train Loss: 0.3928, Valid Loss: 0.4222\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [159/500], Step [7950/25000], Train Loss: 0.3960, Valid Loss: 0.4243\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [160/500], Step [8000/25000], Train Loss: 0.3923, Valid Loss: 0.4347\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [161/500], Step [8050/25000], Train Loss: 0.3929, Valid Loss: 0.4358\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [162/500], Step [8100/25000], Train Loss: 0.3932, Valid Loss: 0.4183\n",
      "Epoch Accuracy: 0.9258555133079848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [163/500], Step [8150/25000], Train Loss: 0.3925, Valid Loss: 0.4249\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [164/500], Step [8200/25000], Train Loss: 0.3932, Valid Loss: 0.4303\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [165/500], Step [8250/25000], Train Loss: 0.3925, Valid Loss: 0.4211\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [166/500], Step [8300/25000], Train Loss: 0.3925, Valid Loss: 0.4184\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [167/500], Step [8350/25000], Train Loss: 0.3943, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [168/500], Step [8400/25000], Train Loss: 0.3926, Valid Loss: 0.4268\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [169/500], Step [8450/25000], Train Loss: 0.3916, Valid Loss: 0.4312\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [170/500], Step [8500/25000], Train Loss: 0.3927, Valid Loss: 0.4250\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [171/500], Step [8550/25000], Train Loss: 0.3905, Valid Loss: 0.4243\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [172/500], Step [8600/25000], Train Loss: 0.3900, Valid Loss: 0.4386\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [173/500], Step [8650/25000], Train Loss: 0.3942, Valid Loss: 0.4238\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [174/500], Step [8700/25000], Train Loss: 0.3930, Valid Loss: 0.4198\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [175/500], Step [8750/25000], Train Loss: 0.3898, Valid Loss: 0.4224\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [176/500], Step [8800/25000], Train Loss: 0.3926, Valid Loss: 0.4176\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [177/500], Step [8850/25000], Train Loss: 0.3884, Valid Loss: 0.4141\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [178/500], Step [8900/25000], Train Loss: 0.3916, Valid Loss: 0.4233\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [179/500], Step [8950/25000], Train Loss: 0.3925, Valid Loss: 0.4289\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [180/500], Step [9000/25000], Train Loss: 0.3900, Valid Loss: 0.4257\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [181/500], Step [9050/25000], Train Loss: 0.3879, Valid Loss: 0.4269\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [182/500], Step [9100/25000], Train Loss: 0.3887, Valid Loss: 0.4300\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [183/500], Step [9150/25000], Train Loss: 0.3930, Valid Loss: 0.4272\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [184/500], Step [9200/25000], Train Loss: 0.3902, Valid Loss: 0.4188\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [185/500], Step [9250/25000], Train Loss: 0.3930, Valid Loss: 0.4396\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [186/500], Step [9300/25000], Train Loss: 0.3912, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [187/500], Step [9350/25000], Train Loss: 0.3896, Valid Loss: 0.4236\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [188/500], Step [9400/25000], Train Loss: 0.3921, Valid Loss: 0.4232\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [189/500], Step [9450/25000], Train Loss: 0.3880, Valid Loss: 0.4265\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [190/500], Step [9500/25000], Train Loss: 0.3876, Valid Loss: 0.4283\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [191/500], Step [9550/25000], Train Loss: 0.3890, Valid Loss: 0.4165\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [192/500], Step [9600/25000], Train Loss: 0.3890, Valid Loss: 0.4228\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [193/500], Step [9650/25000], Train Loss: 0.3871, Valid Loss: 0.4217\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [194/500], Step [9700/25000], Train Loss: 0.3901, Valid Loss: 0.4247\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [195/500], Step [9750/25000], Train Loss: 0.3887, Valid Loss: 0.4150\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [196/500], Step [9800/25000], Train Loss: 0.3884, Valid Loss: 0.4430\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [197/500], Step [9850/25000], Train Loss: 0.3882, Valid Loss: 0.4202\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [198/500], Step [9900/25000], Train Loss: 0.3884, Valid Loss: 0.4155\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [199/500], Step [9950/25000], Train Loss: 0.3906, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [200/500], Step [10000/25000], Train Loss: 0.3884, Valid Loss: 0.4216\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [201/500], Step [10050/25000], Train Loss: 0.3840, Valid Loss: 0.4233\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [202/500], Step [10100/25000], Train Loss: 0.3886, Valid Loss: 0.4184\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [203/500], Step [10150/25000], Train Loss: 0.3859, Valid Loss: 0.4339\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [204/500], Step [10200/25000], Train Loss: 0.3870, Valid Loss: 0.4294\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [205/500], Step [10250/25000], Train Loss: 0.3887, Valid Loss: 0.4131\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [206/500], Step [10300/25000], Train Loss: 0.3873, Valid Loss: 0.4209\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [207/500], Step [10350/25000], Train Loss: 0.3868, Valid Loss: 0.4127\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [208/500], Step [10400/25000], Train Loss: 0.3865, Valid Loss: 0.4165\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [209/500], Step [10450/25000], Train Loss: 0.3848, Valid Loss: 0.4178\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [210/500], Step [10500/25000], Train Loss: 0.3859, Valid Loss: 0.4261\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [211/500], Step [10550/25000], Train Loss: 0.3850, Valid Loss: 0.4220\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [212/500], Step [10600/25000], Train Loss: 0.3862, Valid Loss: 0.4272\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [213/500], Step [10650/25000], Train Loss: 0.3864, Valid Loss: 0.4308\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [214/500], Step [10700/25000], Train Loss: 0.3842, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [215/500], Step [10750/25000], Train Loss: 0.3853, Valid Loss: 0.4225\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [216/500], Step [10800/25000], Train Loss: 0.3840, Valid Loss: 0.4352\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [217/500], Step [10850/25000], Train Loss: 0.3864, Valid Loss: 0.4273\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [218/500], Step [10900/25000], Train Loss: 0.3884, Valid Loss: 0.4296\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [219/500], Step [10950/25000], Train Loss: 0.3862, Valid Loss: 0.4298\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [220/500], Step [11000/25000], Train Loss: 0.3881, Valid Loss: 0.4260\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [221/500], Step [11050/25000], Train Loss: 0.3881, Valid Loss: 0.4208\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [222/500], Step [11100/25000], Train Loss: 0.3855, Valid Loss: 0.4213\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [223/500], Step [11150/25000], Train Loss: 0.3850, Valid Loss: 0.4239\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [224/500], Step [11200/25000], Train Loss: 0.3830, Valid Loss: 0.4307\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [225/500], Step [11250/25000], Train Loss: 0.3853, Valid Loss: 0.4270\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [226/500], Step [11300/25000], Train Loss: 0.3865, Valid Loss: 0.4246\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [227/500], Step [11350/25000], Train Loss: 0.3817, Valid Loss: 0.4354\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [228/500], Step [11400/25000], Train Loss: 0.3867, Valid Loss: 0.4265\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [229/500], Step [11450/25000], Train Loss: 0.3837, Valid Loss: 0.4299\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [230/500], Step [11500/25000], Train Loss: 0.3866, Valid Loss: 0.4352\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [231/500], Step [11550/25000], Train Loss: 0.3851, Valid Loss: 0.4270\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [232/500], Step [11600/25000], Train Loss: 0.3861, Valid Loss: 0.4308\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [233/500], Step [11650/25000], Train Loss: 0.3799, Valid Loss: 0.4256\n",
      "Epoch Accuracy: 0.9397972116603295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [234/500], Step [11700/25000], Train Loss: 0.3848, Valid Loss: 0.4379\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [235/500], Step [11750/25000], Train Loss: 0.3850, Valid Loss: 0.4566\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [236/500], Step [11800/25000], Train Loss: 0.3873, Valid Loss: 0.4231\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [237/500], Step [11850/25000], Train Loss: 0.3830, Valid Loss: 0.4263\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [238/500], Step [11900/25000], Train Loss: 0.3855, Valid Loss: 0.4264\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [239/500], Step [11950/25000], Train Loss: 0.3810, Valid Loss: 0.4295\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [240/500], Step [12000/25000], Train Loss: 0.3846, Valid Loss: 0.4267\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [241/500], Step [12050/25000], Train Loss: 0.3853, Valid Loss: 0.4308\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [242/500], Step [12100/25000], Train Loss: 0.3852, Valid Loss: 0.4332\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [243/500], Step [12150/25000], Train Loss: 0.3854, Valid Loss: 0.4255\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [244/500], Step [12200/25000], Train Loss: 0.3826, Valid Loss: 0.4140\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [245/500], Step [12250/25000], Train Loss: 0.3852, Valid Loss: 0.4161\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [246/500], Step [12300/25000], Train Loss: 0.3822, Valid Loss: 0.4266\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [247/500], Step [12350/25000], Train Loss: 0.3851, Valid Loss: 0.4195\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [248/500], Step [12400/25000], Train Loss: 0.3836, Valid Loss: 0.4360\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [249/500], Step [12450/25000], Train Loss: 0.3821, Valid Loss: 0.4163\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [250/500], Step [12500/25000], Train Loss: 0.3829, Valid Loss: 0.4191\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [251/500], Step [12550/25000], Train Loss: 0.3848, Valid Loss: 0.4137\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [252/500], Step [12600/25000], Train Loss: 0.3836, Valid Loss: 0.4200\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [253/500], Step [12650/25000], Train Loss: 0.3833, Valid Loss: 0.4150\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [254/500], Step [12700/25000], Train Loss: 0.3831, Valid Loss: 0.4093\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [255/500], Step [12750/25000], Train Loss: 0.3817, Valid Loss: 0.4185\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [256/500], Step [12800/25000], Train Loss: 0.3824, Valid Loss: 0.4251\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [257/500], Step [12850/25000], Train Loss: 0.3805, Valid Loss: 0.4205\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [258/500], Step [12900/25000], Train Loss: 0.3855, Valid Loss: 0.4133\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [259/500], Step [12950/25000], Train Loss: 0.3819, Valid Loss: 0.4274\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [260/500], Step [13000/25000], Train Loss: 0.3814, Valid Loss: 0.4149\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [261/500], Step [13050/25000], Train Loss: 0.3824, Valid Loss: 0.4181\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [262/500], Step [13100/25000], Train Loss: 0.3801, Valid Loss: 0.4304\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [263/500], Step [13150/25000], Train Loss: 0.3794, Valid Loss: 0.4405\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [264/500], Step [13200/25000], Train Loss: 0.3814, Valid Loss: 0.4190\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [265/500], Step [13250/25000], Train Loss: 0.3854, Valid Loss: 0.4171\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [266/500], Step [13300/25000], Train Loss: 0.3813, Valid Loss: 0.4214\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [267/500], Step [13350/25000], Train Loss: 0.3835, Valid Loss: 0.4391\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [268/500], Step [13400/25000], Train Loss: 0.3792, Valid Loss: 0.4265\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [269/500], Step [13450/25000], Train Loss: 0.3810, Valid Loss: 0.4191\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [270/500], Step [13500/25000], Train Loss: 0.3833, Valid Loss: 0.4245\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [271/500], Step [13550/25000], Train Loss: 0.3825, Valid Loss: 0.4475\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [272/500], Step [13600/25000], Train Loss: 0.3796, Valid Loss: 0.4164\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [273/500], Step [13650/25000], Train Loss: 0.3836, Valid Loss: 0.4441\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [274/500], Step [13700/25000], Train Loss: 0.3852, Valid Loss: 0.4143\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [275/500], Step [13750/25000], Train Loss: 0.3826, Valid Loss: 0.4250\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [276/500], Step [13800/25000], Train Loss: 0.3838, Valid Loss: 0.4270\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [277/500], Step [13850/25000], Train Loss: 0.3809, Valid Loss: 0.4486\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [278/500], Step [13900/25000], Train Loss: 0.3834, Valid Loss: 0.4419\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [279/500], Step [13950/25000], Train Loss: 0.3819, Valid Loss: 0.4347\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [280/500], Step [14000/25000], Train Loss: 0.3861, Valid Loss: 0.4573\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [281/500], Step [14050/25000], Train Loss: 0.3795, Valid Loss: 0.4330\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [282/500], Step [14100/25000], Train Loss: 0.3821, Valid Loss: 0.4302\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [283/500], Step [14150/25000], Train Loss: 0.3799, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [284/500], Step [14200/25000], Train Loss: 0.3766, Valid Loss: 0.4317\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [285/500], Step [14250/25000], Train Loss: 0.3800, Valid Loss: 0.4207\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [286/500], Step [14300/25000], Train Loss: 0.3847, Valid Loss: 0.4436\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [287/500], Step [14350/25000], Train Loss: 0.3782, Valid Loss: 0.4337\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [288/500], Step [14400/25000], Train Loss: 0.3801, Valid Loss: 0.4167\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [289/500], Step [14450/25000], Train Loss: 0.3799, Valid Loss: 0.4251\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [290/500], Step [14500/25000], Train Loss: 0.3801, Valid Loss: 0.4229\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [291/500], Step [14550/25000], Train Loss: 0.3801, Valid Loss: 0.4217\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [292/500], Step [14600/25000], Train Loss: 0.3800, Valid Loss: 0.4509\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [293/500], Step [14650/25000], Train Loss: 0.3813, Valid Loss: 0.4333\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [294/500], Step [14700/25000], Train Loss: 0.3814, Valid Loss: 0.4388\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [295/500], Step [14750/25000], Train Loss: 0.3773, Valid Loss: 0.4319\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [296/500], Step [14800/25000], Train Loss: 0.3800, Valid Loss: 0.4188\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [297/500], Step [14850/25000], Train Loss: 0.3828, Valid Loss: 0.4172\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [298/500], Step [14900/25000], Train Loss: 0.3816, Valid Loss: 0.4159\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [299/500], Step [14950/25000], Train Loss: 0.3774, Valid Loss: 0.4271\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [300/500], Step [15000/25000], Train Loss: 0.3816, Valid Loss: 0.4324\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [301/500], Step [15050/25000], Train Loss: 0.3779, Valid Loss: 0.4308\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [302/500], Step [15100/25000], Train Loss: 0.3797, Valid Loss: 0.4204\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [303/500], Step [15150/25000], Train Loss: 0.3815, Valid Loss: 0.4183\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [304/500], Step [15200/25000], Train Loss: 0.3812, Valid Loss: 0.4272\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [305/500], Step [15250/25000], Train Loss: 0.3804, Valid Loss: 0.4195\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [306/500], Step [15300/25000], Train Loss: 0.3802, Valid Loss: 0.4357\n",
      "Epoch Accuracy: 0.9328263624841572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [307/500], Step [15350/25000], Train Loss: 0.3764, Valid Loss: 0.4218\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [308/500], Step [15400/25000], Train Loss: 0.3806, Valid Loss: 0.4244\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [309/500], Step [15450/25000], Train Loss: 0.3809, Valid Loss: 0.4305\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [310/500], Step [15500/25000], Train Loss: 0.3790, Valid Loss: 0.4189\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [311/500], Step [15550/25000], Train Loss: 0.3763, Valid Loss: 0.4219\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [312/500], Step [15600/25000], Train Loss: 0.3794, Valid Loss: 0.4230\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [313/500], Step [15650/25000], Train Loss: 0.3806, Valid Loss: 0.4362\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [314/500], Step [15700/25000], Train Loss: 0.3782, Valid Loss: 0.4366\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [315/500], Step [15750/25000], Train Loss: 0.3791, Valid Loss: 0.4402\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [316/500], Step [15800/25000], Train Loss: 0.3789, Valid Loss: 0.4242\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [317/500], Step [15850/25000], Train Loss: 0.3785, Valid Loss: 0.4156\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [318/500], Step [15900/25000], Train Loss: 0.3793, Valid Loss: 0.4211\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [319/500], Step [15950/25000], Train Loss: 0.3781, Valid Loss: 0.4238\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [320/500], Step [16000/25000], Train Loss: 0.3790, Valid Loss: 0.4142\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [321/500], Step [16050/25000], Train Loss: 0.3754, Valid Loss: 0.4175\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [322/500], Step [16100/25000], Train Loss: 0.3769, Valid Loss: 0.4182\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [323/500], Step [16150/25000], Train Loss: 0.3827, Valid Loss: 0.4253\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [324/500], Step [16200/25000], Train Loss: 0.3769, Valid Loss: 0.4333\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [325/500], Step [16250/25000], Train Loss: 0.3781, Valid Loss: 0.4145\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [326/500], Step [16300/25000], Train Loss: 0.3792, Valid Loss: 0.4454\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [327/500], Step [16350/25000], Train Loss: 0.3790, Valid Loss: 0.4215\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [328/500], Step [16400/25000], Train Loss: 0.3773, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [329/500], Step [16450/25000], Train Loss: 0.3768, Valid Loss: 0.4401\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [330/500], Step [16500/25000], Train Loss: 0.3769, Valid Loss: 0.4310\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [331/500], Step [16550/25000], Train Loss: 0.3779, Valid Loss: 0.4187\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [332/500], Step [16600/25000], Train Loss: 0.3784, Valid Loss: 0.4242\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [333/500], Step [16650/25000], Train Loss: 0.3788, Valid Loss: 0.4172\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [334/500], Step [16700/25000], Train Loss: 0.3796, Valid Loss: 0.4405\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [335/500], Step [16750/25000], Train Loss: 0.3797, Valid Loss: 0.4465\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [336/500], Step [16800/25000], Train Loss: 0.3777, Valid Loss: 0.4147\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [337/500], Step [16850/25000], Train Loss: 0.3805, Valid Loss: 0.4180\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [338/500], Step [16900/25000], Train Loss: 0.3765, Valid Loss: 0.4286\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [339/500], Step [16950/25000], Train Loss: 0.3767, Valid Loss: 0.4195\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [340/500], Step [17000/25000], Train Loss: 0.3794, Valid Loss: 0.4269\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [341/500], Step [17050/25000], Train Loss: 0.3766, Valid Loss: 0.4219\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [342/500], Step [17100/25000], Train Loss: 0.3794, Valid Loss: 0.4221\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [343/500], Step [17150/25000], Train Loss: 0.3752, Valid Loss: 0.4339\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [344/500], Step [17200/25000], Train Loss: 0.3778, Valid Loss: 0.4270\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [345/500], Step [17250/25000], Train Loss: 0.3798, Valid Loss: 0.4328\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [346/500], Step [17300/25000], Train Loss: 0.3786, Valid Loss: 0.4240\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [347/500], Step [17350/25000], Train Loss: 0.3757, Valid Loss: 0.4268\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [348/500], Step [17400/25000], Train Loss: 0.3778, Valid Loss: 0.4258\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [349/500], Step [17450/25000], Train Loss: 0.3741, Valid Loss: 0.4138\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [350/500], Step [17500/25000], Train Loss: 0.3801, Valid Loss: 0.4374\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [351/500], Step [17550/25000], Train Loss: 0.3771, Valid Loss: 0.4292\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [352/500], Step [17600/25000], Train Loss: 0.3760, Valid Loss: 0.4302\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [353/500], Step [17650/25000], Train Loss: 0.3745, Valid Loss: 0.4297\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [354/500], Step [17700/25000], Train Loss: 0.3806, Valid Loss: 0.4420\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [355/500], Step [17750/25000], Train Loss: 0.3764, Valid Loss: 0.4413\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [356/500], Step [17800/25000], Train Loss: 0.3788, Valid Loss: 0.4197\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [357/500], Step [17850/25000], Train Loss: 0.3753, Valid Loss: 0.4274\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [358/500], Step [17900/25000], Train Loss: 0.3748, Valid Loss: 0.4171\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [359/500], Step [17950/25000], Train Loss: 0.3751, Valid Loss: 0.4246\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [360/500], Step [18000/25000], Train Loss: 0.3789, Valid Loss: 0.4247\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [361/500], Step [18050/25000], Train Loss: 0.3749, Valid Loss: 0.4189\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [362/500], Step [18100/25000], Train Loss: 0.3783, Valid Loss: 0.4266\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [363/500], Step [18150/25000], Train Loss: 0.3793, Valid Loss: 0.4255\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [364/500], Step [18200/25000], Train Loss: 0.3781, Valid Loss: 0.4228\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [365/500], Step [18250/25000], Train Loss: 0.3755, Valid Loss: 0.4201\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [366/500], Step [18300/25000], Train Loss: 0.3749, Valid Loss: 0.4298\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [367/500], Step [18350/25000], Train Loss: 0.3750, Valid Loss: 0.4331\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [368/500], Step [18400/25000], Train Loss: 0.3747, Valid Loss: 0.4330\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [369/500], Step [18450/25000], Train Loss: 0.3728, Valid Loss: 0.4419\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [370/500], Step [18500/25000], Train Loss: 0.3770, Valid Loss: 0.4305\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [371/500], Step [18550/25000], Train Loss: 0.3743, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [372/500], Step [18600/25000], Train Loss: 0.3750, Valid Loss: 0.4166\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [373/500], Step [18650/25000], Train Loss: 0.3767, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [374/500], Step [18700/25000], Train Loss: 0.3749, Valid Loss: 0.4241\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [375/500], Step [18750/25000], Train Loss: 0.3761, Valid Loss: 0.4453\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [376/500], Step [18800/25000], Train Loss: 0.3777, Valid Loss: 0.4258\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [377/500], Step [18850/25000], Train Loss: 0.3758, Valid Loss: 0.4267\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [378/500], Step [18900/25000], Train Loss: 0.3715, Valid Loss: 0.4252\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [379/500], Step [18950/25000], Train Loss: 0.3781, Valid Loss: 0.4239\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [380/500], Step [19000/25000], Train Loss: 0.3740, Valid Loss: 0.4329\n",
      "Epoch Accuracy: 0.9416983523447402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [381/500], Step [19050/25000], Train Loss: 0.3758, Valid Loss: 0.4226\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [382/500], Step [19100/25000], Train Loss: 0.3773, Valid Loss: 0.4283\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [383/500], Step [19150/25000], Train Loss: 0.3765, Valid Loss: 0.4225\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [384/500], Step [19200/25000], Train Loss: 0.3767, Valid Loss: 0.4283\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [385/500], Step [19250/25000], Train Loss: 0.3764, Valid Loss: 0.4279\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [386/500], Step [19300/25000], Train Loss: 0.3746, Valid Loss: 0.4277\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [387/500], Step [19350/25000], Train Loss: 0.3755, Valid Loss: 0.4230\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [388/500], Step [19400/25000], Train Loss: 0.3753, Valid Loss: 0.4258\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [389/500], Step [19450/25000], Train Loss: 0.3736, Valid Loss: 0.4460\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [390/500], Step [19500/25000], Train Loss: 0.3734, Valid Loss: 0.4259\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [391/500], Step [19550/25000], Train Loss: 0.3758, Valid Loss: 0.4248\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [392/500], Step [19600/25000], Train Loss: 0.3745, Valid Loss: 0.4291\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [393/500], Step [19650/25000], Train Loss: 0.3790, Valid Loss: 0.4230\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [394/500], Step [19700/25000], Train Loss: 0.3733, Valid Loss: 0.4202\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [395/500], Step [19750/25000], Train Loss: 0.3741, Valid Loss: 0.4295\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [396/500], Step [19800/25000], Train Loss: 0.3758, Valid Loss: 0.4398\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [397/500], Step [19850/25000], Train Loss: 0.3731, Valid Loss: 0.4218\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [398/500], Step [19900/25000], Train Loss: 0.3730, Valid Loss: 0.4296\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [399/500], Step [19950/25000], Train Loss: 0.3754, Valid Loss: 0.4261\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [400/500], Step [20000/25000], Train Loss: 0.3737, Valid Loss: 0.4240\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [401/500], Step [20050/25000], Train Loss: 0.3731, Valid Loss: 0.4284\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [402/500], Step [20100/25000], Train Loss: 0.3732, Valid Loss: 0.4298\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [403/500], Step [20150/25000], Train Loss: 0.3760, Valid Loss: 0.4297\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [404/500], Step [20200/25000], Train Loss: 0.3783, Valid Loss: 0.4279\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [405/500], Step [20250/25000], Train Loss: 0.3743, Valid Loss: 0.4201\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [406/500], Step [20300/25000], Train Loss: 0.3726, Valid Loss: 0.4266\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [407/500], Step [20350/25000], Train Loss: 0.3740, Valid Loss: 0.4564\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [408/500], Step [20400/25000], Train Loss: 0.3755, Valid Loss: 0.4289\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [409/500], Step [20450/25000], Train Loss: 0.3754, Valid Loss: 0.4208\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [410/500], Step [20500/25000], Train Loss: 0.3743, Valid Loss: 0.4280\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [411/500], Step [20550/25000], Train Loss: 0.3760, Valid Loss: 0.4274\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [412/500], Step [20600/25000], Train Loss: 0.3752, Valid Loss: 0.4253\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [413/500], Step [20650/25000], Train Loss: 0.3741, Valid Loss: 0.4295\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [414/500], Step [20700/25000], Train Loss: 0.3731, Valid Loss: 0.4398\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [415/500], Step [20750/25000], Train Loss: 0.3745, Valid Loss: 0.4317\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [416/500], Step [20800/25000], Train Loss: 0.3756, Valid Loss: 0.4324\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [417/500], Step [20850/25000], Train Loss: 0.3738, Valid Loss: 0.4367\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [418/500], Step [20900/25000], Train Loss: 0.3741, Valid Loss: 0.4285\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [419/500], Step [20950/25000], Train Loss: 0.3755, Valid Loss: 0.4269\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [420/500], Step [21000/25000], Train Loss: 0.3770, Valid Loss: 0.4441\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [421/500], Step [21050/25000], Train Loss: 0.3748, Valid Loss: 0.4444\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [422/500], Step [21100/25000], Train Loss: 0.3743, Valid Loss: 0.4271\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [423/500], Step [21150/25000], Train Loss: 0.3724, Valid Loss: 0.4268\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [424/500], Step [21200/25000], Train Loss: 0.3731, Valid Loss: 0.4255\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [425/500], Step [21250/25000], Train Loss: 0.3727, Valid Loss: 0.4505\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [426/500], Step [21300/25000], Train Loss: 0.3730, Valid Loss: 0.4340\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [427/500], Step [21350/25000], Train Loss: 0.3721, Valid Loss: 0.4336\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [428/500], Step [21400/25000], Train Loss: 0.3734, Valid Loss: 0.4401\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [429/500], Step [21450/25000], Train Loss: 0.3743, Valid Loss: 0.4510\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [430/500], Step [21500/25000], Train Loss: 0.3714, Valid Loss: 0.4451\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [431/500], Step [21550/25000], Train Loss: 0.3744, Valid Loss: 0.4271\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [432/500], Step [21600/25000], Train Loss: 0.3739, Valid Loss: 0.4454\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [433/500], Step [21650/25000], Train Loss: 0.3743, Valid Loss: 0.4459\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [434/500], Step [21700/25000], Train Loss: 0.3697, Valid Loss: 0.4220\n",
      "Epoch Accuracy: 0.9474017743979721\n",
      "Epoch [435/500], Step [21750/25000], Train Loss: 0.3726, Valid Loss: 0.4348\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [436/500], Step [21800/25000], Train Loss: 0.3703, Valid Loss: 0.4323\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [437/500], Step [21850/25000], Train Loss: 0.3717, Valid Loss: 0.4296\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [438/500], Step [21900/25000], Train Loss: 0.3741, Valid Loss: 0.4300\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [439/500], Step [21950/25000], Train Loss: 0.3748, Valid Loss: 0.4325\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [440/500], Step [22000/25000], Train Loss: 0.3703, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [441/500], Step [22050/25000], Train Loss: 0.3728, Valid Loss: 0.4307\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [442/500], Step [22100/25000], Train Loss: 0.3719, Valid Loss: 0.4316\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [443/500], Step [22150/25000], Train Loss: 0.3738, Valid Loss: 0.4397\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [444/500], Step [22200/25000], Train Loss: 0.3727, Valid Loss: 0.4326\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [445/500], Step [22250/25000], Train Loss: 0.3760, Valid Loss: 0.4264\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [446/500], Step [22300/25000], Train Loss: 0.3729, Valid Loss: 0.4321\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [447/500], Step [22350/25000], Train Loss: 0.3714, Valid Loss: 0.4314\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [448/500], Step [22400/25000], Train Loss: 0.3709, Valid Loss: 0.4392\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [449/500], Step [22450/25000], Train Loss: 0.3742, Valid Loss: 0.4271\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [450/500], Step [22500/25000], Train Loss: 0.3696, Valid Loss: 0.4350\n",
      "Epoch Accuracy: 0.9480354879594424\n",
      "Epoch [451/500], Step [22550/25000], Train Loss: 0.3701, Valid Loss: 0.4345\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [452/500], Step [22600/25000], Train Loss: 0.3733, Valid Loss: 0.4267\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [453/500], Step [22650/25000], Train Loss: 0.3745, Valid Loss: 0.4386\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [454/500], Step [22700/25000], Train Loss: 0.3711, Valid Loss: 0.4347\n",
      "Epoch Accuracy: 0.9448669201520913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [455/500], Step [22750/25000], Train Loss: 0.3711, Valid Loss: 0.4356\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [456/500], Step [22800/25000], Train Loss: 0.3737, Valid Loss: 0.4275\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [457/500], Step [22850/25000], Train Loss: 0.3721, Valid Loss: 0.4454\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [458/500], Step [22900/25000], Train Loss: 0.3710, Valid Loss: 0.4354\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [459/500], Step [22950/25000], Train Loss: 0.3721, Valid Loss: 0.4289\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [460/500], Step [23000/25000], Train Loss: 0.3738, Valid Loss: 0.4368\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [461/500], Step [23050/25000], Train Loss: 0.3685, Valid Loss: 0.4406\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [462/500], Step [23100/25000], Train Loss: 0.3703, Valid Loss: 0.4332\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [463/500], Step [23150/25000], Train Loss: 0.3711, Valid Loss: 0.4362\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [464/500], Step [23200/25000], Train Loss: 0.3729, Valid Loss: 0.4265\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [465/500], Step [23250/25000], Train Loss: 0.3715, Valid Loss: 0.4269\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [466/500], Step [23300/25000], Train Loss: 0.3700, Valid Loss: 0.4322\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [467/500], Step [23350/25000], Train Loss: 0.3754, Valid Loss: 0.4316\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [468/500], Step [23400/25000], Train Loss: 0.3717, Valid Loss: 0.4341\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [469/500], Step [23450/25000], Train Loss: 0.3718, Valid Loss: 0.4375\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [470/500], Step [23500/25000], Train Loss: 0.3729, Valid Loss: 0.4286\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [471/500], Step [23550/25000], Train Loss: 0.3719, Valid Loss: 0.4374\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [472/500], Step [23600/25000], Train Loss: 0.3707, Valid Loss: 0.4388\n",
      "Epoch Accuracy: 0.9461343472750317\n",
      "Epoch [473/500], Step [23650/25000], Train Loss: 0.3708, Valid Loss: 0.4328\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [474/500], Step [23700/25000], Train Loss: 0.3728, Valid Loss: 0.4240\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [475/500], Step [23750/25000], Train Loss: 0.3729, Valid Loss: 0.4394\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [476/500], Step [23800/25000], Train Loss: 0.3720, Valid Loss: 0.4327\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [477/500], Step [23850/25000], Train Loss: 0.3715, Valid Loss: 0.4376\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [478/500], Step [23900/25000], Train Loss: 0.3699, Valid Loss: 0.4453\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [479/500], Step [23950/25000], Train Loss: 0.3701, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [480/500], Step [24000/25000], Train Loss: 0.3722, Valid Loss: 0.4523\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [481/500], Step [24050/25000], Train Loss: 0.3702, Valid Loss: 0.4343\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [482/500], Step [24100/25000], Train Loss: 0.3737, Valid Loss: 0.4206\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [483/500], Step [24150/25000], Train Loss: 0.3678, Valid Loss: 0.4288\n",
      "Epoch Accuracy: 0.9480354879594424\n",
      "Epoch [484/500], Step [24200/25000], Train Loss: 0.3707, Valid Loss: 0.4202\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [485/500], Step [24250/25000], Train Loss: 0.3745, Valid Loss: 0.4190\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [486/500], Step [24300/25000], Train Loss: 0.3676, Valid Loss: 0.4417\n",
      "Epoch Accuracy: 0.949936628643853\n",
      "Epoch [487/500], Step [24350/25000], Train Loss: 0.3717, Valid Loss: 0.4235\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [488/500], Step [24400/25000], Train Loss: 0.3712, Valid Loss: 0.4361\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [489/500], Step [24450/25000], Train Loss: 0.3698, Valid Loss: 0.4254\n",
      "Epoch Accuracy: 0.9486692015209125\n",
      "Epoch [490/500], Step [24500/25000], Train Loss: 0.3728, Valid Loss: 0.4215\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [491/500], Step [24550/25000], Train Loss: 0.3704, Valid Loss: 0.4307\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [492/500], Step [24600/25000], Train Loss: 0.3676, Valid Loss: 0.4224\n",
      "Epoch Accuracy: 0.9493029150823827\n",
      "Epoch [493/500], Step [24650/25000], Train Loss: 0.3705, Valid Loss: 0.4200\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [494/500], Step [24700/25000], Train Loss: 0.3694, Valid Loss: 0.4286\n",
      "Epoch Accuracy: 0.9461343472750317\n",
      "Epoch [495/500], Step [24750/25000], Train Loss: 0.3712, Valid Loss: 0.4347\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [496/500], Step [24800/25000], Train Loss: 0.3696, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [497/500], Step [24850/25000], Train Loss: 0.3700, Valid Loss: 0.4436\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [498/500], Step [24900/25000], Train Loss: 0.3742, Valid Loss: 0.4359\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [499/500], Step [24950/25000], Train Loss: 0.3721, Valid Loss: 0.4460\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [500/500], Step [25000/25000], Train Loss: 0.3707, Valid Loss: 0.4292\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.CrossEntropyLoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 10,\n",
    "          eval_every = len(train_iter),\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total = 0\n",
    "        total_correct = 0\n",
    "        for (labels, (notes, notes_len)), _ in (train_loader):   \n",
    "            labels = labels.to(device)\n",
    "            notes = notes.to(device)\n",
    "            notes_len = notes_len.cpu()\n",
    "            output = model(notes.long())\n",
    "            loss = criterion(output, labels.long())\n",
    "            #loss = criterion(output.view(-1,1),labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            labels_max = labels.detach().cpu()\n",
    "            output_max = np.argmax((output.detach().cpu()),axis=1)\n",
    "            for i in range(len(labels_max)):\n",
    "                total+=1\n",
    "                if labels_max[i] ==  output_max[i]:\n",
    "                    total_correct += 1\n",
    "            accuracy = accuracy_score(labels_max, output_max)\n",
    "            \n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                  # validation loop\n",
    "                    for (labels, (notes, notes_len)), _ in (valid_loader):        \n",
    "                        labels = labels.to(device)\n",
    "                        notes = notes.to(device)\n",
    "                        notes_len = notes_len.cpu()\n",
    "                        output = model(notes.long())\n",
    "                        loss = criterion(output, labels.long())\n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
    "                    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "        print(\"Epoch Accuracy: {}\".format(total_correct/total))\n",
    "    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')\n",
    "\n",
    "\n",
    "model = TransformerModel(ntokens,emsize,nhead,d_hid,nlayers,dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "train(model=model, optimizer=optimizer, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcbc3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "074bd8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "500\n",
      "500\n",
      "500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "epoch_train = []\n",
    "epoch_valid = []\n",
    "epochs = []\n",
    "\n",
    "for x in range(len(train_loss_list)):\n",
    "    epoch_train.append(sum(train_loss_list[x:x+2])/len(train_loss_list[x:x+2]))\n",
    "print(len(epoch_train))\n",
    "\n",
    "for x in range(len(valid_loss_list)):\n",
    "    epoch_valid.append(sum(valid_loss_list[x:x+2])/len(valid_loss_list[x:x+2]))\n",
    "print(len(epoch_valid))\n",
    "\n",
    "for x in range(500):\n",
    "    epochs.append(x)\n",
    "print(len(epochs))\n",
    "\n",
    "plt.plot(epochs, epoch_train, label='Train')\n",
    "plt.plot(epochs, epoch_valid, label='Valid')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"Transformer 500 epochs.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfce53a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABRdUlEQVR4nO2dd5hU1fnHP+92tgG7S19g6U2QsiIoKth7iZpIEks0lvw0JjHR2DUaTTOJMTGJxpbYsEWDimIDxYIUBaT3srSFhW0s28/vj3Pvzp2ZO1tgZxd238/zzDMz5547c+6U8z3ve97zHjHGoCiKoiihxLR2AxRFUZRDExUIRVEUxRcVCEVRFMUXFQhFURTFFxUIRVEUxZe41m5Ac5GVlWVycnJauxmKoiiHFQsXLtxtjOnid6zNCEROTg4LFixo7WYoiqIcVojIpkjH1MWkKIqi+KICoSiKoviiAqEoiqL40mbmIBRFUZpKVVUVeXl5lJeXt3ZTok5SUhLZ2dnEx8c3+hwVCEVR2i15eXmkpaWRk5ODiLR2c6KGMYaCggLy8vLo169fo89TF5OiKO2W8vJyMjMz27Q4AIgImZmZTbaUVCAURWnXtHVxcDmQ62z3ArGvopo/vb+arzfvbe2mKIqiHFK0e4GoqK7lkQ/XsHhLYWs3RVGUdkZBQQGjR49m9OjRdO/enV69etU9r6ysrPfcBQsWcOONN0a1fe1+kjohzmpkRXVtK7dEUZT2RmZmJosWLQLg3nvvJTU1lV/84hd1x6urq4mL8++mc3Nzyc3NjWr72r0FkegIRKUKhKIohwBXXHEF1113HUcffTS33HIL8+bNY+LEiYwZM4ZjjjmGVatWATB79mzOPvtswIrLlVdeyeTJk+nfvz+PPPJIs7Sl3VsQcTGCCFTWqEAoSnvmV28uY/m24mZ9zeE907nnnBFNPi8vL4/PP/+c2NhYiouLmTNnDnFxcXzwwQfcfvvtvPbaa2HnrFy5klmzZlFSUsKQIUP40Y9+1KQ1D360e4EQERJiY9SCUBTlkOHiiy8mNjYWgKKiIi6//HLWrFmDiFBVVeV7zllnnUViYiKJiYl07dqVnTt3kp2dfVDtaPcCAXYeQucgFKV9cyAj/WiRkpJS9/iuu+5iypQpvP7662zcuJHJkyf7npOYmFj3ODY2lurq6oNuR7ufgwBIjItVgVAU5ZCkqKiIXr16AfDMM8+06HurQGAnqtXFpCjKocgtt9zCbbfdxpgxY5rFKmgKYoxp0TeMFrm5ueZANwya8tBsjujVkb9OHdPMrVIU5VBmxYoVDBs2rLWb0WL4Xa+ILDTG+MbLqgUBJMTGUFFV09rNUBRFOaRQgQAS42M0zFVRFCUEFQjQMFdFURQfVCCwYa4qEIqiKMHoOgigt9nGkJI5YCZCO0n9qyiK0hBRtSBE5HQRWSUia0Xk1gh1vi0iy0VkmYi84CmvEZFFzm16NNt5c/6tXFn2FOzbFc23URRFOayImkCISCzwKHAGMByYKiLDQ+oMAm4DjjXGjAB+6jm83xgz2rmdG612AmRV77QP9m6K5tsoiqIEMWXKFGbOnBlU9vDDD/OjH/3It/7kyZNxw/nPPPNMCgsLw+rce++9PPTQQ83SvmhaEOOBtcaY9caYSmAacF5InauBR40xewGMMflRbE/D7N3Yqm+vKEr7YurUqUybNi2obNq0aUydOrXBc2fMmEGnTp2i1DJLNAWiF7DF8zzPKfMyGBgsIp+JyFwROd1zLElEFjjl5/u9gYhc49RZsGvXAbqHKkoCj1UgFEVpQS666CLefvvtus2BNm7cyLZt23jxxRfJzc1lxIgR3HPPPb7n5uTksHv3bgAeeOABBg8ezKRJk+rSgTcHrT1JHQcMAiYD2cAnIjLSGFMI9DXGbBWR/sBHIvKNMWad92RjzOPA42BXUh9QC2qq+LTb95i083nY3XwfrKIohxnv3Ao7vmne1+w+Es74bcTDGRkZjB8/nnfeeYfzzjuPadOm8e1vf5vbb7+djIwMampqOOmkk1iyZAmjRo3yfY2FCxcybdo0Fi1aRHV1NWPHjmXcuHHN0vxoWhBbgd6e59lOmZc8YLoxpsoYswFYjRUMjDFbnfv1wGwgOnkwkjOY0/fH/Lf2eFg9E6rKo/I2iqIofnjdTK576eWXX2bs2LGMGTOGZcuWsXz58ojnz5kzhwsuuIDk5GTS09M599zmm7KNpgUxHxgkIv2wwnAJ8N2QOm8AU4GnRSQL63JaLyKdgTJjTIVTfizw+2g1NCEuhreqx/Otik9g6wLImRStt1IU5VClnpF+NDnvvPP42c9+xldffUVZWRkZGRk89NBDzJ8/n86dO3PFFVdQXt46A9eoWRDGmGrgBmAmsAJ42RizTETuExFX4mYCBSKyHJgF3GyMKQCGAQtEZLFT/ltjTGQJPUgS42LYZrLsk7KCaL2NoihKGKmpqUyZMoUrr7ySqVOnUlxcTEpKCh07dmTnzp2888479Z5//PHH88Ybb7B//35KSkp48803m61tUZ2DMMbMAGaElN3teWyAm5ybt87nwMhots3LoG5pFBpng479e1vqbRVFUQDrZrrggguYNm0aQ4cOZcyYMQwdOpTevXtz7LHH1nvu2LFj+c53vsORRx5J165dOeqoo5qtXa09SX1IMD4ng0JS7RMVCEVRWpjzzz8f79YLkTYGmj17dt3jjRs31j2+4447uOOOO5q9XZqLCeicksC4AT2oMPHsyt/R2s1RFEU5JFCBcHj4krEUksKOHdtbuymKoiiHBCoQDl3SEqmI60hxoeZjUpT2RFvZVbMhDuQ6VSA8JKRlIvsL+XTN7tZuiqIoLUBSUhIFBQVtXiSMMRQUFJCUlNSk83SS2kNmVlcKC1dw8XML+fy2E0lLim/tJimKEkWys7PJy8vjgFP1HEYkJSWRnZ3dpHNUIDzEp2TQu0MlJXur2VRQxhG9OrZ2kxRFiSLx8fH069evtZtxyKIuJi+JaSTV7ANgy56yVm6MoihK66IC4SUxjZiqUsCwZa8KhKIo7RsVCC+JaYippVtSDVv27G/t1iiKorQqKhBeEtMAGJYhrNxR3MqNURRFaV1UILwkpgNwXJ8kvtpcSGFZZSs3SFEUpfVQgfDiWBDHZMdTU2v4csOeVm6QoihK66EC4cURiN4ptQBsKtjXmq1RFEVpVVQgvCRZF1MqZXROjmdjgUYyKYrSflGB8OJYEFSU0DczRS0IRVHaNSoQXpxJaipKyMlMZlNBGeSvgF2rWrddiqIorYAKhJfEdJAY2LebHp06sLO4HP4+AR4d39otUxRFaXFUILzExkFaDyjKo2taIlU1bTvDo6IoSn2oQITSsTcUbaFrWtPS4iqKorQ1VCBC6dQbCjfTNT2xtVuiKIrSqqhAhNIxG4q30TVFM6EritK+UYEIJb0X1FbRNU7XQCiK0r6JqkCIyOkiskpE1orIrRHqfFtElovIMhF5wVN+uYiscW6XR7OdQThrITrU7qNDfGyLva2iKMqhRtT8KCISCzwKnALkAfNFZLoxZrmnziDgNuBYY8xeEenqlGcA9wC5gAEWOufujVZ760hItfeVpaR3iAPN16coSjslmhbEeGCtMWa9MaYSmAacF1LnauBRt+M3xuQ75acB7xtj9jjH3gdOj2JbAyQ6AlFRSrruSa0oSjsmmgLRC9jieZ7nlHkZDAwWkc9EZK6InN6EcxGRa0RkgYgsaLZNxxOcdBuVpaQl6US1oijtl9aepI4DBgGTganAv0SkU2NPNsY8bozJNcbkdunSpXlaVGdBlJDeQS0IRVHaL9EUiK1Ab8/zbKfMSx4w3RhTZYzZAKzGCkZjzo0OnjmINHUxKYrSjommQMwHBolIPxFJAC4BpofUeQNrPSAiWViX03pgJnCqiHQWkc7AqU5Z9Amag1AXk6Io7Zeo9YDGmGoRuQHbsccCTxljlonIfcACY8x0AkKwHKgBbjbGFACIyP1YkQG4zxjTMtu7qQWhKIoCRFEgAIwxM4AZIWV3ex4b4CbnFnruU8BT0WyfLzGxEJ/szEGoBaEoSvultSepD00SUu06CLUgFEVpx6hA+JGYChWlpCaqBaEoSvtFBcIPx4JI0lQbiqK0Y1Qg/EhMh4pSkhNUIBRFab+oQPiRmAoVxXTwCsTs37VeexRFUVoBFQg/HBdThzgJlM1+sPXaoyiK0gqoQPjhTFKHRbm+cgVU7W+NFimKorQ4KhB+1FkQIeXLXodVM3xPURRFaWuoQPiRmAZVZXSIqQ0/JjpxrShK+0AFwg8n3UYHUxp+LEbXRiiK0j5QgfDDSdiXWFUSfixGLQhFUdoHKhB+OBaEVBSHH6vRPUgVRWkfqED4kejsKldeFH6sqrxl26IoitJKqED44ab89hOIahUIRVHaByoQfiSl2/uygvBjKhCKorQTVCD8SHH2ty7dGX5MBUJRlHaCCoQfyZn2vsRHINZ9BG9cD8a0bJsURVFaGBUIP2LjIakTlO4IP7Z+Nix6Doq3tnSrFEVRWhQViEikdIHS/MjHt30N93aEhc+0WJMURVFaEhWISKRkQYmPBeGy0snJ9NGvW6Y9iqIoLYwKRCRSsmD/nrqnZWn9IK1H4Pia9+y9zkUoitJGUYGIhBvJ5FAR0yGwPgKgbLe9N7Ww6EWYeUcLNk5RFCX6qEBEIjkr6Gm1AeKSwuuVF8Eb18EXf2uZdimKorQQURUIETldRFaJyFoRudXn+BUisktEFjm3H3qO1XjKp0eznb6EWBDVtQLxPgJhalqoQYqiKC1L1HJXi0gs8ChwCpAHzBeR6caY5SFVXzLG3ODzEvuNMaOj1b4GSWmkBeGltkazvSqK0maIpgUxHlhrjFlvjKkEpgHnRfH9mpdQgaiV4DkIPyr3RbFBiqIoLUs0BaIXsMXzPM8pC+VCEVkiIq+KSG9PeZKILBCRuSJyvt8biMg1Tp0Fu3btar6Wg4+LyUDmgPrPUYFQFKUN0dqT1G8COcaYUcD7wL89x/oaY3KB7wIPi0hY72yMedwYk2uMye3SpUvo4YMjZJK6qlYgo39Inczg5yoQiqK0IaIpEFsBr0WQ7ZTVYYwpMMZUOE+fAMZ5jm117tcDs4ExUWxrOMkZgNQ9raoFOvUNqRMsIlT6bFGqKIpymBJNgZgPDBKRfiKSAFwCBEUjiYhn5RnnAiuc8s4ikug8zgKOBUInt6NLTGyQhVBVC/Q7HsZcCr0n2MKUUIFQC0JRlLZD1ATCGFMN3ADMxHb8LxtjlonIfSJyrlPtRhFZJiKLgRuBK5zyYcACp3wW8Fuf6Kfo4xGAyhowsfFw3t+g+xG2MNTFVFXWgo1TFEWJLlELcwUwxswAZoSU3e15fBtwm895nwMjo9m2RpHSBXatBKDaCIVlVXROSYDYROe4upgURWm7tPYk9aGNRwAMwo5iZ7OguAR73yEjuL66mBRFaUOoQNSHZxK6hhh2ugLhTl7HJQbX/9/1UF2BoihKW0AFoj48ayFqEY9AOBlcRcLPKcqLfrsURVFaABWI+vC4mLaZLHYUOdZBXYpvj0BkDrT3FcUt0zZFUZQo06hJahFJweZGqhWRwcBQ4B1jTFVUW9fajLjATjyn9+Kfrydxgp8Fcc5f7D4RCSnwzFlQrgKhKErboLFRTJ8Ax4lIZ+A97BqH7wDfi1bDDgmSM+DYnwDQ6aM5AReTqXUqCIy7wj7cvsTeqwWhKEobobEuJjHGlAHfAv5ujLkYGBG9Zh16dO+YxI4iVyBcC8Lz8SWm2fuKkpZtmKIoSpRotECIyESsxfC2U9au8lp3S0/yTFI7eCepkzra+7UfwOe6eZCiKIc/jRWIn2IXtL3urIbuj13h3G7olp5Iwb5KKqproMtQW+hOTEPAglj6GnxwD9TWhr+IoijKYUSj5iCMMR8DHwOISAyw2xhzYzQbdqjRPd1uFpRfXEHvMd+HbsOh17hAhdh463IytVBbDSXboGN2K7VWURTl4GmUBSEiL4hIuhPNtBRYLiI3R7dphxa9M5IB2LynzLqWvOLgYjxWw59HwLavW6h1iqIozU9jXUzDjTHFwPnAO0A/4NJoNepQZHA360L6dO1uamtNA7Ud5vwpii1SFEWJLo0ViHgRiccKxHRn/UMje8m2QVaqzb/0j9nreHnBFv9KienBzws3R7lViqIo0aOxAvEYsBFIAT4Rkb5Auwr4FxG6pdvcSx+vjrC96c+WwS83BZ5r+m9FUQ5jGiUQxphHjDG9jDFnGssmYEqU23bI8dqPjiEnM5l1uyKk9U5Khw6d4IzfQ7cjNLuroiiHNY2dpO4oIn8SkQXO7Y9Ya6Jdkd05mfPH9GJNfimlFdWRKx59LfQ91qbp+Pe58MXfW66RiqIozURjXUxPASXAt51bMfB0tBp1KHNk704YA9/kFdVfMSHFrqreOEejmRRFOSxprEAMMMbcY4xZ79x+BfSPZsMOVY7M7gTA4rzC+ismJNuwV1ML5SFiUlvjyQirKIpyaNJYgdgvIpPcJyJyLLA/Ok06tMlISSC7cweWbWtgjj4hNfDYm8Cvpgruy4CP7o9OAxVFUZqJxgrEdcCjIrJRRDYCfwOujVqrDnH6d0ll4+4GJqATPFM0XgtinxMBNeePakUoinJI09gopsXGmCOBUcAoY8wY4MSotuwQpl9mMht278PU18EHCUQx7NttBaF0Z6B8X4RwWUVRlEOAJu0oZ4wpdlZUA9wUhfYcFuRkpVBaUc3u0srIlbwuppJt8IcB8NbPoNQjChoGqyjKIczBbDnqsyFz+2BQV5t2Y9bK/MiV4pMDj90cTQufhpLtgfLqkPThiqIohxAHIxANOtBF5HQRWSUia0XkVp/jV4jILhFZ5Nx+6Dl2uYiscW6XH0Q7m51jBmQypk8n/jZrbeRKdS6mEB3dvijw2F1pvXgaLHm5OZuoKIpy0NQrECJSIiLFPrcSoGcD58YCjwJnAMOBqSIy3KfqS8aY0c7tCefcDOAe4GhgPHCPs93pIUFMjHDWyB5s3lMWvomQi+tiygiJBt48N/D4nVvtBPbr18J/rw6uV1MNXz1rQ2IVRVFagXoFwhiTZoxJ97mlGWMa2ktiPLDWWTdRCUwDzmtku04D3jfG7DHG7AXeB05v5LktQm5OBgBHP/ih/6rqjr2g+ygYdk5wef7ywOO8efDRA/5v8MXfYPoN1rpQFEVpBQ7GxdQQvQBv2tM8pyyUC0VkiYi8KiK9m3KuiFzjpv/YtatlI4JG9EwnM8VmeP1iXUF4hYQUuG4ODPBJWZV7ZeDxvMcCj+/tCB//wVoPezfastCJ7Df+Dz7UNRSKokSfaApEY3gTyDHGjMJaCf9uysnGmMeNMbnGmNwuXbpEpYGRiI+N4fPbTqRDfCzvLt0RuaI3BXhSR+g5FsZfE7n+rF/DmpmB+Yn4DoFjtbWw6HmY89DBNV5RFKURRFMgtgK9Pc+znbI6jDEFxpgK5+kTwLjGnnsokBgXyyXje/PaV3ks3RohN1NSx8Djq2fB1R8Fl/kRExewHLyRTrtXHVyDFUVRmkA0BWI+MEhE+olIAnAJMN1bQUR6eJ6eC6xwHs8EThWRzs7k9KlO2SHHD4+zk9C/fG0JG/xWV3vFICHVblfqtQr82L3aJvqDwD3AtkUH11hFUZQmEDWBMMZUAzdgO/YVwMvGmGUicp+InOtUu1FElonIYuBG4Arn3D3A/ViRmQ/c55QdcvRITwJg2bZirv7PgvAKXhdTgrM2Iq4BgXjvTtjwsX3sFYjQpH/KocPq9+wcUv6KhusqymFCVOcgjDEzjDGDjTEDjDEPOGV3G2OmO49vM8aMMMYcaYyZYoxZ6Tn3KWPMQOd2yKYWj4kJrHPYs89nZXVcQuCxu3guLjG4zrBziYg30Z93hzrN49TyGANvXB8cquyy8k17v+XL5n/fmip7Uw6OxS/pNsBNpLUnqdsUiXENfJwxsfZeQhbPpfUIr+vitSCqPAl0KyPsaqdEj/JCWPQc/Of88GPifPfRWLfyp+E2VYty4NRUwevXwNNntXZLDitUIJqBt348icHdUtlRXE551QF0EGndIx9b+TbsL7SPvRZEeQPpxmtroHhb09ui+POvk+DVq+zj2ITw4+KIv5tWpTnZl6/uxYPF/e94k2UqDaIC0Qwc0asjt5w2FGNg7nqfNREN4QpEznHhxypL4b077GOvQFSECER5kc0Y6/Lx7+BPw6ColYO/5j8Baz9s3TY0B1sXwDrnOuL8BML5K0VDIA6G6koo3t5wvbZOlRMNGNPQ+l7FiwpEMzFpUBYAVzw9n/kbmzif7k5kS4Svw3UteV1MXtcTwKMTgt0QGz6x9+6Cu2iz9L92knbvpuDyt38Oz32rZdrQUsTE+5RF0YI4GBY+DX8aCoteaO2WtC7u4CpWBaIpqEA0E0nxsdx//hEAfBSa5fX8f8IpIaufveGvrsvC7WRcXMFI6mTvvauqQ11MJY47qdbpoFzRaSnXxJKX7P3OpZHrVFfAzmWw6t2WaVNzERoQEOsjEH4WRP4KePOnge8kEoWb7ecSDQrW2fv1sxuuu20RfPz76LSjtXHXE/mJuxIRFYhm5NIJfTkyuyNfbdobfGD0VDj2xuCyWzdDupM9JDsX4pLguJ8H1znnEZvsz+3kq/YHIqEqInT8xY5LKckRiFBXVLTw6yCrQ6K6ft0V/nEMvPidlmlTc1EVsruu7xyEzyT1cxfZEXxxXv2v//BI+7lEA78Fl5F4/ASY9UDDgnY44loQ6mJqEioQzczR/TP5avNetuwpa7jytXPgR19AcgbcuRNyJgUfT0i2loDbyVfthxTryqKyzHZGM++AJa8Eztmz3t67FsT+ELGKFnUC4Rltt5Q4RYMNn9iQVmhcxJgbmeYVyDJnPqo1Q1TLC+19RQncl2UzBPtR6El9VhvS3trawz+s2p2D8LP+lIioQDQzVx7bDxHhqc82NFw5JRO6hWRAH3p24HF8snVFue6kqn2Q7AhEVRnsWmWzvv73h5DS1Za7AuEuyvNOXLcE3g6yOd1b+3a33EryilL49zk2pLWmKny+x08w6gTSY0FUu3NHjRgsROJgR/Pud1Cabzv+tyNsBPnwEYHHNR7Lr6Ya7usMH953cO1obVwrMNSNq9SLCkQz071jEhP6ZzJnzQF2zJc8H1hpHZ9sXUVeF1OKk5Twk4dsCKxLnSA4WW1rqoOfR5u6CXbPSNMdvfrR1I7vsROsCyTabPwMft8v8LyqLFwQKvwEop5J6spGCoSfpVG9P7ysKbgh0u59TT3b5Pq1w33/uX8/uHa0Nu51HGpzEI9OgOcubO1WREQFIgocNzCLtfml/GHmyoYr14drQdS5mMqgQ2dAbGz8rF8H6rqdUJ1bw8mB2FIWhJ8Pvj4LojEdlRevH3/N+/DKFU07v7Hs3Rjctt/2CZ9AriwJF7i66/cRiCpnHuCF78BL3w+UV1cGu25cS7G2NmAJeuc/anz2HQlq+6ZwMXK/g/rEOhTv9bsrww+16KymUmdBHGJzELtWwNoPWrsVEVGBiAJTj+7DCYO78OisdXy+7kA6aKfTSEiGxI72T77sdRvtkpDsbya7IlLmhNi6E8QH495oCq4PvroiUOYViFAf9oHux20MPH+R/Twa6jAbomRH+ByN3+e1+MXwsjA3k3N9rjBXea7P7bRXvwsrnJQc+wrg9/1h+RuBem7gwft3wSNjbPu87anxfLah1FTBX0aF70zoCkNTVt67ArHsjcDo9kAForoSZtwCJa28QM0VCA1zbRIqEFEgNTGOxy4dR9/MZO58fSm1tU2c4HM70/gO1oKoLA2MmIu3Q61Px+h2uHUWhPMnr66nU2ks+Ssa7ozdEbTbjsqy4FF+qMUQyYIozfcvd/FaKFU+2XP9eO2H/nt+/3GITWPhdamEbtAEUOYREfc6Q60j9zW+fAxKd8F+z1oYP9HZ9pW1RDZ7cje5FoS7i2DJ9mALor7v0l1/sm5WoKy2xj9QYM379bv43MHFLo8F3FSBWDcLPv8rrHnPbor1btiW9C1LS1gQe9bDhjnRe/1WQAUiSiTFx/Kzkwezfvc+zvrrpxSXNyWSxRWIZBvhBIFJaHeuIRJux+SONpsyUt+zIfwHvmc9/H0CfHBPAye7FoTzft4FerGJ4Z2kX2e34k14aBBs/DS4fN6/Ao+9o+hIvv1Zv4G/jA48/+aVwMj6xe/CAk/ux6oyuD8r+HkoXisjc5BTFrIY0hWuylL7XmWeFfV+orNjib13XUkQmAwvc6zOxyfDgqcCx+tzy+1ebe+9aVsiufiev8haM+77r3on+Lj7Pl5RaKpAPHu+zUrsTto3x0DlYKgLc43SHMQLl1ir799nNz7i6zCIDFOBiCKnDO8GwIrtxbyyoIFYeD/ik6HXWPt4X74dvZ7ZwG5yoaGVfp1KeXHAFeXlkdH2B+6l1Jnk9stg6sUdWW+ea62NYk+Kj5i4YJdLpHa5i7lCff4zfhF4/F/PbnxVZTDnj+Grtz/+Lex1osi871uUB6vehrd+6n8NxdvsiDeUMo+bMMsRiNDPzxsaum938PFQ0ampgh3f2MdBAuEz2v/qP4HHbie7f2+4kPsJhCtMsSHZgyGQ1fTRCfDiJSHtc76bZkk86BP+2xrULZSLEMVUVe4v5PXx1k0w95/28WqPyDY2Y2xT368VUIGIIimJcbx5wyS6pyfxmxkrmL64kcnzRl5s7+OTofuoQFRT/ykBi8LFXWzn4rpDquuxIB4eGRypU1MdOWdTaObZhlgxHWY/aDtjgFHfsaP+MAvCadeqdwOrfd3OPC4p8uuvfCvweO8GG375z0mR63snZ93Ov3NOuIulugIeOx62fR3+Gt7PMNNJZxJqQXjdVDExwccry4JddPv3BgSiYI2nrcXhqVG8n5v7nb75Eyvk3hxLfilV3PodOgXKvveavS9y1j34zWu412IaEIj9e/0jr4LcgG77GzFa3va1Dd0+GJa94Z9WxG2Hn3sW4NGj4MGeTXuvBU/Cu78ML89f3rjzD4OMzCoQUWZkdkfuPXc41bWGG1/8mo1+u86Fcs5f4Ob1dkItNj4wak1MDa/bMTvwWGKtX7uyrP45iNCIlvfvhj8PD6/XFLwWwY6l1oKQGOjU1/4pQ0dLbrte/A781dlp1g1FdPfLqK6sPxLKna+oKLYd8K5VwT772tpAeCfYSV+w6dUrQ9Y27C+sPyQ4OdPeZw2x92EWhKfjqdwHr14ZeF61L7gzWPMeFKwNf4+KYmsRRcLtzN0svXnzPec61+NNweIKmzetS5fBkDW4/lHuU6fZ66tv1F+2B36XAzNvD5RV7bffV6HHonO/v9Xv2t9FJHavsS61p8+MXKcxvHI5vPGj8HJ38OEVtIJ1sNv5Hg5mn4jQ/1hj06Z4w6UPUXeTCkQLcOrw7lxzvN2adPaqBiZhwYpCSmbgubt6OiEtvK5XIPo66RrWftC4SWp3pOdG1tSVe9NleM6vqbYRKTt9RkhegdizHrYvgdTukJBiy0Lj6INcTM6fw/0Tux3b/663YaaR8KZuLs6DR8fD69cGyj64J3guwBWPsj3hGU5dl1QkjvkxnP0wjLjAPg+NfvIKRMHaQOcan2wF2ysQ/3NWaLuuHzd9Snlx/ZP07uRxJ+cz8W5O5L7+vnxrVZXs9AhEp0C9+GR7fn0doqmx8zb1uZgWPmPv8zy7KD4+2X5fj4wJlHlF95/H2vtHxtjfkRd3HqRsd3QintwBivd7+utY+Nu4A3s9r0UYKnwN/Zbq2uQZpDQ17LuFUIFoAWJihNvPHEb/rBTeXbaD9btKm7ZvRAfHreRnQaR2CzweeJKtu/pdj4upHoFwO89QV4LX7VDnXjE27fi8x6yPPxTv+xSsgTUzIbVLwF0UGipaXRHeAblugPIiO7pbMZ16KfV0Pm5Htfx/gbLPH4EPfxXext2r4O9HB7/WU6fV/17DzoXcHwTSn3iFByK7LpI6WQsidHFdhwwYcKJ9nNHffk6zfm2/O+936sX9XtzJeW+Ukfv6pTutFfLNK/4WRHwHa0E1tC+CMfWnCHGtmIz+gTJve1z8rLI96+3vyO/1wH8e6GApdaxHv2vydvZfP9e41/NG0HndhBA+JxaKMTZ6zfubqNxnEyXO+VPj3r+FUIFoQc4f04u56/dw4h8/5nfvNmERnTvvkOAjEN49r+OTrUVRtifwR6gviunrZ+3oJ6yj9oZWOudvXQhfOhNyCWk+YZ4+I6CENP+9E8B21qFJ8Nz3ev9uO7rr3C/8PC/7PKPtLfP863hH2Qe69iKtR2DuAexixbI98OLUgCBF6kwTkm2YsCtIKV2sJfLLDYHOtWN28PcYaYdBt/2u9eLtiEJdZjFx/gIR18GKUXV5A5tOmfrDiF2XVkOfaWMXapZssxFiaT3t4GLLfPji7+FpTg4U12IMzTMFwb+j/13fuBQx3s49dN6ksAGBWPsBPHUqfPrnQFlVmU2U6B3QHAKoQLQgU8f3oX+Wdbk8/dlG7npjKZXVjYjuiHdTbzij8YGnBI6Fpg1PSLXuBne0WVMR2b/54X3W7A+1IKorAu6e0OgjsDmKHhlrO+X6UjgkJEeecK6pCO9cQkfZxREmzl287pjG7AV9oAJx04rg58kZdpJ31Qx4+TJbFmpBDD4drnjbisnWhYHyi5+xlghA95H2Pue4QPZdgPQIk6Wui8kViMLNAXdgaEdaUew/SR0TY+d4qivhd32Dz+nrmew3tfVH2bguraoyKzR5C/3rhVoQkV6zeJu97gEnwqYvYPoNMPM2K8CLp8Hnf4vcFhfvbzXUcnYtFL/1PKHuRr/fvMu+Anjnl8EWZH7I76Noa/3rhtzPzt2AChqfjqWFUYFoQbqkJfL+TSfwzA+OIis1kWfnbmLmsh0Nn+j6qt1R6iXPww8/gn4nwPDzAvXiEq3Pv7I0ONV2Q/7NUAti9yp4oJv9Y0bKBVS2G548xaaPAH9XVnyyf2pst36oBbEvxP/eUDZYb+dTsBa6DoeMevZuPlCBCI3k6pAB2xcHl/kJRM4kGzHlxWsFjp4K9xTCMTcEC2mkLWhd0XcFoqYi4CoKFdeK4sDn652DAPudVO8Pn4R2Q6rBEYh6Oq269C/l8NL34IkT/euFCrfXX+/93RVvsxF5qV3sCN7t0Eu223kld1fFUFa/F+jgvcEXXsF8/57AKnU/C6IoZD4mUnRR8TY7yv/yn9b6dvFGLcWn2AHXjsUBt+f+vcEC6je301BK+FZCBaKFiY0RJg/pyme3TiE2RpizZhf5xQ10XK6bxu2E4xIhexxcPj2QvA/sHz8x1Y7SvKLg7Rj9XCGhFoRrMn/1bHjH74bcumxx1kf4WhCp4Z3y2X8O1Pe+9v69Td8v2GtBVJbajjvUPZM9PvC4PpfKERfB9/8beD7xhsh1kzM84ZuOeIR+rhmOe6xTyCjdjdByccXH22m4c06hlDjzC/vyoZtjffxzku18Kkuhz0RIz7bupd1rAx2m18p02+AXoZToCYKorggf7XuDF+pcTPuDV4NHYrIT7eTNO+QKfG2NjTBL72l/M7VVAQEKnbAu3eUJi94PL1wMT59uP39vxJp7fnkRfPZwoLxkO/x+QPCmVaF5vfbtgqfOsKn0Xet77ya7he+CJ53XcQZ2nfsFu5RSnQWt/zoRnjgJ7u8Cj0+xAur+RtzPrstQGOtYoKFuqprqcCtk9xq7a+O7t9v70nx4+ixY/BLRQgWilUiMi6VzcgIvL8hj/IMf8vaSevYNdkfhfp27N799nQWxzxltOp3P+/cE/sR+Jn6oST3bmYTevyd8lJ+ciS+RXEzePy1AXyeSZe/G4Mim/CbMyRx9nV0RWxbi307OCF9p/sP34XTnekInll2OuBAu+Gdg0jguCU57wIrERU+F1/d24HGJMPcfti29JwRWvLuWg9thDD3btqPLUP82RJrk9vLOzYG028POdibLd8PX/7GC1e8EuGmZfe/V79jtXiFcICJZdV7r5qP7YVPIinavNel2clX7G14rc9n/4IRbrIWwZmagfPNc+5suzbeDFFcgvIQOGp48xc5P1dbalf9gf0v3ZwVvuuS2z7sfev8p9r5sd/2bVn3yB9j8uU2l71oy7roVF/e31P2I4HLvgA3s/8KNanLDkl0L5ar3YbSTvNFrhVSVw2PHwUMDg1/LTaMy91F7v+Y9+x29fg3RIqoCISKni8gqEVkrIhGTsYjIhSJiRCTXeZ4jIvtFZJFz+2c029laGGd0khQfwz3Tl1JRHSGyacyltvM6xmdU6/1zxiZ65iCqAhOfC5+G/ziuKD+BCF0s5S7yKtsTbgHEJ+FLdSWMClmRG58c/gdy97P4+HeB0RjYUSDY5IQN0WVI8Gi37rUzAmG1Xtwyv9XjABOvt0IrAhf/G677zJaf9oAVj7D38YhkdbnNM7R9sR25n/1n6DLMjuS9dbuNgAk/ityZegXCL19QaKfeuR9c56ymdkezbpSbm3rcJWuwXZNysjMBGmrFuPh9pl7cwcLGzwLrOEIHEH7kHG+vu8foYNfcK5fbjt3NSpzeM/j7S0gNFoiq8kBnu2Nx8Cp0CLaEK0psSpVXnfmeO/Ptd9AYvNuzuoOQ3aET0Y5bqvuo4PJQgfDy9Bl2fsV1ByakBn4fy97wtL3YCoY3lHrXKngnJDTYFYxQK7UZiZpAiEgs8ChwBjAcmCoiYauxRCQN+AkQaqeuM8aMdm7XRaudrcljl47jrrOH86/LctldWsn3/vVlnWgEkZwBl74eefLSJTbe/sEqSq2LwDvxWb3f7hrWlOX9ZQXBAhGbQJ1VEkpNRbh4JKRC/8lwnsdSiNQ5uWQNrP84WOFx/4jezrRDQwLhY0HcWwS9PLHwI85vuA2hq9ldYuPsyP76uYGsoSMusKIxKcJGPS6uiynnOCtYDZE5wFoKfY4JhJe6HXzohHXPMXDXbpj0U6edHrG5+N+Bx6Fh1JN+Fvzc/fye8Sxmqy4n4m/CJcbpZlIjdJ5uaGmoQPQYHRA/CJ7sX/8x7FkX+T0rSgNpSuI62N+d+1vx68Rd8QQr1q6V6F7zrtXB9d2V6N1CLYgIFnbdeXl2ABefYj+XjP7BKf0B/pYbft4L3yZsNbq7H4zrzowC0bQgxgNrjTHrjTGVwDTgPJ969wO/Aw5wBvHwJTcng6sm9WPSwCyuPq4fCzbtZeS97zU8JxEJibGdsqmxftzQEeG+XY3PgAr2NbyJ7eKTI6+ura4IH+W67p7OnhFOfQJx0VP+HXwo8R0Ci8W8f/bkDPvHCyXVmfSt3h9YCX0wdOjsX+438o+JhdwrI1teLq4Fcd6jwcLuEurCqwuR7RVIs+G6Z0IFIi4xOAeR9zvw7mAY+ntx3R8ufov4Qt2T33vVRtn18dlj23W/RSK9V7CLqdvwYP++V5gWvWCz0kZi/96A28aN4nLdsVmDg9uS3suuIfLS40h7v88RiEhi5EaiuYTO0YUiYr8fV4xjYgIuwOHn23tvmO0Tp1j3sG8qFcd6C937vRmJpkD0Ajwb3ZLnlNUhImOB3saYtwmnn4h8LSIfi8hxUWxnqyMi/Pgkm06jtKKa8Q9+yLtLGxHd5HKh46rpnBP8B0sN+UOWF9nFOE3Bm1MoPtk/P09VuXU1hHb+bniut9OvL91yXIfAquJQvEkK4zwC4b3e5Ex/gek6LPC452i49pPIbWgMbht75UKmx9o4mEyhx/zY3kdyUYS6jVwrxpuLy+3gQ9dEhLq1vMn7vPsjhIprWsiCPb8ggqqy4NdPzoTvv2rTxYQS+nsMJfT7O+rqyHV3r4KNc+w5oZ8NWH+/a/26v0P3+0nvFZyBICY2/HfnCsTaD+wgqWSHtWi8xCXZ1/LO8XhDiv3Yv9daEN7f7dkPw7E/haOvDa+fN8+umaiP0O+7GWm1SWoRiQH+BPzc5/B2oI8xZgxwE/CCiIQNq0TkGhFZICILdu1qoa01o0R6Ujxv3jCJyUNsB/GzlxZxyeNfkF/SCGti5EVw9x47Uvf+wXq5pqrzB174jI3d9yPRZ9QaOjpKiGBBzP27dTENCvkhuxlevX8GETjpbv82xCeFT6i6nVbH3p6yDoE/uLdD7ZDhv+4iOSMwYoxLDHSkfllOG4Pb0Y24AK6fF0gBfjD7HU/8P+vuipTO/Yq37aT5qO8Eu8S8bke/hZR+hC5edC2s0PJQi8LPgqitCk4o6Lo7/BZI1uef75Vrfxve32+XwfWfA9YaOCVkcVlMfLB14bpt3d9jatfgc2Liwgcu3Y6w9ZdMs9l/i7YERMOlU19rAbgLOsddYV2JoULipbzQur+87ryBJ9n2uL/HxszDefHbAreZiKZAbAU8/2qynTKXNOAIYLaIbAQmANNFJNcYU2GMKQAwxiwE1gGDQ9/AGPO4MSbXGJPbpUsDP6TDgJHZHXn6iqN44IIj2F9Vw9z1e/hsbSNXorqdU2KIiQ6BVcBuRMcxN4afH5oVFgITrS7xHfw3mvnwVzDwZOh3vPV3u7h/TPdP7/5B3WiSUOKSwldPuyNlb2cVnxx4zYEnWb99Qhr0OTryjmFdhwbew+1I68saWx/ZuXYie+L19nN3JxpjD8KCaIi+E+2k+bceh6s/CpR7BdX97q96HybfFvm1QoWxk/M39ZtwvmkFXPep7XRLdwaHXvqFArvuN7/PNlJnf/1822YIFzm/CVjvYKZDRvg6j7QewWsb3EGNO+mb0sX+VqdOs89j4u3gyg3BBit0oa5EryUKge/bjVg77ud2kHPZG3DjouC6pzoT8es/tpFcfq6o7kfYTM7XzILz/2HL4lPghIjxPZa9G6ImEtEUiPnAIBHpJyIJwCVAXXIdY0yRMSbLGJNjjMkB5gLnGmMWiEgXZ5IbEekPDALWh79F20NEmHpUH66aZDvKB95eyYbGZIB18f7w3D+pG2lRWWJHi6feHz65lu6T3iHUJeAuAvKS1gOyj4LTHrTPL309fATlmvhue+Ij+GnjksIn3Nw/v7fzjU+ykV2n/tq6Zi77H9y2xf6hI7mw3D9xXJKtl5wJZ9WTObUhuh8RcK24HUlzbkZz8r0wJcLiMC/eztLtXHuPh8n1dCqho/tTH7AWljfK50onH1J6T2tJpna1c1juZOrpv60/esZvrimSi6ljdmAiO9RF2GdC4HFypp1D+tFngeiy5M7BczbJWeHBHO5AxV2I6bbD/T26v61cTwbeLkMCEXcu6T3h+Jvh+FuCX7fOanJ+1x06B1u8AEPPsmlENjqRZ+76IS9xiXDhE3ZA536v8Ulw7E/C64a6xJ46PbxOMxA1gTDGVAM3ADOBFcDLxphlInKfiJzbwOnHA0tEZBHwKnCdMSZCjGLbIyZGuOtsO/rfXVrBlIdmNy4lBwSshW/9CwadZjuZcx72uHucP+D3/wvDzgmc5xchFZo0rqYyfJR80wr44Qf2DwX2z+H+qd1J68SOMOJb8L1X7PNIE9XxHcJXHqd6XEMunXOsK+aYHwcmYN3OOpJA1P1hjb2GW9bDqIv96zaVOoFoxu0sJ/0sMC9RH17LqqEwVZdQC6LP0XDzGnsdsQkw+nu2zEunPjas0t0vIzE93N3oDf/1syC81qH727p7b7BbLVQgTroHLngcvv2sHZXfMM+2xRWz+OTAHERiRzu/5H4fdS4hpyN3XWSuu7FubsLne0tMC55fAisYJ95pv5cOneFkZ5fFoefYjAbe6LZQS7Zjn+D5CTcrcCTq3KAJ9vO5KyQCzyucELVIpqju4G2MmQHMCCnzdUAbYyZ7Hr8GvBbNth0OJMTGUFlj/4RTHprNE5fnMqyHz1yBl8wBdj7CdTmd4Ix2kjpaE9v9A6Z1s+sW3FTfE2+wmw2t8sYLuCOk/jbmfPcaKwaLnreZUsE/rn/K7bYTdjc+iomBiz3RUJEiPeKSoFOn4LILHoMlLwXHm9cX6eT9s3ujqtwOaV/IH605cDukSGlJDpTGuMCSfCyIBl+3nrmXuyLM5Y28GN6+CZ77VuB93SymMXFw+ZvBiwBdEQqdED/j93Z/8Mun27U6MSFj1NDvNi4BjvRZ1ObOTZnawKBl4Ek2qstdu3DU1TankytkR18LGz4OpBRxB02RhP3ke2H7Ijvv8+mfAoKRlA6/3Biolz0Ovv2f8PPvKYRfdQpcu2sNDz4DvvWE/3u6uN+re22hgjPlTvs/Ss6waT/8XMTNgK6kPoSZ/uNjefxSOyG5tXA/lz45j9raRmws4jdZ6vqqvZ2I98+Y1t3mePKSfZS9dyOIKkusL//U++t//6SO1v0TKZNrpJDP+A7W1XWZJ813ahe7QFDE+o1P+0397+1eu8RY33nd67gC0Yj9OJrKiPPtfWNWQzcFEdt5neCza5lL0NxMiPB+9xW46GnCiLSSuj6OnBpYaQ7WgnDdlJe/Zfci8Y6gY2Ks2/Haj4Nf5+hr4eoP7W/PL+LH/f5GNmDduZ27qYUBJ9l5tTOcCL0zfmcHPK6FPMQJjx16lg0EcNvpfl9egZg6Da52FqB1GQw3LbeWwj2F4VFdDSEC33k+EGXovm+PIyPPlbm4g6hI31WPI2HqCwFXU0NrpA6QqFoQysExtHs6Q7unc/NpQ/h0zW6+WF/Aws17OSonwkKt+nB9ml5R8P6o4lPsD/ruvXCfMyIefBrcvs2eIzEw7geB+ld/1HDe+0h4LYhJPwukPXZHtv1P8D/v8jf9y724QnD8LQG3FwTWDbjhsc1J7/Hwg3eD13s0F3c3YPF4I15CrbnBEcIjG1qs6EdCsp1futd5v6R0K9h9JgSHjHppzII/P27f3nAbXddjek/b2XoHLb3GBSK9frY88txHlhP3MsGzDnfIGf51m7r1rsswzzqTU+6zVtaY7zV8nrtJ2BEXBcpi4q2YfevxgMD0Hm/31uh3/IG1rwFUIA4Drp8ykMsm9iX31x/wxtdbD0wgXDeIVyC8naU72o+JsfMKoXMW94TsoOb9EzYV75//+Fs8AtHAIqPGMPRsO2LzZrkFOxq8YkZwlFVz0ndidF63IRo77+DlQCwIl5PvhQ/utROuIpHF4WCIFOrrZfh5/t9zKB3rcb2kZFmLoqXIHAAn3dW4uilZcMuG4AitO3cCEuyWO+JCGxXY0AruA0QF4jAhLSmes0b14PkvN5OaGMc5R/bkiF5NiJd2R1FeF1OkaKIomat1eEdj3jZ4heOU+w7Mrypi14X4kXNs01/vUCeSG6/ecw5w/QdYiy/3Kv/V3i1Jfd9zWyE0pYuf61gkauIAOgdxWPHTkwYzrm9nHvtkPd/6x+dU1TQysgkCkRuNSWXRknjFwvv42J+0/Q6gtTjQBYIurS0OSouhAnEY0SczmVevm8gVx+RQWV3L2vwmLI6J5IftOda/XGm7HIjVobRLVCAOM0SESyfaydAleYWNi2qCwBxEaLK+q96HOw/vNCXtnu4jg9e0NMTBWhBKu0HnIA5D+mWmkJYYxy9f+4YZ3+zg31eOb/gk17UUmu67oXA75dDHG87bGNxJ6j6tNLGuHDaoBXEYEhMjXDfZrpj+ePUurnt2Ib95ZwVFZT47zrm40S5+++Eq7YuYGLvi+Lsvt3ZLlEMcHT4epvzf5AGMyu7IpU/O491lNjX4zKU7ePiSMYzu3Sn8hAEnwvhr/fO6tAY9xx5cuKVycIRmJlUUH8R3B7PDkNzcXLNgwYLWbkaLU1hWyR1vLGXVjhK2F+4nRoS5t59ESuJhpP37Cuyq1qauVFUU5aARkYXGGJ9t7FQg2hSfrN7FZU/NA+CYAZm8cPWEBs5QFKW9U59A6BxEGyI3J5C//vN1BRSUVrRiaxRFOdxRgWhDJCfE8YNjczhthHXVfLxaw1cVRTlwVCDaGPecM4JHpo6hS1oid7y+lI1N2WxIURTFgwpEGyQxLpbXrjuG2Bjhxmlfs3dfZWs3SVGUwxAViDZKn8xkHv7OaFbuKOHyp+extXA/Hyzfyc2vLMYYQ0FpReNXYSuK0i7RKKY2zvNfbuKO15f6Hrv5tCFcP2Wg7zFFUdoHGsXUjjn3yMipu99cvK0FW6IoyuHGYbSaSjkQ0pLimXPLFBLjYoiPjeH4P8yipNxutbhyRwkLN+3hwRkr+b/JAzhpmC5UUxQlgFoQ7YDeGcl0TU+ic0oCi+4O3obywn98wcJNe3novdWt1DpFUQ5VVCDaGbExwl1nDw8r31a4n/IqTeSnKEoAFYh2yFWT+vHpL6cwob/d0nDykC4U7a9i6F3vctNLi6iqqcUYQ35xOfe9uZz9lSocitIeiapAiMjpIrJKRNaKyK311LtQRIyI5HrKbnPOWyUip0Wzne2R7M7JvPDDCTx71XievPwoju5nxeK/X29l+N3vctIfP+aGF7/mqc828LdZa3Cj3f77VR5H/uo9tTYUpR0QNYEQkVjgUeAMYDgwVUTCfBsikgb8BPjSUzYcuAQYAZwO/N15PaUZiYkRjhvUhdgY4cWrJ7Dy/tMBqKoxbN5TxrwNewB4dNY6/j57HQC3vLqEov1VrN+lK7QVpa0TTQtiPLDWGLPeGFMJTAPO86l3P/A7oNxTdh4wzRhTYYzZAKx1Xk+JEjExQlJ8LE//4CiG9Uhnxk+O41tjenHlsf0AeOTDNfzxvVVUO4vr1u4K3g9bF90pStsjmmGuvYAtnud5wNHeCiIyFuhtjHlbRG4OOXduyLm9otVQJcCUIV2ZMqQrAH/6zmgArj2hP1Mfn8tfP1pbV++D5TvZX1lNWlI8n63dzfyNe5h+wySS4mNZs7OErmlJdEyO5+nPNtAvK4XJzmsqinL40GrrIEQkBvgTcMVBvMY1wDUAffr0aZ6GKWF0S0/iw5+fwN3/W8ba/FJ2FpczffE2pocstPvZS4volp7EM59v5JTh3Ti6Xwa/fnsFABt/e1ZdvX/MXsekgVmMzO7YotehKErTiKZAbAV6e55nO2UuacARwGwRAegOTBeRcxtxLgDGmMeBx8Gm2mjOxivBiAj3n38Exhh2FJezo6icrNRElm0rpqqmlpnLdvDWku119d9fvpP3l++se15eVcO2wv2c+MePAetTfP3/jqFbehIGiIsRuqYl4vwWmkx1TS0n/GE2N582hPPHqLGpKM1B1HIxiUgcsBo4Cdu5zwe+a4xZFqH+bOAXxpgFIjICeAE779AT+BAYZIyJGDqjuZhal9paw+frCvjDzJUM6Z7Gywvy+PGJA0lPiueBGdaK6JuZzKaCMt/z05Pi6JAQy0Xjsrn5tKH86LmFJCfE8dDFoxolGpsK9nHCH2aTEBfD6l+f0azXpihtmfpyMUXNgjDGVIvIDcBMIBZ4yhizTETuAxYYY6bXc+4yEXkZWA5UA9fXJw5K6xMTI0walMWkQZOorTVcNK43R+V0pryqloJ9lby8YEuQOJw5sjsiwtuO1VFcXk1xeTWPzlpHxw7xvLN0BwBvLdlGv6wUbjplMIu2FDIquxOnDu9GTIxQUV3D3W8s4/sT+vLs3I22HQdmgCiK4oNmc1VahKKyKk7/yydsL7LBat45iYrqGm7/71Je+yov6JyThnalY3I8//0q2Lv416ljGN4znZMcd5WXDvGxrHDCdV3W7yolMzWRjh3i68oqq2vZvKeMgV1TD/raFOVwplUsCEXx0jE5nrdvPI7YGCE5IXhJS2JcLH/89pGM79eZX772DUnxMVTXGH530SiyUhNJTYzjP19sqqv/0HuryMlM8X2fyppa9lVUExcr7C6tZF1+KZc9Nc+ed/GRLN1axNi+nfkmr5B/zdnA7F9MJifL/7X82LKnjC5piSTF22twV5l3SNBlOkrbQy0I5ZChuqaWd5bu4JTh3diyp4xB3dIAKCit4JZXl3DHWcP4ZmsRP5m2CIBfnDqYET078oNn5gOQkZLAHs/uebExQo3P+ozEuBi6pCWSt3c/qYlxvH/T8RSUVvL8l5tYl7+P31w4kgFdwi2LncXlHP3gh3RNS+Tec0dw5sgeHPXAB1TV1IYlQVSUwwW1IJTDgrjYGM5x9q9wxQEgMzWRJ684CoC+mSkUllUxpHsaE/pnsqukoq7e/DtO5tuPfcH6XaXsLavCGMPE/pl8sb4AgFtOH8ILX24mb+9+8vbuB6C0oppHZ63lnW92UOCIy93/W8qTlx/FL15ZzJQhXblwXDZvLdnGywusCyy/pIL/e/4r7jxrWN37G2N4ecEWCsuquPaEAb7X9/na3SBwzICs5vzYFCVqqAWhHPbk3Po2PTom8cVtJ1FTa4gR+GTNbgZ2TaVnxyRqag27Sivo0bEDa/NLuPTJeZwwuAt3nT2cm19dzIxv7IT4vy7LZd2uUn77zkqOG5TFnDW76Z+VwrUn9OeXr33T6PZ8eftJdElNpMYY4mMDyQpybn0bgAV3nkxWaiIAz83dxMCuqUzon9mMn4iiNJ76LAgVCOWwZ8ueMlIS48hISWjyuTuLy7n22YWcObI71xw/gPySciY8+CENZQ755/fHct1zX0U8Pj4ngzX5JTx+WS7De6RTawwj730PgJSEWP72vbGM6JHO+Ac/BOCtH0/iiF6RFw5W1dRSUl5NRkoCxhiqaqwQxsVqQmbl4FCBUJQmcNlT89i6t4xvjc3mDzNX+db58Ocn8JsZK/hgRT4AvTp14Owje/DYx+uD6nWIj6WqppaMlATySyq4fGJfXpy3hcqaWvpkJLN5TyD0d94dJ9E1LQmwgrBnXyV5e/czomc6p/z5Y7bs2U9SfAzlVbUAfGtsL/548ZHU1Bo+WpnP11sK6ZORzNTxfaiqqeWjlfn07pxMrTH0zkhmX0U1PTt1aPD6q2tque+t5Xz36D4M7Z4edmz59mJGZXdq9OepHNqoQChKEyirrKbWWMvk0ie/5CcnDybZiVo6dUQ3lm4tZuKATIrKqnj96zwum5hDjGcBxhNz1tM1PYn84vK6VCMxAl3SEnnvpyeQX2LL80sqOKJnOq8sDIT3njysGws37WFvWVVdWb+sFDbsjpw9Nz5WqKoJ/I9PH9Gdd5ftCKojAklxsfzf5AFMGpTFqOxOrN5Zwi2vLuGYAZl8f0JfenbqwJ59lSzJK+Sqfy9gWI90pt9wLHe+vpQLxvYit29nnvh0A799ZyWvXDeRnp068Nna3RyZ3YmPVuZzzpE9KNpfxYiemkLlcEIFQlFageqaWu6evoyBXVI5d3RPkhNiSU4Ijwspq6zm2S82sWH3PqbNt/ktY4QG3VwuuX07s2DTXt9jp43oxsxlO0mMi6GiurauPDTiy8vIXh35ZmsRCXExfHd8H575fCMA4/p2plt6Yt2cTSQ2/OZMjIEbXvyKc0b1ZNXOEpZuLeaJy337oBalvKqGX7+9nBtPHETX9KTWbs4hgUYxKUorEBcbw4MXjGywXnJCXF3kU3bnDizJK+KRqWN48tMNFJdXsWDjXo4dmMUPjslhZ0k5a/NL2VFUTlllDcu3FfPPS8fVTYBfcUwOa/NLGd8vg9NGdGdI90A02NEPfsDOYht15YrDnWcNq7NyXL7ZWsSE/hmszd9XJw4ACyOIUChL8op4Z+kOZnyzI0hMvt68l9TEOAZ1S2N3aQVZqYks3lJISmIsA7vadi7bVsSSvCKmjrfJN8uranj96618O7c3xhi+2lzIUTmdqTUwb8Meju6XEWS9gRXczXvKwtxjALNW5vPc3M2Ullfz8CVjGnU97RkVCEU5hLjhxEF1j6+fMjDseOeUBN+Oz7Ui7jlneMTcVX/+zmj+9N5qJvTPZPKQLozr2xkRYeGmvbyzdAe/OHUw24vKef7LzVw6IYcNu0t56L3VdeePyu7Iyu0l3Hn2MFbtKOH5Lzfzx4uP5OevLA56n/Me/SzoeafkeArLqrjg758D8OMTBwaljgfrFuuQEMvrX9tV84lxMZw1qgd3vbGUVxbm8cKXm/lmaxEA9583gm1F5fxj9jruPWc4l03M4Z2lOziqX2d2FlXw3SfmUlJezZJ7TyU9KZ7qmlpeXpDHV5v3EueISUGI9VRYVklpRTXZnZMxxjBrVT65ORmkJ8VzKDN/4x5+8PR8Zv1iMl3SEpv99dXFpChtgLLKakorqusmuZvCH2au5NFZ63j2qvEclZPB9EXbuHBcNlU1tUybt5nJQ7oyY+l2rjveWjniuL/KnP1AVu0oYc6aXfz67RVkpSayr6Kau88Zzh4nB9ej3x3L2X/9NOL7T+yfyZcbCoJcajmZydQagibx/eiensQpw7vx7NxNYW60n548iEFd07j+Bf9osyuOySE3pzMLNu5l3a5S5qzZzYMXjOSl+ZtZnFfEVZP6cdfZYZtgUlNreHPxNpbkFXHlpBw6JSdw8yuLqak1DO6WxknDujKmT2eKy6tIjo/1jTRbvbOETQVlnDysK7NX7+K4gVlh9ZZvK2bGN9v52SmDifVJMrapYB83v7KEeRv38M/vj+P0I7rX+1lFQucgFEWJSEV1DbNW7uK0Ed0OON062FF4xw7xVFTX1qUiAbuI8NjffkS3jkn86twRPDhjBaeP6M7lx+RQWFZF55QE8kvK+XjVLm5+dQld0hLZVVJB9/QkYmOEPfsqGd27E8N6pFNRXcPzX24G4Nrj+/PaV1vZXVpBp+R4UhLi2Fq4P2L7ThneLSgFfSTiYqRu58RLjurNnn2VnDK8G8Xl1QzrkcZfP1xbt/hyeI90lm8vDnuNa0/oz2MfrydG4PFLcxndpxNpSXGUllezckcJ1z23kJLyaqaO78OL8zZz0ymDGdwtDRE4bUR3amsNuQ98wJ59lfz6/CP4/oS+gA2c6J2RzLtLtweFWd9//hFc6tRpKioQiqK0KuVVNSTGxdQrQMYYZq/exdH9Mvh0zW5OGNKFxLjwHFefrN7Fwx+s5rkfHk1CbAx79lWS3iGePfsqmfHNdo4ZkMXb32zjyU83MLp3J/pkJHPMgCzOObInpz/8CeP6dubWM4Yyd/0evtxQwDd5RSzZWsTQ7mksySvi9jOHsrGgjBccIcpMSQhzSd140iD27Kvgubm2zsheHXlk6hhqjeGuN5by+bqCsHb3zujAzuIKKj1Wjh+piXGcMKRLXabjYT3S+c+V4/nduyt5dWEef7hoFP/+YiNLtwaE6Zrj+3P7mcPqfd1IqEAoiqJgRchPpGprDcu2FfPqwi3cefZwNhXs4z9fbOKXpw8lKT6WGd9sZ8++ShLjYoiNES4Y04vP1xVw2VPz+OPFR3LhuOy619pWuJ9jfvsRAEf3y+DLDXvqjqUmxlFaUU1sjPD5rSdy7/RlrNhezEaffVIGdk3l27nZPDhjZYPXddqIbjx26YFFialAKIqiRIFNBfvo65NZ+PkvN/Hxql08flkuS/IKSYiL4e43lvH7i0YBkJoUV5duBWxI9OK8In7/7kp6ZyTz6sI8/nLJaI4f1IXLn57HkryisPf4w0Wj6JAQy3+/2sqOonJm/OS4A7oGFQhFUZTDhNpaw6K8Qsb07oSIUF5Vw98+WsvwnumM7NWRhLgYpi/axlWT+hETIxSWVZKSGBeU96spqEAoiqIovtQnEJrpS1EURfFFBUJRFEXxRQVCURRF8UUFQlEURfFFBUJRFEXxRQVCURRF8UUFQlEURfFFBUJRFEXxpc0slBORXcCmg3iJLGB3MzXncEGvuX2g19w+ONBr7muM6eJ3oM0IxMEiIgsirSZsq+g1tw/0mtsH0bhmdTEpiqIovqhAKIqiKL6oQAR4vLUb0AroNbcP9JrbB81+zToHoSiKoviiFoSiKIriiwqEoiiK4ku7FwgROV1EVonIWhG5tbXb01yIyFMiki8iSz1lGSLyvoisce47O+UiIo84n8ESERnbei0/cESkt4jMEpHlIrJMRH7ilLfZ6xaRJBGZJyKLnWv+lVPeT0S+dK7tJRFJcMoTnedrneM5rXoBB4GIxIrI1yLylvO8TV+ziGwUkW9EZJGILHDKovrbbtcCISKxwKPAGcBwYKqIDG/dVjUbzwCnh5TdCnxojBkEfOg8B3v9g5zbNcA/WqiNzU018HNjzHBgAnC983225euuAE40xhwJjAZOF5EJwO+APxtjBgJ7gauc+lcBe53yPzv1Dld+AqzwPG8P1zzFGDPas94hur9tY0y7vQETgZme57cBt7V2u5rx+nKApZ7nq4AezuMewCrn8WPAVL96h/MN+B9wSnu5biAZ+Ao4GruiNs4pr/udAzOBic7jOKeetHbbD+Bas50O8UTgLUDawTVvBLJCyqL6227XFgTQC9jieZ7nlLVVuhljtjuPdwDdnMdt7nNw3AhjgC9p49ftuFoWAfnA+8A6oNAYU+1U8V5X3TU7x4uAzBZtcPPwMHALUOs8z6TtX7MB3hORhSJyjVMW1d923IG2VDm8McYYEWmTMc4ikgq8BvzUGFMsInXH2uJ1G2NqgNEi0gl4HRjaui2KLiJyNpBvjFkoIpNbuTktySRjzFYR6Qq8LyIrvQej8dtu7xbEVqC353m2U9ZW2SkiPQCc+3ynvM18DiISjxWH540x/3WK2/x1AxhjCoFZWPdKJxFxB4De66q7Zud4R6CgZVt60BwLnCsiG4FpWDfTX2jb14wxZqtzn48dCIwnyr/t9i4Q84FBTvRDAnAJML2V2xRNpgOXO48vx/ro3fLLnMiHCUCRx2w9bBBrKjwJrDDG/MlzqM1et4h0cSwHRKQDds5lBVYoLnKqhV6z+1lcBHxkHCf14YIx5jZjTLYxJgf7n/3IGPM92vA1i0iKiKS5j4FTgaVE+7fd2hMvrX0DzgRWY/22d7R2e5rxul4EtgNVWP/jVVi/64fAGuADIMOpK9hornXAN0Bua7f/AK95EtZPuwRY5NzObMvXDYwCvnaueSlwt1PeH5gHrAVeARKd8iTn+VrneP/WvoaDvP7JwFtt/Zqda1vs3Ja5fVW0f9uaakNRFEXxpb27mBRFUZQIqEAoiqIovqhAKIqiKL6oQCiKoii+qEAoiqIovqhAKO0GEekmIi+IyHonXcEXInKBc2yymxW0nvPvFZFfNPE9SyOU3+FkX13iZOc82in/qYgkN+U9FCVaqEAo7QJnEd0bwCfGmP7GmHHYRVbZrdCWicDZwFhjzCjgZAJ5c36KTbqnKK2OCoTSXjgRqDTG/NMtMMZsMsb8NbSik2P/DWd0P1dERnkOH+lYHmtE5GqnfqqIfCgiXzn5+s9roC09gN3GmAqnHbuNMdtE5EagJzBLRGY5r32q835ficgrTp4pd2+A3zvvN09EBjrlF4vIUrH7Q3xy4B+XoqhAKO2HEdhU2I3hV8DXzuj+duA/nmOjsGIzEbhbRHoC5cAFxpixwBTgj+LNEBjOe0BvEVktIn8XkRMAjDGPANuwOf+niEgWcCdwsvPaC4CbPK9TZIwZCfwNm90U4G7gNGP3hzi3kderKL6oQCjtEhF51Bllz/c5PAl4FsAY8xGQKSLpzrH/GWP2G2N2Y3P/jMemNXhQRJZg0x30IpB2OQxjTCkwDruRyy7gJRG5wqfqBOxGVp856bwvB/p6jr/ouZ/oPP4MeMaxbmIjfwKK0jCa7ltpLywDLnSfGGOud0boC5r4OqG5aQzwPaALMM4YU+VkGU2q90Vsiu7ZwGwR+Qbb+T8TUk2A940xUxvRFuO87nXOhPdZwEIRGWeMOewylyqHBmpBKO2Fj4AkEfmRpyzSZPAcbKePs9/AbmNMsXPsPLH7QGdiE8XNx6aPznfEYQrBo/wwRGSIiAzyFI0GNjmPS4A05/Fc4FjP/EKKiAz2nPcdz/0XTp0BxpgvjTF3Y60Tb8pnRWkSakEo7QJjjBGR84E/i8gt2M5zH/BLn+r3Ak85LqMyAumUwWZNnQVkAfc7k8vPA286lsACYCX1kwr81UnTXY3NMuruEPY48K6IbHPmIa4AXhSRROf4ndjswwCdnTZWAK6V8QdHfASb5XNxA21RlIhoNldFOQxx3Fi5zlyIokQFdTEpiqIovqgFoSiKoviiFoSiKIriiwqEoiiK4osKhKIoiuKLCoSiKIriiwqEoiiK4sv/A0aRLeWm4BuUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "epochs=[]\n",
    "for x in range(500):\n",
    "    epochs.append(x)\n",
    "plt.plot(epochs, train_loss_list, label='Train')\n",
    "plt.plot(epochs, valid_loss_list, label='Valid')\n",
    "\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"Transformer 500 epochs.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "974bdcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8598    0.8214    0.8402       112\n",
      "           0     0.9127    0.9330    0.9227       224\n",
      "\n",
      "    accuracy                         0.8958       336\n",
      "   macro avg     0.8862    0.8772    0.8815       336\n",
      "weighted avg     0.8950    0.8958    0.8952       336\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(model, test_loader, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (labels, (notes, notes_len)), _ in test_loader:           \n",
    "            labels = labels.to(device)\n",
    "            notes = notes.to(device)\n",
    "            notes_len = notes_len.cpu()\n",
    "            output = model(notes.long())\n",
    "\n",
    "            output = np.argmax(output.cpu().detach(), axis=1)\n",
    "            y_pred.extend(output.tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['INSTRUMENTAL SOLO', 'VOCAL'])\n",
    "    ax.yaxis.set_ticklabels(['INSTRUMENTAL SOLO', 'VOCAL'])\n",
    "    \n",
    "    \n",
    "best_model = TransformerModel(ntokens,emsize,nhead,d_hid,nlayers,dropout).to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)\n",
    "evaluate(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "489aefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intro = pd.read_csv(source_folder + '/test.csv')\n",
    "melodies = df_intro['melody'].values\n",
    "labels = df_intro['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ad951e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '104', '28', '67', '73', '27', '7', '68', '43', '27', '29', '67', '73', '27', '10', '60', '43', '27', '37', '41', '43', '27', '11', '67', '43', '27', '30', '67', '73', '31', '32', '60', '43', '27', '33', '71', '73', '31', '18', '21', '43', '31', '24', '19', '42', '27', '20', '67', '43', '31', '0', '1', '19', '43', '27', '28', '21', '43', '27', '7', '16', '73', '27', '29', '67', '44', '31', '10', '66', '73', '27', '37', '67', '73', '27', '11', '71', '73', '27', '30', '67', '43', '25', '15', '16', '12', '27', '33', '41', '42', '77', '0', '29', '68', '44', '27', '10', '68', '73', '27', '37', '60', '73', '27', '11', '78', '73', '27', '30', '78', '73', '27', '32', '71', '73', '31', '33', '74', '43', '27', '18', '16', '42', '27', '24', '60', '42', '27', '20', '67', '42', '27', '0', '1', '21', '79', '27', '28', '4', '79', '27', '7', '19', '22', '27', '29', '4', '42', '25', '37', '78', '12', '31', '30', '67', '12', '89', '26', '16', '12', '27', '0', '1', '34', '42', '9', '32', '4', '79', '25', '15', '60', '22', '101']\n"
     ]
    }
   ],
   "source": [
    "test_instance = [x.lower() for x in melodies[0].split(' ')]\n",
    "print(test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "050a723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 30, 158, 20, 41, 47, 6, 18, 14, 40, 6, 25, 41, 47, 6, 11, 9, 40, 6, 34, 8, 40, 6, 19, 41, 40, 6, 26, 41, 47, 2, 36, 9, 40, 6, 37, 15, 47, 2, 16, 65, 40, 2, 42, 53, 23, 6, 28, 41, 40, 2, 4, 7, 53, 40, 6, 20, 65, 40, 6, 18, 12, 47, 6, 25, 41, 60, 2, 11, 17, 47, 6, 34, 41, 47, 6, 19, 15, 47, 6, 26, 41, 40, 5, 21, 12, 27, 6, 37, 8, 23, 69, 4, 25, 14, 60, 6, 11, 14, 47, 6, 34, 9, 47, 6, 19, 32, 47, 6, 26, 32, 47, 6, 36, 15, 47, 2, 37, 59, 40, 6, 16, 12, 23, 6, 42, 9, 23, 6, 28, 41, 23, 6, 4, 7, 65, 38, 6, 20, 24, 38, 6, 18, 53, 44, 6, 25, 24, 23, 5, 34, 32, 27, 2, 26, 41, 27, 84, 33, 12, 27, 6, 4, 7, 10, 23, 45, 36, 24, 38, 5, 21, 9, 44, 103]\n"
     ]
    }
   ],
   "source": [
    "tokens = [text_field.vocab.stoi[token] for token in test_instance]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e136c5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7095e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 3.1082e-20],\n",
      "        [1.0000e+00, 1.5642e-24],\n",
      "        [4.9197e-25, 1.0000e+00],\n",
      "        [3.2338e-24, 1.0000e+00],\n",
      "        [8.6531e-26, 1.0000e+00],\n",
      "        [9.0611e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 4.7799e-22],\n",
      "        [2.2345e-25, 1.0000e+00],\n",
      "        [1.9060e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0706e-19],\n",
      "        [1.0000e+00, 6.4574e-22],\n",
      "        [2.6405e-23, 1.0000e+00],\n",
      "        [8.8408e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 1.4071e-19],\n",
      "        [1.0000e+00, 6.3143e-22],\n",
      "        [1.0000e+00, 2.6471e-23],\n",
      "        [8.5144e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 8.6398e-19],\n",
      "        [1.0000e+00, 1.9478e-24],\n",
      "        [4.3017e-24, 1.0000e+00],\n",
      "        [8.6894e-22, 1.0000e+00],\n",
      "        [6.1413e-16, 1.0000e+00],\n",
      "        [1.0000e+00, 4.7866e-24],\n",
      "        [7.0811e-25, 1.0000e+00],\n",
      "        [3.9402e-23, 1.0000e+00],\n",
      "        [5.7394e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 1.1796e-21],\n",
      "        [6.6878e-16, 1.0000e+00],\n",
      "        [7.8062e-23, 1.0000e+00],\n",
      "        [7.2688e-15, 1.0000e+00],\n",
      "        [1.0000e+00, 2.5386e-21],\n",
      "        [8.1365e-25, 1.0000e+00],\n",
      "        [1.7223e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 3.4686e-08],\n",
      "        [1.0000e+00, 2.5082e-24],\n",
      "        [1.0000e+00, 4.0386e-10],\n",
      "        [1.5809e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 6.4766e-09],\n",
      "        [1.0000e+00, 1.3270e-20],\n",
      "        [7.8464e-25, 1.0000e+00],\n",
      "        [1.7424e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 2.9078e-08],\n",
      "        [1.0000e+00, 5.6173e-24],\n",
      "        [2.2786e-25, 1.0000e+00],\n",
      "        [2.6592e-14, 1.0000e+00],\n",
      "        [2.6643e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 1.2477e-24],\n",
      "        [2.5501e-25, 1.0000e+00],\n",
      "        [8.3241e-25, 1.0000e+00],\n",
      "        [1.9643e-21, 1.0000e+00],\n",
      "        [1.0000e+00, 5.3895e-24],\n",
      "        [2.1045e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 4.5832e-21],\n",
      "        [1.9536e-24, 1.0000e+00],\n",
      "        [9.9974e-01, 5.3109e-04],\n",
      "        [1.0000e+00, 6.6029e-20],\n",
      "        [7.4850e-20, 1.0000e+00],\n",
      "        [3.8885e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0105e-11],\n",
      "        [1.0000e+00, 5.1600e-23],\n",
      "        [2.8230e-24, 1.0000e+00],\n",
      "        [2.4970e-24, 1.0000e+00],\n",
      "        [1.4173e-22, 1.0000e+00],\n",
      "        [1.0000e+00, 3.8397e-24],\n",
      "        [6.0345e-25, 1.0000e+00],\n",
      "        [4.6747e-25, 1.0000e+00],\n",
      "        [3.4870e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6735e-23],\n",
      "        [8.2370e-24, 1.0000e+00],\n",
      "        [1.9218e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 1.9042e-23],\n",
      "        [1.0000e+00, 3.9511e-23],\n",
      "        [3.0428e-23, 1.0000e+00],\n",
      "        [3.8840e-23, 1.0000e+00],\n",
      "        [1.6886e-18, 1.0000e+00],\n",
      "        [1.0000e+00, 1.4431e-22],\n",
      "        [9.7101e-25, 1.0000e+00],\n",
      "        [1.0497e-22, 1.0000e+00],\n",
      "        [1.0000e+00, 1.2770e-20],\n",
      "        [1.0000e+00, 3.5084e-23],\n",
      "        [4.0304e-20, 1.0000e+00],\n",
      "        [4.3962e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 1.1946e-18],\n",
      "        [1.0000e+00, 2.0237e-22],\n",
      "        [1.4003e-18, 1.0000e+00],\n",
      "        [7.5752e-24, 1.0000e+00],\n",
      "        [4.9695e-22, 1.0000e+00],\n",
      "        [1.0000e+00, 9.4009e-23],\n",
      "        [1.9897e-05, 9.9988e-01],\n",
      "        [1.6341e-24, 1.0000e+00],\n",
      "        [2.6963e-23, 1.0000e+00],\n",
      "        [3.6411e-24, 1.0000e+00],\n",
      "        [1.8054e-23, 1.0000e+00],\n",
      "        [3.8389e-24, 1.0000e+00],\n",
      "        [4.9344e-22, 1.0000e+00],\n",
      "        [9.5096e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 4.0125e-23],\n",
      "        [1.3649e-09, 1.0000e+00],\n",
      "        [1.8241e-25, 1.0000e+00],\n",
      "        [1.6530e-15, 1.0000e+00],\n",
      "        [1.0000e+00, 5.3197e-23],\n",
      "        [2.0711e-24, 1.0000e+00],\n",
      "        [1.1360e-23, 1.0000e+00],\n",
      "        [3.2094e-17, 1.0000e+00],\n",
      "        [1.0000e+00, 1.9357e-23],\n",
      "        [6.5224e-25, 1.0000e+00],\n",
      "        [4.0370e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 5.6493e-22],\n",
      "        [1.0000e+00, 1.4597e-24],\n",
      "        [9.9913e-01, 3.8872e-03],\n",
      "        [2.3018e-23, 1.0000e+00],\n",
      "        [1.8329e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 6.6082e-22],\n",
      "        [1.7520e-21, 1.0000e+00],\n",
      "        [6.7603e-22, 1.0000e+00],\n",
      "        [1.0000e+00, 6.4119e-16],\n",
      "        [1.0000e+00, 9.1874e-25],\n",
      "        [1.0000e+00, 2.5296e-20],\n",
      "        [2.4481e-22, 1.0000e+00],\n",
      "        [1.0000e+00, 4.2398e-20],\n",
      "        [1.0000e+00, 5.4441e-22],\n",
      "        [2.6412e-23, 1.0000e+00],\n",
      "        [2.2684e-24, 1.0000e+00],\n",
      "        [2.0196e-20, 1.0000e+00],\n",
      "        [1.0000e+00, 3.8670e-23],\n",
      "        [9.7145e-23, 1.0000e+00],\n",
      "        [1.1477e-23, 1.0000e+00],\n",
      "        [4.7240e-17, 1.0000e+00],\n",
      "        [1.0000e+00, 9.7629e-23],\n",
      "        [7.9462e-25, 1.0000e+00],\n",
      "        [7.1161e-26, 1.0000e+00],\n",
      "        [8.5858e-21, 1.0000e+00],\n",
      "        [1.0000e+00, 3.4280e-23],\n",
      "        [1.8051e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 1.5920e-22],\n",
      "        [1.5010e-25, 1.0000e+00],\n",
      "        [1.0408e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 2.2793e-23],\n",
      "        [8.6683e-24, 1.0000e+00],\n",
      "        [8.9439e-25, 1.0000e+00],\n",
      "        [1.3842e-05, 1.0000e+00],\n",
      "        [1.0000e+00, 4.3272e-22],\n",
      "        [2.6803e-24, 1.0000e+00],\n",
      "        [1.3306e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 1.2703e-19],\n",
      "        [1.0000e+00, 5.9403e-23],\n",
      "        [1.0167e-23, 1.0000e+00],\n",
      "        [7.4175e-25, 1.0000e+00],\n",
      "        [4.1940e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 2.0901e-14],\n",
      "        [4.0896e-23, 1.0000e+00],\n",
      "        [2.3606e-24, 1.0000e+00],\n",
      "        [3.1786e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6061e-24],\n",
      "        [2.9435e-15, 1.0000e+00],\n",
      "        [7.8066e-23, 1.0000e+00],\n",
      "        [7.0341e-22, 1.0000e+00],\n",
      "        [3.0958e-26, 1.0000e+00],\n",
      "        [3.6766e-25, 1.0000e+00],\n",
      "        [2.1298e-23, 1.0000e+00],\n",
      "        [3.6330e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 5.2179e-22],\n",
      "        [1.0570e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 3.8810e-23],\n",
      "        [2.4646e-24, 1.0000e+00],\n",
      "        [3.3922e-22, 1.0000e+00],\n",
      "        [3.0265e-23, 1.0000e+00],\n",
      "        [1.0081e-24, 1.0000e+00],\n",
      "        [7.9502e-24, 1.0000e+00],\n",
      "        [1.5745e-18, 1.0000e+00],\n",
      "        [1.0000e+00, 9.5047e-22],\n",
      "        [1.5464e-23, 1.0000e+00],\n",
      "        [2.3189e-24, 1.0000e+00],\n",
      "        [6.3876e-19, 1.0000e+00],\n",
      "        [2.4839e-24, 1.0000e+00]], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "tensor_tokens = torch.LongTensor(tokens).unsqueeze(1).to(device)\n",
    "outputs = model(tensor_tokens)\n",
    "attention = outputs\n",
    "print(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "063e23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "AutoConfig.register(\"POP-MODEL\", TransformerModel)\n",
    "AutoModel.register(TransformerModel,best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910ed685",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://huggingface.co/api/models/POP-MODEL",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28696/639925203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POP-MODEL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POP-MODEL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_from_auto\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             configuration_file = get_configuration_file(\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_configuration_file\u001b[0;34m(path_or_repo, revision, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \"\"\"\n\u001b[1;32m    842\u001b[0m     \u001b[0;31m# Inspect all files from the repo/folder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m     all_files = get_list_of_files(\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0mpath_or_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m     )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_list_of_files\u001b[0;34m(path_or_repo, revision, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   2101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist_repo_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mlist_repo_files\u001b[0;34m(self, repo_id, revision, repo_type, token, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \"\"\"\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrepo_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             info = self.model_info(\n\u001b[0m\u001b[1;32m    603\u001b[0m                 \u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mmodel_info\u001b[0;34m(self, repo_id, revision, token, timeout)\u001b[0m\n\u001b[1;32m    584\u001b[0m         )\n\u001b[1;32m    585\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mModelInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/api/models/POP-MODEL"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"POP-MODEL\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"POP-MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf91c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
