{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022889aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator,ReversibleField\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import remi_utils as utils\n",
    "import twoencodertransformer as kk\n",
    "import pickle\n",
    "source_folder = \"solo_generation_dataset_fixed\"\n",
    "folder = \"dynamic_fixed_models/2enc\"\n",
    "destination_folder = folder + \"/solo_generation_weights\"\n",
    "generated_outputs = folder +  \"/generated_samples\"\n",
    "dissimilar_interpolation = folder + \"/interpolation\"\n",
    "vocab = folder + \"/vocab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088348f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(destination_folder).mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs).mkdir(parents=True, exist_ok=True)\n",
    "Path(dissimilar_interpolation).mkdir(parents=True, exist_ok=True)\n",
    "Path(vocab).mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/intro\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/outro\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/solo\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/predict\").mkdir(parents=True, exist_ok=True)\n",
    "Path(dissimilar_interpolation+\"/intro\").mkdir(parents=True, exist_ok=True)\n",
    "Path(dissimilar_interpolation+\"/outro\").mkdir(parents=True, exist_ok=True)\n",
    "Path(dissimilar_interpolation+\"/predict\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d9b7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "event2word, word2event = pickle.load(open('dictionary_augmented.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193a1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:1\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "print(dev)\n",
    "device = torch.device(dev)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc28e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields\n",
    "\n",
    "intro_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "intro_piano_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "outro_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "outro_piano_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "solo_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "solo_piano_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "fields = [('intro', intro_field), ('intro_piano', intro_piano_field), \\\n",
    "          ('outro', outro_field), ('outro_piano', outro_piano_field), \\\n",
    "          ('solo', solo_field), ('solo_piano', solo_piano_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='train_torchtext.csv', validation='val_torchtext.csv', test='test_torchtext.csv',\n",
    "                                           format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "BATCH_SIZE = 8\n",
    "train_iter = BucketIterator(train, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.intro),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.intro),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "test_iter = BucketIterator(test, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.intro),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "\n",
    "# Vocabulary\n",
    "\n",
    "intro_field.build_vocab(train, min_freq=1)\n",
    "intro_piano_field.build_vocab(train, min_freq=3)\n",
    "outro_field.build_vocab(train, min_freq=1)\n",
    "outro_piano_field.build_vocab(train, min_freq=3)\n",
    "solo_field.build_vocab(train, min_freq=1)\n",
    "solo_piano_field.build_vocab(train, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300385ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444\n",
      "414\n",
      "335\n",
      "509\n",
      "353\n",
      "619\n",
      "253\n",
      "326\n",
      "325\n",
      "279\n",
      "281\n",
      "272\n",
      "522\n",
      "319\n"
     ]
    }
   ],
   "source": [
    "for ((intro, intro_len), (intro_piano, intro_piano_len),\\\n",
    "     (outro, outro_len),(outro_piano, outro_piano_len),\\\n",
    "     (solo, solo_len),(solo_piano, solo_piano_len)), _ in (test_iter):\n",
    "    #print(intro.transpose(1,0).size(0))\n",
    "    print(solo.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82eec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "torch.backends.cudnn.enabled=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2906224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Tuple\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2794d9da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/seq2seq_transformer/seq2seq_transformer.py\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        src2_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_len,\n",
    "        device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.src2_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src2_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.transformer = kk.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "\n",
    "        # (N, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, src2, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        src2_seq_length, N = src2.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(src_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "        \n",
    "        src2_positions = (\n",
    "            torch.arange(0, src2_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(src2_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(trg_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
    "        ).to(self.device)\n",
    "        embed_src2 = self.dropout(\n",
    "            (self.src2_word_embedding(src2) + self.src2_position_embedding(src2_positions))\n",
    "        ).to(self.device)\n",
    "        embed_trg = self.dropout(\n",
    "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
    "        ).to(self.device)\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        src2_padding_mask = self.make_src_mask(src2)\n",
    "        #print(src_padding_mask.size())\n",
    "        #print(src2_padding_mask.size())\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_src2,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            src2_key_padding_mask=src2_padding_mask,\n",
    "            tgt_mask=trg_mask,\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e4ad3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(intro_field.vocab)\n",
    "src2_vocab_size = len(outro_field.vocab)\n",
    "trg_vocab_size = len(solo_field.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.10\n",
    "max_len = 1200\n",
    "forward_expansion = 4\n",
    "src_pad_idx = 1 #english.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    src2_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3910013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 14,997,275 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4) #non augmented 3e-4\n",
    "\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "\n",
    "def save_best_checkpoint(state, nth,filename=\"_checkpoint.pt\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "#     torch.save(state, destination_folder + str(nth)+filename)\n",
    "    torch.save(state, destination_folder + '/metrics.pt')\n",
    "\n",
    "def save_final_checkpoint(state, nth,filename=\"_checkpoint.pt\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, destination_folder + \"/\" + str(nth)+filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43049c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoi input str get int\n",
    "# intro_field.vocab.stoi\n",
    "# itos input into get token/str\n",
    "# intro_field.vocab.itos[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d99045b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "#criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b08d03f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: torch.utils.data.DataLoader,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    #for _, (src, _,trg,_) in enumerate(iterator):\n",
    "    for ((intro, intro_len), (intro_piano, intro_piano_len),\\\n",
    "     (outro, outro_len),(outro_piano, outro_piano_len),\\\n",
    "     (solo, solo_len),(solo_piano, solo_piano_len)), _ in (iterator):\n",
    "        src, src2, trg = intro.transpose(1,0), outro.transpose(1,0), solo.transpose(1,0)\n",
    "        src, src2, trg = src.to(device), src2.to(device), trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src ,src2, trg[:-1, :])\n",
    "        \n",
    "#         print(output.size())\n",
    "#         print(trg.size())\n",
    "        \n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        loss = criterion(output, trg)\n",
    "#         print(torch.isfinite(trg).all().cpu().item())\n",
    "#         print(torch.isfinite(output).all().cpu().item())\n",
    "#         print(torch.isfinite(loss).all().cpu().item())\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.cpu().detach().item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             iterator: torch.utils.data.DataLoader,\n",
    "             criterion: nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        #for _, (src, _,trg,_) in enumerate(iterator):\n",
    "        for ((intro, intro_len), (intro_piano, intro_piano_len),\\\n",
    "         (outro, outro_len),(outro_piano, outro_piano_len),\\\n",
    "         (solo, solo_len),(solo_piano, solo_piano_len)), _ in (iterator):\n",
    "            src, src2, trg = intro.transpose(1,0), outro.transpose(1,0), solo.transpose(1,0)\n",
    "            src, src2, trg = src.to(device), src2.to(device), trg.to(device)\n",
    "\n",
    "            output = model(src, src2, trg[:-1, :]) #turn off teacher forcing\n",
    "\n",
    "            output = output.view(-1, output.shape[-1])\n",
    "            trg = trg[1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.cpu().detach().item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71aa22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, sentence2, intro, outro, solo, device, max_length=1200):\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    tokens = [token.lower() for token in sentence.split(' ')]\n",
    "    # print(tokens)\n",
    "    tokens2 = [token.lower() for token in sentence2.split(' ')]\n",
    "    # sys.exit()\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, intro.init_token)\n",
    "    tokens.append(intro.eos_token)\n",
    "\n",
    "    tokens2.insert(0, outro.init_token)\n",
    "    tokens2.append(outro.eos_token)\n",
    "    \n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [intro.vocab.stoi[token] for token in tokens]\n",
    "    text_to_indices2 = [outro.vocab.stoi[token] for token in tokens2]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "    sentence2_tensor = torch.LongTensor(text_to_indices2).unsqueeze(1).to(device)\n",
    "    \n",
    "    outputs = [solo.vocab.stoi[\"<sos>\"]]\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, sentence2_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == solo.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "    # print(outputs)\n",
    "    translated_sentence = [solo.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86887ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "df_intro = pd.read_csv(source_folder + '/val_torchtext.csv')\n",
    "val_intro = df_intro['intro'].values\n",
    "val_solo = df_intro['solo'].values\n",
    "val_outro = df_intro['outro'].values\n",
    "val_data=[]\n",
    "for i in range(len(val_intro)):\n",
    "    temp_dict = {}\n",
    "    temp_dict['intro'] = val_intro[i]\n",
    "    temp_dict['solo'] = val_solo[i]\n",
    "    temp_dict['outro'] = val_outro[i]\n",
    "    val_data.append(temp_dict)\n",
    "print(len(val_intro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ead0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mode_collapse(model):\n",
    "    count = 0\n",
    "    translations = []\n",
    "    for i in range(3):\n",
    "        if len(val_intro) > 1200:\n",
    "            continue\n",
    "        intro = val_intro[i]\n",
    "        solo = val_solo[i]\n",
    "        outro = val_outro[i]\n",
    "        #print(intro)\n",
    "        list_intro = [int(x) for x in intro.split(' ')]\n",
    "        list_solo = [int(x) for x in solo.split(' ')]\n",
    "        list_outro = [int(x) for x in outro.split(' ')]\n",
    "        translated_sentence = translate_sentence(model, intro, outro, intro_field, outro_field, solo_field, device, max_length=1200)\n",
    "        \n",
    "        translated_sentence = [int(x) for x in translated_sentence if x != '<pad>' and x != '<sos>' and x != '<eos>' and x != '<unk>']\n",
    "        print(translated_sentence)\n",
    "        translations.append(translated_sentence)\n",
    "        if i > 0:\n",
    "            if translations[i-1] == translations[i]:\n",
    "                count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "894016c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 502 | Time: 1m 1s\n",
      "\tTrain Loss: 0.055 | Train PPL:   1.056\n",
      "\t Val. Loss: 7.443 |  Val. PPL: 1708.190\n",
      "=> Saving checkpoint\n",
      "Epoch: 503 | Time: 1m 2s\n",
      "\tTrain Loss: 0.054 | Train PPL:   1.056\n",
      "\t Val. Loss: 7.325 |  Val. PPL: 1518.234\n",
      "=> Saving checkpoint\n",
      "Epoch: 504 | Time: 1m 4s\n",
      "\tTrain Loss: 0.055 | Train PPL:   1.057\n",
      "\t Val. Loss: 7.296 |  Val. PPL: 1473.745\n",
      "=> Saving checkpoint\n",
      "Epoch: 505 | Time: 1m 3s\n",
      "\tTrain Loss: 0.054 | Train PPL:   1.055\n",
      "\t Val. Loss: 7.404 |  Val. PPL: 1642.706\n",
      "Epoch: 506 | Time: 1m 3s\n",
      "\tTrain Loss: 0.053 | Train PPL:   1.055\n",
      "\t Val. Loss: 7.291 |  Val. PPL: 1466.314\n",
      "=> Saving checkpoint\n",
      "Epoch: 507 | Time: 1m 3s\n",
      "\tTrain Loss: 0.053 | Train PPL:   1.054\n",
      "\t Val. Loss: 7.487 |  Val. PPL: 1785.093\n",
      "Epoch: 508 | Time: 1m 4s\n",
      "\tTrain Loss: 0.053 | Train PPL:   1.055\n",
      "\t Val. Loss: 7.312 |  Val. PPL: 1497.834\n",
      "Epoch: 509 | Time: 1m 4s\n",
      "\tTrain Loss: 0.053 | Train PPL:   1.055\n",
      "\t Val. Loss: 7.491 |  Val. PPL: 1792.688\n",
      "Epoch: 510 | Time: 1m 4s\n",
      "\tTrain Loss: 0.052 | Train PPL:   1.053\n",
      "\t Val. Loss: 7.349 |  Val. PPL: 1555.009\n",
      "Epoch: 511 | Time: 1m 4s\n",
      "\tTrain Loss: 0.052 | Train PPL:   1.053\n",
      "\t Val. Loss: 7.400 |  Val. PPL: 1636.751\n",
      "Epoch: 512 | Time: 1m 4s\n",
      "\tTrain Loss: 0.051 | Train PPL:   1.052\n",
      "\t Val. Loss: 7.436 |  Val. PPL: 1695.808\n",
      "Epoch: 513 | Time: 1m 4s\n",
      "\tTrain Loss: 0.051 | Train PPL:   1.053\n",
      "\t Val. Loss: 7.412 |  Val. PPL: 1655.297\n",
      "Epoch: 514 | Time: 1m 4s\n",
      "\tTrain Loss: 0.051 | Train PPL:   1.053\n",
      "\t Val. Loss: 7.368 |  Val. PPL: 1584.127\n",
      "Epoch: 515 | Time: 1m 4s\n",
      "\tTrain Loss: 0.051 | Train PPL:   1.052\n",
      "\t Val. Loss: 7.381 |  Val. PPL: 1604.894\n",
      "Epoch: 516 | Time: 1m 4s\n",
      "\tTrain Loss: 0.051 | Train PPL:   1.052\n",
      "\t Val. Loss: 7.445 |  Val. PPL: 1712.037\n",
      "Epoch: 517 | Time: 1m 4s\n",
      "\tTrain Loss: 0.051 | Train PPL:   1.053\n",
      "\t Val. Loss: 7.497 |  Val. PPL: 1802.389\n",
      "Epoch: 518 | Time: 1m 4s\n",
      "\tTrain Loss: 0.052 | Train PPL:   1.054\n",
      "\t Val. Loss: 7.612 |  Val. PPL: 2021.535\n",
      "Epoch: 519 | Time: 1m 4s\n",
      "\tTrain Loss: 0.050 | Train PPL:   1.051\n",
      "\t Val. Loss: 7.559 |  Val. PPL: 1918.129\n",
      "Epoch: 520 | Time: 1m 6s\n",
      "\tTrain Loss: 0.049 | Train PPL:   1.050\n",
      "\t Val. Loss: 7.666 |  Val. PPL: 2133.598\n",
      "=> Saving checkpoint\n",
      "Epoch: 521 | Time: 1m 4s\n",
      "\tTrain Loss: 0.050 | Train PPL:   1.051\n",
      "\t Val. Loss: 7.543 |  Val. PPL: 1887.582\n",
      "=> Saving checkpoint\n",
      "Epoch: 522 | Time: 1m 4s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.050\n",
      "\t Val. Loss: 7.576 |  Val. PPL: 1950.115\n",
      "Epoch: 523 | Time: 1m 5s\n",
      "\tTrain Loss: 0.050 | Train PPL:   1.051\n",
      "\t Val. Loss: 7.444 |  Val. PPL: 1708.879\n",
      "Epoch: 524 | Time: 1m 5s\n",
      "\tTrain Loss: 0.050 | Train PPL:   1.052\n",
      "\t Val. Loss: 7.615 |  Val. PPL: 2029.029\n",
      "Epoch: 525 | Time: 1m 4s\n",
      "\tTrain Loss: 0.050 | Train PPL:   1.051\n",
      "\t Val. Loss: 7.509 |  Val. PPL: 1824.464\n",
      "[0, 1, 2, 95, 1, 35, 46, 87, 1, 35, 48, 22, 67, 53, 46, 52, 4, 35, 46, 22, 8, 35, 48, 15, 17, 35, 46, 22, 90, 64, 48, 22, 27, 32, 46, 22, 74, 35, 48, 22, 0, 1, 51, 46, 102, 1, 32, 46, 22, 67, 35, 46, 22, 4, 54, 48, 15, 23, 35, 46, 15, 78, 53, 100, 28, 0, 1, 35, 100, 7, 67, 35, 100, 34, 8, 35, 55, 31, 70, 54, 55, 66, 78, 35, 127, 22, 17, 53, 46, 22, 17, 54, 46, 31, 27, 53, 75, 22, 74, 35, 128, 15, 0, 1, 35, 104, 22, 67, 35, 100, 7, 4, 54, 104, 7, 23, 35, 55, 31, 72, 35, 100, 47, 13, 32, 104, 28, 27, 53, 127, 15, 74, 53, 127, 41]\n",
      "[0, 1, 43, 165, 1, 38, 48, 83, 27, 32, 50, 15, 74, 38, 6, 15, 0, 1, 64, 58, 125, 17, 32, 57, 31, 27, 51, 58, 31, 0, 1, 64, 12, 83, 27, 64, 96, 15, 74, 32, 82, 15, 0, 1, 64, 86, 87, 17, 32, 82, 66, 0, 1, 32, 86, 85, 13, 32, 58, 36, 27, 64, 57, 15, 74, 32, 12, 15, 0, 1, 32, 61, 28, 10, 32, 12, 7, 13, 32, 12, 34]\n",
      "[0, 1, 2, 134, 1, 32, 21, 41, 1, 32, 96, 41, 8, 2, 162, 13, 2, 162, 17, 2, 162, 0, 1, 64, 96, 47, 1, 2, 162, 8, 64, 57, 15, 72, 64, 96, 15, 10, 51, 57, 22, 91, 54, 61, 15, 13, 64, 21, 15, 70, 54, 86, 22, 16, 54, 12, 15, 17, 64, 21, 15, 17, 64, 21, 31, 27, 54, 86, 15, 74, 51, 21, 15, 0, 1, 64, 96, 15, 67, 51, 21, 15, 4, 54, 86, 15, 23, 53, 21, 15, 8, 2, 162, 0, 1, 51, 21, 15, 67, 51, 96, 15, 4, 54, 21, 15, 23, 51, 40, 15, 8, 2, 162, 72, 51, 12, 15, 10, 51, 21, 22, 91, 54, 57, 15, 13, 51, 96, 22, 70, 51, 21, 7, 78, 54, 12, 15, 17, 64, 21, 15, 90, 32, 96, 15, 27, 51, 96, 15, 74, 54, 96, 15, 0, 1, 51, 57, 15, 67, 64, 21, 15, 4, 51, 86, 15, 23, 51, 21, 15, 8, 64, 21, 47, 72, 54, 12, 42, 13, 32, 57, 15, 70, 54, 12, 7, 17, 51, 21, 15, 90, 64, 96, 15, 27, 64, 82, 15, 74, 54, 86, 15, 0, 1, 51, 21, 15, 1, 51, 12, 15, 67, 54, 96, 15, 4, 64, 96, 31, 8, 54, 21, 15, 72, 54, 12, 15, 10, 51, 21, 15, 10, 54, 12, 22, 91, 54, 96, 15, 13, 64, 21, 31, 13, 64, 86, 15, 13, 64, 98, 15, 70, 51, 121, 15, 16, 51, 82, 15, 78, 51, 9, 15, 17, 2, 162, 90, 64, 40, 15, 27, 51, 40, 15, 74, 51, 39, 15, 74, 64, 40, 15, 0, 1, 54, 86, 22, 67, 54, 21, 15, 1, 32, 12, 15, 67, 51, 21, 15, 4, 64, 40, 15, 23, 54, 96, 15, 8, 54, 9, 15, 72, 54, 40, 15, 91, 54, 84, 15, 13, 51, 9, 15, 8, 2, 162, 13, 32, 40, 15, 70, 38, 40, 15, 16, 54, 40, 15, 78, 51, 98, 15, 17, 51, 40, 15, 17, 2, 162, 1, 2, 146, 17, 54, 39, 15, 74, 51, 21, 15, 74, 51, 21, 15, 0, 1, 2, 162, 1, 2, 146, 1, 2, 162, 23, 54, 96, 15, 8, 54, 39, 15, 72, 64, 96, 15, 8, 64, 40, 15, 72, 54, 40, 15, 72, 32, 167, 15, 10, 51, 118, 15, 91, 64, 235, 15, 13, 51, 167, 15, 70, 32, 167, 15, 16, 51, 140, 15, 78, 51, 118, 15, 17, 2, 162, 1, 51, 167, 22, 78, 51, 121, 15, 17, 32, 167, 15, 90, 51, 118, 22, 90, 54, 121, 15, 74, 32, 140, 15, 27, 32, 167, 15, 0, 1, 2, 162, 74, 54, 120, 22, 0, 1, 2, 162, 23, 54, 57, 22, 1, 2, 162, 1, 54, 167, 15, 67, 51, 118, 15, 4, 51, 98, 15, 23, 35, 167, 15, 8, 2, 162, 8, 51, 118, 22, 8, 51, 118, 15, 72, 64, 167, 15, 72, 54, 143, 15, 10, 54, 121, 15, 91, 38, 121, 15, 13, 2, 162, 13, 54, 121, 15, 70, 54, 121, 15, 16, 51, 9, 15, 78, 64, 121, 15, 13, 64, 118, 15, 13, 51, 57, 22, 16, 51, 98, 15, 13, 51, 57, 15, 13, 35, 21, 15, 16, 64, 121, 15, 16, 54, 58, 15, 16, 64, 143, 22, 16, 64, 57, 41, 17, 2, 162, 13, 51, 121, 22, 17, 54, 40, 15, 17, 64, 21, 15, 78, 51, 118, 15]\n",
      "Epoch: 526 | Time: 1m 5s\n",
      "\tTrain Loss: 0.049 | Train PPL:   1.050\n",
      "\t Val. Loss: 7.314 |  Val. PPL: 1501.654\n",
      "Epoch: 527 | Time: 1m 4s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.049\n",
      "\t Val. Loss: 7.473 |  Val. PPL: 1759.282\n",
      "Epoch: 528 | Time: 1m 4s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.050\n",
      "\t Val. Loss: 7.500 |  Val. PPL: 1808.618\n",
      "Epoch: 529 | Time: 1m 5s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.049\n",
      "\t Val. Loss: 7.433 |  Val. PPL: 1690.156\n",
      "Epoch: 530 | Time: 1m 4s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.050\n",
      "\t Val. Loss: 7.442 |  Val. PPL: 1706.085\n",
      "Epoch: 531 | Time: 1m 5s\n",
      "\tTrain Loss: 0.047 | Train PPL:   1.048\n",
      "\t Val. Loss: 7.493 |  Val. PPL: 1796.167\n",
      "Epoch: 532 | Time: 1m 5s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.049\n",
      "\t Val. Loss: 7.473 |  Val. PPL: 1760.436\n",
      "Epoch: 533 | Time: 1m 4s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.049\n",
      "\t Val. Loss: 7.511 |  Val. PPL: 1828.559\n",
      "Epoch: 534 | Time: 1m 4s\n",
      "\tTrain Loss: 0.049 | Train PPL:   1.050\n",
      "\t Val. Loss: 7.392 |  Val. PPL: 1623.001\n",
      "Epoch: 535 | Time: 1m 5s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.049\n",
      "\t Val. Loss: 7.424 |  Val. PPL: 1675.646\n",
      "Epoch: 536 | Time: 1m 5s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.049\n",
      "\t Val. Loss: 7.445 |  Val. PPL: 1710.773\n",
      "Epoch: 537 | Time: 1m 4s\n",
      "\tTrain Loss: 0.047 | Train PPL:   1.048\n",
      "\t Val. Loss: 7.423 |  Val. PPL: 1673.286\n",
      "Epoch: 538 | Time: 1m 4s\n",
      "\tTrain Loss: 0.048 | Train PPL:   1.049\n",
      "\t Val. Loss: 7.450 |  Val. PPL: 1720.032\n",
      "Epoch: 539 | Time: 1m 4s\n",
      "\tTrain Loss: 0.047 | Train PPL:   1.048\n",
      "\t Val. Loss: 7.511 |  Val. PPL: 1828.257\n",
      "Epoch: 540 | Time: 1m 4s\n",
      "\tTrain Loss: 0.047 | Train PPL:   1.048\n",
      "\t Val. Loss: 7.530 |  Val. PPL: 1863.588\n",
      "=> Saving checkpoint\n",
      "Epoch: 541 | Time: 1m 5s\n",
      "\tTrain Loss: 0.047 | Train PPL:   1.048\n",
      "\t Val. Loss: 7.411 |  Val. PPL: 1653.876\n",
      "=> Saving checkpoint\n",
      "Epoch: 542 | Time: 1m 5s\n",
      "\tTrain Loss: 0.047 | Train PPL:   1.048\n",
      "\t Val. Loss: 7.425 |  Val. PPL: 1676.709\n",
      "Epoch: 543 | Time: 1m 5s\n",
      "\tTrain Loss: 0.045 | Train PPL:   1.046\n",
      "\t Val. Loss: 7.534 |  Val. PPL: 1870.334\n",
      "Epoch: 544 | Time: 1m 4s\n",
      "\tTrain Loss: 0.046 | Train PPL:   1.047\n",
      "\t Val. Loss: 7.536 |  Val. PPL: 1874.816\n",
      "Epoch: 545 | Time: 1m 4s\n",
      "\tTrain Loss: 0.045 | Train PPL:   1.046\n",
      "\t Val. Loss: 7.570 |  Val. PPL: 1939.072\n",
      "Epoch: 546 | Time: 1m 4s\n",
      "\tTrain Loss: 0.045 | Train PPL:   1.046\n",
      "\t Val. Loss: 7.536 |  Val. PPL: 1873.421\n",
      "Epoch: 547 | Time: 1m 5s\n",
      "\tTrain Loss: 0.045 | Train PPL:   1.046\n",
      "\t Val. Loss: 7.488 |  Val. PPL: 1786.240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 548 | Time: 1m 5s\n",
      "\tTrain Loss: 0.046 | Train PPL:   1.047\n",
      "\t Val. Loss: 7.584 |  Val. PPL: 1965.628\n",
      "Epoch: 549 | Time: 1m 5s\n",
      "\tTrain Loss: 0.045 | Train PPL:   1.046\n",
      "\t Val. Loss: 7.548 |  Val. PPL: 1896.177\n",
      "Epoch: 550 | Time: 1m 4s\n",
      "\tTrain Loss: 0.045 | Train PPL:   1.046\n",
      "\t Val. Loss: 7.535 |  Val. PPL: 1872.300\n",
      "[0, 1, 2, 95, 1, 79, 127, 52, 128, 31, 4, 5, 129, 31, 8, 2, 95, 10, 79, 46, 31, 13, 2, 95, 13, 35, 55, 60, 0, 1, 79, 46, 7, 4, 5, 55, 31, 8, 79, 55, 15, 72, 24, 100, 15, 10, 79, 55, 31, 13, 79, 100, 7, 16, 79, 55, 31, 17, 79, 55, 31, 27, 38, 100, 31, 0, 1, 64, 100, 31, 4, 79, 55, 52, 8, 24, 46, 31, 10, 79, 55, 85, 27, 5, 46, 31, 0, 1, 79, 55, 31, 4, 79, 46, 31, 8, 79, 55, 7, 10, 79, 46, 31, 13, 38, 55, 31, 16, 79, 46, 31, 17, 79, 55, 7, 90, 11, 100, 31, 27, 11, 122, 31, 0, 1, 79, 100, 22, 4, 79, 55, 15, 8, 11, 46, 15, 72, 64, 128, 7, 10, 79, 127, 7, 13, 79, 128, 7, 16, 79, 46, 22, 17, 79, 55, 15, 90, 79, 46, 15, 27, 11, 48, 15, 0, 1, 79, 48, 15, 4, 79, 46, 22, 8, 11, 46, 15, 72, 11, 128, 15, 10, 5, 46, 15, 91, 79, 46, 31, 13, 79, 55, 15, 70, 5, 128, 31, 16, 79, 46, 15, 17, 5, 128, 52, 90, 5, 46, 22, 27, 79, 55, 31, 0, 1, 79, 46, 15, 4, 5, 128, 31, 8, 11, 127, 52, 10, 79, 48, 15, 72, 11, 46, 15, 10, 79, 46, 15, 13, 79, 46, 7, 16, 79, 48, 15, 17, 11, 127, 52, 17, 11, 127, 15, 90, 79, 100, 15, 27, 79, 100, 15, 0, 1, 79, 100, 15, 4, 79, 100, 15, 23, 79, 100, 15, 8, 46, 15]\n",
      "[0, 1, 43, 165, 67, 32, 12, 15, 23, 49, 57, 15, 72, 35, 58, 15, 91, 24, 50, 34, 78, 35, 58, 15, 90, 53, 57, 22, 74, 51, 61, 15, 0, 67, 51, 12, 22, 23, 49, 57, 15, 72, 35, 58, 22, 91, 11, 50, 19, 78, 11, 50, 15, 90, 53, 58, 15, 74, 64, 57, 15, 0, 67, 54, 58, 31, 23, 51, 50, 31, 72, 49, 48, 7, 91, 51, 46, 52, 78, 32, 48, 7, 90, 35, 58, 7, 74, 51, 50, 87, 0, 78, 51, 58, 31, 78, 51, 61, 15, 17, 71, 86, 15, 90, 45, 57, 15, 90, 49, 96, 7, 27, 35, 76, 7, 74, 51, 61, 31, 74, 32, 84, 87, 0, 67, 63, 12, 31, 23, 49, 57, 31, 72, 45, 58, 15, 91, 51, 50, 52, 78, 35, 58, 7, 78, 14, 107, 52, 90, 49, 57, 7, 27, 79, 39, 15, 74, 53, 61, 31, 74, 24, 98, 103, 0, 67, 45, 12, 31, 23, 45, 57, 15, 72, 45, 58, 7, 91, 49, 50, 52, 78, 35, 50, 31, 17, 51, 96, 19, 90, 63, 58, 31, 74, 53, 57, 7, 74, 32, 98, 102, 0, 67, 49, 58, 22, 23, 54, 58, 15, 72, 54, 50, 15, 91, 53, 48, 19, 78, 35, 50, 15, 90, 53, 57, 15, 74, 64, 58, 19, 0, 67, 64, 58, 15, 23, 64, 57, 15, 72, 64, 58, 52, 91, 64, 57, 31, 70, 51, 61, 7, 78, 11, 86, 15, 90, 24, 96, 15, 74, 79, 84, 31]\n",
      "[0, 1, 2, 162, 1, 64, 12, 15, 67, 35, 57, 31, 67, 51, 21, 7, 23, 64, 12, 31, 72, 51, 57, 15, 91, 35, 48, 36, 91, 35, 57, 36, 0, 67, 54, 50, 52, 67, 35, 9, 52, 8, 35, 57, 15, 72, 64, 12, 15, 91, 35, 57, 22, 91, 54, 96, 22, 13, 35, 57, 47, 13, 64, 21, 47, 90, 51, 33, 15, 90, 51, 21, 22, 27, 51, 30, 22, 27, 51, 12, 22, 74, 54, 30, 15, 74, 54, 12, 15, 0, 1, 51, 55, 22, 1, 51, 57, 22, 67, 54, 55, 85, 67, 54, 57, 41, 23, 35, 82, 15, 8, 51, 98, 15, 72, 51, 21, 7, 91, 54, 12, 15, 13, 51, 57, 22, 70, 54, 6, 7, 70, 45, 21, 7, 78, 54, 6, 19, 78, 35, 73, 19, 74, 51, 21, 15, 0, 1, 64, 86, 7, 67, 54, 12, 7, 23, 54, 50, 7, 23, 54, 12, 15, 8, 54, 57, 22, 72, 63, 33, 31, 72, 51, 6, 7, 91, 35, 50, 31, 91, 54, 57, 31, 70, 35, 62, 85, 70, 54, 57, 85, 0, 67, 35, 57, 34, 72, 64, 46, 22, 72, 64, 61, 22, 10, 54, 48, 22, 10, 54, 86, 22, 10, 54, 50, 22, 10, 54, 96, 22, 91, 54, 62, 22, 91, 54, 76, 22]\n",
      "Epoch: 551 | Time: 1m 5s\n",
      "\tTrain Loss: 0.044 | Train PPL:   1.045\n",
      "\t Val. Loss: 7.467 |  Val. PPL: 1749.128\n",
      "Epoch: 552 | Time: 1m 5s\n",
      "\tTrain Loss: 0.045 | Train PPL:   1.046\n",
      "\t Val. Loss: 7.589 |  Val. PPL: 1976.219\n",
      "Epoch: 553 | Time: 1m 5s\n",
      "\tTrain Loss: 0.045 | Train PPL:   1.046\n",
      "\t Val. Loss: 7.542 |  Val. PPL: 1885.720\n",
      "Epoch: 554 | Time: 1m 5s\n",
      "\tTrain Loss: 0.044 | Train PPL:   1.045\n",
      "\t Val. Loss: 7.532 |  Val. PPL: 1867.761\n",
      "Epoch: 555 | Time: 1m 4s\n",
      "\tTrain Loss: 0.045 | Train PPL:   1.046\n",
      "\t Val. Loss: 7.480 |  Val. PPL: 1771.563\n",
      "Epoch: 556 | Time: 1m 4s\n",
      "\tTrain Loss: 0.044 | Train PPL:   1.045\n",
      "\t Val. Loss: 7.426 |  Val. PPL: 1678.834\n",
      "Epoch: 557 | Time: 1m 4s\n",
      "\tTrain Loss: 0.044 | Train PPL:   1.045\n",
      "\t Val. Loss: 7.605 |  Val. PPL: 2007.781\n",
      "Epoch: 558 | Time: 1m 4s\n",
      "\tTrain Loss: 0.043 | Train PPL:   1.044\n",
      "\t Val. Loss: 7.566 |  Val. PPL: 1931.958\n",
      "Epoch: 559 | Time: 1m 4s\n",
      "\tTrain Loss: 0.043 | Train PPL:   1.044\n",
      "\t Val. Loss: 7.593 |  Val. PPL: 1984.765\n",
      "Epoch: 560 | Time: 1m 4s\n",
      "\tTrain Loss: 0.043 | Train PPL:   1.044\n",
      "\t Val. Loss: 7.626 |  Val. PPL: 2051.062\n",
      "=> Saving checkpoint\n",
      "Epoch: 561 | Time: 1m 5s\n",
      "\tTrain Loss: 0.043 | Train PPL:   1.044\n",
      "\t Val. Loss: 7.461 |  Val. PPL: 1739.299\n",
      "=> Saving checkpoint\n",
      "Epoch: 562 | Time: 1m 5s\n",
      "\tTrain Loss: 0.043 | Train PPL:   1.044\n",
      "\t Val. Loss: 7.592 |  Val. PPL: 1981.652\n",
      "Epoch: 563 | Time: 1m 4s\n",
      "\tTrain Loss: 0.042 | Train PPL:   1.043\n",
      "\t Val. Loss: 7.527 |  Val. PPL: 1856.692\n",
      "Epoch: 564 | Time: 1m 4s\n",
      "\tTrain Loss: 0.043 | Train PPL:   1.044\n",
      "\t Val. Loss: 7.582 |  Val. PPL: 1962.480\n",
      "Epoch: 565 | Time: 1m 5s\n",
      "\tTrain Loss: 0.042 | Train PPL:   1.043\n",
      "\t Val. Loss: 7.475 |  Val. PPL: 1763.564\n",
      "Epoch: 566 | Time: 1m 5s\n",
      "\tTrain Loss: 0.042 | Train PPL:   1.042\n",
      "\t Val. Loss: 7.587 |  Val. PPL: 1972.760\n",
      "Epoch: 567 | Time: 1m 5s\n",
      "\tTrain Loss: 0.043 | Train PPL:   1.044\n",
      "\t Val. Loss: 7.385 |  Val. PPL: 1611.840\n",
      "Epoch: 568 | Time: 1m 5s\n",
      "\tTrain Loss: 0.042 | Train PPL:   1.043\n",
      "\t Val. Loss: 7.577 |  Val. PPL: 1953.192\n",
      "Epoch: 569 | Time: 1m 4s\n",
      "\tTrain Loss: 0.042 | Train PPL:   1.043\n",
      "\t Val. Loss: 7.537 |  Val. PPL: 1876.496\n",
      "Epoch: 570 | Time: 1m 4s\n",
      "\tTrain Loss: 0.041 | Train PPL:   1.042\n",
      "\t Val. Loss: 7.553 |  Val. PPL: 1906.913\n",
      "Epoch: 571 | Time: 1m 4s\n",
      "\tTrain Loss: 0.042 | Train PPL:   1.042\n",
      "\t Val. Loss: 7.539 |  Val. PPL: 1879.643\n",
      "Epoch: 572 | Time: 1m 4s\n",
      "\tTrain Loss: 0.041 | Train PPL:   1.042\n",
      "\t Val. Loss: 7.578 |  Val. PPL: 1955.528\n",
      "Epoch: 573 | Time: 1m 4s\n",
      "\tTrain Loss: 0.042 | Train PPL:   1.042\n",
      "\t Val. Loss: 7.622 |  Val. PPL: 2041.783\n",
      "Epoch: 574 | Time: 1m 5s\n",
      "\tTrain Loss: 0.041 | Train PPL:   1.042\n",
      "\t Val. Loss: 7.644 |  Val. PPL: 2087.970\n",
      "Epoch: 575 | Time: 1m 4s\n",
      "\tTrain Loss: 0.041 | Train PPL:   1.042\n",
      "\t Val. Loss: 7.505 |  Val. PPL: 1817.540\n",
      "[0, 1, 2, 95, 1, 54, 127, 52, 23, 35, 129, 22, 8, 54, 132, 22, 8, 35, 129, 15, 72, 35, 129, 31, 10, 35, 129, 15, 91, 32, 129, 7, 13, 25, 48, 47, 17, 49, 129, 15, 90, 53, 129, 22, 27, 54, 129, 28, 74, 53, 129, 22, 0, 1, 35, 129, 15, 4, 35, 129, 22, 23, 54, 129, 66, 8, 35, 129, 22, 10, 51, 122, 22, 91, 32, 128, 22, 13, 79, 55, 22, 70, 79, 55, 22, 16, 79, 55, 22, 78, 18, 55, 22, 17, 18, 55, 22, 90, 79, 55, 22, 27, 35, 55, 22, 74, 54, 122, 22, 0, 1, 32, 30, 22, 67, 79, 55, 22, 4, 51, 128, 22, 23, 38, 55, 15, 8, 54, 100, 22, 72, 35, 55, 22, 10, 5, 55, 22, 91, 11, 55, 22, 13, 32, 55, 22, 70, 11, 55, 22, 16, 32, 128, 22, 78, 38, 55, 22, 17, 11, 55, 22, 90, 38, 55, 22, 27, 18, 55, 22, 74, 38, 100, 22, 0, 1, 32, 55, 22, 67, 11, 55, 22, 4, 24, 55, 22, 23, 11, 55, 22, 8, 32, 100, 22, 72, 35, 55, 22, 10, 5, 46, 22, 91, 53, 55, 15, 13, 45, 100, 28, 78, 54, 55, 15, 17, 14, 46, 15, 90, 32, 55, 15, 74, 32, 55, 22, 0, 1, 32, 55, 22]\n",
      "[0, 1, 43, 165, 23, 49, 57, 15, 8, 43, 117, 8, 64, 57, 15, 10, 35, 58, 15, 91, 45, 57, 31, 13, 35, 58, 34, 78, 35, 58, 31, 17, 49, 62, 34, 0, 1, 54, 57, 31, 4, 51, 58, 31, 8, 49, 58, 31, 10, 51, 57, 52, 13, 35, 57, 31, 16, 51, 86, 31, 17, 35, 57, 15, 90, 51, 58, 31, 27, 51, 62, 31, 0, 1, 54, 48, 85, 27, 51, 57, 34, 0, 1, 54, 57, 85, 8, 64, 48, 31, 10, 51, 86, 34, 13, 54, 48, 28, 27, 63, 57, 31, 0, 1, 53, 61, 31, 4, 51, 57, 31, 8, 64, 48, 31, 10, 51, 57, 31, 13, 51, 58, 34, 17, 64, 12, 28, 27, 54, 48, 15, 74, 51, 62, 31, 0, 1, 64, 48, 87, 1, 64, 50, 31, 4, 64, 58, 31, 8, 54, 57, 31, 10, 51, 61, 31, 13, 54, 57, 34, 16, 51, 86, 28, 17, 64, 96, 34, 27, 35, 86, 34, 0, 1, 32, 61, 34, 4, 51, 86, 31, 4, 64, 96, 31, 8, 35, 76, 31, 10, 64, 58, 31, 13, 64, 86, 31, 17, 35, 57, 31, 27, 35, 48, 31, 27, 35, 50, 31, 0, 1, 64, 86, 28, 1, 64, 86, 34, 8, 64, 96, 15, 10, 35, 57, 31, 13, 54, 48, 28, 27, 54, 86, 56, 27, 35, 96, 19, 0, 1, 64, 86, 31, 4, 54, 57, 31, 8, 51, 58, 31, 10, 51, 48, 85, 27, 32, 61, 31, 13, 64, 48, 34, 17, 54, 57, 34, 0, 1, 51, 50, 41, 4, 51, 58, 34, 8, 51, 58, 34, 10, 51, 84, 85]\n",
      "[0, 1, 2, 162, 1, 64, 21, 15, 67, 35, 12, 31, 67, 51, 20, 7, 23, 64, 21, 31, 72, 51, 12, 15, 91, 35, 39, 36, 91, 35, 12, 36, 0, 67, 54, 6, 52, 67, 35, 73, 52, 8, 35, 12, 15, 72, 64, 21, 15, 91, 35, 12, 22, 91, 54, 82, 22, 13, 35, 12, 47, 13, 64, 20, 47, 90, 51, 26, 15, 90, 51, 20, 22, 27, 51, 33, 22, 27, 51, 21, 22, 74, 54, 33, 15, 74, 54, 21, 15, 0, 1, 51, 30, 22, 1, 51, 12, 22, 67, 54, 30, 85, 67, 54, 12, 41, 23, 35, 20, 15, 8, 51, 82, 15, 72, 51, 20, 7, 91, 54, 21, 15, 13, 51, 12, 22, 70, 54, 9, 7, 70, 45, 20, 7, 78, 54, 9, 19, 78, 35, 61, 19, 74, 51, 20, 15, 0, 1, 64, 96, 7, 67, 54, 21, 7, 23, 54, 6, 7, 23, 54, 21, 15, 8, 54, 12, 22, 72, 63, 26, 31, 72, 51, 9, 7, 91, 35, 6, 31, 91, 54, 12, 31, 70, 35, 58, 85, 70, 54, 12, 85, 0, 67, 35, 12, 34, 72, 64, 48, 22, 72, 64, 86, 22, 10, 54, 50, 22, 10, 54, 96, 22, 10, 54, 6, 22, 10, 54, 82, 22, 91, 54, 58, 22, 91, 54, 84, 22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 576 | Time: 1m 4s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.041\n",
      "\t Val. Loss: 7.590 |  Val. PPL: 1977.424\n",
      "Epoch: 577 | Time: 1m 5s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.041\n",
      "\t Val. Loss: 7.597 |  Val. PPL: 1992.771\n",
      "Epoch: 578 | Time: 1m 4s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.041\n",
      "\t Val. Loss: 7.695 |  Val. PPL: 2197.735\n",
      "Epoch: 579 | Time: 1m 4s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.041\n",
      "\t Val. Loss: 7.600 |  Val. PPL: 1998.255\n",
      "Epoch: 580 | Time: 1m 5s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.041\n",
      "\t Val. Loss: 7.753 |  Val. PPL: 2327.677\n",
      "=> Saving checkpoint\n",
      "Epoch: 581 | Time: 1m 5s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.041\n",
      "\t Val. Loss: 7.627 |  Val. PPL: 2052.602\n",
      "=> Saving checkpoint\n",
      "Epoch: 582 | Time: 1m 5s\n",
      "\tTrain Loss: 0.041 | Train PPL:   1.041\n",
      "\t Val. Loss: 7.444 |  Val. PPL: 1709.017\n",
      "Epoch: 583 | Time: 1m 5s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.040\n",
      "\t Val. Loss: 7.532 |  Val. PPL: 1866.011\n",
      "Epoch: 584 | Time: 1m 4s\n",
      "\tTrain Loss: 0.039 | Train PPL:   1.040\n",
      "\t Val. Loss: 7.615 |  Val. PPL: 2028.085\n",
      "Epoch: 585 | Time: 1m 4s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.041\n",
      "\t Val. Loss: 7.701 |  Val. PPL: 2210.963\n",
      "Epoch: 586 | Time: 1m 4s\n",
      "\tTrain Loss: 0.039 | Train PPL:   1.040\n",
      "\t Val. Loss: 7.497 |  Val. PPL: 1801.766\n",
      "Epoch: 587 | Time: 1m 4s\n",
      "\tTrain Loss: 0.039 | Train PPL:   1.040\n",
      "\t Val. Loss: 7.675 |  Val. PPL: 2154.537\n",
      "Epoch: 588 | Time: 1m 4s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.041\n",
      "\t Val. Loss: 7.630 |  Val. PPL: 2058.353\n",
      "Epoch: 589 | Time: 1m 4s\n",
      "\tTrain Loss: 0.039 | Train PPL:   1.040\n",
      "\t Val. Loss: 7.573 |  Val. PPL: 1944.859\n",
      "Epoch: 590 | Time: 1m 5s\n",
      "\tTrain Loss: 0.039 | Train PPL:   1.040\n",
      "\t Val. Loss: 7.653 |  Val. PPL: 2107.478\n",
      "Epoch: 591 | Time: 1m 5s\n",
      "\tTrain Loss: 0.038 | Train PPL:   1.039\n",
      "\t Val. Loss: 7.453 |  Val. PPL: 1724.933\n",
      "Epoch: 592 | Time: 1m 4s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.040\n",
      "\t Val. Loss: 7.557 |  Val. PPL: 1913.770\n",
      "Epoch: 593 | Time: 1m 4s\n",
      "\tTrain Loss: 0.038 | Train PPL:   1.039\n",
      "\t Val. Loss: 7.594 |  Val. PPL: 1985.981\n",
      "Epoch: 594 | Time: 1m 5s\n",
      "\tTrain Loss: 0.038 | Train PPL:   1.039\n",
      "\t Val. Loss: 7.710 |  Val. PPL: 2230.961\n",
      "Epoch: 595 | Time: 1m 5s\n",
      "\tTrain Loss: 0.039 | Train PPL:   1.040\n",
      "\t Val. Loss: 7.591 |  Val. PPL: 1980.869\n",
      "Epoch: 596 | Time: 1m 4s\n",
      "\tTrain Loss: 0.040 | Train PPL:   1.040\n",
      "\t Val. Loss: 7.607 |  Val. PPL: 2011.878\n",
      "Epoch: 597 | Time: 1m 5s\n",
      "\tTrain Loss: 0.039 | Train PPL:   1.039\n",
      "\t Val. Loss: 7.655 |  Val. PPL: 2110.336\n",
      "Epoch: 598 | Time: 1m 5s\n",
      "\tTrain Loss: 0.038 | Train PPL:   1.039\n",
      "\t Val. Loss: 7.562 |  Val. PPL: 1923.472\n",
      "Epoch: 599 | Time: 1m 4s\n",
      "\tTrain Loss: 0.038 | Train PPL:   1.039\n",
      "\t Val. Loss: 7.485 |  Val. PPL: 1780.339\n",
      "Epoch: 600 | Time: 1m 4s\n",
      "\tTrain Loss: 0.038 | Train PPL:   1.039\n",
      "\t Val. Loss: 7.464 |  Val. PPL: 1743.912\n",
      "=> Saving checkpoint\n",
      "[0, 1, 2, 95, 1, 35, 46, 87, 1, 35, 48, 22, 67, 53, 46, 52, 4, 35, 46, 15, 23, 35, 46, 15, 17, 35, 100, 22, 27, 35, 46, 22, 74, 35, 48, 15, 0, 1, 53, 46, 15, 67, 35, 46, 15, 4, 53, 46, 22, 23, 35, 46, 34, 78, 54, 55, 34, 90, 32, 46, 15, 27, 35, 48, 22, 0, 1, 35, 100, 31, 1, 35, 46, 15, 67, 35, 46, 31, 4, 35, 46, 22, 23, 35, 46, 56, 90, 54, 46, 31, 74, 54, 46, 15, 0, 1, 35, 46, 31, 67, 53, 48, 15, 4, 53, 46, 31, 8, 35, 46, 7, 72, 35, 46, 66, 17, 51, 46, 31, 27, 35, 46, 7, 0, 67, 35, 46, 31, 4, 35, 46, 7, 23, 53, 55, 31, 72, 35, 46, 34, 13, 35, 46, 31, 78, 35, 46, 31, 17, 35, 100, 34, 27, 35, 46, 7, 0, 1, 35, 46, 31, 4, 11, 48, 7, 23, 54, 55, 31, 8, 65, 46, 31, 10, 54, 104, 7, 91, 35, 100, 34, 16, 49, 46, 31, 17, 32, 46, 31, 27, 35, 46, 31, 0, 1, 35, 46, 7, 67, 54, 46, 31, 4, 35, 46, 15, 23, 35, 46, 15, 23, 35, 30, 66, 10, 5, 46, 31, 13, 32, 46, 31, 16, 38, 46, 15, 17, 35, 127, 28, 0, 1, 38, 104, 31, 4, 49, 46, 7, 23, 35, 46, 31, 23, 35, 46, 31, 8, 35, 46, 31, 10, 35, 46, 31, 13, 32, 46, 31, 16, 51, 104, 31, 17, 51, 46, 31, 90, 35, 104, 31]\n",
      "[0, 1, 43, 165, 67, 32, 12, 15, 23, 49, 57, 15, 72, 35, 58, 15, 91, 24, 50, 34, 78, 35, 58, 15, 90, 53, 57, 22, 74, 51, 61, 15, 0, 67, 51, 12, 22, 23, 49, 57, 15, 72, 35, 58, 22, 91, 11, 50, 19, 78, 11, 50, 15, 90, 53, 58, 15, 74, 64, 57, 15, 0, 67, 54, 58, 31, 23, 51, 50, 31, 72, 49, 48, 7, 91, 51, 46, 52, 78, 32, 48, 7, 90, 35, 58, 7, 74, 51, 50, 87, 0, 78, 51, 58, 31, 78, 51, 61, 15, 17, 71, 86, 15, 90, 45, 57, 15, 90, 49, 96, 7, 27, 35, 76, 7, 74, 51, 61, 31, 74, 32, 84, 87, 0, 67, 63, 12, 31, 23, 49, 57, 31, 72, 45, 58, 15, 91, 51, 50, 52, 78, 35, 58, 7, 78, 14, 107, 52, 90, 49, 57, 7, 27, 54, 98, 15, 74, 53, 61, 31, 74, 24, 98, 103, 0, 67, 45, 12, 31, 23, 45, 57, 15, 72, 45, 58, 7, 91, 49, 50, 52, 78, 35, 50, 31, 17, 51, 96, 19, 90, 63, 58, 31, 74, 53, 57, 7, 74, 32, 98, 102, 0, 67, 49, 58, 22, 23, 54, 58, 15, 72, 54, 50, 15, 91, 53, 48, 19, 78, 35, 50, 15, 90, 53, 57, 15, 74, 64, 58, 19, 0, 67, 64, 58, 15, 23, 64, 57, 15, 72, 64, 58, 52, 91, 64, 57, 31, 70, 51, 61, 7, 78, 11, 86, 15, 90, 24, 96, 15, 74, 79, 84, 31]\n",
      "[0, 1, 2, 162, 1, 64, 21, 15, 67, 35, 12, 31, 67, 51, 20, 7, 23, 64, 21, 31, 72, 51, 12, 15, 91, 35, 50, 36, 91, 35, 12, 36, 0, 67, 54, 6, 52, 67, 35, 73, 52, 8, 35, 12, 15, 72, 64, 21, 15, 91, 35, 12, 22, 91, 54, 82, 22, 13, 35, 12, 47, 13, 64, 20, 47, 90, 51, 26, 15, 90, 51, 20, 22, 27, 51, 33, 22, 27, 51, 21, 22, 74, 54, 33, 15, 74, 54, 21, 15, 0, 1, 51, 30, 22, 1, 51, 12, 22, 67, 54, 30, 85, 67, 54, 12, 41, 23, 35, 20, 15, 8, 51, 39, 15, 72, 51, 20, 7, 91, 54, 21, 15, 13, 51, 12, 22, 70, 54, 9, 7, 70, 45, 20, 7, 78, 54, 9, 19, 78, 35, 61, 19, 74, 51, 20, 15, 0, 1, 64, 96, 7, 67, 54, 21, 7, 23, 54, 6, 7, 23, 54, 21, 15, 8, 54, 12, 22, 72, 63, 26, 31, 72, 51, 9, 7, 91, 35, 6, 31, 91, 54, 12, 31, 70, 35, 58, 85, 70, 54, 12, 85, 0, 67, 35, 12, 34, 72, 64, 48, 22, 72, 64, 86, 22, 10, 54, 50, 22, 10, 54, 96, 22, 10, 54, 6, 22, 10, 54, 82, 22, 91, 54, 58, 22, 91, 54, 20, 22]\n",
      "=> Saving checkpoint\n",
      "| Test Loss: 7.882 | Test PPL: 2650.051 |\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 500\n",
    "S_EPOCH = 0\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "#model = nn.DataParallel(model, device_ids=[0,1]).to(device)\n",
    "for epoch in range(S_EPOCH, N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        checkpoint = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "        save_best_checkpoint(checkpoint,N_EPOCHS)\n",
    "    if (epoch+1) % 20 == 0 or (epoch) % 20 == 0:\n",
    "        save_final_checkpoint(checkpoint,epoch)\n",
    "    if (epoch+1) % 25 ==0:\n",
    "        if check_mode_collapse(model) > 1:\n",
    "            print(\"model is mode collapsing\")\n",
    "save_final_checkpoint(checkpoint,N_EPOCHS)\n",
    "test_loss = evaluate(model, test_iter, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc8317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checkpoint = {'model_state_dict': model.state_dict(),\n",
    "#                   'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                   'valid_loss': valid_loss}\n",
    "# save_checkpoint(destination_folder + checkpoint,N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33caff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "005d41b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "state = torch.load(destination_folder + '/500_checkpoint.pt', map_location=device)\n",
    "load_checkpoint(state, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "501467c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2075.079574125391\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_iter, criterion)\n",
    "print(math.exp(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f33d25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_outputs = folder +  \"/generated_samples_600epochs\"\n",
    "Path(generated_outputs+\"/intro\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/outro\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/solo\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/predict\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1f6ba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "df_intro = pd.read_csv(source_folder + '/test_torchtext.csv')\n",
    "test_intro = df_intro['intro'].values\n",
    "test_solo = df_intro['solo'].values\n",
    "test_outro = df_intro['outro'].values\n",
    "test_data=[]\n",
    "for i in range(len(test_intro)):\n",
    "    temp_dict = {}\n",
    "    temp_dict['intro'] = test_intro[i]\n",
    "    temp_dict['solo'] = test_solo[i]\n",
    "    temp_dict['outro'] = test_outro[i]\n",
    "    test_data.append(temp_dict)\n",
    "print(len(test_intro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "caada925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 162, 72, 64, 73, 52, 13, 64, 26, 7, 16, 64, 62, 7, 17, 64, 9, 15, 90, 11, 58, 52, 0, 1, 51, 75, 7, 67, 64, 26, 15, 4, 14, 58, 31, 8, 38, 26, 22, 8, 51, 62, 22, 72, 51, 75, 52, 13, 51, 75, 7, 70, 51, 26, 15, 16, 38, 58, 31, 17, 64, 26, 22, 17, 54, 26, 22, 90, 51, 62, 52, 0, 1, 54, 75, 15, 67, 53, 33, 15, 4, 54, 26, 15, 23, 51, 33, 15, 8, 54, 26, 15, 72, 64, 62, 15, 10, 64, 9, 15, 91, 38, 20, 15, 13, 54, 86, 22, 13, 35, 61, 22, 70, 51, 86, 22, 16, 54, 73, 22, 16, 51, 86, 22, 78, 51, 20, 15, 17, 51, 86, 22, 17, 54, 61, 22, 90, 32, 12, 52, 0, 1, 54, 12, 22, 1, 35, 61, 15, 67, 51, 86, 15, 4, 53, 20, 15, 23, 64, 76, 15, 8, 51, 84, 15, 72, 64, 107, 19, 13, 64, 88, 22, 70, 51, 88, 22, 16, 64, 120, 15, 78, 51, 106, 31, 90, 32, 120, 52, 0, 1, 32, 97, 22, 1, 51, 84, 22, 67, 51, 84, 15, 4, 64, 97, 31, 8, 54, 40, 22, 72, 54, 40, 15, 10, 51, 84, 22, 91, 64, 84, 22, 91, 64, 40, 22, 13, 35, 76, 22, 13, 51, 20, 22, 70, 64, 86, 15, 16, 38, 76, 7, 78, 51, 84, 15, 17, 64, 76, 15, 90, 32, 84, 85, 0, 70, 38, 107, 19, 17, 54, 97, 22, 17, 64, 107, 22, 90, 38, 97, 22, 27, 38, 97, 31, 0, 1, 64, 86, 22, 1, 54, 40, 22, 67, 64, 84, 15, 4, 32, 84, 7, 23, 35, 76, 7, 72, 38, 20, 41, 16, 51, 86, 22, 78, 51, 86, 15, 17, 54, 20, 15, 90, 51, 76, 15, 27, 51, 84, 15, 74, 51, 40, 15, 0, 1, 51, 97, 15, 67, 38, 40, 7, 4, 64, 84, 15, 23, 38, 76, 15, 8, 54, 84, 15, 72, 64, 84, 52, 13, 51, 84, 15, 70, 64, 107, 15, 16, 51, 120, 15, 78, 51, 107, 22, 78, 53, 120, 22, 17, 35, 107, 22, 17, 53, 106, 22, 90, 35, 106, 41, 0, 67, 64, 120, 52, 8, 32, 88, 22, 72, 64, 88, 15, 10, 51, 97, 22, 91, 32, 107, 22, 13, 51, 97, 22, 70, 51, 97, 22, 70, 51, 40, 22, 16, 51, 84, 22, 16, 51, 40, 22, 78, 64, 84, 22, 78, 32, 76, 22, 17, 51, 84, 22, 17, 64, 20, 22, 90, 51, 20, 22, 90, 54, 86, 22, 27, 35, 73, 22, 27, 49, 20, 22, 74, 49, 86, 22, 74, 49, 61, 22, 0, 1, 49, 73, 22, 1, 49, 73, 22, 67, 49, 73, 22, 67, 49, 9, 22, 4, 54, 73, 22, 4, 49, 9, 22, 23, 53, 73, 22, 23, 35, 9, 22]\n",
      "0\n",
      "[0, 1, 2, 126, 1, 38, 20, 7, 67, 38, 76, 15, 4, 38, 73, 15, 23, 38, 76, 15, 8, 32, 20, 15, 72, 38, 61, 15, 10, 64, 20, 15, 91, 38, 76, 15, 13, 32, 9, 15, 70, 38, 73, 15, 16, 38, 20, 15, 78, 38, 76, 15, 17, 38, 73, 15, 90, 38, 73, 15, 27, 38, 20, 15, 74, 38, 76, 15, 0, 1, 38, 9, 15, 67, 38, 20, 19, 4, 38, 73, 15, 23, 38, 76, 15, 8, 38, 9, 15, 72, 38, 76, 15, 10, 38, 76, 15, 91, 38, 40, 15, 13, 32, 9, 15, 70, 38, 73, 15, 16, 38, 73, 15, 78, 38, 20, 47, 0, 1, 38, 62, 15, 67, 38, 76, 15, 23, 38, 26, 15, 8, 38, 62, 15, 72, 38, 73, 34, 10, 38, 76, 15, 91, 38, 9, 15, 13, 38, 40, 15, 70, 32, 73, 15, 70, 38, 97, 15, 16, 38, 20, 15, 78, 38, 97, 15, 17, 38, 20, 15, 90, 38, 76, 15, 27, 38, 20, 15, 74, 38, 76, 7, 0, 1, 38, 76, 7, 67, 38, 20, 15, 4, 38, 76, 15, 23, 38, 73, 15, 8, 38, 9, 15, 72, 38, 73, 15, 10, 38, 73, 28, 23, 38, 97, 15, 72, 38, 76, 19, 91, 38, 97, 15, 13, 38, 40, 7, 13, 38, 97, 22, 70, 38, 9, 15, 16, 38, 73, 15, 78, 38, 9, 15, 17, 38, 20, 15, 17, 38, 73, 15, 90, 38, 97, 15, 27, 38, 97, 7, 74, 38, 40, 7, 0, 1, 38, 40, 15, 67, 38, 97, 15, 4, 38, 97, 15, 23, 38, 97, 15, 8, 38, 97, 15, 72, 38, 97, 15, 10, 38, 97, 15, 91, 38, 97, 15, 13, 38, 62, 15, 70, 38, 26, 15, 16, 38, 73, 15, 78, 38, 97, 15, 17, 38, 26, 15, 90, 38, 97, 15, 27, 38, 40, 15, 74, 38, 40, 15, 0, 1, 38, 73, 15, 67, 38, 73, 15, 4, 38, 62, 15, 23, 38, 97, 15, 8, 38, 73, 15, 72, 38, 9, 15, 10, 38, 40, 15, 91, 38, 97, 15, 13, 38, 73, 7, 70, 38, 97, 22, 16, 38, 73, 15, 78, 38, 97, 22, 17, 38, 9, 15, 90, 38, 20, 15, 27, 38, 97, 15, 27, 79, 20, 7, 0, 1, 38, 76, 15, 67, 38, 20, 15, 4, 38, 9, 15, 4, 38, 20, 22, 23, 38, 62, 15, 23, 79, 61, 15, 8, 38, 73, 15, 8, 11, 20, 15, 10, 38, 120, 15, 8, 38, 9, 15, 8, 79, 61, 31, 72, 38, 73, 15, 10, 38, 26, 15, 91, 38, 107, 22, 13, 38, 9, 15, 70, 38, 73, 15, 16, 38, 73, 15, 16, 79, 76, 22, 78, 38, 20, 15, 78, 79, 73, 22, 17, 38, 9, 15, 17, 38, 73, 22, 90, 38, 62, 15, 90, 79, 73, 7, 27, 38, 26, 15, 27, 79, 73, 15, 74, 38, 97, 15, 0, 1, 38, 73, 15, 1, 38, 20, 7, 67, 38, 97, 15, 4, 38, 97, 15, 23, 38, 97, 15, 8, 38, 20, 15, 72, 38, 73, 15, 10, 38, 26, 15, 91, 38, 106, 15, 13, 38, 9, 15, 70, 38, 40, 15]\n",
      "1\n",
      "[0, 1, 2, 155, 1, 24, 55, 36, 8, 24, 46, 31, 10, 11, 48, 31, 13, 24, 55, 42, 27, 24, 46, 31, 0, 1, 24, 48, 31, 4, 64, 46, 31, 8, 24, 55, 31, 10, 53, 100, 31, 13, 54, 104, 59, 74, 64, 46, 22, 0, 1, 24, 46, 41, 8, 24, 46, 31, 10, 51, 48, 31, 13, 24, 55, 47, 27, 24, 46, 31, 0, 1, 32, 48, 31, 4, 11, 46, 15, 8, 24, 55, 15, 72, 53, 100, 15, 10, 64, 104, 31, 13, 32, 100, 37, 27, 11, 100, 15, 0, 1, 24, 46, 66, 8, 32, 62, 31, 10, 32, 58, 31, 13, 24, 57, 47, 27, 11, 61, 15, 0, 1, 51, 61, 31, 4, 24, 57, 7, 8, 64, 61, 31, 10, 11, 86, 31, 13, 24, 96, 66, 27, 32, 76, 7, 0, 1, 54, 86, 34, 8, 24, 86, 22, 10, 51, 61, 31, 13, 32, 86, 47, 27, 24, 86, 31, 0, 1, 11, 57, 41, 8, 24, 58, 41, 13, 35, 62, 36, 16, 32, 46, 15, 78, 35, 48, 15, 17, 24, 55, 31, 27, 54, 100, 31]\n",
      "2\n",
      "[0, 1, 43, 211, 1, 14, 9, 52, 4, 14, 73, 31, 8, 14, 20, 31, 10, 14, 21, 80, 0, 8, 25, 9, 52, 10, 14, 73, 7, 13, 5, 21, 7, 16, 25, 26, 31, 17, 14, 33, 31, 27, 25, 26, 94, 0, 13, 5, 62, 66, 17, 32, 26, 15, 90, 14, 33, 15, 27, 25, 26, 34, 0, 8, 25, 62, 31, 10, 14, 26, 31, 13, 5, 33, 31, 16, 14, 75, 31, 17, 24, 29, 31, 27, 5, 75, 77, 0, 13, 5, 33, 34, 17, 5, 75, 31, 27, 5, 29, 66, 0, 8, 24, 29, 15, 72, 64, 75, 15, 10, 5, 33, 31, 13, 24, 75, 31, 16, 24, 33, 7, 17, 14, 62, 31, 27, 5, 26, 66, 0, 13, 14, 62, 31, 16, 14, 73, 31, 17, 14, 62, 31, 27, 5, 9, 66, 0, 8, 5, 73, 52, 10, 14, 9, 52, 70, 5, 62, 52, 17, 25, 26, 31, 27, 5, 62, 28, 0, 1, 25, 73, 19, 8, 5, 21, 31, 10, 5, 73, 7, 17, 14, 9, 22, 90, 38, 62, 15, 27, 25, 73, 66, 0, 4, 5, 9, 31, 8, 25, 6, 36, 17, 25, 20, 19, 0, 1, 5, 21, 15, 4, 5, 21, 31, 8, 25, 61, 15, 10, 5, 61, 7, 13, 25, 21, 52, 16, 11, 61, 31, 17, 5, 9, 31, 27, 14, 62, 47, 0, 13, 25, 76, 19, 17, 25, 21, 34, 0, 1, 5, 73, 31, 4, 5, 9, 31, 8, 14, 62, 7, 10, 14, 9, 31, 13, 5, 62, 31, 16, 25, 26, 31, 17, 38, 33, 15, 90, 5, 75, 15, 27, 25, 26, 19, 0, 13, 5, 62, 7, 16, 14, 9, 7, 17, 32, 26, 15, 90, 11, 33, 15, 27, 5, 26, 41, 0, 8, 14, 26, 15, 72, 64, 33, 15, 10, 11, 75, 7, 13, 11, 29, 31, 16, 24, 75, 7, 17, 25, 26, 31, 27, 5, 33, 41, 0, 1, 14, 93, 31, 4, 38, 104, 31, 8, 64, 29, 52, 10, 24, 75, 7, 13, 24, 33, 7, 16, 14, 75, 31, 17, 64, 29, 31]\n",
      "3\n",
      "[0, 1, 2, 113, 4, 54, 30, 31, 8, 64, 48, 31, 10, 51, 30, 31, 13, 64, 48, 31, 16, 64, 30, 31, 17, 64, 48, 7, 27, 11, 48, 31, 0, 1, 54, 50, 31, 4, 51, 30, 31, 8, 51, 48, 28, 16, 54, 55, 31, 17, 54, 30, 31, 27, 51, 48, 31, 0, 1, 51, 48, 31, 4, 53, 30, 31, 8, 54, 55, 31, 10, 54, 55, 31, 13, 51, 30, 31, 16, 54, 30, 31, 17, 54, 48, 31, 27, 54, 30, 31, 0, 1, 54, 55, 31, 4, 51, 30, 31, 8, 54, 55, 31, 10, 64, 55, 31, 13, 64, 30, 31, 16, 32, 48, 31, 17, 64, 30, 31, 27, 64, 55, 31, 0, 1, 32, 30, 31, 4, 51, 48, 31, 8, 32, 30, 31, 10, 32, 55, 31, 13, 32, 30, 31, 16, 64, 48, 31, 17, 32, 30, 34, 17, 32, 48, 31, 27, 11, 30, 34, 0, 1, 32, 30, 31, 4, 64, 55, 31, 8, 51, 30, 31, 10, 38, 48, 31, 13, 54, 100, 31, 16, 32, 30, 31, 17, 32, 48, 31, 27, 32, 48, 31, 0, 1, 64, 100, 31, 4, 64, 30, 31, 8, 51, 55, 31, 10, 64, 30, 31, 13, 51, 55, 31, 16, 11, 30, 31, 17, 32, 55, 34, 0, 1, 51, 30, 31, 4, 51, 55, 31, 8, 11, 111, 31, 10, 64, 30, 31, 13, 32, 30, 31, 16, 32, 55, 31, 17, 64, 55, 31]\n",
      "4\n",
      "[0, 1, 43, 209, 8, 43, 209, 13, 43, 209, 13, 11, 6, 34, 13, 11, 82, 34, 17, 43, 209, 17, 38, 57, 34, 17, 38, 98, 34, 0, 1, 43, 209, 1, 38, 12, 34, 1, 38, 39, 34, 8, 43, 209, 8, 32, 21, 31, 8, 32, 118, 31, 10, 51, 57, 31, 10, 51, 98, 31, 13, 43, 209, 13, 38, 12, 108, 13, 38, 39, 108, 17, 43, 209, 0, 1, 43, 209, 8, 43, 209, 13, 43, 209, 13, 38, 6, 34, 13, 38, 82, 34, 17, 43, 209, 17, 64, 57, 34, 17, 64, 98, 34, 0, 1, 43, 209, 1, 64, 12, 34, 1, 64, 39, 34, 8, 43, 209, 8, 51, 57, 31, 8, 51, 98, 31, 10, 32, 6, 31, 10, 32, 82, 31, 13, 43, 209, 13, 38, 50, 87, 13, 38, 96, 87, 17, 43, 209, 0, 1, 43, 209, 8, 43, 209, 8, 32, 82, 15, 72, 35, 98, 15, 10, 35, 39, 15, 91, 51, 118, 15, 13, 43, 209, 13, 32, 86, 31, 13, 32, 88, 31, 16, 51, 96, 31, 16, 51, 121, 31, 17, 43, 209, 17, 51, 86, 31, 17, 51, 88, 31, 27, 51, 96, 31, 27, 51, 121, 31, 0, 1, 43, 209, 1, 64, 82, 31, 1, 64, 140, 31, 4, 64, 98, 31, 4, 64, 143, 31, 8, 43, 209, 8, 32, 82, 31, 8, 32, 140, 31, 10, 64, 98, 31, 10, 64, 121, 31, 13, 11, 39, 34, 13, 11, 140, 34, 17, 54, 98, 31, 17, 54, 143, 31, 27, 64, 82, 31, 27, 64, 140, 31, 0, 1, 64, 96, 34, 1, 64, 121, 34, 8, 64, 82, 31, 8, 64, 140, 31, 10, 54, 96, 31, 10, 54, 121, 31, 13, 32, 86, 34, 13, 32, 88, 34, 17, 51, 96, 31, 17, 51, 121, 31, 27, 54, 86, 31, 27, 54, 88, 31, 0, 1, 32, 21, 85, 1, 32, 118, 85, 13, 38, 12, 34, 13, 38, 39, 34, 17, 32, 82, 31, 17, 32, 140, 31, 27, 32, 82, 31, 27, 32, 140, 31, 0, 1, 38, 12, 31, 1, 38, 39, 31, 4, 54, 82, 31, 4, 54, 140, 31, 8, 64, 82, 34, 8, 64, 140, 34, 13, 32, 12, 34, 13, 32, 39, 34]\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 110, 8, 2, 110, 72, 18, 50, 28, 13, 2, 110, 78, 11, 30, 31, 17, 2, 110, 90, 25, 33, 37, 0, 1, 2, 110, 8, 2, 110, 72, 24, 30, 66, 13, 2, 110, 16, 25, 33, 15, 78, 38, 30, 15, 17, 2, 110, 17, 24, 55, 85, 0, 1, 2, 110, 8, 2, 110, 72, 11, 55, 28, 78, 25, 30, 15, 17, 51, 33, 22, 90, 5, 33, 42, 0, 23, 18, 30, 15, 8, 32, 55, 15, 72, 11, 111, 47, 16, 11, 55, 15, 78, 32, 30, 15, 17, 32, 55, 22, 90, 11, 55, 85]\n",
      "6\n",
      "[0, 1, 2, 113, 67, 45, 86, 42, 8, 2, 113, 10, 35, 96, 7, 91, 53, 86, 15, 13, 2, 113, 13, 53, 82, 22, 70, 49, 98, 15, 16, 51, 86, 15, 78, 5, 96, 41, 17, 2, 113, 90, 35, 86, 22, 27, 51, 61, 19, 0, 1, 2, 113, 67, 53, 57, 19, 4, 35, 12, 15, 23, 53, 84, 15, 8, 2, 113, 8, 11, 98, 31, 72, 51, 57, 31, 10, 53, 57, 15, 91, 35, 96, 15, 13, 51, 82, 22, 70, 51, 98, 31, 16, 53, 84, 15, 78, 51, 96, 7, 17, 64, 86, 15, 90, 51, 86, 7, 74, 64, 84, 15, 0, 1, 11, 96, 15, 67, 64, 86, 31, 23, 32, 96, 52, 8, 54, 86, 31, 10, 35, 96, 15, 91, 54, 84, 15, 13, 51, 98, 15, 70, 32, 86, 7, 16, 35, 96, 15, 78, 54, 86, 15, 17, 35, 86, 7, 90, 11, 121, 15, 27, 51, 88, 15, 74, 38, 121, 15, 0, 1, 2, 117, 67, 11, 88, 19, 72, 54, 107, 19, 13, 35, 121, 15, 70, 49, 86, 15, 16, 35, 96, 31, 17, 51, 86, 31, 27, 51, 12, 31, 0, 1, 53, 86, 47, 67, 53, 86, 15, 4, 51, 61, 15, 23, 54, 12, 15, 8, 54, 57, 15, 10, 35, 96, 15, 91, 54, 86, 15, 13, 35, 96, 15, 70, 53, 84, 47, 70, 35, 61, 15, 16, 53, 98, 15, 78, 54, 86, 15, 17, 32, 88, 15, 17, 35, 57, 15, 90, 35, 58, 15, 27, 35, 86, 15, 74, 63, 98, 15, 0, 1, 53, 57, 19, 67, 51, 96, 41, 8, 35, 57, 31, 91, 35, 61, 15, 13, 35, 57, 22, 70, 32, 86, 15, 70, 51, 12, 15, 16, 35, 61, 41, 17, 51, 86, 15, 74, 32, 86, 15, 0, 1, 54, 58, 31, 4, 35, 12, 15, 23, 51, 86, 15, 8, 51, 84, 15, 72, 54, 57, 31, 10, 45, 57, 31, 91, 35, 86, 31, 16, 35, 58, 15, 91, 51, 57, 15, 13, 63, 50, 22, 13, 35, 96, 15, 70, 51, 12, 15, 16, 35, 12, 15, 78, 51, 86, 7, 17, 51, 6, 41, 17, 51, 96, 31, 90, 35, 86, 15, 74, 35, 86, 31, 74, 54, 58, 52, 0, 1, 54, 58, 31, 67, 51, 86, 19, 67, 51, 57, 31, 4, 35, 96, 52, 8, 35, 12, 31, 91, 35, 86, 31, 16, 35, 12, 31]\n",
      "7\n",
      "[0, 1, 2, 114, 1, 32, 86, 15, 1, 32, 96, 15, 67, 32, 21, 22, 67, 64, 12, 22, 4, 64, 21, 15, 4, 64, 12, 15, 23, 32, 86, 22, 23, 51, 12, 22, 8, 64, 57, 22, 72, 64, 96, 22, 72, 32, 86, 119, 13, 32, 88, 42, 0, 1, 64, 12, 15, 67, 32, 39, 52, 13, 64, 21, 101, 8, 51, 88, 15, 74, 32, 118, 52, 13, 32, 121, 101, 0, 1, 32, 39, 34, 1, 32, 118, 41, 1, 32, 118, 42, 8, 32, 21, 42, 10, 38, 118, 42, 13, 32, 118, 31, 16, 32, 118, 85, 17, 51, 118, 85, 0, 1, 64, 118, 85, 1, 43, 114, 1, 24, 118, 19, 4, 32, 98, 41, 8, 64, 50, 41, 8, 43, 114, 13, 32, 96, 34, 0, 1, 32, 121, 34, 8, 64, 57, 34, 1, 32, 98, 85, 1, 64, 98, 7, 10, 51, 39, 34, 17, 32, 96, 31, 27, 32, 121, 31, 0, 1, 64, 57, 87, 1, 38, 98, 108, 0, 1, 11, 98, 31, 4, 32, 12, 15, 4, 64, 57, 52, 8, 64, 98, 7, 10, 64, 57, 66, 13, 64, 98, 22, 16, 64, 57, 15, 78, 51, 98, 22, 17, 64, 98, 22, 17, 64, 57, 41, 0, 1, 51, 96, 22, 1, 64, 12, 41, 8, 64, 57, 41, 13, 51, 12, 41, 17, 64, 57, 31, 27, 51, 98, 31, 27, 32, 57, 85, 0, 1, 64, 98, 22, 74, 32, 98, 34, 1, 64, 98, 19, 1, 64, 50, 52, 23, 64, 98, 87]\n",
      "8\n",
      "[0, 1, 43, 191, 67, 24, 75, 15, 4, 11, 20, 87, 4, 38, 33, 15, 23, 64, 75, 15, 8, 32, 29, 15, 8, 64, 75, 59, 27, 38, 73, 7, 74, 14, 75, 15, 74, 32, 30, 7, 0, 1, 38, 21, 7, 1, 32, 75, 22, 67, 32, 29, 15, 4, 38, 20, 34, 4, 24, 75, 52, 8, 51, 33, 15, 10, 38, 82, 41, 10, 38, 33, 7, 13, 32, 30, 15, 70, 11, 75, 42, 16, 11, 76, 52, 27, 32, 21, 7, 0, 1, 11, 73, 135, 72, 38, 93, 15, 10, 38, 30, 15, 91, 38, 75, 15, 13, 64, 29, 15, 70, 64, 111, 15, 16, 14, 75, 31, 17, 38, 29, 66, 27, 11, 6, 52, 0, 1, 32, 111, 15, 4, 11, 75, 34, 4, 38, 97, 137, 10, 11, 75, 15, 91, 32, 30, 15, 13, 38, 48, 22, 70, 24, 26, 15, 78, 24, 62, 7, 90, 14, 6, 15, 74, 11, 9, 7, 0, 4, 24, 73, 31, 4, 38, 75, 31, 4, 38, 73, 31, 8, 38, 33, 15, 8, 38, 21, 15, 72, 38, 26, 7, 72, 38, 20, 7, 91, 11, 33, 7, 91, 11, 21, 7, 70, 11, 29, 36, 70, 11, 9, 36, 0, 67, 24, 29, 31, 67, 24, 9, 31, 23, 11, 75, 7, 23, 11, 73, 7, 72, 11, 111, 7, 72, 11, 6, 7, 91, 38, 104, 31, 91, 38, 62, 31, 70, 24, 93, 28, 70, 24, 26, 28, 0, 67, 11, 75, 31, 67, 11, 73, 31, 23, 11, 33, 7, 23, 11, 21, 7, 72, 38, 26, 7, 72, 38, 20, 7, 91, 38, 33, 7, 91, 38, 21, 7, 16, 11, 29, 47, 16, 11, 9, 47, 74, 38, 33, 15, 74, 38, 21, 15, 0, 67, 38, 75, 125, 67, 38, 73, 125, 0, 67, 38, 75, 7, 67, 38, 73, 7, 23, 38, 33, 7, 23, 38, 21, 7, 72, 38, 26, 7, 72, 38, 20, 7, 91, 38, 33, 15, 91, 38, 21, 15, 70, 24, 29, 36, 70, 24, 9, 36, 0, 67, 38, 29, 7, 67, 38, 9, 7, 23, 38, 75, 7, 23, 38, 73, 7, 72, 11, 111, 7, 72, 11, 6, 7, 91, 38, 104, 31, 91, 38, 62, 31, 70, 11, 93, 42, 70, 11, 26, 42, 0, 67, 38, 75, 7, 67, 38, 73, 7, 23, 38, 29, 7, 23, 38, 9, 7, 72, 38, 75, 7, 72, 38, 73, 7, 91, 11, 111, 7, 91, 11, 6, 7, 70, 11, 29, 41, 70, 11, 9, 41, 90, 38, 104, 41, 90, 38, 62, 41, 0, 67, 11, 93, 135, 67, 11, 26, 135]\n",
      "9\n",
      "[0, 1, 2, 142, 10, 54, 57, 7, 91, 11, 61, 15, 13, 32, 86, 15, 70, 25, 76, 31, 78, 11, 96, 31, 90, 5, 86, 31, 74, 38, 12, 22, 0, 1, 25, 61, 47, 10, 54, 57, 7, 91, 32, 86, 15, 13, 32, 96, 15, 70, 25, 76, 31, 78, 38, 96, 31, 90, 11, 86, 7, 74, 24, 61, 15, 0, 1, 18, 76, 52, 23, 5, 96, 7, 72, 38, 86, 31, 91, 32, 61, 15, 13, 38, 98, 41, 90, 25, 98, 34, 0, 67, 5, 84, 34, 23, 79, 76, 22, 8, 38, 96, 15, 72, 5, 12, 15, 10, 5, 58, 15, 91, 5, 58, 15, 13, 49, 39, 15, 70, 24, 88, 34, 74, 18, 107, 15, 0, 1, 11, 12, 22, 67, 25, 57, 37, 70, 11, 39, 7, 16, 5, 107, 7, 17, 32, 88, 15, 90, 11, 88, 15, 74, 24, 121, 15, 0, 1, 51, 88, 15, 67, 32, 121, 7, 23, 38, 144, 66, 16, 64, 121, 15, 78, 38, 88, 15, 17, 32, 107, 15, 90, 11, 39, 7, 74, 24, 88, 15, 0, 1, 64, 98, 22, 67, 38, 39, 31, 23, 64, 107, 34, 16, 51, 88, 22, 16, 49, 121, 15, 78, 32, 88, 15, 78, 25, 121, 31, 27, 11, 121, 22, 27, 51, 98, 22, 74, 54, 39, 22, 74, 38, 84, 31, 0, 4, 5, 84, 22, 4, 49, 98, 7, 23, 38, 98, 22, 23, 5, 107, 7, 10, 18, 88, 7, 13, 24, 88, 22, 13, 64, 121, 15, 70, 54, 98, 22, 16, 24, 39, 15, 78, 38, 88, 7, 17, 64, 88, 22, 74, 54, 39, 15, 0, 1, 64, 121, 15, 67, 54, 88, 15, 4, 24, 88, 22, 4, 32, 88, 22, 23, 54, 39, 15, 8, 14, 88, 15, 72, 38, 121, 15, 10, 51, 88, 15, 91, 51, 39, 15, 13, 51, 98, 15, 70, 54, 88, 15, 70, 64, 39, 7, 16, 38, 88, 31, 78, 51, 88, 15, 17, 14, 121, 7, 90, 54, 88, 15, 27, 38, 121, 7, 74, 54, 88, 31, 0, 1, 64, 39, 22, 67, 51, 107, 7, 67, 51, 88, 22, 4, 63, 84, 15, 23, 11, 98, 22, 8, 5, 143, 41, 72, 54, 98, 22, 10, 64, 144, 22, 72, 24, 84, 7, 91, 54, 88, 22, 13, 51, 96, 7, 70, 64, 121, 41, 16, 49, 121, 7, 16, 35, 39, 7, 17, 38, 143, 19, 17, 64, 121, 7, 17, 64, 121, 31, 27, 51, 144, 31, 27, 54, 121, 15, 74, 54, 144, 15, 74, 51, 121, 22]\n",
      "10\n",
      "[0, 1, 2, 114, 1, 5, 9, 15, 4, 5, 20, 15, 23, 5, 26, 19, 10, 5, 20, 31, 16, 25, 76, 19, 90, 64, 26, 15, 27, 25, 20, 31, 0, 1, 5, 26, 31, 4, 5, 26, 7, 8, 5, 20, 15, 72, 25, 9, 15, 10, 25, 20, 15, 91, 5, 26, 19, 16, 25, 20, 7, 16, 5, 20, 15, 78, 5, 26, 15, 17, 11, 20, 31, 27, 25, 20, 31, 0, 67, 14, 26, 15, 4, 64, 20, 41, 10, 25, 20, 31, 13, 5, 26, 15, 70, 14, 9, 15, 16, 25, 20, 7, 17, 25, 20, 15, 90, 5, 20, 7, 27, 25, 21, 47, 0, 8, 11, 73, 31, 10, 5, 26, 15, 91, 5, 20, 15, 13, 5, 26, 15, 70, 11, 26, 41, 78, 64, 26, 31, 17, 14, 26, 31, 27, 18, 20, 22, 0, 1, 5, 20, 15, 67, 5, 9, 15, 4, 5, 26, 15, 23, 11, 20, 31, 8, 25, 73, 15, 72, 14, 9, 31, 10, 25, 20, 31, 91, 45, 26, 31, 16, 5, 73, 31, 16, 45, 9, 19]\n",
      "11\n",
      "[0, 1, 43, 170, 1, 38, 76, 47, 10, 64, 84, 7, 13, 38, 76, 77, 27, 64, 20, 41, 0, 4, 24, 76, 7, 8, 32, 106, 22, 10, 11, 76, 22, 13, 38, 76, 15, 16, 11, 20, 36, 0, 8, 32, 97, 7, 10, 38, 76, 41, 13, 38, 76, 19, 17, 24, 73, 52, 27, 38, 76, 52, 0, 1, 11, 76, 52, 8, 11, 73, 112, 0, 1, 38, 76, 41, 8, 38, 76, 7, 10, 11, 76, 7, 13, 11, 107, 52, 16, 32, 76, 31, 17, 64, 20, 52, 27, 11, 76, 7, 0, 1, 38, 73, 7, 4, 24, 97, 52, 8, 51, 73, 108, 0, 8, 11, 97, 52, 10, 38, 97, 19, 16, 11, 107, 7, 17, 64, 97, 31, 0, 1, 38, 97, 52, 8, 38, 97, 31, 10, 38, 97, 31, 13, 64, 97, 7, 16, 11, 107, 52]\n",
      "12\n",
      "[0, 1, 43, 114, 1, 32, 20, 31, 4, 51, 73, 15, 8, 51, 58, 31, 10, 51, 62, 31, 13, 51, 58, 66, 17, 54, 26, 31, 27, 54, 62, 31, 0, 1, 54, 9, 125, 13, 45, 100, 66, 17, 45, 104, 31, 17, 35, 26, 31, 27, 45, 93, 31, 27, 35, 58, 52, 0, 1, 45, 104, 52, 1, 51, 61, 52, 4, 49, 100, 166, 4, 54, 9, 7, 8, 35, 26, 31, 10, 54, 61, 7, 13, 54, 61, 28, 17, 35, 73, 66, 0, 1, 35, 58, 136, 91, 35, 75, 77, 74, 49, 100, 15, 0, 1, 53, 104, 108, 4, 35, 58, 31, 8, 51, 62, 31, 10, 54, 26, 31, 13, 54, 75, 52, 16, 51, 46, 31, 17, 54, 26, 31, 27, 54, 46, 31, 0, 1, 54, 62, 85, 10, 49, 104, 7, 91, 53, 93, 47, 13, 51, 46, 31, 16, 35, 26, 31, 17, 53, 104, 66, 17, 54, 46, 31, 27, 35, 75, 31, 0, 1, 49, 100, 173, 1, 54, 46, 173, 0, 13, 51, 58, 66, 17, 64, 20, 34, 0, 1, 54, 61, 77, 13, 51, 20, 85, 0, 1, 54, 76, 34, 8, 54, 20, 34, 13, 64, 61, 52, 78, 49, 86, 15, 17, 54, 61, 22, 17, 51, 73, 34, 0, 1, 35, 58, 215, 0, 13, 64, 58, 66, 17, 38, 73, 41, 0, 1, 54, 61, 85, 13, 51, 84, 59, 0, 1, 54, 76, 87, 17, 35, 20, 31, 27, 35, 86, 31, 0, 1, 54, 61, 196, 0, 8, 54, 100, 34, 13, 35, 104, 34, 17, 35, 93, 34]\n",
      "13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 147, 23, 64, 21, 41, 23, 64, 118, 41, 91, 64, 118, 19, 70, 32, 118, 15, 16, 54, 82, 15, 78, 51, 40, 22, 78, 51, 82, 22, 17, 54, 40, 22, 90, 51, 82, 7, 27, 51, 118, 7, 74, 51, 118, 22, 74, 51, 39, 22, 0, 1, 51, 40, 15, 67, 51, 39, 22, 67, 51, 39, 15, 4, 64, 40, 22, 23, 54, 39, 22, 23, 54, 40, 15, 72, 51, 39, 15, 10, 51, 82, 15, 91, 51, 39, 15, 91, 64, 40, 22, 13, 64, 9, 22, 13, 64, 12, 22, 70, 51, 21, 15, 16, 64, 12, 15, 78, 32, 21, 15, 78, 51, 12, 15, 17, 64, 39, 15, 90, 51, 21, 15, 27, 64, 40, 22, 74, 64, 82, 15, 0, 1, 51, 6, 31, 4, 38, 39, 22, 23, 51, 9, 22, 8, 51, 12, 22, 72, 51, 6, 22, 10, 32, 82, 22, 91, 64, 21, 15, 13, 64, 12, 22, 70, 51, 12, 22, 70, 64, 12, 22, 16, 64, 39, 22, 78, 51, 21, 15, 17, 51, 12, 15, 90, 54, 21, 22, 27, 51, 12, 22, 74, 51, 21, 15, 0, 1, 51, 12, 15, 67, 51, 21, 15, 4, 38, 21, 15, 23, 51, 118, 15, 8, 51, 21, 22, 72, 64, 118, 15, 10, 64, 82, 15, 91, 64, 118, 22, 13, 38, 82, 15, 70, 51, 12, 22, 16, 64, 12, 22, 78, 64, 21, 15, 17, 64, 21, 7, 90, 51, 6, 15, 27, 51, 12, 15, 74, 51, 12, 22, 0, 1, 51, 21, 15, 67, 51, 12, 15, 4, 51, 12, 15, 23, 51, 6, 15, 72, 51, 21, 15, 91, 54, 21, 22, 10, 38, 82, 31, 13, 64, 12, 31, 16, 64, 21, 15, 70, 51, 96, 34, 16, 51, 21, 15, 78, 51, 96, 15, 17, 64, 21, 22, 90, 64, 12, 15, 27, 51, 12, 22, 74, 32, 96, 22, 0, 1, 51, 21, 15, 67, 51, 82, 15, 4, 51, 40, 15, 23, 51, 21, 22, 8, 64, 12, 15, 72, 51, 21, 15, 10, 64, 21, 22, 91, 54, 96, 22, 13, 38, 12, 15, 13, 38, 82, 15, 16, 11, 82, 15, 78, 5, 21, 15, 17, 51, 6, 22, 90, 51, 21, 22, 27, 51, 82, 15, 0, 1, 51, 40, 15]\n",
      "14\n",
      "[0, 1, 43, 156, 1, 32, 61, 34, 8, 11, 86, 41, 13, 32, 96, 41, 17, 32, 76, 52, 0, 1, 38, 57, 28, 13, 38, 57, 7, 16, 32, 73, 15, 17, 14, 57, 15, 27, 24, 96, 19, 0, 4, 38, 61, 19, 10, 11, 58, 41, 16, 38, 61, 47, 0, 1, 38, 57, 37, 13, 11, 57, 7, 16, 11, 58, 15, 17, 14, 62, 15, 27, 38, 50, 36, 0, 8, 32, 46, 7, 10, 32, 58, 19, 16, 38, 57, 28, 0, 1, 38, 57, 108, 0, 1, 24, 62, 7, 4, 38, 58, 7, 8, 32, 57, 31, 10, 38, 58, 34]\n",
      "15\n",
      "[0, 1, 43, 141, 67, 64, 21, 52, 8, 64, 20, 52, 91, 38, 6, 7, 70, 64, 9, 19, 90, 64, 6, 31, 74, 32, 20, 7, 0, 67, 51, 21, 31, 8, 54, 20, 31, 91, 64, 6, 7, 70, 32, 26, 34, 90, 64, 26, 7, 74, 51, 20, 7, 0, 67, 51, 21, 19, 8, 51, 20, 52, 91, 51, 9, 7, 70, 51, 6, 19, 17, 51, 9, 19, 74, 54, 73, 41, 0, 23, 64, 26, 80, 90, 64, 26, 31, 74, 54, 20, 31, 0, 67, 54, 21, 19, 8, 51, 20, 52, 91, 51, 82, 31, 70, 51, 21, 42, 74, 51, 21, 15, 0, 1, 35, 20, 15, 67, 64, 21, 52, 8, 54, 20, 52, 91, 54, 12, 31, 70, 32, 9, 41, 90, 51, 26, 31, 74, 51, 6, 31, 0, 67, 51, 9, 31, 23, 51, 20, 31, 72, 51, 40, 31, 91, 64, 82, 7, 70, 64, 118, 52, 17, 32, 120, 19, 74, 54, 82, 7, 0, 1, 64, 40, 136]\n",
      "16\n",
      "[0, 1, 43, 208, 23, 54, 61, 15, 8, 35, 20, 22, 8, 64, 40, 135, 0, 23, 53, 73, 7, 8, 53, 20, 22, 8, 51, 84, 135, 0, 23, 45, 9, 34, 8, 54, 21, 22, 8, 64, 76, 135, 0, 23, 53, 61, 7, 8, 35, 20, 15, 8, 64, 40, 108, 0, 8, 5, 9, 31, 10, 14, 9, 31, 13, 14, 9, 31, 16, 5, 61, 31, 17, 25, 20, 31, 27, 5, 61, 31, 0, 1, 25, 9, 34, 8, 14, 73, 31, 10, 5, 73, 31, 13, 25, 73, 31, 16, 14, 61, 31, 17, 5, 73, 31, 27, 14, 58, 31, 0, 1, 24, 26, 34, 8, 11, 9, 31, 10, 24, 9, 31, 13, 14, 9, 31, 16, 24, 61, 31, 17, 14, 20, 31, 27, 14, 61, 31, 0, 1, 14, 9, 34, 8, 5, 61, 31, 10, 24, 9, 31, 13, 5, 73, 31, 16, 5, 26, 31, 17, 24, 9, 34]\n",
      "17\n",
      "[0, 1, 43, 89, 1, 71, 107, 7, 1, 71, 39, 7, 4, 71, 107, 15, 4, 71, 40, 15, 8, 43, 89, 8, 71, 107, 15, 8, 71, 107, 7, 10, 71, 61, 15, 10, 71, 76, 15, 13, 43, 89, 13, 71, 107, 15, 13, 71, 107, 15, 16, 63, 61, 15, 16, 63, 107, 15, 17, 43, 89, 17, 63, 84, 7, 17, 63, 84, 7, 27, 49, 76, 15, 27, 49, 76, 15, 0, 1, 43, 89, 1, 49, 107, 15, 1, 49, 107, 15, 4, 49, 107, 15, 4, 49, 97, 15, 8, 43, 89, 8, 63, 204, 7, 8, 63, 204, 7, 10, 49, 107, 7, 10, 51, 84, 7, 13, 43, 89, 13, 123, 107, 15, 13, 38, 107, 7, 16, 71, 107, 7, 16, 53, 107, 7, 17, 43, 89, 17, 71, 106, 7, 17, 53, 97, 7, 27, 187, 106, 15, 27, 53, 107, 7, 0, 1, 43, 89, 1, 63, 107, 7, 1, 35, 107, 7, 4, 187, 144, 15, 4, 45, 107, 15, 8, 43, 89, 8, 63, 107, 15, 8, 49, 107, 7, 10, 63, 107, 15, 10, 49, 97, 15, 13, 43, 89, 13, 45, 107, 15, 13, 53, 107, 15, 16, 49, 107, 15, 16, 49, 107, 15, 17, 43, 89, 17, 63, 204, 7, 17, 63, 107, 7]\n",
      "18\n",
      "[0, 1, 43, 89, 67, 51, 21, 66, 91, 53, 73, 15, 13, 51, 12, 22, 70, 51, 21, 66, 74, 51, 12, 22, 0, 1, 53, 73, 22, 67, 64, 73, 59, 74, 35, 73, 15, 0, 1, 54, 12, 15, 67, 35, 21, 22, 4, 53, 82, 77, 74, 53, 12, 15, 0, 1, 63, 73, 15, 67, 14, 9, 103, 70, 54, 6, 137, 74, 35, 21, 15, 0, 1, 11, 21, 68]\n",
      "19\n",
      "[0, 1, 2, 142, 8, 2, 142, 13, 2, 142, 70, 54, 9, 47, 78, 54, 29, 31, 17, 2, 142, 90, 54, 26, 31, 74, 64, 33, 28, 0, 1, 2, 142, 8, 2, 142, 8, 32, 33, 31, 10, 35, 26, 31, 10, 51, 33, 31, 91, 35, 26, 15, 13, 2, 142, 13, 53, 33, 31, 70, 35, 26, 15, 16, 51, 33, 15, 78, 64, 9, 15, 17, 2, 142, 90, 51, 29, 28, 27, 35, 33, 31, 0, 1, 2, 142, 1, 35, 29, 31, 23, 53, 29, 28, 10, 35, 26, 15, 91, 51, 33, 31, 13, 2, 142, 13, 2, 142, 70, 35, 26, 22, 70, 54, 26, 31, 16, 54, 20, 15, 78, 54, 21, 31, 17, 35, 33, 7, 90, 35, 33, 15, 27, 53, 33, 7, 0, 1, 2, 142, 1, 2, 142, 1, 53, 30, 31, 4, 32, 9, 31, 8, 35, 33, 37, 91, 54, 9, 7, 13, 54, 33, 19, 13, 51, 9, 19, 17, 35, 46, 15, 90, 51, 26, 15, 27, 51, 33, 31, 0, 1, 2, 142, 1, 49, 29, 31, 67, 51, 9, 31, 23, 51, 29, 31, 23, 51, 29, 7, 8, 35, 29, 31, 10, 35, 29, 15, 10, 51, 29, 28, 91, 51, 29, 31, 13, 2, 142, 13, 43, 142, 17, 64, 9, 31, 27, 51, 29, 15, 74, 64, 26, 15, 0, 1, 2, 142, 8, 51, 9, 15, 72, 64, 33, 52, 10, 51, 46, 7, 13, 64, 29, 31, 70, 54, 29, 15, 16, 51, 29, 31, 0, 1, 2, 142, 67, 53, 111, 31, 23, 51, 29, 31, 23, 64, 29, 31, 72, 51, 30, 7, 10, 35, 29, 31, 91, 64, 29, 31, 13, 2, 142, 13, 64, 29, 47, 17, 2, 142]\n",
      "20\n",
      "[0, 1, 43, 165, 1, 11, 96, 34, 8, 38, 84, 34, 13, 14, 86, 31, 16, 14, 84, 31, 17, 5, 98, 31, 27, 14, 39, 31, 0, 1, 25, 88, 34, 8, 25, 107, 31, 10, 11, 39, 31, 13, 25, 107, 28, 27, 5, 107, 31, 0, 1, 25, 98, 28, 10, 5, 39, 31, 13, 18, 88, 34, 17, 14, 107, 31, 27, 14, 84, 31, 0, 1, 14, 76, 31, 4, 24, 96, 31, 8, 14, 76, 31, 10, 5, 84, 31, 13, 25, 96, 34, 17, 5, 86, 34, 0, 1, 5, 61, 85, 13, 25, 39, 34, 17, 25, 107, 34, 0, 1, 25, 88, 19, 4, 11, 107, 31, 8, 24, 39, 31, 10, 14, 98, 31, 13, 24, 96, 28, 27, 5, 61, 31, 0, 1, 5, 57, 34, 8, 14, 98, 31, 10, 14, 84, 31, 13, 25, 76, 31, 16, 14, 96, 31, 17, 24, 86, 31, 27, 64, 86, 31, 74, 24, 76, 85]\n",
      "21\n",
      "[0, 1, 2, 142, 8, 24, 62, 15, 72, 32, 58, 22, 10, 5, 73, 34, 10, 5, 76, 136, 27, 32, 58, 41, 0, 67, 14, 26, 31, 8, 14, 46, 31, 72, 51, 20, 22, 10, 51, 61, 42, 0, 1, 5, 76, 15, 4, 5, 40, 15, 8, 14, 62, 15, 8, 5, 97, 15, 72, 32, 58, 22, 10, 5, 73, 7, 10, 25, 97, 66, 17, 5, 107, 41, 27, 25, 58, 31, 0, 67, 11, 26, 52, 23, 14, 76, 52, 8, 64, 46, 7, 10, 14, 62, 19, 10, 14, 76, 31, 0, 67, 24, 107, 22, 23, 25, 120, 7, 72, 25, 120, 19, 10, 5, 61, 47, 78, 32, 107, 15, 17, 64, 20, 31, 17, 64, 120, 22, 90, 38, 73, 7, 90, 24, 97, 15, 74, 5, 107, 31, 0, 10, 24, 61, 34, 91, 32, 120, 22, 13, 11, 120, 15, 16, 14, 106, 22, 78, 24, 106, 15, 17, 14, 76, 15, 90, 11, 73, 7, 0, 8, 14, 62, 15, 8, 51, 107, 22, 72, 32, 58, 22, 72, 64, 120, 22, 72, 25, 88, 7, 10, 25, 9, 41, 91, 5, 107, 15, 13, 5, 120, 15, 16, 14, 107, 15, 78, 14, 97, 15, 17, 64, 40, 15, 90, 11, 84, 31, 27, 25, 58, 52, 0, 67, 14, 26, 31, 67, 51, 76, 22, 4, 35, 84, 22, 4, 51, 40, 15, 23, 11, 46, 52, 23, 201, 84, 22, 23, 54, 76, 15, 72, 54, 20, 15, 72, 14, 62, 19, 72, 64, 76, 31]\n",
      "22\n",
      "[0, 1, 2, 69, 1, 51, 58, 15, 67, 51, 86, 7, 23, 32, 86, 31, 8, 2, 69, 72, 64, 61, 28, 13, 2, 69, 78, 64, 62, 31, 17, 2, 69, 90, 54, 58, 31, 74, 51, 62, 31, 0, 67, 51, 58, 66, 91, 51, 73, 31, 70, 51, 58, 31, 78, 54, 73, 31, 90, 51, 61, 34, 0, 67, 32, 73, 31, 23, 32, 61, 31, 72, 51, 48, 42, 78, 51, 62, 31, 90, 51, 58, 31, 74, 51, 73, 31, 0, 67, 51, 62, 31, 23, 51, 58, 31, 72, 51, 73, 103, 0, 67, 64, 58, 31, 23, 32, 73, 31, 72, 64, 61, 42, 78, 51, 20, 31, 90, 38, 61, 36, 0, 23, 64, 20, 31, 72, 51, 86, 28, 78, 51, 61, 31, 90, 64, 73, 41, 0, 67, 51, 61, 7, 23, 35, 73, 31, 72, 51, 58, 28, 78, 51, 73, 31, 90, 54, 62, 31, 74, 51, 46, 52, 0, 67, 51, 48, 31, 23, 54, 62, 31, 72, 54, 58, 87]\n",
      "23\n",
      "[0, 1, 2, 116, 67, 11, 48, 7, 67, 11, 86, 7, 23, 11, 57, 31, 23, 11, 98, 31, 72, 38, 48, 59, 72, 38, 86, 59, 74, 32, 12, 7, 74, 32, 39, 7, 0, 67, 38, 86, 7, 67, 38, 88, 7, 23, 24, 12, 7, 23, 24, 39, 7, 72, 24, 58, 52, 72, 24, 84, 52, 13, 38, 50, 42, 13, 38, 96, 42, 74, 24, 48, 7, 74, 24, 86, 7, 0, 67, 11, 58, 7, 67, 11, 84, 7, 23, 11, 57, 31, 23, 11, 98, 31, 72, 38, 48, 59, 72, 38, 86, 59, 74, 32, 12, 7, 74, 32, 39, 7, 0, 67, 38, 86, 7, 67, 38, 88, 7, 23, 24, 12, 7, 23, 24, 39, 7, 72, 24, 57, 52, 72, 24, 98, 52, 13, 38, 58, 42, 13, 38, 84, 42, 74, 24, 48, 7, 74, 24, 86, 7, 0, 67, 11, 58, 7, 67, 11, 98, 7, 23, 11, 57, 31, 23, 11, 98, 31, 72, 38, 86, 59, 72, 38, 88, 59, 74, 32, 12, 7, 74, 32, 39, 7, 0, 67, 38, 86, 7, 67, 38, 88, 7, 23, 24, 12, 7, 23, 24, 39, 7, 72, 24, 58, 52, 72, 24, 84, 52, 13, 38, 50, 42, 13, 38, 96, 42, 74, 24, 48, 7, 74, 24, 86, 7, 0, 67, 11, 58, 7, 67, 11, 84, 7, 23, 11, 57, 31, 23, 11, 98, 31, 72, 38, 12, 59, 72, 38, 39, 59, 90, 38, 57, 77, 90, 38, 98, 77]\n",
      "24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 139, 1, 54, 29, 15, 67, 51, 26, 15, 4, 11, 33, 7, 23, 54, 26, 15, 8, 14, 46, 56, 0, 1, 32, 33, 22, 1, 35, 46, 7, 4, 14, 33, 15, 23, 32, 29, 22, 8, 11, 46, 31, 10, 51, 33, 22, 91, 32, 33, 77, 0, 4, 11, 33, 15, 23, 24, 46, 15, 8, 11, 111, 31, 10, 63, 46, 15, 91, 32, 75, 52, 16, 11, 33, 7, 17, 14, 75, 66, 0, 4, 11, 33, 15, 23, 14, 26, 22, 8, 24, 50, 7, 10, 32, 62, 15, 91, 14, 26, 19, 16, 54, 33, 15, 78, 51, 62, 66, 0, 1, 64, 29, 15, 67, 38, 33, 22, 4, 38, 26, 15, 23, 51, 33, 15, 8, 5, 26, 59, 0, 1, 24, 26, 7, 4, 11, 62, 7, 23, 5, 6, 7, 8, 24, 9, 77, 0, 4, 32, 6, 15, 23, 38, 26, 22, 8, 14, 26, 31, 10, 32, 33, 22, 91, 11, 33, 31, 16, 11, 30, 7, 17, 11, 46, 52, 74, 11, 29, 52, 0, 4, 32, 46, 31, 8, 32, 33, 125]\n",
      "25\n",
      "[0, 1, 43, 124, 8, 43, 124, 10, 35, 73, 34, 13, 43, 124, 16, 54, 61, 41, 17, 43, 124, 27, 54, 9, 83, 0, 1, 43, 124, 8, 43, 124, 13, 43, 124, 17, 43, 124, 17, 35, 62, 31, 27, 35, 26, 34, 0, 1, 43, 124, 4, 35, 33, 34, 8, 43, 124, 10, 35, 46, 34, 13, 43, 124, 16, 35, 33, 34, 17, 43, 124, 27, 35, 75, 87, 0, 1, 43, 124, 8, 43, 124, 13, 43, 124, 16, 35, 46, 31, 17, 43, 124, 17, 35, 33, 31, 27, 35, 33, 28, 0, 1, 43, 124, 8, 43, 124, 8, 35, 46, 28, 13, 43, 124, 16, 35, 75, 34, 17, 43, 124, 27, 35, 29, 108, 0, 1, 43, 124, 8, 43, 124, 10, 35, 21, 41, 13, 43, 124, 16, 54, 61, 34, 17, 43, 124, 27, 35, 73, 31, 0, 1, 43, 124, 1, 53, 9, 7, 4, 35, 9, 31, 8, 43, 124, 8, 35, 62, 31, 10, 35, 9, 66, 13, 43, 124, 16, 35, 73, 34, 17, 43, 124, 27, 53, 9, 56, 0, 1, 43, 124, 8, 43, 124, 13, 43, 124, 13, 54, 26, 31, 16, 35, 62, 31, 17, 43, 124, 17, 35, 6, 41, 27, 35, 9, 66, 0, 1, 43, 124, 4, 35, 21, 66, 8, 43, 124, 10, 35, 61, 34, 13, 43, 124, 16, 35, 9, 34, 17, 43, 124, 27, 35, 20, 85, 0, 1, 43, 124, 8, 43, 124, 10, 35, 21, 66, 13, 43, 124, 16, 35, 61, 66, 17, 43, 124, 27, 35, 9, 87, 0, 1, 43, 124, 8, 43, 124, 13, 43, 124, 16, 35, 6, 31, 17, 43, 124, 17, 35, 9, 52, 27, 54, 21, 59, 0, 1, 43, 124, 8, 43, 124, 10, 35, 6, 34, 13, 43, 124, 16, 35, 9, 34, 17, 43, 124, 27, 35, 20, 171, 0, 1, 43, 124, 8, 43, 124, 13, 43, 124, 16, 35, 21, 34, 17, 43, 124, 90, 35, 9, 81]\n",
      "26\n",
      "[0, 1, 2, 150, 90, 79, 26, 34, 90, 79, 33, 34, 0, 23, 24, 33, 31, 23, 11, 30, 103, 0, 72, 18, 30, 31, 91, 11, 33, 31, 70, 25, 30, 31, 78, 11, 33, 31, 90, 79, 50, 41, 0, 23, 25, 33, 31, 72, 18, 30, 31, 91, 18, 33, 56, 78, 79, 21, 31, 90, 79, 9, 15, 27, 38, 55, 15, 74, 38, 29, 31, 0, 67, 24, 9, 31, 23, 38, 6, 41, 72, 18, 33, 7, 72, 24, 9, 31, 91, 5, 50, 34, 78, 79, 6, 7, 90, 5, 30, 31, 74, 25, 33, 80, 0, 72, 11, 21, 31, 91, 11, 12, 31, 70, 5, 21, 31, 78, 11, 21, 7, 90, 38, 96, 31, 74, 32, 82, 7, 0, 67, 32, 9, 31, 23, 5, 6, 56, 78, 5, 50, 31, 90, 11, 33, 31, 90, 38, 33, 31, 74, 11, 33, 34, 0, 67, 5, 30, 31, 23, 5, 33, 31, 72, 79, 21, 31, 91, 11, 33, 31, 70, 11, 33, 31, 70, 11, 33, 31, 78, 11, 33, 31, 90, 25, 30, 31, 74, 11, 33, 31, 0, 67, 11, 33, 31, 23, 38, 50, 31, 72, 11, 33, 7, 91, 35, 30, 85]\n",
      "27\n",
      "[0, 1, 43, 191, 67, 24, 46, 15, 4, 11, 76, 87, 4, 38, 33, 15, 23, 64, 46, 15, 8, 32, 75, 15, 8, 64, 46, 59, 27, 38, 61, 7, 74, 14, 46, 15, 74, 32, 33, 7, 0, 1, 38, 20, 7, 1, 32, 46, 22, 67, 32, 75, 15, 4, 38, 76, 34, 4, 24, 46, 52, 8, 51, 26, 15, 10, 38, 40, 41, 10, 38, 26, 7, 13, 32, 33, 15, 70, 11, 46, 42, 16, 11, 84, 52, 27, 32, 20, 7, 0, 1, 11, 61, 135, 72, 38, 104, 15, 10, 38, 33, 15, 91, 38, 46, 15, 13, 64, 75, 15, 70, 64, 29, 15, 16, 14, 46, 31, 17, 38, 75, 66, 27, 11, 9, 52, 0, 1, 32, 29, 15, 4, 11, 46, 34, 4, 38, 107, 137, 10, 11, 46, 15, 91, 32, 33, 15, 13, 38, 50, 22, 70, 24, 62, 15, 78, 24, 58, 7, 90, 14, 9, 15, 74, 11, 73, 7, 0, 4, 24, 61, 31, 4, 38, 46, 31, 4, 38, 61, 31, 8, 38, 26, 15, 8, 38, 20, 15, 72, 38, 62, 7, 72, 38, 76, 7, 91, 11, 26, 7, 91, 11, 20, 7, 70, 11, 75, 36, 70, 11, 73, 36, 0, 67, 24, 75, 31, 67, 24, 73, 31, 23, 11, 46, 7, 23, 11, 61, 7, 72, 11, 29, 7, 72, 11, 9, 7, 91, 38, 100, 31, 91, 38, 58, 31, 70, 24, 104, 28, 70, 24, 62, 28, 0, 67, 11, 46, 31, 67, 11, 61, 31, 23, 11, 26, 7, 23, 11, 20, 7, 72, 38, 62, 7, 72, 38, 76, 7, 91, 38, 26, 7, 91, 38, 20, 7, 16, 11, 75, 47, 16, 11, 73, 47, 74, 38, 26, 15, 74, 38, 20, 15, 0, 67, 38, 46, 125, 67, 38, 61, 125, 0, 67, 38, 46, 7, 67, 38, 61, 7, 23, 38, 26, 7, 23, 38, 20, 7, 72, 38, 62, 7, 72, 38, 76, 7, 91, 38, 26, 15, 91, 38, 20, 15, 70, 24, 75, 36, 70, 24, 73, 36, 0, 67, 38, 75, 7, 67, 38, 73, 7, 23, 38, 46, 7, 23, 38, 61, 7, 72, 11, 29, 7, 72, 11, 9, 7, 91, 38, 100, 31, 91, 38, 58, 31, 70, 11, 104, 42, 70, 11, 62, 42, 0, 67, 38, 46, 7, 67, 38, 61, 7, 23, 38, 75, 7, 23, 38, 73, 7, 72, 38, 46, 7, 72, 38, 61, 7, 91, 11, 29, 7, 91, 11, 9, 7, 70, 11, 75, 41, 70, 11, 73, 41, 90, 38, 100, 41, 90, 38, 58, 41, 0, 67, 11, 104, 135, 67, 11, 62, 135]\n",
      "28\n",
      "[0, 1, 2, 162, 23, 64, 62, 85, 23, 51, 76, 85, 8, 2, 162, 13, 64, 62, 52, 13, 64, 76, 31, 16, 38, 76, 7, 78, 35, 62, 15, 17, 54, 62, 15, 17, 51, 62, 15, 90, 54, 76, 15, 27, 64, 62, 15, 74, 54, 62, 15, 0, 1, 64, 62, 15, 67, 64, 62, 47, 8, 54, 62, 15, 72, 64, 61, 7, 91, 38, 62, 15, 13, 64, 62, 7, 16, 54, 62, 15, 78, 35, 62, 15, 17, 51, 62, 31, 27, 51, 61, 31, 0, 1, 64, 62, 22, 1, 64, 62, 7, 4, 64, 62, 15, 8, 51, 62, 7, 10, 64, 75, 7, 13, 64, 62, 15, 70, 51, 62, 7, 17, 51, 62, 15, 90, 54, 62, 7, 27, 64, 62, 7, 0, 1, 64, 62, 7, 67, 64, 62, 7, 4, 64, 62, 7, 8, 5, 61, 7, 10, 53, 62, 7, 13, 64, 62, 15, 70, 35, 62, 31, 16, 51, 62, 15, 78, 51, 62, 7, 17, 51, 62, 47, 0, 1, 64, 62, 31, 4, 32, 62, 7, 23, 51, 62, 7, 8, 54, 62, 52, 10, 54, 62, 7, 13, 54, 62, 7, 16, 35, 46, 52, 17, 51, 62, 31, 27, 51, 62, 7, 0, 1, 64, 62, 52, 1, 64, 62, 41, 4, 64, 62, 31, 8, 64, 62, 66, 10, 51, 62, 22, 91, 54, 62, 7, 13, 54, 62, 7, 13, 51, 62, 7, 16, 51, 62, 15, 78, 64, 62, 52, 27, 35, 62, 85, 0, 8, 51, 62, 52, 13, 35, 62, 36, 16, 35, 62, 31, 17, 64, 62, 41, 0, 1, 54, 62, 15, 67, 64, 62, 7, 8, 35, 62, 7, 10, 54, 62, 15, 70, 51, 62, 7, 78, 35, 62, 7, 90, 64, 62, 52, 27, 51, 62, 15]\n",
      "29\n",
      "[0, 1, 2, 126, 67, 64, 9, 47, 10, 53, 6, 37, 27, 32, 57, 19, 0, 67, 54, 9, 47, 10, 54, 6, 15, 91, 51, 9, 22, 91, 63, 6, 22, 13, 54, 50, 41, 27, 38, 57, 34, 0, 4, 51, 9, 42, 10, 35, 6, 66, 27, 5, 12, 34, 0, 4, 32, 57, 66, 10, 32, 9, 41, 27, 11, 57, 41, 0, 4, 32, 9, 66, 10, 54, 6, 41, 0, 4, 11, 57, 15, 8, 38, 9, 7, 72, 53, 6, 15, 10, 32, 6, 31, 70, 51, 6, 15, 27, 24, 57, 34, 0, 4, 11, 9, 34, 10, 64, 6, 41, 27, 24, 12, 41, 0, 4, 38, 57, 34, 10, 32, 9, 66, 27, 24, 57, 19, 0, 4, 11, 9, 34, 72, 64, 6, 34]\n",
      "30\n",
      "[0, 1, 43, 165, 1, 38, 48, 83, 27, 32, 50, 15, 74, 38, 6, 15, 0, 1, 64, 58, 125, 17, 32, 57, 31, 27, 51, 58, 31, 0, 1, 64, 12, 83, 27, 64, 96, 15, 74, 32, 82, 15, 0, 1, 64, 84, 87, 17, 32, 82, 66, 0, 1, 32, 86, 85, 13, 32, 58, 36, 27, 64, 57, 15, 74, 32, 12, 15, 0, 1, 32, 61, 28, 10, 32, 12, 7, 13, 32, 12, 34]\n",
      "31\n",
      "[0, 1, 43, 105, 8, 43, 105, 13, 43, 105, 70, 32, 21, 7, 70, 24, 76, 7, 78, 38, 21, 7, 78, 24, 76, 7, 17, 43, 105, 90, 38, 61, 7, 90, 11, 20, 7, 74, 38, 73, 52, 74, 14, 21, 52, 0, 1, 43, 105, 4, 38, 61, 52, 4, 14, 20, 31, 8, 43, 105, 72, 38, 21, 7, 72, 5, 76, 7, 91, 38, 76, 52, 91, 14, 40, 52, 13, 43, 105, 16, 32, 20, 31, 16, 11, 82, 52, 17, 43, 105, 90, 38, 21, 7, 90, 38, 76, 7, 74, 11, 21, 41, 74, 24, 76, 19, 0, 1, 43, 105, 23, 38, 20, 34, 23, 24, 82, 34, 8, 43, 105, 13, 43, 105, 70, 51, 9, 7, 70, 38, 61, 7, 78, 32, 9, 7, 78, 38, 61, 7, 17, 43, 105, 90, 64, 73, 7, 90, 32, 21, 7, 74, 64, 61, 52, 74, 38, 20, 52, 0, 1, 43, 105, 4, 32, 9, 31, 4, 38, 61, 31, 8, 43, 105, 72, 11, 26, 31, 72, 38, 9, 31, 91, 38, 20, 52, 91, 14, 82, 52, 13, 43, 105, 16, 38, 21, 19, 16, 14, 76, 52, 17, 43, 105, 90, 38, 61, 31, 90, 51, 73, 7, 74, 11, 21, 34, 74, 24, 76, 37, 0, 1, 43, 105, 8, 43, 105, 13, 43, 105, 70, 24, 97, 15, 16, 5, 107, 15, 78, 25, 118, 34, 17, 43, 105, 90, 32, 75, 22, 90, 51, 73, 7, 74, 38, 75, 31, 74, 38, 73, 31, 0, 1, 43, 105, 67, 32, 46, 31, 67, 32, 61, 31, 23, 64, 33, 41, 23, 32, 21, 41, 8, 43, 105, 8, 5, 118, 7, 72, 38, 107, 15, 10, 24, 97, 22, 91, 51, 73, 22, 13, 43, 105, 13, 51, 9, 15, 70, 14, 107, 22, 16, 38, 107, 31, 17, 43, 105, 17, 38, 97, 31, 90, 64, 75, 15, 90, 51, 73, 7, 27, 32, 82, 22, 74, 38, 75, 31, 74, 32, 73, 52, 74, 32, 82, 34, 0, 1, 43, 105, 67, 64, 46, 15, 67, 64, 61, 15, 23, 64, 33, 31, 23, 32, 21, 52, 8, 43, 105, 72, 64, 75, 7, 72, 51, 73, 31, 91, 54, 46, 34, 91, 51, 61, 19, 13, 43, 105, 70, 24, 76, 15, 16, 11, 20, 7, 78, 32, 61, 15, 17, 43, 105, 17, 38, 57, 7, 90, 51, 62, 52, 0, 1, 43, 105, 8, 64, 104, 15, 72, 51, 100, 15, 72, 64, 55, 15, 10, 38, 75, 15, 10, 64, 46, 15, 91, 64, 33, 7, 91, 64, 26, 52, 70, 38, 82, 22, 16, 38, 82, 22, 78, 38, 82, 22, 17, 11, 20, 22, 90, 38, 20, 22, 27, 38, 20, 47, 0, 23, 38, 76, 41]\n",
      "32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 43, 89, 67, 51, 61, 66, 91, 53, 57, 15, 13, 51, 73, 22, 70, 51, 61, 66, 74, 51, 73, 22, 0, 1, 53, 57, 22, 67, 64, 57, 59, 74, 35, 57, 15, 0, 1, 54, 73, 15, 67, 35, 61, 22, 4, 53, 76, 77, 74, 53, 73, 15, 0, 1, 63, 57, 15, 67, 14, 58, 103, 70, 54, 62, 137, 74, 35, 61, 15, 0, 1, 11, 61, 68]\n",
      "33\n",
      "[0, 1, 43, 134, 4, 32, 33, 52, 8, 43, 134, 13, 43, 134, 16, 32, 33, 77, 17, 43, 134, 0, 1, 43, 134, 8, 43, 134, 10, 38, 29, 41, 13, 43, 134, 16, 5, 50, 41, 17, 43, 134, 27, 38, 33, 7, 0, 1, 43, 134, 1, 54, 50, 7, 4, 5, 33, 66, 8, 43, 134, 13, 43, 134, 16, 25, 30, 52, 17, 43, 134, 27, 32, 33, 19, 0, 1, 43, 134, 4, 38, 111, 7, 8, 43, 134, 8, 64, 122, 52, 10, 64, 111, 31, 13, 43, 134, 13, 53, 29, 31, 16, 32, 92, 56, 17, 43, 134, 0, 1, 43, 134, 8, 43, 134, 13, 43, 134, 16, 25, 122, 66, 17, 43, 134, 0, 1, 43, 134, 1, 24, 122, 15, 4, 38, 122, 31, 8, 43, 134, 8, 64, 92, 52, 10, 11, 122, 41, 13, 43, 134, 16, 38, 111, 37, 17, 43, 134, 27, 5, 29, 7, 0, 1, 43, 134, 1, 35, 30, 7, 4, 32, 29, 31, 8, 43, 134, 8, 64, 111, 31, 10, 51, 122, 31, 13, 43, 134, 13, 32, 111, 31, 16, 32, 29, 60, 17, 43, 134, 0, 1, 43, 134, 8, 43, 134, 13, 43, 134, 16, 79, 21, 56, 17, 43, 134, 0, 1, 43, 134, 8, 43, 134, 10, 79, 21, 31, 13, 43, 134, 13, 32, 12, 31, 16, 25, 21, 41, 17, 43, 134, 27, 79, 96, 52, 0, 1, 43, 134, 4, 79, 96, 28, 8, 43, 134, 13, 43, 134, 16, 18, 96, 52, 17, 43, 134, 27, 38, 21, 7, 0, 1, 43, 134, 1, 38, 96, 7, 4, 79, 21, 41, 8, 43, 134, 10, 11, 12, 34, 13, 43, 134, 16, 11, 9, 94, 17, 43, 134, 0, 1, 43, 134, 8, 43, 134, 13, 43, 134, 16, 25, 6, 31, 17, 43, 134, 27, 38, 6, 31, 0, 1, 43, 134, 1, 32, 9, 31, 4, 38, 50, 34, 8, 43, 134, 10, 32, 6, 41, 13, 43, 134, 16, 38, 26, 42, 17, 43, 134, 0, 1, 43, 134, 4, 38, 30, 34, 8, 43, 134, 10, 5, 26, 34, 13, 43, 134, 16, 11, 33, 22, 16, 35, 21, 22, 17, 43, 134, 17, 64, 33, 22, 27, 38, 33, 7, 0, 1, 43, 134, 1, 54, 30, 7, 4, 35, 12, 7, 8, 43, 134, 10, 25, 33, 7, 13, 43, 134, 13, 64, 30, 15, 16, 51, 21, 7, 17, 43, 134, 17, 54, 50, 31, 27, 64, 33, 31, 0, 1, 43, 134, 1, 54, 30, 52, 4, 11, 33, 52, 8, 43, 134, 8, 11, 30, 7, 72, 53, 29, 52, 13, 43, 134]\n",
      "34\n",
      "[0, 1, 2, 142, 1, 51, 39, 85, 8, 2, 142, 13, 2, 142, 13, 54, 58, 22, 70, 54, 58, 15, 16, 51, 57, 22, 78, 54, 12, 15, 17, 2, 142, 17, 64, 61, 31, 27, 54, 12, 15, 74, 64, 61, 15, 0, 1, 2, 142, 1, 51, 86, 31, 4, 54, 61, 15, 23, 54, 86, 15, 8, 2, 142, 8, 64, 20, 15, 72, 64, 86, 15, 10, 64, 61, 15, 91, 35, 73, 15, 13, 2, 142, 13, 51, 61, 7, 16, 54, 73, 15, 78, 64, 57, 15, 17, 2, 142, 17, 51, 73, 7, 27, 64, 57, 15, 74, 49, 58, 22, 0, 1, 2, 142, 1, 51, 73, 15, 67, 53, 61, 15, 4, 64, 73, 22, 4, 64, 57, 15, 23, 64, 58, 22, 8, 2, 142, 8, 51, 57, 7, 72, 54, 48, 7, 10, 54, 6, 7, 91, 54, 48, 15, 13, 2, 142, 13, 51, 26, 22, 70, 51, 26, 15, 16, 51, 62, 15, 78, 35, 58, 15, 17, 2, 142, 17, 64, 57, 15, 27, 51, 46, 7, 0, 1, 2, 142, 1, 35, 73, 7, 67, 51, 62, 7, 4, 35, 73, 7, 23, 35, 62, 15, 8, 2, 142, 8, 53, 73, 15, 72, 51, 62, 15, 10, 35, 73, 7, 91, 54, 62, 15, 13, 2, 142, 13, 54, 58, 15, 70, 35, 57, 15, 16, 54, 73, 15, 78, 11, 20, 15, 17, 2, 142, 17, 51, 86, 7, 90, 64, 61, 15, 27, 51, 73, 15, 74, 64, 57, 22, 0, 1, 2, 142, 1, 35, 57, 7, 4, 54, 73, 22, 4, 54, 57, 15, 23, 35, 58, 22, 8, 2, 142, 8, 35, 58, 7, 10, 35, 6, 7, 13, 2, 142, 13, 54, 73, 15, 70, 54, 26, 15, 16, 54, 61, 15, 78, 51, 73, 22, 17, 53, 57, 22, 17, 53, 26, 22, 90, 53, 48, 22, 90, 53, 46, 22, 27, 53, 55, 22, 27, 53, 100, 22, 74, 53, 111, 22, 74, 53, 73, 22, 0, 1, 53, 61, 22, 1, 53, 86, 85]\n",
      "35\n",
      "[0, 1, 2, 142, 8, 51, 58, 52, 10, 51, 46, 52, 13, 51, 62, 31, 16, 32, 58, 31, 17, 38, 73, 52, 27, 51, 46, 31, 0, 1, 54, 62, 31, 4, 32, 58, 7, 8, 64, 73, 31, 10, 64, 50, 31, 13, 64, 57, 31, 16, 51, 61, 7, 17, 64, 86, 7, 27, 54, 48, 31, 0, 1, 53, 46, 31, 4, 64, 73, 7, 8, 51, 61, 31, 10, 35, 46, 7, 13, 51, 58, 31, 16, 51, 57, 7, 17, 35, 61, 31, 27, 54, 62, 31, 0, 1, 51, 58, 7, 4, 51, 61, 7, 8, 64, 86, 31, 10, 51, 48, 7, 13, 35, 58, 7, 16, 51, 61, 31, 17, 64, 57, 34, 0, 1, 54, 62, 22, 1, 51, 57, 15, 67, 54, 62, 52, 67, 51, 58, 19, 8, 54, 46, 85, 8, 38, 73, 31, 10, 64, 61, 31, 13, 64, 86, 31, 16, 32, 61, 31, 17, 51, 46, 28, 17, 64, 96, 31, 27, 11, 86, 52, 0, 1, 32, 61, 31, 4, 51, 100, 31, 4, 64, 57, 31, 8, 35, 100, 34, 8, 64, 57, 31, 10, 64, 61, 31, 13, 51, 100, 34, 13, 64, 84, 19, 78, 64, 96, 22, 17, 35, 104, 36, 17, 35, 55, 37, 17, 51, 76, 66, 0, 67, 51, 58, 15, 4, 32, 73, 15, 23, 51, 58, 15, 8, 35, 75, 77, 8, 32, 73, 47, 16, 64, 86, 31, 17, 51, 46, 34, 17, 32, 61, 42, 0, 1, 54, 104, 41, 4, 38, 96, 31, 8, 54, 104, 28, 8, 51, 76, 112, 16, 35, 100, 31, 17, 54, 104, 85, 17, 35, 55, 85, 27, 51, 62, 7, 74, 54, 58, 15, 0, 1, 51, 46, 34, 1, 51, 58, 15, 67, 64, 61, 15, 4, 64, 86, 15, 23, 51, 96, 15]\n",
      "36\n",
      "[0, 27, 5, 55, 31, 0, 1, 25, 75, 83, 27, 14, 55, 34, 0, 4, 32, 104, 87, 27, 14, 127, 34, 0, 4, 25, 128, 87, 90, 5, 75, 31]\n",
      "37\n",
      "[0, 1, 43, 208, 23, 54, 6, 15, 8, 35, 57, 22, 8, 64, 86, 135, 0, 23, 53, 50, 7, 8, 53, 57, 22, 8, 51, 21, 135, 0, 23, 45, 48, 34, 8, 54, 58, 22, 8, 64, 12, 135, 0, 23, 53, 6, 7, 8, 35, 57, 15, 8, 64, 86, 108, 0, 8, 5, 48, 31, 10, 14, 48, 31, 13, 14, 48, 31, 16, 5, 6, 31, 17, 25, 57, 31, 27, 5, 6, 31, 0, 1, 25, 48, 34, 8, 14, 50, 31, 10, 5, 50, 31, 13, 25, 50, 31, 16, 14, 6, 31, 17, 5, 50, 31, 27, 14, 33, 31, 0, 1, 24, 55, 34, 8, 11, 48, 31, 10, 24, 48, 31, 13, 14, 48, 31, 16, 24, 6, 31, 17, 14, 57, 31, 27, 14, 6, 31, 0, 1, 14, 48, 34, 8, 5, 6, 31, 10, 24, 48, 31, 13, 5, 50, 31, 16, 5, 55, 31, 17, 24, 48, 34]\n",
      "38\n",
      "[0, 1, 43, 191, 23, 54, 50, 15, 72, 54, 48, 15, 10, 54, 50, 22, 91, 51, 50, 15, 13, 51, 48, 7, 70, 64, 9, 34, 90, 35, 6, 31, 74, 35, 50, 31, 0, 67, 51, 48, 31, 23, 51, 50, 31, 72, 51, 48, 15, 10, 51, 50, 31, 91, 51, 58, 31, 70, 35, 50, 31, 78, 51, 57, 31, 90, 64, 48, 31, 74, 32, 48, 31, 0, 67, 35, 48, 52, 72, 32, 48, 31, 91, 51, 48, 31, 70, 51, 50, 31, 78, 11, 48, 31, 90, 35, 48, 31, 74, 64, 48, 15, 0, 1, 35, 50, 31, 67, 51, 50, 19, 72, 51, 48, 41, 0, 67, 35, 48, 15, 23, 64, 48, 15, 8, 51, 48, 28, 72, 51, 50, 31, 72, 64, 48, 31, 91, 54, 50, 31, 70, 54, 48, 31, 78, 51, 50, 31, 90, 32, 48, 52, 27, 54, 50, 31, 0, 67, 51, 58, 31, 23, 64, 50, 31, 72, 51, 48, 52, 91, 54, 50, 31, 70, 54, 48, 52, 78, 51, 30, 52, 74, 54, 48, 31, 0, 67, 51, 48, 31, 23, 64, 48, 52, 72, 64, 48, 31, 72, 64, 57, 19, 70, 54, 58, 31, 78, 54, 57, 31, 90, 51, 55, 19, 27, 54, 48, 31, 0, 67, 35, 6, 31, 23, 64, 57, 31, 72, 64, 48, 52, 72, 51, 48, 31, 91, 54, 57, 31, 70, 64, 48, 31, 78, 54, 57, 31, 17, 64, 48, 7, 90, 54, 57, 15, 27, 54, 57, 31, 74, 64, 48, 31, 0, 67, 35, 48, 31, 67, 54, 48, 31, 23, 54, 62, 31, 72, 51, 50, 31, 91, 51, 57, 31, 70, 51, 48, 31]\n",
      "39\n",
      "[0, 1, 43, 156, 67, 54, 73, 7, 23, 54, 61, 7, 72, 54, 86, 19, 13, 35, 73, 31, 70, 35, 73, 31, 78, 54, 61, 28, 0, 72, 51, 73, 31, 91, 54, 61, 31, 70, 51, 73, 31, 78, 64, 58, 31, 90, 64, 62, 7, 74, 51, 58, 31, 0, 67, 54, 62, 31, 23, 51, 58, 52, 72, 54, 33, 34, 91, 51, 6, 31, 70, 35, 58, 31, 78, 54, 62, 31, 90, 54, 73, 31, 74, 54, 86, 31, 0, 67, 51, 62, 31, 23, 54, 26, 31, 72, 51, 62, 31, 91, 51, 58, 31, 91, 51, 58, 31, 70, 51, 58, 52, 78, 54, 73, 31, 90, 51, 58, 41, 0, 67, 51, 73, 31, 23, 51, 48, 31, 72, 51, 62, 31, 72, 64, 58, 31, 91, 51, 73, 31, 70, 35, 61, 31, 78, 64, 58, 15, 90, 54, 73, 7, 27, 54, 58, 31, 0, 67, 51, 73, 31, 72, 64, 58, 31, 72, 51, 62, 52, 91, 51, 73, 28, 78, 64, 58, 52, 0, 67, 54, 62, 19, 72, 64, 62, 31, 10, 54, 58, 52, 91, 54, 62, 31, 70, 54, 62, 31, 78, 54, 58, 31, 17, 54, 73, 31, 90, 54, 61, 31, 74, 54, 86, 15, 0, 67, 64, 58, 31, 23, 51, 73, 31, 72, 51, 62, 15, 91, 64, 58, 15, 13, 64, 62, 31, 70, 54, 61, 31, 78, 64, 62, 7]\n",
      "40\n",
      "[0, 1, 2, 181, 8, 43, 115, 13, 43, 115, 16, 54, 33, 31, 17, 51, 21, 7, 17, 51, 21, 7, 27, 51, 21, 7, 0, 1, 43, 115, 8, 43, 115, 8, 54, 21, 7, 10, 51, 6, 31, 13, 51, 6, 31, 16, 64, 9, 7, 17, 51, 6, 7, 27, 54, 50, 7, 0, 1, 43, 115, 8, 43, 115, 8, 51, 6, 15, 10, 51, 6, 15, 13, 54, 30, 15, 16, 54, 33, 7, 17, 64, 33, 31, 27, 51, 33, 31, 0, 1, 43, 115, 1, 51, 33, 7, 4, 51, 6, 103, 13, 43, 115, 16, 54, 33, 31, 17, 35, 21, 36, 0, 1, 64, 33, 7, 4, 51, 33, 7, 8, 43, 115, 8, 64, 9, 31, 10, 51, 6, 15, 10, 64, 33, 31, 13, 64, 26, 31, 16, 64, 33, 31, 17, 51, 33, 7, 27, 54, 33, 7]\n",
      "41\n",
      "[0, 1, 2, 89, 23, 35, 21, 34, 91, 35, 96, 52, 70, 49, 98, 15, 16, 35, 82, 15, 78, 35, 96, 77, 0, 23, 53, 21, 34, 91, 35, 96, 52, 70, 35, 82, 15, 16, 53, 98, 15, 78, 53, 96, 37, 0, 23, 35, 98, 34, 91, 35, 39, 31, 70, 53, 118, 52, 78, 35, 39, 34, 74, 53, 98, 66, 0, 23, 54, 39, 31, 72, 53, 98, 31, 91, 53, 82, 31, 70, 49, 98, 31, 78, 35, 96, 77, 0, 23, 35, 96, 34, 91, 35, 21, 31, 70, 35, 96, 52, 78, 53, 82, 28, 0, 67, 35, 96, 15, 4, 49, 82, 7, 23, 35, 98, 34, 91, 53, 39, 31, 70, 53, 98, 52, 78, 53, 82, 85, 0, 23, 49, 21, 52, 72, 53, 12, 31, 91, 53, 57, 66, 78, 35, 12, 34, 74, 53, 57, 31, 0, 67, 53, 6, 31, 23, 54, 50, 52, 72, 49, 6, 31, 91, 49, 12, 52, 70, 53, 21, 31, 78, 35, 96, 85, 0, 23, 49, 98, 34, 91, 53, 12, 31, 70, 53, 21, 31, 78, 35, 96, 85]\n",
      "42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 43, 206, 8, 32, 50, 19, 13, 38, 50, 7, 16, 32, 26, 15, 78, 64, 50, 22, 17, 32, 30, 34, 0, 1, 32, 30, 31, 4, 32, 30, 31, 8, 32, 6, 15, 8, 64, 57, 15, 10, 64, 50, 15, 10, 64, 9, 15, 13, 64, 6, 15, 13, 51, 57, 7, 16, 51, 9, 7, 16, 64, 12, 7, 17, 64, 6, 31, 17, 64, 57, 31, 27, 54, 50, 7, 27, 64, 9, 7, 0, 1, 51, 26, 7, 1, 64, 6, 7, 4, 51, 33, 7, 4, 51, 50, 7, 8, 64, 30, 15, 8, 64, 26, 7, 10, 64, 30, 22, 91, 64, 75, 22, 13, 38, 55, 31, 16, 64, 111, 31, 16, 51, 30, 31, 17, 54, 30, 7, 17, 64, 26, 7, 27, 54, 111, 15, 27, 54, 30, 15, 0, 1, 64, 30, 31, 1, 64, 26, 31, 4, 64, 30, 7, 4, 64, 50, 7, 8, 64, 30, 34, 8, 32, 50, 34, 13, 64, 50, 7, 13, 32, 9, 7, 16, 32, 9, 7, 16, 32, 12, 7, 17, 64, 50, 47, 17, 64, 9, 47, 0, 8, 64, 50, 22, 72, 64, 6, 22, 72, 51, 50, 22, 10, 64, 6, 22, 10, 64, 50, 22, 91, 64, 6, 22, 91, 64, 50, 22, 13, 24, 6, 15, 70, 64, 50, 7, 16, 51, 9, 15, 78, 32, 12, 22, 17, 54, 50, 28, 17, 64, 9, 28, 0, 4, 32, 30, 31, 8, 64, 26, 19, 8, 32, 6, 19, 13, 51, 26, 7, 13, 32, 6, 15, 16, 54, 50, 7, 16, 32, 9, 7, 17, 64, 6, 31, 17, 51, 57, 31, 27, 51, 9, 7, 0, 1, 24, 6, 31, 4, 32, 50, 7, 8, 32, 26, 7, 10, 64, 26, 22, 91, 54, 50, 15, 13, 35, 26, 7, 70, 64, 33, 7]\n",
      "43\n",
      "[0, 1, 43, 208, 8, 35, 73, 31, 10, 54, 73, 31, 13, 64, 9, 31, 16, 64, 6, 31, 17, 53, 26, 31, 27, 35, 62, 31, 0, 1, 54, 26, 31, 4, 64, 73, 31, 8, 35, 73, 31, 10, 35, 73, 31, 13, 64, 9, 31, 16, 49, 62, 31, 17, 51, 26, 31, 27, 54, 62, 31, 0, 1, 53, 26, 31, 4, 54, 26, 31, 8, 49, 26, 31, 10, 35, 26, 31, 13, 54, 26, 31, 16, 51, 62, 31, 17, 51, 26, 52, 27, 54, 26, 31, 0, 4, 51, 26, 31, 8, 35, 26, 31, 10, 54, 62, 31, 13, 51, 26, 7, 16, 54, 62, 31, 17, 51, 9, 31, 27, 64, 73, 31, 0, 1, 49, 75, 31, 4, 54, 62, 31, 8, 38, 26, 52, 10, 35, 26, 31, 13, 35, 26, 31, 16, 54, 62, 31, 17, 35, 75, 34, 17, 35, 33, 34, 0, 1, 35, 29, 34, 8, 35, 62, 31, 10, 54, 26, 31, 13, 51, 26, 31, 16, 51, 75, 31, 17, 54, 73, 31, 27, 35, 26, 31, 0, 1, 51, 62, 31, 4, 54, 26, 52, 8, 35, 62, 31, 10, 54, 26, 31, 13, 51, 73, 31, 16, 51, 26, 31, 17, 51, 46, 31, 17, 35, 26, 31, 27, 54, 29, 31, 0, 1, 54, 75, 31, 4, 51, 29, 31, 8, 35, 75, 31, 10, 54, 75, 31, 13, 64, 75, 31, 16, 35, 29, 31, 17, 51, 75, 52]\n",
      "44\n",
      "[0, 1, 43, 208, 1, 32, 55, 31, 4, 25, 30, 184, 0, 4, 11, 57, 31, 8, 38, 9, 31, 10, 38, 50, 31, 13, 11, 57, 19, 17, 79, 9, 7, 27, 11, 50, 31, 0, 1, 11, 30, 31, 4, 25, 33, 135, 0, 4, 79, 57, 31, 8, 5, 9, 31, 10, 32, 50, 31, 13, 32, 57, 34, 17, 25, 9, 31, 27, 32, 50, 31, 0, 1, 32, 55, 31, 4, 25, 30, 112, 27, 25, 30, 7, 0, 1, 79, 33, 15, 4, 24, 48, 103, 0, 1, 79, 33, 31, 4, 11, 55, 108]\n",
      "45\n",
      "[0, 1, 2, 114, 1, 14, 62, 22, 67, 14, 58, 22, 4, 14, 73, 22, 23, 25, 61, 42, 8, 2, 114, 13, 2, 114, 70, 14, 73, 22, 16, 25, 61, 22, 78, 18, 61, 7, 17, 2, 114, 90, 14, 20, 22, 27, 18, 61, 19, 0, 1, 2, 114, 67, 5, 73, 22, 4, 25, 58, 22, 23, 18, 73, 47, 8, 2, 114, 13, 2, 114, 70, 5, 73, 7, 78, 5, 58, 7, 17, 2, 114, 90, 24, 58, 22, 27, 5, 62, 31, 0, 1, 2, 114, 1, 14, 62, 15, 67, 11, 26, 22, 4, 14, 46, 22, 23, 11, 46, 7, 8, 2, 114, 72, 14, 61, 22, 10, 18, 73, 34, 13, 2, 114, 16, 14, 73, 22, 78, 25, 61, 22, 17, 2, 114, 17, 14, 61, 22, 90, 5, 20, 22, 27, 18, 20, 52, 0, 1, 2, 114, 67, 5, 61, 22, 4, 14, 20, 22, 23, 5, 76, 85, 8, 2, 114, 17, 25, 61, 66, 0, 67, 5, 73, 22, 4, 14, 9, 22, 23, 25, 61, 66, 13, 5, 73, 22, 70, 25, 61, 22]\n",
      "46\n",
      "[0, 1, 2, 99, 4, 32, 92, 19, 72, 32, 92, 7, 10, 51, 92, 7, 13, 11, 33, 41, 17, 11, 33, 34, 0, 1, 53, 111, 52, 4, 32, 33, 31, 8, 32, 75, 34, 13, 32, 33, 37, 0, 1, 32, 26, 19, 8, 51, 33, 7, 10, 54, 26, 7, 13, 32, 33, 7, 16, 51, 29, 7, 17, 51, 30, 7, 27, 53, 75, 7, 0, 1, 32, 29, 112, 0, 1, 11, 33, 41, 8, 51, 26, 7, 10, 32, 33, 7, 13, 32, 92, 19, 17, 64, 92, 41, 0, 1, 51, 111, 34, 8, 51, 122, 7, 10, 51, 92, 7, 13, 32, 92, 77, 0, 1, 32, 33, 41, 8, 32, 93, 15, 10, 51, 92, 7, 13, 51, 149, 41, 17, 32, 92, 7, 27, 51, 93, 31, 0, 1, 32, 92, 135]\n",
      "47\n",
      "[0, 1, 2, 89, 67, 14, 61, 15, 23, 18, 21, 34, 91, 5, 6, 7, 70, 25, 21, 7, 78, 25, 61, 7, 90, 24, 21, 31, 74, 5, 61, 47, 0, 91, 25, 61, 28, 90, 5, 73, 7, 74, 5, 57, 7, 0, 67, 18, 62, 41, 72, 5, 21, 22, 10, 5, 61, 22, 91, 18, 73, 125, 70, 14, 62, 31, 78, 64, 21, 7, 78, 24, 76, 7, 90, 64, 62, 15, 27, 64, 61, 31, 27, 11, 20, 52, 0, 1, 35, 62, 15, 67, 64, 21, 47, 67, 51, 76, 47, 72, 25, 62, 7, 91, 5, 73, 41, 78, 24, 73, 7, 90, 25, 57, 7, 74, 5, 73, 7, 0, 67, 25, 61, 7, 23, 14, 21, 19, 91, 25, 6, 31, 70, 14, 21, 31, 78, 14, 61, 31, 90, 11, 21, 37, 0, 67, 32, 62, 41, 23, 5, 6, 31, 72, 11, 21, 7, 72, 25, 21, 7, 91, 24, 61, 47, 91, 25, 20, 42, 90, 38, 9, 15, 74, 14, 61, 52, 0, 4, 5, 61, 52, 72, 25, 9, 7, 91, 54, 73, 47, 91, 14, 73, 47, 91, 24, 20, 66, 90, 54, 73, 37, 90, 38, 86, 37, 0, 72, 32, 73, 7, 72, 11, 21, 28, 78, 14, 73, 7, 90, 14, 61, 7, 74, 14, 61, 7, 0, 67, 38, 21, 7, 23, 24, 21, 7]\n",
      "48\n",
      "[0, 1, 43, 208, 67, 71, 73, 34, 72, 71, 62, 34, 78, 64, 6, 37, 0, 72, 51, 21, 28, 78, 45, 12, 28, 0, 67, 35, 73, 66, 72, 53, 9, 59, 0, 72, 79, 82, 42, 78, 79, 76, 66, 74, 18, 21, 66, 0, 67, 38, 82, 22, 72, 38, 82, 15, 70, 11, 82, 22, 90, 24, 82, 15, 0, 67, 38, 33, 15, 4, 35, 6, 7, 23, 51, 9, 15, 8, 11, 73, 7, 72, 38, 21, 28, 78, 11, 12, 52, 74, 18, 73, 19, 0, 4, 24, 9, 31]\n",
      "49\n",
      "[0, 1, 2, 139, 8, 32, 129, 87, 0, 1, 32, 57, 34, 8, 64, 129, 135, 0, 8, 51, 50, 60, 8, 64, 122, 87, 0, 1, 51, 128, 31, 4, 51, 48, 31, 8, 38, 50, 136, 8, 38, 50, 136]\n",
      "50\n",
      "[0, 1, 2, 150, 4, 35, 12, 15, 23, 51, 21, 22, 8, 51, 96, 22, 72, 51, 39, 22, 10, 51, 98, 22, 91, 51, 39, 22, 13, 51, 98, 7, 16, 11, 98, 15, 78, 11, 82, 41, 0, 67, 11, 39, 22, 23, 11, 98, 7, 72, 64, 98, 7, 10, 64, 98, 15, 91, 32, 98, 66, 0, 67, 11, 96, 15, 23, 51, 82, 7, 72, 64, 57, 22, 91, 11, 98, 22, 13, 51, 84, 7, 70, 32, 96, 15, 16, 64, 96, 22, 78, 51, 84, 31, 90, 32, 98, 22, 27, 51, 39, 15, 74, 51, 98, 22, 0, 1, 51, 98, 22, 67, 32, 98, 7, 23, 51, 98, 15, 8, 38, 84, 15, 72, 53, 121, 15, 10, 51, 118, 15, 91, 64, 121, 15, 13, 51, 88, 15, 70, 64, 121, 22, 16, 51, 88, 15, 78, 51, 39, 15, 17, 64, 121, 15, 90, 32, 88, 15, 27, 51, 121, 15, 74, 51, 88, 15, 0, 1, 51, 121, 31, 4, 51, 118, 15, 23, 51, 121, 22, 23, 51, 98, 47, 70, 53, 39, 52, 8, 54, 39, 31, 72, 54, 98, 52, 13, 51, 39, 66, 0, 1, 51, 98, 7, 16, 51, 39, 31, 78, 51, 98, 22, 78, 51, 98, 22, 17, 51, 98, 41, 0, 67, 51, 57, 22, 4, 51, 98, 7, 23, 51, 98, 15, 8, 51, 98, 41, 91, 51, 98, 15, 16, 35, 98, 15, 78, 54, 98, 22, 78, 51, 98, 41, 17, 51, 121, 15]\n",
      "51\n",
      "[0, 1, 43, 162, 23, 32, 75, 85, 23, 32, 73, 85, 8, 43, 162, 13, 43, 162, 78, 11, 75, 103, 78, 11, 73, 103, 17, 43, 162, 0, 1, 43, 162, 8, 43, 162, 72, 11, 93, 31, 72, 11, 26, 31, 91, 11, 131, 31, 91, 11, 75, 31, 13, 43, 162, 70, 24, 93, 34, 70, 24, 26, 34, 17, 43, 162, 90, 64, 75, 19, 90, 64, 93, 19, 0, 1, 43, 162, 1, 64, 46, 19, 1, 64, 104, 19, 23, 64, 75, 135, 23, 64, 104, 135, 8, 43, 162, 13, 43, 162, 17, 43, 162, 0, 1, 43, 162, 67, 32, 75, 15, 67, 32, 73, 15, 4, 24, 75, 15, 4, 24, 73, 15, 23, 38, 75, 37, 23, 38, 73, 37, 8, 43, 162, 13, 43, 162, 78, 14, 29, 85, 78, 14, 9, 85, 17, 43, 162, 0, 1, 43, 162, 23, 24, 100, 85, 23, 24, 58, 85, 78, 64, 75, 31, 78, 64, 73, 31, 90, 32, 100, 85, 90, 32, 58, 85, 0, 72, 64, 75, 31, 72, 64, 73, 31, 91, 54, 58, 31, 70, 53, 62, 15, 16, 51, 26, 15, 78, 54, 62, 34, 74, 64, 26, 31, 0, 67, 32, 48, 133]\n",
      "52\n",
      "[0, 1, 2, 114, 10, 35, 127, 22, 10, 63, 128, 15, 91, 71, 122, 22, 91, 49, 46, 22, 13, 32, 55, 42, 74, 63, 46, 22, 74, 71, 48, 22, 0, 1, 45, 46, 66, 13, 51, 128, 31, 13, 51, 48, 31, 16, 71, 46, 22, 16, 71, 61, 22, 78, 53, 46, 7, 78, 53, 61, 7, 27, 64, 30, 15, 27, 64, 50, 15, 74, 71, 55, 15, 74, 71, 58, 15, 0, 1, 35, 104, 19, 1, 35, 62, 19, 10, 54, 46, 22, 10, 63, 75, 22, 91, 64, 30, 22, 91, 51, 46, 22, 13, 63, 46, 15, 13, 63, 48, 31, 27, 49, 48, 22, 27, 53, 86, 22, 74, 71, 61, 22, 74, 45, 107, 22, 0, 1, 49, 58, 52, 1, 49, 84, 52, 4, 49, 46, 22, 4, 49, 61, 22, 23, 53, 50, 7, 23, 71, 76, 7, 91, 53, 46, 22, 91, 49, 55, 22, 13, 49, 100, 19, 13, 45, 57, 19, 17, 35, 48, 15, 17, 53, 50, 15, 27, 71, 46, 22, 27, 53, 58, 15, 74, 123, 48, 22, 74, 35, 57, 22, 0, 1, 63, 46, 34, 1, 49, 61, 66, 8, 35, 62, 31, 8, 53, 76, 31, 13, 53, 46, 36, 13, 35, 57, 37, 27, 51, 58, 22, 27, 54, 84, 22, 0, 1, 11, 73, 41, 1, 64, 97, 41, 8, 35, 62, 31, 8, 51, 61, 31, 13, 64, 46, 34, 13, 53, 61, 66, 27, 35, 46, 22, 27, 54, 61, 22, 74, 35, 61, 22, 74, 71, 46, 22, 0, 1, 63, 62, 41, 1, 54, 61, 41, 17, 38, 100, 7, 17, 38, 62, 7, 27, 54, 46, 7, 27, 54, 61, 7, 74, 35, 48, 15, 74, 35, 61, 15, 0, 1, 54, 46, 7, 1, 54, 86, 7, 67, 54, 26, 7, 67, 54, 12, 7, 23, 54, 46, 15, 23, 54, 61, 15, 8, 11, 46, 7, 8, 11, 9, 7, 10, 35, 33, 7, 10, 35, 61, 7, 10, 64, 46, 15, 10, 64, 61, 15]\n",
      "53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 69, 8, 51, 26, 34, 8, 51, 20, 34, 13, 32, 26, 103, 13, 32, 20, 103, 27, 49, 33, 52, 27, 49, 21, 52, 0, 1, 35, 26, 19, 1, 35, 20, 19, 8, 32, 6, 34, 8, 32, 82, 34, 13, 64, 26, 77, 13, 64, 20, 77, 27, 45, 30, 31, 27, 45, 12, 31, 0, 1, 53, 33, 31, 1, 53, 21, 31, 4, 49, 30, 52, 4, 49, 12, 52, 8, 49, 33, 31, 8, 49, 21, 31, 10, 35, 26, 31, 10, 35, 20, 31, 13, 35, 33, 36, 13, 35, 21, 36, 17, 51, 30, 31, 17, 51, 12, 31, 27, 63, 29, 31, 27, 63, 9, 31, 0, 1, 35, 30, 37, 1, 35, 12, 37, 10, 49, 33, 15, 10, 49, 21, 15, 91, 35, 30, 15, 91, 35, 12, 15, 13, 53, 75, 28, 13, 53, 73, 28, 27, 123, 26, 52, 0, 1, 53, 9, 34, 8, 54, 20, 34, 13, 24, 20, 34, 17, 51, 20, 34, 0, 1, 32, 20, 34, 8, 14, 40, 34, 13, 35, 20, 80, 27, 45, 12, 31, 0, 1, 53, 21, 52, 4, 53, 12, 31, 8, 71, 9, 31, 10, 63, 12, 31, 13, 45, 73, 28, 90, 35, 58, 31]\n",
      "54\n",
      "[0, 1, 43, 211, 8, 43, 211, 10, 64, 9, 31, 13, 43, 211, 13, 32, 73, 31, 16, 11, 9, 7, 17, 43, 211, 17, 11, 40, 101, 0, 1, 43, 211, 4, 51, 9, 22, 4, 32, 21, 22, 23, 54, 9, 22, 23, 64, 21, 22, 8, 43, 211, 8, 35, 9, 15, 8, 64, 21, 22, 10, 64, 9, 22, 10, 32, 21, 22, 13, 43, 211, 13, 51, 9, 15, 13, 32, 21, 22, 16, 64, 9, 15, 16, 32, 21, 15, 17, 43, 211, 17, 64, 9, 31, 17, 32, 21, 31, 0, 1, 43, 211, 1, 32, 97, 31, 4, 32, 40, 7, 8, 43, 211, 8, 38, 97, 31, 10, 38, 40, 41, 13, 43, 211, 16, 11, 76, 15, 78, 38, 20, 15, 17, 43, 211, 17, 11, 76, 101, 0, 1, 43, 211, 1, 32, 62, 15, 67, 32, 9, 15, 4, 64, 62, 15, 23, 51, 26, 7, 8, 43, 211, 8, 32, 62, 47, 13, 43, 211, 16, 32, 26, 15, 78, 51, 33, 15, 17, 43, 211, 17, 32, 75, 85, 0, 1, 43, 211, 8, 43, 211, 13, 43, 211, 13, 64, 9, 7, 70, 32, 73, 15, 16, 54, 61, 15, 78, 64, 21, 15, 17, 43, 211, 17, 11, 20, 184, 0, 1, 43, 211, 4, 54, 26, 22, 4, 35, 6, 22, 23, 51, 26, 22, 23, 54, 6, 22, 8, 43, 211, 8, 64, 26, 22, 8, 64, 6, 22, 10, 64, 26, 22, 10, 64, 6, 22, 13, 43, 211, 13, 64, 26, 22, 13, 64, 6, 22, 16, 64, 26, 15, 16, 64, 6, 15, 17, 43, 211, 17, 64, 26, 137, 17, 64, 9, 137, 0, 1, 43, 211, 1, 64, 40, 31, 4, 32, 76, 31, 8, 38, 20, 31, 10, 38, 76, 52, 13, 24, 21, 31, 16, 64, 73, 52, 17, 64, 33, 31, 17, 64, 62, 52, 17, 24, 21, 34, 0, 1, 64, 33, 31, 1, 64, 62, 31, 10, 64, 33, 52, 10, 64, 6, 52, 16, 51, 33, 15, 16, 54, 6, 15, 78, 51, 33, 15, 78, 64, 62, 15]\n",
      "55\n",
      "[0, 1, 43, 220, 23, 54, 82, 52, 10, 54, 82, 41, 13, 79, 82, 31, 16, 64, 40, 31, 17, 24, 39, 47, 0, 4, 11, 39, 7, 8, 24, 39, 66, 13, 38, 40, 31, 16, 25, 39, 31, 17, 24, 40, 34, 0, 1, 24, 9, 31, 4, 54, 40, 31, 8, 24, 39, 47, 16, 14, 40, 7, 17, 24, 39, 31, 17, 11, 40, 42, 0, 16, 38, 12, 31, 17, 54, 121, 47, 0, 4, 32, 6, 31, 8, 32, 82, 31, 10, 54, 12, 34, 16, 11, 82, 15, 17, 11, 140, 7, 27, 51, 121, 52, 0, 1, 32, 12, 31, 4, 32, 12, 31, 8, 38, 39, 7, 10, 54, 118, 31, 13, 54, 120, 31, 16, 24, 118, 52, 16, 11, 118, 31, 17, 51, 118, 31, 27, 54, 39, 31, 0, 1, 51, 39, 42, 16, 51, 118, 47, 0, 16, 64, 39, 31, 17, 38, 39, 7, 27, 11, 39, 31, 0, 1, 38, 39, 31, 4, 51, 222, 31, 4, 54, 39, 31, 8, 11, 118, 31, 10, 38, 118, 34, 13, 64, 39, 52, 16, 51, 118, 31, 17, 51, 39, 52, 27, 49, 118, 31, 0, 1, 51, 118, 31, 4, 51, 39, 31, 8, 11, 118, 31, 10, 38, 39, 31, 13, 11, 39, 47, 0, 1, 11, 40, 31, 8, 11, 39, 31, 10, 51, 39, 31, 13, 54, 118, 31, 16, 32, 39, 31, 16, 51, 39, 52, 27, 54, 140, 7]\n",
      "56\n",
      "[0, 1, 43, 105, 1, 32, 57, 87, 1, 32, 98, 87, 17, 32, 48, 34, 17, 32, 86, 34, 0, 1, 38, 61, 85, 1, 38, 107, 85, 13, 32, 58, 85, 13, 32, 84, 85, 0, 1, 24, 62, 85, 1, 24, 76, 85, 13, 11, 58, 34, 13, 11, 84, 34, 17, 32, 57, 34, 17, 32, 98, 34, 0, 1, 32, 50, 108, 1, 32, 96, 108, 0, 1, 38, 57, 87, 1, 38, 98, 87, 17, 64, 48, 34, 17, 64, 86, 34, 0, 1, 32, 61, 85, 1, 32, 107, 85, 13, 64, 58, 85, 13, 64, 84, 85, 0, 1, 24, 62, 85, 1, 24, 76, 85, 13, 38, 58, 34, 13, 38, 84, 34, 17, 32, 57, 108]\n",
      "57\n",
      "[0, 1, 43, 105, 1, 54, 12, 15, 67, 51, 57, 15, 67, 51, 58, 22, 4, 11, 50, 59, 17, 11, 50, 22, 90, 11, 50, 22, 27, 11, 58, 7, 0, 1, 11, 12, 7, 4, 32, 57, 52, 10, 32, 57, 22, 91, 11, 12, 22, 13, 32, 57, 22, 70, 51, 58, 22, 16, 32, 57, 66, 0, 1, 11, 57, 22, 67, 53, 58, 22, 4, 32, 6, 36, 17, 51, 6, 22, 90, 32, 50, 22, 27, 11, 48, 7, 0, 1, 11, 55, 15, 4, 11, 30, 52, 10, 11, 30, 22, 91, 32, 48, 22, 13, 32, 30, 22, 70, 32, 55, 22, 16, 32, 30, 66, 0, 4, 5, 50, 41, 10, 5, 12, 7, 13, 11, 57, 15, 16, 24, 12, 47, 0, 1, 11, 58, 7, 4, 11, 57, 19, 10, 32, 57, 15, 13, 32, 12, 7, 16, 24, 50, 34, 27, 32, 58, 7, 0, 1, 11, 57, 15, 4, 11, 6, 47, 13, 32, 50, 7, 16, 32, 48, 41, 27, 24, 30, 7, 0, 1, 32, 48, 15, 4, 11, 50, 60, 13, 63, 39, 22, 70, 32, 98, 15, 16, 54, 84, 22, 16, 51, 96, 7, 17, 53, 84, 15, 27, 51, 98, 15, 74, 51, 88, 15]\n",
      "58\n",
      "[0, 1, 2, 188, 67, 32, 9, 22, 4, 64, 6, 22, 23, 38, 6, 22, 8, 25, 73, 22, 10, 79, 21, 36, 90, 25, 21, 31, 74, 5, 20, 15, 0, 1, 79, 20, 19, 72, 25, 20, 19, 13, 79, 21, 31, 16, 64, 73, 31, 90, 11, 9, 77, 0, 23, 45, 9, 22, 8, 45, 73, 22, 8, 64, 6, 52, 91, 38, 9, 31, 13, 38, 9, 28, 90, 38, 33, 28, 0, 72, 11, 6, 31, 91, 38, 9, 41, 78, 5, 9, 47, 0, 1, 11, 9, 31, 23, 11, 73, 31, 72, 11, 21, 31, 91, 38, 21, 22, 13, 38, 20, 31, 16, 11, 20, 7, 90, 18, 82, 66, 0, 1, 18, 20, 15, 23, 5, 20, 7, 72, 11, 76, 31, 91, 32, 21, 31, 13, 11, 20, 87]\n",
      "59\n",
      "[0, 1, 43, 191, 67, 54, 61, 15, 67, 54, 73, 15, 23, 54, 61, 22, 8, 35, 57, 15, 72, 53, 61, 15, 10, 35, 57, 34, 90, 35, 61, 31, 74, 35, 58, 56, 0, 70, 51, 62, 7, 78, 51, 61, 15, 17, 51, 62, 15, 90, 54, 50, 31, 74, 51, 61, 83, 0, 90, 32, 58, 31, 74, 35, 62, 31, 0, 67, 35, 58, 31, 23, 35, 62, 15, 8, 35, 58, 15, 72, 35, 62, 31, 91, 35, 62, 31, 70, 35, 62, 31, 78, 54, 50, 31, 90, 32, 58, 31, 74, 51, 62, 56, 0, 70, 35, 62, 28, 74, 35, 62, 28, 0, 72, 51, 58, 31, 91, 53, 86, 31, 70, 35, 76, 31, 78, 54, 84, 28, 90, 35, 48, 31, 74, 35, 62, 31, 0, 67, 54, 76, 31, 23, 54, 62, 31, 72, 51, 61, 34, 91, 53, 62, 52, 70, 53, 58, 31, 78, 54, 76, 15, 90, 35, 84, 15, 27, 54, 61, 15, 74, 35, 57, 15, 0, 1, 51, 62, 31, 67, 51, 61, 31, 67, 35, 62, 31, 23, 54, 62, 31, 72, 51, 62, 15, 10, 54, 76, 31, 91, 53, 46, 15, 91, 53, 48, 31, 70, 51, 62, 7, 70, 35, 62, 31, 78, 64, 61, 47, 0, 23, 35, 58, 31, 23, 54, 57, 31, 72, 51, 61, 15, 10, 54, 61, 31, 91, 53, 58, 31, 91, 54, 57, 31, 70, 35, 61, 85]\n",
      "60\n",
      "[0, 1, 43, 191, 67, 54, 57, 15, 23, 54, 58, 15, 72, 51, 9, 22, 10, 51, 6, 59, 10, 53, 50, 7, 91, 51, 48, 15, 13, 35, 57, 7, 70, 35, 58, 7, 0, 4, 45, 50, 31, 8, 45, 48, 31, 10, 49, 48, 15, 91, 51, 58, 15, 13, 49, 50, 52, 70, 51, 57, 31, 78, 51, 73, 7, 90, 32, 86, 34, 90, 51, 57, 7, 27, 32, 58, 15, 74, 32, 57, 7, 0, 1, 51, 58, 7, 67, 49, 6, 22, 4, 51, 58, 15, 23, 54, 50, 15, 8, 51, 62, 15, 72, 51, 62, 31, 10, 51, 58, 31, 91, 51, 57, 22, 13, 54, 48, 31, 16, 54, 86, 31, 16, 51, 62, 52, 17, 54, 50, 7, 17, 51, 6, 31, 27, 54, 58, 31, 0, 1, 64, 48, 34, 67, 51, 50, 31, 4, 64, 58, 28, 10, 54, 50, 31, 13, 64, 48, 31, 70, 51, 86, 7, 16, 51, 86, 22, 78, 51, 76, 31, 17, 51, 48, 31, 27, 54, 30, 7, 0, 1, 51, 86, 15, 4, 64, 86, 52, 8, 64, 76, 7, 10, 51, 84, 7, 13, 51, 98, 7, 16, 51, 30, 19, 17, 51, 46, 36, 90, 51, 98, 31, 27, 51, 84, 52, 0, 1, 51, 98, 15, 67, 64, 48, 31, 4, 51, 57, 7, 23, 51, 86, 15, 8, 51, 48, 7, 10, 53, 86, 31, 91, 64, 48, 31, 13, 53, 86, 19, 13, 51, 48, 31, 16, 51, 86, 31, 17, 54, 48, 41, 17, 54, 48, 19, 27, 51, 30, 7, 0, 1, 51, 48, 31, 4, 35, 48, 15, 23, 35, 57, 7, 8, 35, 48, 7, 10, 64, 30, 31, 13, 51, 48, 7, 91, 35, 48, 7, 16, 51, 86, 52, 16, 51, 50, 31, 17, 51, 48, 31, 17, 54, 30, 31, 27, 51, 48, 31, 0, 1, 51, 48, 15, 4, 51, 86, 31, 4, 51, 48, 31, 8, 51, 58, 7, 10, 35, 48, 15, 10, 64, 48, 15, 13, 51, 55, 15]\n",
      "61\n",
      "[0, 1, 43, 170, 23, 64, 75, 15, 72, 11, 46, 15, 91, 38, 48, 7, 70, 11, 46, 7, 78, 38, 46, 31, 90, 51, 46, 192, 0, 23, 53, 46, 52, 72, 45, 48, 31, 91, 53, 46, 52, 70, 35, 46, 31, 78, 51, 100, 85, 0, 72, 54, 46, 22, 72, 51, 58, 22, 70, 51, 48, 66, 70, 51, 46, 66, 0, 1, 53, 100, 31, 67, 49, 46, 15, 23, 64, 46, 15, 72, 51, 46, 31, 91, 45, 75, 31, 70, 35, 46, 52, 78, 51, 46, 225, 0, 27, 49, 100, 52, 0, 67, 53, 46, 15, 23, 51, 46, 31, 72, 35, 48, 52, 91, 35, 46, 52, 13, 35, 46, 31]\n",
      "62\n",
      "[0, 1, 2, 89, 1, 11, 40, 31, 4, 64, 21, 41, 4, 25, 39, 34, 10, 32, 21, 41, 10, 11, 97, 41, 16, 35, 21, 7, 16, 11, 97, 31, 17, 49, 21, 7, 17, 49, 118, 7, 27, 45, 21, 19, 27, 11, 40, 31, 0, 1, 54, 82, 31, 4, 51, 21, 36, 4, 38, 40, 41, 16, 25, 40, 31, 17, 64, 82, 7, 27, 32, 82, 31, 0, 1, 64, 76, 31, 4, 5, 82, 31, 8, 5, 82, 15, 10, 32, 73, 31, 10, 11, 82, 7, 13, 32, 9, 31, 13, 38, 76, 31, 16, 32, 6, 34, 16, 64, 20, 52, 27, 32, 76, 34, 0, 4, 54, 120, 52, 23, 54, 118, 31, 23, 54, 97, 52, 8, 54, 82, 31, 72, 54, 20, 31, 72, 54, 21, 31, 10, 54, 73, 31, 91, 54, 6, 52, 91, 54, 26, 52, 13, 54, 33, 31, 70, 54, 75, 19, 70, 54, 111, 19, 16, 54, 93, 52, 78, 54, 92, 52, 78, 54, 131, 31, 17, 35, 92, 19, 90, 35, 180, 7, 27, 35, 131, 19, 74, 35, 92, 19, 74, 35, 93, 19, 0, 1, 35, 111, 19, 67, 35, 75, 19, 67, 35, 33, 31, 4, 35, 26, 37]\n",
      "63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 177, 67, 64, 100, 15, 4, 32, 104, 52, 8, 5, 122, 22, 72, 11, 104, 22, 10, 38, 100, 31, 70, 71, 48, 31, 78, 71, 100, 66, 90, 49, 48, 41, 0, 67, 51, 100, 22, 4, 51, 100, 22, 23, 51, 104, 31, 8, 5, 48, 22, 72, 64, 48, 15, 10, 51, 48, 22, 91, 32, 55, 47, 27, 25, 128, 66, 91, 32, 100, 7, 70, 51, 104, 31, 78, 54, 48, 31, 90, 53, 62, 31, 27, 32, 48, 52, 74, 64, 57, 31, 0, 67, 51, 46, 15, 4, 32, 55, 34, 72, 32, 46, 22, 10, 54, 48, 22, 91, 64, 62, 15, 13, 64, 48, 15, 70, 64, 111, 15, 16, 64, 100, 15, 78, 54, 104, 31, 90, 64, 128, 31, 27, 64, 100, 31, 74, 32, 128, 66, 0, 67, 24, 128, 7, 4, 64, 48, 19, 23, 51, 100, 15, 8, 64, 104, 15, 72, 64, 46, 47, 91, 64, 75, 15, 13, 64, 55, 15, 16, 51, 48, 15, 78, 51, 128, 7, 17, 51, 128, 31, 27, 64, 104, 41, 74, 64, 55, 31, 0, 67, 64, 128, 34, 91, 32, 128, 19, 78, 51, 100, 31, 27, 51, 128, 15, 0, 1, 51, 104, 31, 4, 5, 128, 15, 8, 51, 128, 31, 8, 51, 104, 15, 72, 64, 100, 31, 72, 64, 128, 31, 91, 32, 128, 15, 70, 5, 58, 15, 16, 64, 100, 31, 78, 32, 128, 52, 17, 51, 104, 31, 27, 32, 128, 66]\n",
      "64\n",
      "[0, 1, 2, 158, 67, 64, 96, 7, 4, 5, 9, 7, 8, 11, 9, 22, 72, 11, 9, 7, 91, 32, 9, 15, 70, 64, 50, 22, 70, 32, 33, 22, 16, 51, 50, 31, 78, 32, 33, 52, 0, 67, 210, 50, 22, 67, 54, 50, 22, 4, 11, 9, 7, 23, 64, 26, 7, 72, 32, 26, 22, 72, 49, 50, 22, 10, 38, 26, 31, 91, 11, 33, 22, 13, 11, 48, 22, 13, 79, 26, 22, 70, 5, 33, 22, 70, 49, 30, 22, 16, 11, 33, 15, 78, 35, 30, 34, 74, 18, 30, 22, 0, 1, 64, 30, 22, 67, 5, 30, 15, 4, 11, 9, 22, 4, 35, 30, 15, 23, 64, 9, 22, 8, 51, 30, 22, 8, 38, 12, 22, 72, 64, 30, 15, 10, 32, 9, 22, 91, 45, 30, 22, 91, 51, 9, 22, 13, 51, 30, 22, 70, 64, 57, 22, 70, 32, 30, 22, 16, 11, 6, 15, 78, 24, 30, 22, 78, 32, 9, 22, 17, 51, 30, 22, 90, 32, 57, 22, 27, 5, 9, 15, 74, 24, 6, 15, 0, 1, 51, 50, 22, 67, 38, 26, 15, 4, 64, 50, 15, 23, 38, 30, 22, 23, 32, 6, 22, 8, 32, 30, 22, 72, 38, 9, 22, 72, 53, 30, 22, 10, 54, 6, 22, 91, 32, 30, 22, 91, 64, 50, 22, 13, 64, 30, 22, 70, 11, 6, 22, 70, 64, 30, 22, 16, 24, 9, 22, 78, 18, 6, 41, 74, 24, 6, 22, 74, 35, 50, 22, 0, 1, 51, 26, 15, 67, 35, 50, 15, 4, 11, 6, 52, 23, 32, 30, 15, 8, 11, 12, 22, 8, 11, 12, 125]\n",
      "65\n",
      "[0, 1, 2, 212, 4, 79, 57, 22, 8, 79, 57, 22, 10, 79, 12, 15, 13, 24, 86, 22, 16, 79, 82, 31, 17, 79, 96, 31, 0, 8, 25, 86, 15, 72, 24, 21, 15, 10, 32, 86, 15, 91, 24, 21, 15, 13, 5, 57, 41, 0, 1, 11, 50, 15, 67, 38, 57, 22, 4, 24, 12, 15, 8, 79, 57, 34, 0, 1, 25, 12, 7, 4, 38, 86, 15, 8, 79, 82, 31, 10, 79, 96, 42, 0, 67, 64, 82, 22, 4, 25, 82, 7, 8, 25, 96, 7, 10, 79, 82, 7, 13, 79, 98, 31, 16, 79, 98, 7, 17, 79, 98, 31, 27, 18, 98, 59, 0, 16, 18, 84, 15, 78, 11, 82, 15, 17, 38, 86, 7, 90, 11, 57, 15, 90, 79, 96, 112]\n",
      "66\n",
      "[0, 1, 2, 181, 1, 38, 75, 7, 4, 79, 46, 7, 8, 79, 48, 68, 0, 8, 24, 128, 7, 10, 32, 75, 42, 10, 38, 48, 42, 17, 51, 75, 7, 17, 32, 48, 7, 27, 64, 48, 7, 0, 1, 24, 50, 7, 4, 38, 62, 7, 8, 38, 48, 7, 10, 18, 46, 7, 13, 11, 58, 7, 16, 51, 62, 7, 17, 38, 58, 41, 0, 1, 64, 46, 7, 4, 25, 48, 7, 8, 38, 46, 7, 10, 18, 48, 41, 13, 11, 46, 7, 16, 14, 55, 19, 17, 64, 46, 7, 27, 14, 48, 7, 0, 1, 38, 48, 7, 4, 25, 46, 7, 8, 11, 75, 7, 10, 38, 100, 7, 13, 11, 100, 7, 16, 24, 58, 41, 17, 38, 48, 7, 27, 11, 46, 7, 0, 1, 38, 58, 7, 4, 18, 58, 7, 8, 11, 62, 7, 10, 11, 62, 7, 13, 11, 48, 47, 0, 1, 38, 46, 15, 4, 11, 48, 7, 8, 24, 46, 15, 10, 38, 75, 31, 16, 11, 75, 7, 17, 32, 100, 52, 27, 11, 75, 19, 0, 1, 24, 46, 31, 4, 11, 104, 31, 8, 51, 100, 31, 10, 64, 100, 31, 13, 25, 104, 15, 16, 51, 104, 31, 17, 38, 127, 31, 27, 11, 127, 7, 0, 1, 38, 128, 52, 8, 24, 93, 7, 10, 51, 128, 19, 16, 5, 104, 7, 17, 32, 131, 31, 27, 24, 128, 7, 0, 1, 25, 128, 7, 4, 11, 127, 7, 8, 11, 104, 7, 10, 32, 128, 36, 16, 11, 127, 36, 16, 32, 128, 7, 17, 32, 127, 7, 27, 24, 127, 41, 0, 1, 24, 127, 7, 4, 11, 131, 31, 8, 24, 131, 52, 10, 11, 127, 47, 27, 25, 128, 19, 0, 1, 24, 128, 47, 8, 24, 127, 125]\n",
      "67\n",
      "[0, 1, 2, 181, 1, 54, 75, 19, 4, 32, 75, 7, 8, 11, 75, 68, 0, 8, 24, 104, 7, 10, 32, 75, 42, 10, 38, 75, 42, 17, 51, 75, 7, 17, 32, 62, 7, 27, 64, 75, 7, 27, 11, 33, 7, 0, 1, 51, 75, 7, 1, 64, 46, 7, 4, 32, 75, 7, 4, 64, 26, 7, 8, 38, 75, 41, 8, 32, 26, 41, 13, 11, 48, 31, 13, 11, 62, 31, 16, 64, 29, 59, 16, 38, 46, 59, 0, 72, 38, 62, 15, 10, 64, 61, 15, 91, 38, 73, 15, 13, 11, 61, 15, 70, 38, 26, 15, 16, 11, 46, 19, 27, 24, 75, 15, 74, 38, 26, 15, 0, 1, 24, 46, 15, 67, 38, 75, 22, 4, 24, 75, 19, 72, 64, 75, 7, 10, 24, 75, 22, 91, 64, 75, 15, 13, 38, 33, 15, 70, 38, 26, 85, 0, 8, 11, 104, 15, 8, 11, 73, 15, 72, 38, 104, 15, 72, 38, 75, 15, 10, 38, 29, 15, 10, 38, 111, 15, 91, 38, 104, 47, 91, 38, 62, 47, 17, 38, 29, 15, 17, 38, 6, 15, 90, 51, 93, 15, 90, 51, 75, 15, 27, 38, 29, 15, 27, 38, 26, 15, 74, 11, 75, 34, 74, 11, 73, 34, 0, 72, 14, 75, 15, 72, 14, 58, 15, 10, 11, 75, 31, 10, 11, 73, 31, 13, 32, 75, 15, 13, 32, 73, 15, 70, 14, 75, 52, 70, 14, 73, 52, 17, 38, 46, 15, 17, 38, 93, 15, 90, 11, 75, 15, 90, 11, 73, 15, 27, 64, 29, 15, 27, 64, 104, 15, 74, 14, 46, 19, 74, 14, 104, 15, 0, 4, 11, 29, 22, 4, 11, 127, 31, 8, 24, 75, 22, 72, 11, 62, 22, 10, 11, 26, 47, 8, 24, 93, 47, 70, 11, 33, 15, 70, 11, 104, 31, 17, 38, 100, 15, 16, 38, 104, 31, 17, 11, 104, 15, 78, 11, 131, 15]\n",
      "68\n",
      "[0, 1, 2, 95, 23, 51, 48, 34, 72, 35, 57, 31, 78, 54, 57, 7, 17, 32, 58, 15, 90, 35, 6, 15, 27, 64, 48, 66, 0, 23, 11, 30, 31, 72, 64, 48, 47, 78, 11, 50, 15, 17, 51, 48, 15, 90, 64, 33, 15, 27, 38, 48, 34, 0, 23, 32, 30, 52, 10, 64, 33, 52, 70, 38, 48, 7, 78, 38, 50, 31, 27, 38, 6, 52, 0, 67, 11, 58, 7, 23, 32, 57, 52, 72, 35, 57, 22, 91, 38, 57, 19, 78, 54, 86, 7, 17, 64, 21, 15, 90, 64, 57, 15, 27, 38, 50, 34, 0, 23, 51, 6, 7, 72, 32, 6, 7, 91, 38, 6, 41, 78, 38, 57, 7, 17, 53, 6, 7, 90, 45, 50, 15, 27, 32, 48, 31, 0, 23, 38, 30, 52, 72, 32, 48, 28, 78, 35, 50, 7, 17, 54, 48, 15, 90, 35, 33, 7, 27, 54, 48, 41, 0, 23, 38, 30, 19, 10, 32, 33, 19, 70, 64, 48, 31, 78, 32, 50, 19, 27, 51, 6, 19, 0, 67, 38, 58, 31, 23, 35, 57, 15, 8, 35, 12, 15, 72, 35, 86, 15, 10, 64, 57, 15, 91, 53, 12, 15, 13, 45, 86, 31, 70, 32, 57, 15, 16, 53, 12, 15, 78, 49, 86, 15, 17, 45, 57, 15, 90, 35, 12, 15, 27, 38, 86, 15]\n",
      "69\n",
      "[0, 1, 2, 89, 17, 79, 73, 31, 27, 18, 9, 137, 0, 27, 79, 6, 125, 0, 17, 18, 21, 31, 27, 79, 20, 34, 0, 4, 11, 20, 22, 10, 79, 20, 31, 16, 79, 29, 7, 17, 11, 30, 7, 27, 79, 33, 7, 0, 1, 5, 30, 31, 4, 25, 33, 31, 8, 79, 9, 31, 10, 79, 6, 47, 17, 49, 30, 31, 27, 79, 9, 31, 0, 1, 11, 30, 31, 4, 11, 6, 31, 8, 11, 30, 31, 10, 18, 50, 34, 27, 25, 50, 7, 0, 1, 32, 33, 7, 4, 79, 50, 31, 8, 11, 33, 31, 10, 79, 26, 7, 91, 11, 33, 15, 13, 32, 30, 7, 16, 79, 33, 7, 17, 18, 26, 31]\n",
      "70\n",
      "[0, 1, 2, 89, 67, 35, 6, 66, 91, 53, 26, 15, 13, 51, 50, 22, 70, 51, 6, 66, 74, 51, 50, 22, 0, 1, 53, 26, 22, 67, 64, 26, 59, 74, 35, 26, 15, 0, 1, 54, 50, 15, 67, 35, 6, 22, 4, 53, 12, 77, 74, 53, 50, 15, 0, 1, 63, 26, 15, 67, 14, 33, 103, 70, 54, 30, 137, 74, 35, 6, 15, 0, 1, 11, 6, 68]\n",
      "71\n",
      "[0, 1, 43, 105, 1, 11, 57, 85, 1, 11, 96, 41, 8, 14, 86, 31, 10, 38, 86, 31, 13, 24, 86, 31, 16, 14, 96, 31, 17, 24, 57, 34, 17, 24, 12, 34, 0, 1, 24, 57, 108, 0, 1, 11, 58, 112, 13, 11, 57, 41, 17, 24, 57, 34, 17, 24, 58, 7, 27, 11, 57, 7, 0, 1, 11, 50, 108, 1, 14, 48, 108, 0, 1, 11, 58, 41, 8, 11, 57, 34, 13, 64, 48, 7, 16, 14, 58, 31, 17, 64, 57, 34, 17, 64, 58, 7, 27, 11, 57, 15, 27, 24, 58, 7, 0, 1, 24, 58, 85, 1, 32, 46, 108]\n",
      "72\n",
      "[0, 1, 43, 105, 1, 38, 75, 31, 4, 38, 62, 15, 8, 32, 62, 15, 10, 64, 26, 7, 13, 32, 62, 31, 16, 32, 9, 7, 17, 32, 9, 7, 27, 64, 73, 7, 0, 1, 32, 62, 15, 67, 11, 26, 22, 4, 32, 62, 125, 4, 32, 97, 22, 23, 11, 40, 22, 8, 38, 97, 22, 10, 32, 97, 22, 91, 11, 40, 22, 13, 64, 97, 22, 70, 38, 40, 22, 16, 24, 76, 15, 17, 11, 76, 19, 0, 1, 38, 21, 15, 4, 64, 73, 15, 8, 11, 9, 7, 10, 64, 62, 7, 13, 32, 26, 15, 16, 64, 33, 7, 17, 32, 75, 7, 27, 64, 9, 15, 74, 64, 62, 22, 0, 1, 11, 26, 87, 4, 11, 20, 22, 23, 11, 21, 22, 8, 32, 20, 15, 10, 11, 20, 22, 91, 38, 21, 22, 13, 11, 20, 22, 70, 11, 21, 22, 16, 32, 73, 22, 17, 11, 73, 7, 0, 1, 38, 73, 66, 10, 32, 62, 7, 13, 32, 26, 19, 17, 32, 75, 7, 27, 32, 9, 41, 0, 4, 11, 40, 22, 4, 64, 62, 94, 23, 53, 97, 22, 23, 38, 40, 22, 8, 32, 76, 15, 10, 11, 20, 15, 13, 38, 76, 19, 16, 38, 75, 15, 78, 32, 33, 22, 17, 64, 9, 7, 27, 64, 62, 7, 0, 1, 11, 26, 15, 1, 11, 26, 15, 4, 32, 26, 15, 4, 32, 26, 15, 8, 11, 26, 15, 8, 11, 26, 15, 10, 32, 62, 15, 10, 32, 62, 15, 13, 32, 9, 19, 13, 32, 9, 19, 17, 32, 62, 15, 17, 32, 62, 15, 27, 32, 9, 7, 27, 32, 9, 7, 0, 1, 32, 73, 137, 1, 32, 73, 137, 4, 38, 97, 22, 23, 11, 40, 22, 8, 32, 97, 22, 10, 32, 97, 22, 91, 38, 40, 22, 13, 32, 97, 22, 70, 32, 40, 22, 16, 32, 76, 22, 78, 38, 40, 22, 17, 38, 97, 7, 27, 38, 97, 15]\n",
      "73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 43, 105, 1, 5, 48, 60, 1, 5, 86, 60, 17, 5, 50, 7, 27, 18, 86, 7, 0, 1, 25, 58, 52, 1, 5, 84, 60, 0, 10, 25, 86, 66, 17, 25, 86, 19, 0, 1, 25, 58, 7, 4, 11, 57, 7, 8, 24, 58, 22, 72, 14, 57, 31, 10, 11, 58, 36, 13, 25, 86, 7, 16, 25, 58, 31, 17, 25, 58, 31, 27, 25, 58, 31, 0, 1, 5, 57, 28, 67, 5, 58, 31, 23, 24, 58, 31, 72, 24, 58, 31, 10, 11, 86, 15, 91, 32, 61, 31, 16, 5, 57, 31, 17, 5, 58, 31, 27, 14, 58, 31, 0, 1, 5, 48, 31, 4, 11, 100, 19, 8, 5, 48, 31, 10, 11, 48, 19]\n",
      "74\n",
      "[0, 1, 2, 95, 4, 11, 46, 31, 8, 11, 62, 31, 10, 38, 58, 31, 13, 38, 62, 31, 16, 5, 46, 34, 27, 25, 75, 52, 0, 1, 54, 46, 7, 4, 38, 104, 80, 16, 24, 93, 37, 0, 4, 38, 104, 34, 10, 32, 46, 34, 16, 32, 29, 36, 0, 4, 5, 75, 85, 16, 32, 29, 34, 27, 32, 75, 34, 0, 67, 11, 46, 83]\n",
      "75\n",
      "[0, 1, 2, 130, 1, 11, 6, 52, 23, 11, 9, 22, 8, 11, 6, 15, 8, 24, 6, 15, 10, 38, 57, 52, 70, 11, 33, 15, 16, 38, 33, 15, 78, 24, 6, 15, 17, 38, 62, 19, 74, 32, 62, 22, 0, 1, 38, 50, 22, 1, 38, 62, 52, 23, 32, 62, 22, 8, 11, 50, 22, 8, 38, 62, 22, 72, 38, 57, 7, 70, 24, 50, 15, 16, 38, 57, 15, 78, 38, 12, 22, 17, 38, 21, 7, 27, 24, 21, 7, 0, 1, 14, 21, 22, 67, 54, 21, 15, 4, 32, 12, 15, 4, 38, 50, 15, 23, 64, 57, 7, 72, 38, 58, 52, 13, 38, 6, 19, 17, 24, 21, 34, 0, 67, 11, 57, 22, 4, 38, 50, 22, 4, 64, 57, 22, 23, 24, 82, 15, 8, 24, 96, 34, 13, 11, 57, 31, 16, 11, 12, 15, 78, 32, 57, 15, 17, 38, 21, 66, 0, 67, 11, 21, 15, 4, 32, 12, 15, 23, 32, 57, 7]\n",
      "76\n",
      "[0, 1, 2, 95, 8, 2, 95, 10, 79, 84, 56, 13, 2, 95, 17, 2, 95, 0, 1, 2, 95, 1, 79, 84, 22, 23, 79, 84, 52, 8, 2, 95, 10, 79, 84, 7, 13, 2, 95, 70, 25, 76, 22, 70, 38, 86, 22, 16, 5, 76, 15, 78, 79, 86, 22, 17, 2, 95, 17, 11, 61, 22, 90, 25, 73, 22, 27, 25, 58, 15, 74, 38, 73, 22, 0, 1, 2, 95, 1, 32, 73, 22, 67, 11, 58, 22, 4, 25, 58, 52, 8, 2, 95, 13, 2, 95, 78, 79, 58, 22, 17, 2, 95, 17, 79, 73, 22, 90, 79, 61, 22, 27, 79, 86, 7, 0, 1, 2, 95, 1, 79, 58, 15, 67, 5, 73, 22, 4, 79, 61, 15, 23, 24, 73, 22, 8, 79, 86, 52, 16, 79, 84, 15, 78, 11, 86, 15, 17, 5, 61, 15, 90, 25, 86, 15, 27, 79, 98, 47, 0, 4, 79, 86, 41, 10, 79, 107, 28, 17, 79, 107, 15, 90, 25, 39, 15, 27, 79, 107, 7, 0, 1, 79, 39, 15, 67, 11, 107, 22, 4, 79, 107, 7, 8, 79, 39, 15, 72, 11, 107, 15, 10, 79, 88, 52, 13, 79, 39, 31, 16, 18, 84, 31, 17, 18, 97, 15, 90, 79, 39, 22, 27, 18, 107, 15, 74, 79, 88, 15, 0, 67, 79, 97, 15, 4, 25, 84, 7, 8, 79, 97, 19, 16, 79, 76, 31, 90, 5, 20, 15, 27, 24, 86, 15, 74, 25, 20, 15, 0, 1, 79, 76, 7, 67, 79, 76, 22, 4, 79, 76, 15, 23, 79, 76, 22, 23, 32, 20, 22, 8, 38, 86, 22, 72, 18, 61, 22, 10, 79, 86, 19, 70, 79, 61, 15, 16, 79, 86, 31, 90, 79, 86, 15, 27, 79, 33, 15, 27, 79, 82, 15, 74, 18, 58, 15, 74, 79, 20, 15, 0, 1, 79, 57, 15, 1, 79, 86, 15, 67, 79, 73, 15, 67, 79, 21, 15]\n",
      "77\n",
      "[0, 1, 2, 3, 17, 53, 57, 31, 27, 51, 61, 34, 0, 4, 45, 57, 31, 8, 45, 58, 31, 10, 49, 57, 31, 13, 35, 48, 56, 0, 4, 51, 61, 31, 8, 35, 58, 7, 10, 35, 57, 31, 13, 14, 46, 42, 0, 8, 11, 62, 31, 10, 32, 58, 31, 13, 51, 48, 42, 27, 35, 62, 7, 0, 1, 38, 58, 34, 8, 14, 61, 19, 13, 51, 57, 59, 0, 1, 53, 46, 41, 4, 45, 48, 7, 8, 35, 58, 52, 91, 49, 62, 15, 13, 54, 48, 66, 0, 4, 49, 57, 31, 8, 32, 61, 31, 10, 63, 57, 31, 13, 53, 58, 42, 27, 45, 46, 56, 0, 1, 53, 58, 47, 10, 35, 57, 34, 16, 210, 46, 137]\n",
      "78\n",
      "[0, 1, 43, 177, 67, 51, 55, 15, 4, 32, 55, 52, 8, 5, 21, 22, 72, 11, 96, 22, 10, 79, 82, 31, 70, 79, 96, 19, 17, 5, 21, 22, 90, 11, 96, 22, 27, 79, 21, 7, 74, 38, 12, 34, 0, 23, 79, 82, 19, 91, 79, 82, 7, 70, 79, 140, 15, 16, 79, 39, 31, 17, 25, 98, 15, 90, 5, 82, 31, 74, 79, 96, 15, 0, 1, 5, 21, 31, 4, 18, 82, 15, 23, 38, 12, 22, 8, 5, 57, 7, 16, 79, 50, 15, 78, 38, 48, 15, 17, 79, 6, 15, 17, 38, 57, 22, 90, 38, 50, 22, 27, 79, 96, 15, 74, 38, 21, 15, 0, 1, 79, 96, 7, 4, 79, 12, 15, 23, 11, 86, 22, 8, 79, 96, 22, 72, 11, 86, 22, 72, 24, 96, 22, 10, 5, 12, 42, 17, 18, 21, 15, 17, 79, 96, 15]\n",
      "79\n",
      "[0, 1, 2, 110, 1, 32, 50, 47, 4, 32, 58, 19, 91, 64, 30, 15, 13, 38, 50, 7, 16, 38, 58, 52, 90, 11, 12, 77, 0, 91, 38, 50, 15, 13, 38, 58, 31, 16, 11, 57, 19, 74, 51, 50, 15, 0, 1, 32, 58, 52, 4, 11, 57, 41, 91, 64, 48, 52, 13, 38, 58, 31, 16, 24, 57, 52, 17, 64, 58, 15, 90, 38, 86, 77, 0, 91, 32, 50, 7, 13, 32, 58, 31, 16, 38, 57, 31, 17, 64, 58, 7, 74, 51, 50, 15, 0, 1, 32, 58, 52, 4, 38, 57, 52, 8, 64, 58, 15, 91, 51, 48, 7, 13, 32, 58, 31, 16, 11, 57, 52, 17, 64, 58, 77, 90, 38, 86, 77, 0, 91, 64, 50, 7, 13, 38, 58, 31, 16, 11, 57, 52, 17, 51, 58, 15, 74, 51, 50, 7, 0, 1, 38, 58, 31, 4, 11, 57, 52, 8, 64, 58, 7, 91, 35, 48, 15, 13, 32, 58, 52, 16, 38, 57, 31, 17, 64, 58, 7, 90, 38, 86, 77, 0, 91, 51, 50, 7, 13, 38, 58, 31, 16, 51, 50, 52, 17, 64, 58, 15, 74, 64, 50, 15, 0, 1, 38, 58, 31, 4, 11, 57, 52, 8, 51, 58, 7, 91, 35, 48, 15, 13, 32, 57, 52, 16, 38, 86, 52, 17, 64, 57, 7, 90, 38, 48, 37]\n",
      "80\n",
      "[0, 1, 2, 142, 8, 51, 30, 52, 10, 51, 122, 52, 13, 51, 55, 31, 16, 32, 30, 31, 17, 38, 48, 52, 27, 51, 111, 31, 0, 1, 54, 55, 31, 4, 32, 48, 7, 8, 64, 50, 31, 10, 64, 29, 31, 13, 64, 33, 31, 16, 51, 50, 7, 17, 64, 6, 7, 27, 54, 111, 31, 0, 1, 53, 55, 31, 4, 64, 48, 7, 8, 51, 50, 31, 10, 35, 55, 7, 13, 51, 30, 31, 16, 51, 33, 7, 17, 35, 50, 31, 27, 54, 30, 31, 0, 1, 51, 48, 7, 4, 51, 6, 7, 8, 64, 9, 31, 10, 51, 29, 7, 13, 35, 33, 7, 16, 51, 50, 31, 17, 64, 33, 34, 0, 1, 54, 30, 22, 1, 51, 48, 15, 67, 54, 55, 52, 67, 51, 33, 19, 8, 54, 128, 85, 8, 38, 48, 31, 10, 64, 50, 31, 13, 64, 6, 31, 16, 32, 57, 31, 17, 51, 122, 28, 17, 64, 9, 31, 27, 11, 6, 52, 0, 1, 32, 50, 31, 4, 51, 149, 31, 4, 64, 48, 31, 8, 35, 92, 34, 8, 64, 33, 31, 10, 64, 50, 31, 13, 51, 122, 34, 13, 64, 12, 19, 78, 64, 92, 22, 17, 35, 129, 36, 17, 35, 92, 37, 17, 51, 57, 66, 0, 67, 51, 50, 15, 4, 32, 48, 15, 23, 51, 33, 15, 8, 35, 128, 77, 8, 32, 48, 47, 16, 64, 6, 31, 17, 51, 122, 34, 17, 32, 50, 42, 0, 1, 54, 122, 41, 4, 38, 9, 31, 8, 54, 129, 28, 8, 51, 92, 112, 16, 35, 122, 31, 17, 54, 129, 85, 17, 35, 92, 85, 27, 51, 55, 7, 74, 54, 111, 15, 0, 1, 51, 122, 34, 1, 51, 30, 15, 67, 64, 122, 15, 4, 64, 92, 108]\n",
      "81\n",
      "[0, 1, 2, 95, 1, 79, 9, 52, 23, 24, 73, 22, 23, 25, 9, 22, 8, 64, 6, 15, 72, 5, 9, 15, 10, 11, 62, 15, 91, 38, 26, 15, 13, 11, 33, 22, 70, 38, 26, 47, 0, 1, 32, 33, 22, 67, 11, 9, 22, 4, 11, 6, 15, 23, 38, 9, 15, 8, 11, 62, 15, 72, 38, 9, 15, 10, 38, 33, 15, 91, 38, 26, 15, 13, 32, 33, 15, 70, 25, 26, 15, 78, 79, 9, 15, 17, 5, 33, 15, 90, 5, 26, 15, 27, 25, 9, 7, 0, 1, 32, 29, 15, 67, 38, 33, 15, 4, 5, 26, 7, 8, 38, 33, 15, 72, 11, 26, 15, 10, 38, 33, 15, 91, 38, 33, 15, 13, 38, 30, 34, 0, 1, 11, 33, 41, 72, 5, 26, 15, 10, 38, 26, 15, 91, 79, 33, 15, 13, 25, 9, 15, 70, 79, 9, 15, 16, 38, 9, 15, 78, 18, 33, 15, 17, 5, 26, 15, 90, 38, 6, 22, 90, 38, 73, 15, 27, 38, 21, 15, 0, 1, 5, 9, 15, 67, 24, 73, 15, 23, 38, 21, 15, 8, 38, 21, 15, 72, 38, 73, 15, 91, 11, 9, 19, 13, 11, 9, 15, 70, 11, 73, 15, 16, 32, 9, 15, 78, 38, 21, 15, 78, 11, 9, 15, 17, 38, 6, 15, 90, 5, 6, 15, 27, 25, 9, 15, 74, 18, 73, 15, 0, 1, 32, 33, 15, 67, 79, 9, 15, 4, 11, 33, 31, 8, 11, 9, 15, 72, 38, 6, 15, 72, 38, 6, 15, 10, 53, 9, 15, 91, 11, 9, 15, 13, 11, 9, 31, 70, 79, 6, 31, 78, 79, 9, 31, 90, 38, 62, 31, 90, 79, 9, 15, 74, 54, 9, 15, 0, 1, 38, 6, 15, 67, 5, 26, 15, 23, 38, 6, 15, 8, 11, 9, 15, 72, 64, 26, 15, 10, 11, 33, 31, 91, 38, 21, 15, 70, 38, 9, 15, 78, 79, 21, 15, 90, 38, 20, 31, 74, 24, 21, 7, 0, 67, 64, 73, 15, 8, 11, 9, 15, 72, 51, 20, 15, 10, 64, 33, 15, 91, 38, 9, 83, 0, 10, 11, 21, 31, 91, 64, 33, 7, 13, 24, 33, 7, 70, 79, 21, 52, 78, 79, 21, 31, 90, 38, 21, 31, 0, 67, 38, 21, 19, 23, 5, 9, 15]\n",
      "82\n",
      "[0, 1, 2, 194, 1, 35, 127, 22, 67, 63, 128, 22, 4, 53, 127, 47, 16, 32, 127, 15, 78, 54, 127, 15, 17, 11, 128, 47, 0, 67, 38, 122, 22, 4, 53, 127, 66, 0, 23, 32, 128, 15, 8, 32, 127, 15, 72, 53, 100, 7, 10, 35, 127, 15, 91, 38, 128, 15, 13, 11, 127, 15, 70, 38, 127, 15, 16, 49, 127, 37, 0, 1, 51, 100, 7, 4, 11, 46, 7, 8, 32, 48, 7, 72, 11, 50, 7, 10, 63, 100, 7, 91, 45, 122, 15, 13, 45, 100, 7, 16, 65, 55, 7, 78, 49, 100, 47, 0, 67, 51, 100, 15, 8, 51, 58, 15, 72, 35, 46, 15, 91, 38, 128, 15, 13, 38, 122, 7, 16, 49, 46, 47, 0, 23, 54, 100, 7, 72, 11, 55, 15, 10, 63, 100, 15, 91, 32, 104, 47, 0, 1, 49, 100, 15, 67, 38, 100, 15, 4, 64, 100, 15, 23, 32, 128, 15, 8, 32, 100, 66, 16, 51, 100, 15, 90, 53, 122, 7, 17, 32, 122, 15, 27, 71, 100, 15, 74, 49, 100, 15, 0, 1, 38, 122, 15, 67, 32, 100, 15, 4, 38, 122, 36, 8, 35, 100, 7, 10, 54, 122, 15, 91, 54, 100, 15, 91, 38, 122, 7, 13, 32, 100, 77]\n",
      "83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 110, 8, 5, 30, 36, 78, 11, 33, 22, 17, 25, 33, 36, 0, 8, 79, 33, 28, 70, 18, 26, 15, 16, 11, 33, 15, 78, 38, 30, 22, 17, 38, 30, 28, 0, 8, 18, 6, 41, 13, 79, 26, 22, 70, 38, 6, 15, 16, 38, 26, 15, 78, 38, 6, 15, 17, 79, 26, 31, 27, 11, 33, 34, 0, 4, 24, 33, 22, 23, 32, 30, 15, 8, 25, 33, 34, 13, 11, 33, 22, 70, 51, 30, 15, 16, 64, 29, 15, 78, 32, 30, 15, 17, 64, 30, 85]\n",
      "84\n",
      "[0, 1, 43, 124, 10, 54, 111, 7, 91, 11, 33, 15, 91, 64, 33, 22, 13, 14, 26, 42, 27, 71, 30, 15, 74, 11, 33, 15, 0, 1, 32, 50, 31, 4, 38, 30, 15, 8, 38, 50, 7, 10, 38, 6, 7, 13, 11, 6, 28, 27, 64, 50, 15, 74, 24, 6, 22, 74, 5, 6, 22, 0, 1, 11, 57, 66, 10, 14, 6, 15, 91, 51, 6, 22, 91, 38, 50, 22, 13, 54, 33, 41, 27, 54, 55, 15, 74, 54, 33, 15, 0, 1, 24, 26, 31, 4, 14, 30, 7, 8, 14, 6, 15, 72, 38, 26, 15, 10, 24, 33, 7, 13, 14, 30, 19, 0, 1, 5, 50, 22, 67, 11, 6, 15, 4, 14, 9, 22, 23, 11, 12, 15, 8, 24, 21, 15, 10, 24, 12, 15, 91, 25, 21, 15, 13, 14, 12, 15, 16, 14, 21, 22, 78, 25, 96, 22, 17, 79, 20, 31, 0, 1, 14, 97, 31, 23, 11, 40, 15, 8, 24, 40, 15, 10, 5, 82, 7, 13, 24, 33, 19, 13, 14, 21, 34, 17, 14, 30, 19, 17, 79, 20, 19, 74, 38, 111, 136, 74, 24, 55, 136, 74, 18, 118, 137]\n",
      "85\n",
      "[0, 1, 2, 159, 1, 49, 29, 41, 1, 54, 46, 34, 8, 2, 159, 72, 49, 29, 52, 72, 49, 29, 52, 13, 2, 159, 70, 32, 29, 15, 16, 32, 29, 22, 17, 2, 159, 17, 11, 111, 22, 90, 32, 29, 52, 0, 1, 2, 159, 1, 11, 33, 47, 8, 2, 159, 13, 2, 159, 70, 51, 30, 15, 16, 64, 33, 15, 78, 51, 30, 15, 17, 2, 159, 90, 32, 33, 52, 74, 51, 29, 19, 0, 1, 2, 159, 4, 11, 30, 22, 8, 2, 159, 8, 32, 33, 22, 72, 11, 33, 31, 13, 2, 159, 13, 32, 26, 22, 70, 11, 33, 15, 16, 51, 30, 22, 17, 2, 159, 17, 64, 29, 31, 17, 32, 33, 22, 90, 51, 29, 22, 27, 51, 30, 22, 74, 51, 29, 15, 0, 1, 2, 159, 1, 51, 111, 7, 67, 32, 29, 19, 8, 2, 159, 91, 24, 29, 22, 13, 2, 159, 70, 32, 29, 7, 16, 32, 33, 37, 17, 2, 159, 27, 54, 29, 22, 74, 51, 9, 42, 0, 1, 2, 159, 8, 2, 159, 8, 51, 111, 22, 72, 32, 29, 15, 91, 51, 111, 7, 13, 64, 29, 15, 70, 32, 111, 22, 70, 64, 29, 22, 16, 38, 30, 15, 78, 51, 29, 15, 17, 2, 159, 90, 32, 29, 22, 27, 51, 111, 15, 74, 51, 29, 7, 0, 1, 11, 93, 22, 67, 64, 111, 19, 8, 2, 159, 1, 51, 111, 22, 67, 32, 92, 22, 4, 51, 29, 22, 23, 51, 111, 15, 8, 51, 29, 22, 72, 54, 92, 15, 10, 38, 93, 22, 10, 54, 93, 7, 91, 32, 92, 22, 13, 2, 159, 13, 2, 159, 16, 51, 92, 22, 78, 11, 92, 22, 17, 2, 159, 17, 35, 92, 22, 90, 11, 29, 15, 90, 32, 29, 7, 27, 45, 92, 22, 74, 32, 92, 22, 0, 1, 2, 159, 1, 51, 92, 22, 67, 51, 92, 22, 4, 11, 92, 22, 8, 2, 159, 16, 11, 29, 22, 16, 38, 92, 22, 78, 51, 93, 22, 17, 2, 159, 17, 11, 92, 22, 90, 11, 92, 22, 90, 11, 92, 22, 27, 53, 92, 22, 74, 32, 92, 22, 0, 1, 11, 92, 22, 67, 32, 92, 52, 8, 11, 92, 22, 16, 11, 92, 22, 78, 32, 92, 22, 72, 32, 92, 22, 10, 123, 93, 22, 10, 11, 93, 15, 17, 54, 93, 52, 27, 51, 104, 19, 0, 1, 11, 92, 15]\n",
      "86\n",
      "[0, 1, 2, 3, 1, 14, 46, 31, 4, 14, 62, 31, 8, 14, 58, 31, 10, 24, 62, 15, 91, 14, 9, 15, 13, 14, 58, 31, 16, 14, 62, 31, 17, 14, 62, 22, 27, 11, 26, 31, 0, 1, 24, 62, 108, 0, 1, 14, 58, 34, 8, 5, 58, 31, 10, 14, 62, 31, 13, 14, 26, 31, 16, 24, 62, 31, 17, 24, 62, 31, 27, 24, 26, 31, 0, 1, 14, 46, 108, 0, 1, 5, 46, 31, 4, 14, 62, 31, 8, 14, 62, 31, 10, 24, 62, 15, 91, 64, 9, 15, 13, 64, 62, 31, 16, 64, 62, 31, 17, 32, 26, 31, 27, 11, 46, 31, 0, 1, 24, 75, 31, 4, 14, 29, 34, 10, 14, 46, 31, 13, 24, 75, 28, 27, 64, 75, 15, 74, 32, 46, 15, 0, 1, 14, 26, 31, 4, 32, 26, 15, 23, 38, 62, 15, 8, 24, 26, 31, 10, 24, 46, 31, 13, 11, 75, 31, 16, 38, 75, 22, 17, 24, 93, 31, 27, 24, 100, 31, 74, 11, 104, 77]\n",
      "87\n",
      "[0, 1, 43, 116, 23, 38, 62, 7, 72, 38, 58, 15, 91, 38, 57, 7, 70, 64, 61, 15, 78, 64, 57, 15, 90, 24, 58, 34, 0, 67, 64, 62, 7, 23, 32, 48, 7, 72, 32, 46, 15, 91, 38, 48, 52, 78, 24, 48, 47, 0, 23, 32, 62, 31, 72, 32, 58, 31, 91, 38, 57, 31, 70, 32, 61, 31, 78, 32, 86, 31, 90, 38, 58, 34, 0, 67, 32, 62, 7, 23, 32, 48, 7, 72, 32, 46, 31, 91, 32, 48, 52, 78, 11, 48, 37, 0, 23, 38, 62, 7, 72, 38, 58, 15, 91, 38, 57, 7, 70, 64, 61, 15, 78, 64, 57, 15, 90, 24, 58, 34, 0, 67, 64, 62, 7, 23, 32, 48, 7, 72, 32, 46, 15, 91, 38, 48, 52, 78, 24, 48, 47, 0, 23, 32, 62, 31, 72, 32, 58, 31, 91, 38, 57, 31, 70, 32, 62, 31, 78, 32, 58, 34]\n",
      "88\n",
      "[0, 1, 43, 105, 91, 38, 12, 31, 70, 5, 12, 103, 0, 23, 38, 50, 52, 72, 24, 21, 34, 70, 24, 96, 37, 74, 18, 118, 31, 0, 67, 25, 39, 34, 72, 18, 98, 28, 78, 11, 82, 31, 90, 79, 39, 59, 0, 72, 79, 39, 22, 91, 18, 118, 52, 70, 79, 39, 60, 0, 67, 38, 50, 34, 72, 24, 57, 59, 90, 24, 12, 31, 74, 18, 96, 31, 0, 67, 79, 21, 59, 70, 24, 6, 34, 90, 5, 57, 28, 0, 23, 5, 12, 31, 72, 38, 6, 34, 70, 11, 50, 85, 0, 67, 25, 21, 34, 72, 79, 96, 80, 90, 11, 21, 34, 0, 67, 5, 12, 47, 72, 24, 6, 34, 70, 25, 57, 34, 90, 79, 57, 137, 0, 23, 32, 12, 31, 72, 11, 21, 31, 91, 54, 96, 52, 70, 51, 57, 52, 74, 38, 30, 15, 74, 51, 33, 15]\n",
      "89\n",
      "[0, 1, 2, 69, 72, 18, 12, 31, 72, 38, 39, 7, 91, 11, 96, 7, 70, 79, 39, 19, 90, 24, 98, 31, 74, 11, 39, 41, 0, 72, 5, 39, 7, 91, 38, 12, 7, 70, 11, 12, 15, 78, 11, 12, 31, 90, 38, 39, 52, 0, 67, 11, 57, 15, 23, 11, 12, 52, 72, 38, 12, 15, 10, 32, 82, 34, 70, 38, 96, 22, 78, 11, 12, 7, 90, 38, 12, 34, 0, 67, 11, 12, 19, 72, 79, 96, 31, 91, 11, 12, 7, 70, 32, 12, 37, 78, 11, 12, 52, 90, 24, 82, 7, 74, 24, 96, 15, 0, 67, 11, 82, 66, 72, 24, 82, 7, 91, 5, 82, 7, 70, 11, 39, 34, 78, 38, 39, 31, 90, 24, 40, 31, 74, 11, 39, 31, 0, 67, 38, 39, 102, 0, 67, 38, 39, 7, 23, 25, 39, 7, 72, 18, 96, 7, 70, 11, 39, 7, 78, 38, 140, 60, 0, 72, 5, 39, 52, 72, 5, 39, 52, 91, 38, 39, 7, 70, 11, 39, 31, 78, 38, 39, 15, 90, 24, 39, 31, 74, 24, 39, 7, 0, 67, 11, 39, 7, 23, 38, 98, 31, 72, 11, 39, 31, 91, 38, 39, 7, 70, 11, 98, 52, 17, 38, 39, 37]\n",
      "90\n",
      "[0, 1, 43, 208, 4, 38, 50, 31, 8, 11, 57, 31, 10, 14, 57, 31, 13, 24, 86, 31, 16, 24, 12, 31, 17, 24, 57, 31, 27, 38, 48, 31, 0, 1, 14, 57, 133, 0, 4, 32, 86, 15, 23, 51, 86, 15, 8, 32, 86, 31, 10, 14, 61, 31, 13, 11, 86, 52, 16, 11, 57, 31, 17, 11, 48, 31, 27, 38, 57, 31, 0, 1, 11, 57, 133, 0, 4, 5, 76, 34, 10, 24, 86, 31, 13, 14, 57, 31, 16, 24, 57, 31, 17, 32, 58, 31, 27, 11, 57, 31, 0, 1, 24, 57, 52, 4, 24, 58, 34, 10, 11, 57, 31, 13, 38, 58, 31, 16, 38, 57, 31, 17, 5, 12, 52, 27, 14, 57, 31, 0, 1, 38, 58, 28, 10, 38, 62, 31, 13, 38, 58, 31, 16, 11, 57, 31, 17, 5, 57, 31, 27, 64, 58, 31, 0, 1, 24, 58, 31, 67, 32, 62, 83]\n",
      "91\n",
      "[0, 1, 43, 161, 1, 38, 46, 31, 4, 45, 48, 15, 8, 63, 46, 31, 10, 64, 46, 52, 13, 38, 104, 125, 0, 1, 64, 46, 31, 4, 53, 46, 52, 8, 54, 46, 52, 10, 35, 75, 52, 13, 54, 100, 85, 0, 1, 11, 46, 31, 4, 32, 26, 52, 8, 38, 46, 52, 10, 35, 46, 31, 13, 38, 75, 85, 0, 1, 32, 46, 31, 4, 35, 26, 52, 8, 51, 46, 31, 10, 53, 75, 7, 13, 32, 75, 36, 17, 32, 100, 19, 0, 1, 38, 104, 125, 10, 11, 100, 42, 0, 1, 38, 104, 42, 8, 11, 46, 41, 13, 11, 62, 66, 17, 11, 26, 41, 0, 1, 38, 26, 66, 8, 38, 48, 41, 13, 32, 48, 19, 17, 11, 46, 41, 0, 1, 38, 46, 34, 8, 64, 46, 66, 13, 64, 75, 19, 17, 11, 128, 41, 0, 1, 38, 100, 15, 4, 11, 100, 68, 4, 32, 75, 31, 8, 32, 75, 31, 10, 32, 48, 34, 16, 32, 46, 31, 78, 201, 100, 34, 17, 32, 104, 31, 27, 32, 46, 34, 0, 4, 32, 104, 31, 8, 32, 93, 31, 10, 32, 75, 34, 16, 32, 104, 31, 17, 32, 127, 31, 27, 32, 128, 31, 0, 4, 32, 75, 31, 8, 32, 75, 31, 10, 32, 26, 34, 16, 32, 75, 31, 17, 32, 100, 31, 27, 32, 46, 34, 0, 4, 32, 104, 31, 8, 32, 93, 31, 10, 32, 75, 34, 16, 32, 104, 31, 17, 32, 127, 31, 90, 32, 128, 31]\n",
      "92\n",
      "[0, 1, 2, 150, 67, 79, 97, 42, 91, 18, 118, 31, 70, 18, 97, 31, 78, 79, 39, 7, 90, 79, 97, 7, 74, 5, 118, 15, 0, 1, 38, 97, 47, 10, 18, 39, 42, 0, 67, 11, 40, 7, 23, 18, 39, 7, 72, 79, 97, 7, 91, 79, 39, 7, 70, 79, 118, 7, 78, 79, 120, 15, 17, 11, 118, 15, 90, 38, 39, 22, 27, 11, 97, 22, 74, 5, 118, 22, 0, 1, 11, 120, 15, 67, 38, 118, 15, 4, 38, 39, 15, 23, 11, 97, 47, 91, 38, 118, 15, 13, 38, 97, 22, 70, 5, 40, 15, 16, 11, 39, 22, 78, 79, 118, 15, 17, 11, 120, 7, 27, 11, 97, 22, 74, 38, 118, 15, 0, 1, 38, 39, 47, 67, 11, 97, 47, 70, 79, 39, 15, 16, 11, 97, 7, 78, 5, 118, 15, 17, 32, 97, 15, 27, 11, 40, 15, 0, 1, 25, 97, 7, 1, 11, 39, 15, 67, 5, 118, 7, 23, 38, 118, 19, 10, 14, 120, 7, 91, 38, 118, 19, 70, 38, 118, 15, 16, 11, 97, 15, 78, 5, 118, 15, 17, 11, 97, 15, 90, 38, 40, 15, 27, 32, 118, 34, 0, 1, 32, 118, 15, 67, 32, 118, 19, 91, 79, 39, 7, 70, 79, 168, 7, 16, 11, 118, 22, 78, 5, 167, 15, 17, 11, 140, 15, 90, 38, 39, 22, 27, 79, 118, 7, 74, 5, 39, 52, 0, 1, 38, 82, 15, 67, 38, 118, 7, 23, 5, 97, 52, 72, 11, 97, 7]\n",
      "93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 43, 217, 72, 11, 111, 22, 10, 32, 30, 15, 91, 38, 33, 22, 13, 79, 48, 42, 27, 79, 33, 15, 0, 1, 79, 33, 41, 10, 79, 30, 7, 13, 79, 30, 42, 27, 11, 111, 7, 0, 1, 25, 111, 85, 13, 5, 111, 47, 27, 24, 55, 15, 0, 1, 5, 55, 41, 8, 79, 111, 34, 13, 79, 122, 36, 27, 64, 122, 22, 74, 38, 111, 15, 0, 1, 38, 55, 7, 4, 5, 55, 31, 8, 18, 30, 7, 10, 24, 33, 31, 13, 79, 30, 47, 27, 64, 55, 15, 27, 38, 30, 15, 0, 1, 38, 30, 28, 1, 11, 30, 28, 10, 38, 122, 15, 10, 38, 55, 7, 13, 11, 122, 19, 13, 25, 30, 66, 16, 11, 92, 7, 16, 64, 122, 15, 17, 25, 92, 28, 17, 64, 122, 15, 0, 4, 38, 92, 22, 4, 54, 122, 22, 8, 18, 92, 34, 8, 32, 122, 34, 16, 5, 111, 7, 17, 25, 48, 52, 27, 24, 50, 31, 0, 1, 18, 6, 34, 8, 79, 6, 22, 72, 25, 82, 52]\n",
      "94\n",
      "[0, 1, 2, 142, 1, 49, 129, 42, 8, 2, 142, 10, 35, 55, 15, 91, 53, 128, 37, 13, 2, 142, 17, 2, 142, 90, 45, 129, 19, 0, 1, 2, 142, 1, 2, 142, 8, 32, 128, 34, 8, 35, 55, 66, 10, 51, 55, 31, 10, 35, 122, 66, 13, 2, 142, 17, 2, 142, 27, 64, 128, 31, 0, 1, 2, 142, 1, 64, 129, 47, 23, 35, 128, 15, 8, 2, 142, 13, 2, 142, 13, 53, 129, 19, 78, 35, 55, 47, 17, 2, 142, 74, 64, 122, 19, 0, 1, 2, 142, 8, 2, 142, 13, 2, 142, 17, 2, 142, 90, 35, 122, 15, 90, 35, 122, 15, 27, 49, 128, 15, 27, 49, 128, 15, 74, 35, 55, 47, 74, 35, 128, 47, 0, 1, 2, 142, 23, 45, 55, 31, 23, 53, 55, 31, 23, 45, 128, 31, 8, 2, 142, 13, 2, 142, 13, 53, 55, 15, 13, 53, 129, 15, 17, 2, 142, 90, 49, 128, 31, 0, 1, 2, 142, 8, 2, 142, 8, 35, 55, 31, 10, 35, 55, 31, 13, 53, 55, 28, 13, 53, 30, 15, 70, 49, 128, 31, 16, 51, 55, 31, 17, 35, 122, 31, 17, 2, 142, 27, 49, 55, 31, 27, 45, 129, 31, 0, 1, 49, 122, 41, 8, 2, 142, 10, 35, 122, 31, 13, 64, 129, 31, 16, 35, 128, 41, 17, 51, 55, 31, 27, 49, 122, 15, 90, 49, 128, 31, 74, 49, 122, 47, 0, 1, 2, 142, 4, 49, 128, 31, 23, 53, 55, 7, 8, 2, 142, 10, 35, 55, 31, 10, 35, 122, 31, 13, 54, 122, 31, 16, 53, 55, 41, 17, 53, 122, 31, 17, 2, 142, 27, 53, 128, 31, 0, 1, 53, 128, 19, 8, 32, 128, 7, 10, 35, 122, 15, 91, 35, 122, 34, 13, 2, 142, 13, 2, 142, 17, 35, 122, 34, 0, 1, 2, 142, 1, 2, 142, 13, 51, 55, 52, 17, 35, 122, 22, 27, 51, 100, 41, 0, 1, 2, 142, 8, 2, 142, 8, 35, 122, 41, 13, 2, 142, 10, 35, 122, 7, 13, 2, 142, 70, 63, 122, 7, 16, 35, 122, 7, 78, 53, 122, 7, 17, 2, 142, 17, 35, 185, 31, 27, 63, 122, 31, 27, 45, 122, 31, 0, 1, 49, 129, 31, 27, 49, 122, 7]\n",
      "95\n",
      "[0, 1, 2, 113, 1, 24, 58, 41, 8, 18, 57, 31, 91, 24, 58, 15, 13, 11, 48, 28, 0, 1, 25, 50, 19, 8, 32, 6, 19, 91, 32, 50, 15, 13, 38, 30, 28, 0, 1, 79, 30, 19, 8, 11, 55, 52, 91, 38, 48, 15, 13, 24, 30, 19, 17, 38, 55, 52, 74, 64, 128, 15, 0, 1, 11, 122, 52, 23, 32, 30, 77, 0, 1, 79, 58, 41, 8, 18, 57, 52, 91, 11, 58, 15, 13, 5, 48, 36, 0, 1, 18, 50, 19, 8, 11, 6, 52, 91, 54, 50, 15, 13, 38, 30, 77, 0, 1, 25, 30, 19, 8, 5, 55, 31, 91, 32, 48, 15, 13, 25, 30, 41, 17, 11, 55, 52, 74, 32, 128, 15, 0, 1, 5, 122, 19]\n",
      "96\n",
      "[0, 1, 2, 113, 4, 54, 122, 31, 8, 64, 100, 31, 10, 38, 55, 34, 10, 51, 100, 31, 13, 51, 55, 31, 16, 35, 46, 31, 17, 32, 46, 31, 27, 35, 46, 31, 0, 1, 54, 55, 31, 4, 51, 100, 28, 10, 64, 127, 66, 17, 11, 46, 31, 27, 53, 55, 31, 0, 1, 11, 46, 31, 4, 53, 122, 31, 8, 53, 104, 31, 10, 54, 46, 31, 13, 11, 55, 31, 16, 11, 46, 31, 17, 32, 55, 31, 27, 11, 55, 31, 0, 1, 51, 100, 31, 4, 51, 100, 31, 8, 54, 104, 31, 10, 53, 128, 31, 13, 64, 55, 31, 16, 32, 46, 31, 17, 64, 100, 31, 27, 64, 122, 31, 0, 1, 32, 100, 31, 4, 51, 55, 31, 8, 32, 100, 34, 10, 32, 122, 31, 13, 32, 100, 31, 16, 64, 55, 31, 17, 32, 100, 34, 0, 1, 32, 127, 31, 4, 64, 129, 31, 10, 64, 129, 31, 16, 32, 100, 31, 17, 51, 100, 31, 27, 32, 127, 31, 0, 1, 32, 55, 31, 4, 64, 100, 31, 8, 51, 122, 31, 10, 64, 100, 31, 13, 51, 122, 31, 16, 51, 55, 31, 17, 32, 100, 31, 27, 51, 122, 31, 0, 1, 51, 128, 31, 4, 51, 100, 31, 8, 51, 122, 31, 10, 38, 128, 31, 13, 51, 122, 31, 16, 64, 127, 31, 17, 51, 128, 31, 27, 64, 128, 31, 0, 1, 54, 128, 31, 4, 51, 122, 52, 10, 51, 46, 31, 13, 35, 127, 52, 16, 64, 128, 31, 16, 51, 128, 31, 17, 51, 122, 31, 17, 64, 128, 31, 27, 64, 127, 34, 0, 1, 51, 55, 31, 4, 64, 122, 31, 8, 51, 127, 31, 8, 51, 127, 52, 13, 64, 128, 34, 16, 51, 127, 34]\n",
      "97\n",
      "[0, 1, 43, 208, 1, 11, 46, 31, 4, 25, 48, 184, 0, 4, 11, 61, 31, 8, 38, 12, 31, 10, 38, 58, 31, 13, 11, 61, 19, 17, 79, 12, 7, 27, 11, 58, 31, 0, 1, 11, 48, 31, 4, 25, 50, 135, 0, 4, 79, 61, 31, 8, 5, 12, 31, 10, 32, 58, 31, 13, 32, 61, 34, 17, 25, 12, 31, 27, 32, 58, 31, 0, 1, 32, 46, 31, 4, 25, 48, 112, 27, 25, 48, 7, 0, 1, 79, 50, 15, 4, 24, 62, 103, 0, 1, 79, 50, 31, 4, 11, 46, 108]\n",
      "98\n",
      "[0, 1, 2, 194, 8, 79, 82, 80, 27, 5, 96, 31, 0, 1, 79, 82, 31, 4, 79, 98, 31, 8, 79, 82, 56, 0, 1, 25, 12, 7, 67, 5, 21, 31, 8, 5, 86, 34, 13, 79, 96, 31, 16, 5, 86, 31, 17, 25, 21, 41, 27, 25, 12, 31, 0, 1, 38, 21, 31, 4, 24, 57, 31, 8, 38, 6, 66, 10, 5, 30, 15, 91, 32, 33, 15, 13, 64, 48, 15, 70, 5, 33, 15, 16, 11, 30, 15, 78, 11, 55, 15, 17, 38, 111, 47, 0, 1, 25, 12, 7, 67, 24, 57, 31, 8, 79, 12, 42, 16, 79, 86, 31, 17, 18, 21, 52, 27, 79, 12, 31, 0, 1, 11, 21, 52, 4, 25, 57, 31, 8, 11, 50, 42, 13, 38, 57, 52, 16, 18, 50, 31, 17, 11, 48, 66, 0, 1, 5, 6, 31, 4, 79, 57, 7, 23, 5, 12, 31, 10, 5, 82, 31, 13, 79, 96, 31, 16, 79, 86, 31, 17, 25, 21, 34, 0, 1, 79, 12, 31, 4, 79, 57, 31, 23, 79, 12, 103]\n",
      "99\n",
      "[0, 1, 2, 181, 67, 54, 50, 22, 67, 11, 48, 22, 4, 79, 50, 22, 23, 11, 58, 15, 8, 24, 50, 22, 72, 38, 58, 22, 10, 51, 50, 22, 91, 11, 58, 22, 13, 79, 50, 22, 70, 51, 50, 22, 16, 79, 50, 22, 78, 11, 50, 22, 17, 5, 50, 22, 90, 11, 50, 22, 27, 38, 50, 22, 74, 11, 48, 22, 0, 1, 38, 48, 66, 91, 11, 55, 22, 13, 79, 50, 15, 70, 51, 30, 15, 16, 51, 50, 15, 78, 11, 48, 15, 17, 25, 50, 15, 90, 32, 50, 15, 27, 25, 50, 15, 74, 38, 50, 15, 0, 1, 24, 30, 7, 4, 25, 12, 15, 23, 51, 50, 15, 8, 32, 58, 15, 72, 24, 30, 15, 10, 32, 55, 15, 91, 11, 50, 34, 78, 32, 48, 22, 17, 5, 50, 15, 90, 25, 58, 15, 27, 11, 50, 15, 74, 25, 48, 22, 0, 1, 38, 50, 31, 23, 11, 48, 22, 8, 38, 50, 15, 72, 11, 57, 15, 10, 64, 12, 15, 91, 32, 58, 15, 13, 38, 57, 31, 78, 11, 12, 15, 17, 64, 50, 22, 90, 35, 58, 22, 27, 35, 30, 15, 74, 24, 55, 15, 0, 1, 11, 55, 15, 4, 11, 100, 15, 8, 32, 122, 15, 72, 32, 122, 15, 72, 51, 30, 22, 10, 51, 55, 22, 91, 64, 57, 15, 13, 38, 50, 15, 70, 24, 12, 15, 16, 11, 50, 15, 78, 32, 12, 15, 17, 32, 50, 15, 90, 79, 96, 15, 27, 18, 50, 31, 0, 1, 32, 48, 31, 4, 38, 50, 31, 8, 11, 50, 15, 23, 32, 48, 15, 72, 5, 50, 15, 91, 5, 50, 15, 13, 32, 50, 15, 70, 11, 50, 15, 16, 11, 30, 15, 16, 11, 30, 15, 78, 38, 48, 15, 78, 25, 48, 15, 17, 24, 50, 15, 17, 38, 50, 15, 90, 25, 50, 31, 27, 5, 96, 15, 27, 11, 50, 22, 27, 25, 50, 15, 74, 11, 50, 15, 74, 64, 96, 15, 0, 1, 24, 30, 19, 1, 24, 55, 19, 0, 1, 25, 50, 15, 67, 38, 48, 15, 4, 11, 50, 22, 4, 38, 48, 15, 23, 5, 50, 15, 8, 5, 30, 15, 72, 18, 55, 15, 72, 11, 55, 15, 10, 5, 30, 15, 91, 24, 57, 15, 13, 5, 12, 15, 70, 24, 57, 34, 74, 51, 30, 15, 70, 5, 50, 15, 0, 1, 24, 58, 15, 67, 38, 96, 15, 23, 32, 12, 15, 8, 5, 86, 59, 90, 32, 100, 15, 10, 38, 57, 15, 91, 51, 100, 15, 13, 32, 50, 19, 17, 54, 50, 15, 70, 11, 57, 31, 70, 45, 58, 15, 90, 32, 58, 15, 27, 38, 55, 15, 74, 32, 57, 15, 0, 1, 25, 50, 34, 0, 1, 38, 50, 15, 67, 24, 50, 15, 67, 38, 12, 15, 67, 24, 30, 22, 4, 38, 55, 15, 23, 79, 50, 15, 23, 24, 30, 15, 8, 11, 57, 15, 72, 5, 12, 15, 10, 38, 55, 15, 10, 38, 50, 47]\n",
      "100\n",
      "[0, 1, 2, 188, 1, 11, 33, 15, 67, 32, 26, 15, 4, 53, 62, 15, 23, 38, 6, 15, 8, 25, 9, 77, 16, 64, 62, 31, 17, 11, 73, 31, 27, 32, 9, 19, 0, 4, 32, 73, 7, 8, 38, 62, 34, 13, 32, 26, 52, 16, 64, 33, 28, 27, 51, 104, 15, 74, 35, 29, 15, 0, 1, 53, 104, 31, 4, 45, 93, 31, 8, 53, 92, 28, 8, 11, 62, 66, 16, 38, 9, 31, 17, 32, 73, 31, 27, 32, 21, 41, 0, 4, 64, 73, 31, 8, 54, 9, 36, 10, 32, 46, 31, 13, 32, 33, 7, 16, 64, 26, 31, 17, 32, 62, 52, 27, 51, 26, 31, 0, 1, 45, 33, 52, 4, 53, 29, 31, 8, 53, 75, 42, 8, 11, 73, 47, 16, 24, 21, 15, 78, 64, 20, 15, 17, 11, 21, 34, 0, 4, 32, 73, 31, 8, 64, 9, 52, 13, 32, 73, 7, 16, 32, 62, 42, 0, 8, 5, 26, 41, 13, 32, 62, 31, 16, 38, 9, 47, 27, 38, 73, 15, 74, 49, 9, 15, 0, 1, 32, 62, 52, 4, 64, 26, 7, 8, 32, 33, 7, 10, 64, 33, 31, 13, 64, 26, 52, 16, 51, 62, 7, 17, 38, 9, 31, 27, 5, 73, 7, 0, 1, 38, 21, 15, 67, 64, 20, 15, 4, 32, 21, 15, 23, 24, 20, 22, 8, 18, 76, 94, 0, 1, 25, 73, 7, 4, 38, 21, 15, 8, 11, 20, 66, 0, 1, 79, 21, 15, 67, 54, 20, 15, 4, 64, 21, 7, 23, 11, 20, 15, 8, 5, 76, 36, 0, 1, 5, 9, 31, 4, 32, 73, 31, 8, 24, 21, 80]\n",
      "101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 188, 1, 25, 58, 66, 8, 2, 188, 10, 25, 57, 22, 91, 24, 58, 22, 13, 2, 188, 13, 14, 61, 7, 16, 14, 86, 15, 17, 2, 188, 17, 25, 12, 52, 0, 1, 2, 188, 1, 14, 86, 7, 4, 24, 96, 15, 8, 2, 188, 8, 24, 96, 7, 10, 11, 86, 7, 13, 32, 12, 19, 17, 11, 57, 7, 27, 25, 61, 7, 0, 1, 11, 57, 7, 4, 11, 12, 15, 8, 14, 12, 7, 10, 14, 12, 7, 13, 14, 57, 31, 16, 18, 57, 22, 78, 24, 58, 22, 17, 14, 57, 7, 27, 14, 58, 7, 0, 1, 14, 50, 103, 16, 14, 46, 22, 78, 24, 48, 22, 17, 5, 6, 22, 90, 14, 50, 22, 27, 25, 6, 22, 74, 5, 58, 22, 0, 1, 5, 57, 34, 10, 14, 61, 7, 13, 14, 61, 7, 16, 14, 86, 7, 78, 5, 12, 15, 17, 11, 57, 7, 27, 14, 58, 7, 0, 1, 24, 12, 7, 4, 24, 86, 7, 8, 24, 96, 7, 10, 5, 12, 7, 13, 14, 86, 52, 17, 24, 61, 7, 27, 14, 57, 7, 0, 1, 11, 12, 42, 10, 14, 96, 7, 13, 11, 86, 7, 16, 14, 12, 22, 78, 14, 86, 22, 17, 5, 12, 7, 27, 14, 57, 15, 0, 1, 5, 58, 102]\n",
      "102\n",
      "[0, 1, 2, 150, 23, 79, 30, 7, 72, 25, 30, 7, 91, 5, 48, 31, 70, 38, 30, 15, 16, 79, 48, 41, 0, 1, 32, 128, 15, 67, 5, 122, 15, 4, 11, 128, 22, 23, 18, 128, 41, 91, 79, 128, 15, 13, 38, 122, 15, 70, 38, 128, 15, 16, 79, 122, 28, 0, 23, 18, 129, 31, 72, 18, 128, 15, 10, 38, 122, 22, 91, 11, 122, 7, 13, 24, 128, 15, 70, 11, 55, 15, 16, 79, 30, 52, 17, 11, 128, 15, 90, 5, 122, 15, 27, 24, 100, 15, 74, 24, 55, 15, 0, 1, 5, 122, 15, 67, 18, 57, 15, 4, 32, 58, 15, 23, 79, 58, 7, 10, 11, 12, 22, 91, 79, 12, 15, 70, 79, 12, 15, 16, 79, 12, 22, 78, 79, 12, 7, 90, 79, 57, 22, 27, 18, 12, 22, 74, 79, 6, 15, 0, 67, 18, 6, 15, 4, 5, 12, 22, 23, 79, 12, 31, 72, 18, 57, 34, 70, 25, 6, 31, 78, 24, 96, 28, 0, 67, 18, 86, 31, 23, 79, 21, 66, 78, 24, 12, 94, 17, 32, 132, 15, 90, 64, 129, 15, 27, 51, 122, 22, 74, 32, 128, 15, 0, 1, 64, 122, 15, 67, 64, 128, 15, 4, 45, 122, 15, 23, 38, 122, 34, 91, 11, 129, 34]\n",
      "103\n",
      "[0, 1, 2, 115, 16, 5, 48, 7, 16, 5, 86, 7, 17, 5, 58, 15, 17, 5, 84, 15, 27, 14, 73, 15, 27, 14, 97, 15, 0, 1, 5, 57, 52, 1, 5, 98, 52, 23, 5, 62, 52, 23, 5, 76, 52, 10, 5, 46, 85, 10, 5, 61, 85, 27, 5, 100, 22, 27, 5, 58, 22, 74, 5, 55, 22, 74, 5, 57, 22, 0, 1, 25, 84, 52, 23, 25, 76, 22, 23, 5, 20, 22, 8, 25, 76, 22, 72, 18, 73, 31, 13, 25, 61, 15, 70, 24, 73, 15, 16, 18, 57, 15, 78, 14, 73, 22, 17, 18, 61, 19, 0, 1, 18, 62, 15, 67, 25, 73, 15, 23, 79, 57, 15, 8, 18, 61, 15, 72, 18, 73, 22, 91, 18, 61, 22, 13, 18, 86, 34, 17, 18, 86, 22, 90, 5, 82, 15, 27, 18, 84, 22, 74, 18, 98, 22, 0, 1, 79, 97, 42, 91, 14, 84, 22, 91, 11, 98, 22, 13, 79, 97, 7, 70, 25, 98, 15, 78, 18, 84, 15, 17, 18, 86, 41, 74, 14, 61, 22, 0, 1, 64, 86, 22, 67, 5, 86, 22, 4, 5, 84, 15, 23, 25, 76, 22, 8, 79, 61, 22, 8, 38, 86, 15, 72, 11, 61, 22, 72, 51, 73, 22, 10, 38, 61, 22, 91, 18, 61, 34, 17, 5, 61, 22, 17, 38, 86, 7, 90, 25, 61, 15, 27, 25, 73, 15, 74, 5, 57, 15, 0, 1, 18, 58, 19, 8, 18, 76, 22, 8, 51, 84, 15, 10, 25, 76, 22, 91, 11, 86, 22, 13, 18, 76, 22, 70, 14, 61, 66, 90, 18, 73, 22, 27, 25, 57, 15, 74, 18, 73, 22, 74, 18, 58, 83]\n",
      "104\n",
      "[0, 1, 2, 188, 67, 11, 50, 22, 4, 5, 6, 22, 23, 38, 58, 22, 8, 25, 57, 22, 10, 79, 12, 36, 90, 25, 12, 31, 74, 5, 84, 15, 0, 1, 79, 84, 34, 72, 25, 82, 19, 13, 79, 96, 31, 16, 64, 86, 31, 90, 11, 12, 77, 0, 23, 45, 61, 22, 8, 45, 12, 22, 8, 64, 57, 52, 91, 38, 58, 31, 13, 38, 12, 28, 90, 38, 50, 28, 0, 72, 11, 57, 31, 91, 38, 12, 41, 78, 5, 61, 47, 0, 1, 11, 61, 31, 23, 11, 86, 31, 72, 11, 96, 31, 91, 38, 96, 22, 13, 38, 82, 31, 16, 11, 84, 7, 90, 18, 98, 66, 0, 1, 18, 84, 15, 23, 5, 84, 7, 72, 11, 82, 31, 91, 32, 96, 31, 13, 11, 82, 87]\n",
      "105\n",
      "[0, 74, 18, 26, 41, 0, 67, 25, 33, 34, 72, 25, 33, 31, 91, 24, 33, 31, 70, 5, 33, 52, 78, 11, 26, 15, 90, 11, 33, 52, 74, 11, 26, 19, 0, 72, 38, 33, 7, 91, 24, 33, 80, 70, 11, 21, 7, 0, 67, 38, 21, 94, 0, 72, 38, 33, 60, 0, 91, 5, 50, 7, 70, 11, 26, 7, 78, 38, 33, 36, 0, 70, 24, 33, 31, 23, 24, 33, 7, 72, 11, 30, 7, 91, 14, 33, 77, 74, 11, 21, 31, 0, 67, 11, 6, 77, 90, 11, 21, 42, 0, 67, 11, 12, 15, 23, 38, 21, 15, 8, 35, 73, 7, 72, 11, 21, 7, 91, 32, 12, 7, 70, 38, 21, 15, 78, 18, 96, 66, 0, 23, 11, 21, 15, 72, 38, 12, 7, 91, 11, 9, 37, 78, 38, 33, 7, 90, 24, 21, 7, 74, 11, 21, 60, 0, 67, 24, 21, 7, 23, 5, 9, 31, 72, 24, 9, 15, 72, 11, 6, 15, 91, 38, 33, 7, 70, 11, 33, 31, 78, 11, 33, 31, 90, 24, 33, 31, 74, 24, 33, 125]\n",
      "106\n",
      "[0, 1, 2, 69, 67, 79, 62, 15, 23, 5, 76, 41, 8, 2, 69, 72, 5, 76, 19, 91, 5, 62, 19, 13, 2, 69, 70, 38, 62, 15, 16, 45, 62, 15, 78, 54, 62, 41, 90, 5, 76, 41, 0, 1, 2, 69, 67, 5, 62, 15, 23, 5, 58, 7, 72, 5, 73, 19, 13, 2, 69, 70, 5, 62, 31, 78, 5, 76, 7, 90, 18, 73, 19, 0, 67, 5, 62, 34, 72, 5, 76, 7, 91, 5, 76, 41, 70, 11, 73, 42, 90, 5, 62, 22, 74, 5, 62, 31, 0, 1, 2, 69, 67, 14, 62, 41, 67, 5, 62, 7, 23, 5, 76, 7, 23, 5, 76, 7, 72, 24, 76, 31, 91, 5, 76, 31, 70, 5, 106, 7, 70, 5, 76, 7, 78, 11, 106, 34, 78, 5, 62, 19, 74, 5, 62, 7, 0, 67, 5, 76, 7, 23, 5, 73, 7, 72, 18, 97, 7, 91, 5, 107, 7, 70, 25, 97, 7, 78, 5, 107, 7, 90, 25, 61, 7, 74, 14, 73, 7, 0, 67, 5, 61, 41, 72, 25, 73, 7, 91, 11, 97, 7, 70, 5, 76, 7, 78, 5, 62, 34, 74, 11, 76, 7, 0, 67, 25, 9, 19, 8, 5, 62, 19, 72, 5, 62, 31, 91, 5, 62, 7, 70, 25, 76, 31, 78, 5, 62, 31, 90, 5, 76, 41, 70, 5, 62, 7, 27, 79, 76, 7, 74, 25, 62, 42, 74, 25, 76, 7, 0, 67, 5, 62, 7, 23, 11, 76, 31, 8, 14, 73, 7, 72, 5, 62, 15, 70, 38, 76, 7, 78, 25, 62, 7, 90, 14, 76, 19, 74, 24, 106, 19, 0, 67, 5, 76, 22, 4, 45, 62, 22, 23, 5, 76, 41, 72, 5, 106, 7, 70, 5, 106, 19, 0, 67, 5, 106, 34, 72, 5, 76, 15, 10, 11, 76, 7, 91, 5, 76, 7, 70, 14, 73, 7, 70, 5, 76, 7, 16, 45, 62, 34, 78, 64, 62, 7, 78, 5, 97, 15, 17, 35, 62, 7, 90, 11, 76, 41, 90, 5, 76, 7, 74, 25, 106, 31, 74, 24, 62, 7, 0, 67, 5, 106, 7, 67, 5, 76, 7, 67, 5, 62, 7, 23, 5, 62, 19, 67, 5, 62, 41, 23, 5, 76, 7, 23, 24, 76, 19, 72, 5, 76, 7, 91, 5, 76, 19, 13, 35, 62, 7, 70, 5, 76, 41, 70, 5, 76, 7, 16, 25, 76, 7, 78, 14, 76, 19, 17, 2, 69, 74, 14, 76, 7, 0, 67, 25, 106, 7, 67, 5, 106, 7, 23, 5, 76, 31, 23, 5, 62, 52]\n",
      "107\n",
      "[0, 1, 2, 197, 67, 18, 40, 15, 4, 54, 82, 15, 23, 25, 96, 31, 72, 32, 73, 66, 72, 18, 97, 22, 10, 11, 97, 22, 91, 38, 97, 22, 13, 38, 97, 22, 70, 18, 118, 22, 16, 11, 39, 22, 78, 38, 97, 22, 17, 32, 73, 22, 90, 38, 97, 22, 27, 11, 118, 22, 74, 38, 97, 22, 0, 1, 11, 73, 22, 67, 25, 12, 22, 4, 11, 73, 22, 23, 38, 73, 22, 8, 38, 73, 22, 72, 11, 73, 22, 10, 11, 73, 22, 91, 5, 97, 22, 13, 38, 97, 22, 70, 18, 97, 22, 16, 25, 40, 22, 78, 38, 40, 22, 17, 5, 97, 22, 90, 5, 76, 22, 27, 11, 20, 22, 74, 38, 20, 22, 0, 1, 38, 21, 22, 67, 11, 21, 22, 4, 11, 21, 22, 23, 38, 21, 22, 8, 5, 73, 22, 72, 11, 73, 22, 10, 79, 76, 15, 13, 32, 20, 22, 70, 11, 20, 22, 16, 25, 21, 22, 78, 24, 21, 22, 17, 38, 73, 22, 90, 79, 20, 22, 27, 38, 21, 22, 74, 32, 21, 22, 0, 1, 32, 73, 22, 67, 11, 73, 22, 4, 5, 21, 22, 23, 11, 21, 22, 8, 11, 73, 22, 72, 25, 20, 22, 72, 18, 97, 52, 10, 5, 21, 22, 91, 32, 73, 7, 91, 51, 21, 22, 13, 38, 73, 22, 70, 11, 73, 22, 70, 24, 97, 52, 90, 25, 97, 31, 74, 38, 73, 31, 0, 67, 79, 97, 52, 72, 79, 20, 28, 78, 5, 21, 31, 90, 5, 20, 34, 0, 1, 11, 21, 15, 67, 24, 20, 22, 4, 11, 76, 15, 23, 5, 40, 31, 72, 79, 76, 66, 16, 38, 40, 22, 78, 11, 40, 22, 17, 38, 76, 22, 90, 38, 76, 22, 27, 64, 20, 22, 74, 24, 20, 22, 0, 1, 38, 21, 22, 67, 11, 20, 22, 4, 11, 21, 22, 23, 32, 21, 22, 8, 11, 73, 22, 72, 5, 9, 52, 72, 11, 73, 22, 91, 24, 73, 31, 70, 5, 20, 34, 90, 18, 21, 34, 0, 67, 25, 73, 31, 72, 24, 73, 83, 0, 72, 11, 97, 31, 91, 64, 73, 52, 70, 32, 97, 52, 78, 54, 73, 52, 90, 32, 97, 52, 74, 64, 73, 31, 0, 67, 38, 97, 31, 23, 5, 73, 31]\n",
      "108\n",
      "[0, 1, 2, 110, 4, 38, 57, 15, 23, 18, 86, 7, 8, 5, 96, 7, 10, 5, 21, 7, 13, 25, 86, 7, 16, 5, 12, 7, 17, 25, 57, 7, 27, 38, 57, 31, 0, 1, 5, 96, 66, 13, 5, 21, 36, 16, 18, 58, 7, 17, 5, 9, 52, 27, 5, 12, 7, 0, 1, 5, 21, 7, 4, 5, 96, 66, 13, 18, 82, 7, 16, 5, 40, 52, 90, 25, 82, 22, 27, 25, 82, 7, 0, 1, 5, 96, 7, 4, 25, 86, 28, 13, 25, 12, 7, 16, 5, 57, 77, 0, 4, 25, 86, 7, 4, 25, 88, 7, 8, 5, 86, 7, 8, 5, 118, 7, 10, 5, 9, 7, 10, 5, 40, 7, 13, 5, 12, 7, 13, 5, 39, 7, 16, 5, 9, 7, 16, 5, 98, 7, 17, 25, 58, 31, 17, 25, 84, 31, 27, 38, 6, 31, 27, 38, 82, 31, 0, 1, 5, 96, 7, 1, 5, 121, 7, 4, 25, 86, 36, 4, 25, 88, 36, 16, 18, 6, 7, 16, 18, 82, 7, 17, 5, 9, 7, 17, 5, 40, 7, 27, 5, 12, 7, 27, 5, 39, 7, 0, 1, 5, 21, 7, 1, 5, 118, 7, 4, 5, 12, 66, 4, 5, 39, 66, 13, 18, 84, 7, 13, 18, 140, 7, 16, 5, 82, 52, 16, 5, 140, 52, 90, 25, 82, 22, 90, 25, 140, 22, 27, 25, 98, 7, 27, 25, 143, 7, 0, 1, 5, 40, 7, 1, 5, 167, 7, 67, 25, 84, 108, 67, 25, 144, 108]\n",
      "109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 130, 10, 24, 111, 15, 91, 53, 29, 15, 13, 24, 30, 15, 70, 53, 29, 15, 16, 79, 30, 31, 27, 53, 33, 41, 0, 4, 79, 30, 34, 10, 79, 33, 34, 70, 32, 92, 15, 16, 38, 111, 31, 17, 18, 30, 31, 27, 32, 29, 19, 0, 1, 38, 30, 31, 4, 11, 6, 31, 8, 38, 26, 31, 10, 11, 29, 66, 10, 5, 50, 52, 17, 79, 33, 15, 90, 79, 50, 15, 27, 5, 26, 31, 0, 4, 79, 30, 34, 10, 79, 33, 36]\n",
      "110\n",
      "[0, 1, 2, 148, 1, 24, 57, 31, 23, 32, 48, 15, 8, 32, 57, 31, 10, 11, 58, 31, 13, 11, 48, 34, 16, 54, 86, 15, 78, 32, 96, 15, 17, 51, 100, 7, 17, 51, 84, 15, 90, 32, 98, 7, 27, 51, 46, 31, 74, 32, 98, 15, 0, 1, 54, 48, 15, 1, 49, 98, 41, 67, 51, 58, 52, 8, 11, 58, 7, 10, 51, 57, 15, 91, 32, 58, 22, 13, 11, 58, 41, 17, 32, 58, 31, 27, 54, 57, 15, 74, 32, 58, 22, 0, 1, 64, 62, 52, 23, 45, 55, 15, 8, 32, 62, 47, 16, 53, 62, 22, 78, 11, 57, 7, 17, 11, 61, 15, 90, 64, 61, 7, 27, 11, 57, 7, 0, 1, 32, 62, 15, 67, 14, 58, 66, 67, 11, 107, 52, 8, 51, 88, 52, 91, 53, 107, 31, 70, 51, 88, 77, 16, 49, 86, 22, 78, 32, 86, 22, 78, 11, 86, 22, 17, 32, 61, 22, 90, 32, 61, 22, 90, 24, 86, 22, 27, 32, 61, 15, 0, 1, 11, 57, 22, 67, 32, 20, 52, 67, 32, 61, 15, 4, 32, 57, 15, 23, 51, 62, 15, 8, 32, 86, 19, 8, 24, 58, 42, 91, 51, 57, 31, 70, 51, 61, 85, 78, 49, 46, 22, 78, 51, 48, 15, 17, 32, 62, 15, 90, 32, 62, 7, 27, 11, 48, 7]\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(test_intro)):\n",
    "#     if len(test_intro) > 1200:\n",
    "#         continue\n",
    "    intro = test_intro[i]\n",
    "    solo = test_solo[i]\n",
    "    outro = test_outro[i]\n",
    "    #print(intro)\n",
    "    #print(outro)\n",
    "    list_intro = [int(x) for x in intro.split(' ')]\n",
    "    list_solo = [int(x) for x in solo.split(' ')]\n",
    "    list_outro = [int(x) for x in outro.split(' ')]\n",
    "    #print(list_sentence)\n",
    "    translated_sentence = translate_sentence(model, intro, outro, intro_field, outro_field, solo_field, device, max_length=1200)\n",
    "    #print(translated_sentence)\n",
    "    translated_sentence = [int(x) for x in translated_sentence if x != '<pad>' and x != '<sos>' and x != '<eos>' and x != '<unk>']\n",
    "    print(translated_sentence)\n",
    "    utils.write_midi(list_intro, word2event, generated_outputs + \"/intro/\" + \"/intro\" + str(i)  + \".mid\")\n",
    "    utils.write_midi(list_solo, word2event, generated_outputs  + \"/solo/\" + \"/solo\" + str(i)  + \".mid\")\n",
    "    utils.write_midi(list_outro, word2event, generated_outputs + \"/outro/\" + \"/outro\" + str(i)  + \".mid\")\n",
    "    utils.write_midi(translated_sentence, word2event, generated_outputs + \"/predict/\" + \"/predict\" + str(i)  + \".mid\")\n",
    "    print(i)\n",
    "#     if i == 10:\n",
    "#         break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a43b85e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30480\n",
      "30480\n",
      "33000\n",
      "33000\n",
      "40200\n",
      "40200\n",
      "34920\n",
      "34920\n",
      "27720\n",
      "27720\n",
      "29280\n",
      "29280\n",
      "53340\n",
      "53340\n",
      "57960\n",
      "57960\n",
      "25800\n",
      "25800\n",
      "28080\n",
      "28080\n",
      "20400\n",
      "20400\n",
      "27000\n",
      "27000\n",
      "30900\n",
      "30900\n",
      "23760\n",
      "23760\n",
      "31680\n",
      "31680\n",
      "30780\n",
      "30780\n",
      "30720\n",
      "30720\n",
      "33060\n",
      "33060\n",
      "61500\n",
      "61500\n",
      "53820\n",
      "53820\n",
      "31380\n",
      "31380\n",
      "34920\n",
      "34920\n"
     ]
    }
   ],
   "source": [
    "import mido\n",
    "for i in range(11):\n",
    "    intro = mido.MidiFile(generated_outputs + \"/intro/\" + '/intro' + str(i) + '.mid')\n",
    "    solo = mido.MidiFile(generated_outputs + \"/solo/\" +'/solo' + str(i) + '.mid')\n",
    "    outro = mido.MidiFile(generated_outputs + \"/outro/\" +'/outro' + str(i) + '.mid')\n",
    "    predict = mido.MidiFile(generated_outputs + \"/predict/\" +'/predict' + str(i) + '.mid')\n",
    "    total_intro_time = 0\n",
    "    total_solo_time = 0\n",
    "    total_predict_time = 0\n",
    "    for msg in intro.tracks[1]:\n",
    "        if msg.type == \"note_on\":\n",
    "            total_intro_time += msg.time\n",
    "    for msg in solo.tracks[1]:\n",
    "        if msg.type == \"note_on\":\n",
    "            total_solo_time += msg.time\n",
    "    for msg in predict.tracks[1]:\n",
    "        if msg.type == \"note_on\":\n",
    "            total_predict_time += msg.time\n",
    "            \n",
    "    original_outro_time = 0 + outro.tracks[1][1].time\n",
    "    \n",
    "    print(original_outro_time + total_solo_time + total_intro_time)\n",
    "    solo.tracks[1][1].time += total_intro_time\n",
    "    outro.tracks[1][1].time = original_outro_time + total_solo_time + total_intro_time\n",
    "    print(outro.tracks[1][1].time)\n",
    "    intro.tracks[1].name = \"intro\"\n",
    "    solo.tracks[1].name = \"solo\"\n",
    "    outro.tracks[1].name = \"outro\"\n",
    "    predict.tracks[1].name = \"predict\"\n",
    "    merged_mid = mido.MidiFile()\n",
    "    merged_mid.ticks_per_beat = intro.ticks_per_beat\n",
    "    merged_mid.tracks = intro.tracks + solo.tracks + outro.tracks\n",
    "    merged_mid.save(generated_outputs + '/merged' + str(i) + '.mid')\n",
    "    \n",
    "    \n",
    "    outro = mido.MidiFile(generated_outputs + \"/outro/\" +'/outro' + str(i) + '.mid')\n",
    "    \n",
    "    print(original_outro_time + total_predict_time + total_intro_time)\n",
    "    predict.tracks[1][1].time += total_intro_time\n",
    "    outro.tracks[1][1].time = original_outro_time + total_predict_time + total_intro_time\n",
    "    print(outro.tracks[1][1].time)\n",
    "    merged_mid = mido.MidiFile()\n",
    "    merged_mid.ticks_per_beat = intro.ticks_per_beat\n",
    "    merged_mid.tracks = intro.tracks + predict.tracks + outro.tracks\n",
    "    merged_mid.save(generated_outputs + '/merged_predict' + str(i) + '.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b29e021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 50, 194, 1, 56, 16, 43, 14, 37, 25, 43, 18, 37, 91, 39, 30, 56, 91, 43, 33, 67, 10, 43, 53, 37, 91, 43, 38, 61, 25, 43, 0, 1, 61, 16, 43, 14, 37, 93, 43, 18, 61, 89, 76, 0, 1, 63, 16, 43, 14, 67, 25, 43, 18, 61, 91, 39, 30, 37, 91, 43, 33, 62, 10, 43, 53, 67, 91, 43, 38, 67, 25, 43, 0, 1, 67, 25, 43, 14, 67, 16, 43, 18, 67, 25, 76, 0, 1, 56, 16, 43, 14, 37, 25, 43, 18, 37, 91, 39, 30, 56, 91, 43, 33, 67, 10, 43, 53, 37, 91, 43, 38, 61, 25, 43, 0, 1, 61, 16, 43, 14, 37, 93, 43, 18, 61, 89, 76, 0, 1, 58, 89, 43, 14, 56, 91, 43, 18, 63, 25, 39, 30, 61, 25, 43, 33, 37, 16, 43, 53, 58, 89, 39, 0, 1, 37, 93, 43, 14, 61, 89, 43]\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4951/483130940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlist_outro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#print(list_sentence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtranslated_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintro_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutro_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolo_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m#print(translated_sentence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtranslated_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranslated_sentence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'<pad>'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'<sos>'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'<eos>'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'<unk>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4951/2900468083.py\u001b[0m in \u001b[0;36mtranslate_sentence\u001b[0;34m(model, sentence, sentence2, intro, outro, solo, device, max_length)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mbest_guess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4951/2970432970.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src2, trg)\u001b[0m\n\u001b[1;32m     86\u001b[0m         )\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         out = self.transformer(\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0membed_src\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0membed_src2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Kevin Thesis/twoencodertransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src2, tgt, src_mask, src2_mask, tgt_mask, memory_mask, memory2_mask, src_key_padding_mask, src2_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, memory2_key_padding_mask)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mmemory2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc2_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc2_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         output = self.decoder(tgt, memory, memory2, tgt_mask=tgt_mask, memory_mask=memory_mask, memory2_mask=memory2_mask,\n\u001b[0m\u001b[1;32m    143\u001b[0m                               \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                               \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Kevin Thesis/twoencodertransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, memory2, tgt_mask, memory_mask, memory2_mask, tgt_key_padding_mask, memory_key_padding_mask, memory2_key_padding_mask)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             output = mod(output, memory, memory2, tgt_mask=tgt_mask,\n\u001b[0m\u001b[1;32m    242\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory2_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory2_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Kevin Thesis/twoencodertransformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, memory2, tgt_mask, memory_mask, memory2_mask, tgt_key_padding_mask, memory_key_padding_mask, memory2_key_padding_mask)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mha_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mha_block2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory2_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory2_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Kevin Thesis/twoencodertransformer.py\u001b[0m in \u001b[0;36m_ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_VF.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dissimilar_interpolation\n",
    "for i in range(0,len(test_intro)):\n",
    "#     if len(test_intro) > 1200:\n",
    "#         continue\n",
    "    intro = test_intro[i]\n",
    "    #solo = test_solo[i]\n",
    "    if i + 3 < (len(test_intro)):\n",
    "        outro = test_outro[i+3]\n",
    "    else:\n",
    "        outro = test_outro[i]\n",
    "    #print(intro)\n",
    "    #print(outro)\n",
    "    list_intro = [int(x) for x in intro.split(' ')]\n",
    "    #list_solo = [int(x) for x in solo.split(' ')]\n",
    "    list_outro = [int(x) for x in outro.split(' ')]\n",
    "    #print(list_sentence)\n",
    "    translated_sentence = translate_sentence(model, intro, outro, intro_field, outro_field, solo_field, device, max_length=1200)\n",
    "    #print(translated_sentence)\n",
    "    translated_sentence = [int(x) for x in translated_sentence if x != '<pad>' and x != '<sos>' and x != '<eos>' and x != '<unk>']\n",
    "    print(translated_sentence)\n",
    "    utils.write_midi(list_intro, word2event, dissimilar_interpolation + \"/intro/\" + \"/intro\" + str(i)  + \".mid\")\n",
    "    #utils.write_midi(list_solo, word2event, generated_outputs  + \"/solo/\" + \"/solo\" + str(i)  + \".mid\")\n",
    "    utils.write_midi(list_outro, word2event, dissimilar_interpolation + \"/outro/\" + \"/outro\" + str(i)  + \".mid\")\n",
    "    utils.write_midi(translated_sentence, word2event, dissimilar_interpolation + \"/predict/\" + \"/predict\" + str(i)  + \".mid\")\n",
    "    print(i)\n",
    "#     if i == 10:\n",
    "#         break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4fb2841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33720\n",
      "33720\n",
      "34200\n",
      "34200\n",
      "23520\n",
      "23520\n",
      "44280\n",
      "44280\n",
      "27600\n",
      "27600\n",
      "24060\n",
      "24060\n",
      "23760\n",
      "23760\n",
      "33420\n",
      "33420\n",
      "31560\n",
      "31560\n",
      "45780\n",
      "45780\n",
      "26280\n",
      "26280\n",
      "30540\n",
      "30540\n",
      "30780\n",
      "30780\n",
      "25500\n",
      "25500\n",
      "30000\n",
      "30000\n",
      "54420\n",
      "54420\n",
      "18660\n",
      "18660\n",
      "30420\n",
      "30420\n",
      "41940\n",
      "41940\n",
      "49440\n",
      "49440\n",
      "35520\n",
      "35520\n",
      "27660\n",
      "27660\n",
      "36840\n",
      "36840\n",
      "30540\n",
      "30540\n",
      "29220\n",
      "29220\n",
      "31260\n",
      "31260\n",
      "36960\n",
      "36960\n",
      "28320\n",
      "28320\n",
      "41160\n",
      "41160\n",
      "14940\n",
      "14940\n",
      "30780\n",
      "30780\n",
      "27660\n",
      "27660\n",
      "22020\n",
      "22020\n",
      "30480\n",
      "30480\n",
      "46560\n",
      "46560\n",
      "24180\n",
      "24180\n",
      "31500\n",
      "31500\n",
      "45960\n",
      "45960\n",
      "32460\n",
      "32460\n",
      "38880\n",
      "38880\n",
      "23040\n",
      "23040\n",
      "28200\n",
      "28200\n",
      "33720\n",
      "33720\n",
      "22800\n",
      "22800\n",
      "24840\n",
      "24840\n",
      "22920\n",
      "22920\n",
      "32220\n",
      "32220\n",
      "46800\n",
      "46800\n",
      "23760\n",
      "23760\n",
      "24420\n",
      "24420\n",
      "19740\n",
      "19740\n",
      "30060\n",
      "30060\n",
      "36720\n",
      "36720\n",
      "29280\n",
      "29280\n",
      "30960\n",
      "30960\n",
      "28620\n",
      "28620\n",
      "39900\n",
      "39900\n",
      "26760\n",
      "26760\n",
      "40140\n",
      "40140\n",
      "27420\n",
      "27420\n",
      "33600\n",
      "33600\n",
      "35520\n",
      "35520\n",
      "30240\n",
      "30240\n",
      "29280\n",
      "29280\n",
      "17940\n",
      "17940\n",
      "31200\n",
      "31200\n",
      "32940\n",
      "32940\n",
      "31800\n",
      "31800\n",
      "27000\n",
      "27000\n",
      "24960\n",
      "24960\n",
      "30240\n",
      "30240\n",
      "23760\n",
      "23760\n",
      "23820\n",
      "23820\n",
      "32580\n",
      "32580\n",
      "16200\n",
      "16200\n",
      "46740\n",
      "46740\n",
      "31080\n",
      "31080\n",
      "32400\n",
      "32400\n",
      "38220\n",
      "38220\n",
      "41280\n",
      "41280\n",
      "18540\n",
      "18540\n",
      "24720\n",
      "24720\n",
      "36960\n",
      "36960\n",
      "22140\n",
      "22140\n",
      "16800\n",
      "16800\n",
      "46440\n",
      "46440\n",
      "16860\n",
      "16860\n",
      "31320\n",
      "31320\n",
      "36480\n",
      "36480\n",
      "28680\n",
      "28680\n",
      "30900\n",
      "30900\n",
      "32040\n",
      "32040\n",
      "28500\n",
      "28500\n",
      "30120\n",
      "30120\n",
      "49560\n",
      "49560\n",
      "30840\n",
      "30840\n",
      "34980\n",
      "34980\n",
      "20280\n",
      "20280\n",
      "21840\n",
      "21840\n",
      "33960\n",
      "33960\n",
      "31140\n",
      "31140\n",
      "25200\n",
      "25200\n",
      "47760\n",
      "47760\n",
      "48000\n",
      "48000\n",
      "30480\n",
      "30480\n",
      "31440\n",
      "31440\n",
      "37680\n",
      "37680\n",
      "34560\n",
      "34560\n",
      "51600\n",
      "51600\n",
      "35940\n",
      "35940\n",
      "15900\n",
      "15900\n",
      "20280\n",
      "20280\n"
     ]
    }
   ],
   "source": [
    "import mido\n",
    "for i in range(len(test_intro)):\n",
    "    intro = mido.MidiFile(dissimilar_interpolation + \"/intro/\" + '/intro' + str(i) + '.mid')\n",
    "    outro = mido.MidiFile(dissimilar_interpolation + \"/outro/\" +'/outro' + str(i) + '.mid')\n",
    "    predict = mido.MidiFile(dissimilar_interpolation + \"/predict/\" +'/predict' + str(i) + '.mid')\n",
    "    total_intro_time = 0\n",
    "    total_solo_time = 0\n",
    "    total_predict_time = 0\n",
    "    for msg in intro.tracks[1]:\n",
    "        if msg.type == \"note_on\":\n",
    "            total_intro_time += msg.time\n",
    "    for msg in predict.tracks[1]:\n",
    "        if msg.type == \"note_on\":\n",
    "            total_predict_time += msg.time\n",
    "            \n",
    "    original_outro_time = 0 + outro.tracks[1][1].time\n",
    "    \n",
    "    print(original_outro_time + total_predict_time + total_intro_time)\n",
    "    predict.tracks[1][1].time += total_intro_time\n",
    "    outro.tracks[1][1].time = original_outro_time + total_predict_time + total_intro_time\n",
    "    print(outro.tracks[1][1].time)\n",
    "    merged_mid = mido.MidiFile()\n",
    "    merged_mid.ticks_per_beat = intro.ticks_per_beat\n",
    "    merged_mid.tracks = intro.tracks + predict.tracks + outro.tracks\n",
    "    merged_mid.save(dissimilar_interpolation + '/merged_predict' + str(i) + '.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchNode(object):\n",
    "    def __init__(self, prev_node, wid, logp, length):\n",
    "        self.prev_node = prev_node\n",
    "        self.wid = wid\n",
    "        self.logp = logp\n",
    "        self.length = length\n",
    "\n",
    "    def eval(self):\n",
    "        return self.logp / float(self.length - 1 + 1e-6)\n",
    "# }}}\n",
    "import copy\n",
    "from heapq import heappush, heappop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2930460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence_beam(model, sentence, german, english, device, max_length=1200,beam_width=2,max_dec_steps=25000):\n",
    "    \n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    tokens = [token.lower() for token in sentence.split(' ')]\n",
    "    # print(tokens)\n",
    "\n",
    "    # sys.exit()\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    eos_token = english.vocab.stoi[\"<eos>\"]\n",
    "    sos_token = english.vocab.stoi[\"<sos>\"]\n",
    "    \n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "    \n",
    "    n_best_list = []\n",
    "    \n",
    "     \n",
    "    #trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "    #first token as input\n",
    "    trg_tensor = torch.LongTensor(outputs).to(device)\n",
    "    \n",
    "    end_nodes = []\n",
    "\n",
    "    #starting node\n",
    "    node = BeamSearchNode(prev_node=None, wid=trg_tensor, logp=0, length=1)\n",
    "\n",
    "    nodes = []\n",
    "\n",
    "    heappush(nodes, (-node.eval(), id(node), node))\n",
    "    n_dec_steps = 0\n",
    "\n",
    "    while True:\n",
    "        # Give up when decoding takes too long\n",
    "        if n_dec_steps > max_dec_steps:\n",
    "            break\n",
    "        \n",
    "        # Fetch the best node\n",
    "        #print([n[2].wid for n in nodes])\n",
    "        score, _, n = heappop(nodes)\n",
    "        decoder_input = n.wid\n",
    "        \n",
    "        if n.wid.item() == eos_token and n.prev_node is not None:\n",
    "            end_nodes.append((score, id(n), n))\n",
    "            # If we reached maximum # of sentences required\n",
    "            if len(end_nodes) >= beam_width:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "   \n",
    "        sequence = [n.wid.item()]\n",
    "        a = n\n",
    "        while a.prev_node is not None:\n",
    "            a = a.prev_node\n",
    "            sequence.append(a.wid.item())\n",
    "        sequence = sequence[::-1] # reverse\n",
    "        \n",
    "        #print(sequence)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, torch.LongTensor(sequence).unsqueeze(1).to(device))\n",
    "        \n",
    "        # Get top-k from this decoded result\n",
    "        topk_log_prob, topk_indexes = torch.topk(output, beam_width)\n",
    "        #print(topk_indexes)\n",
    "        #print(topk_log_prob)\n",
    "        # Then, register new top-k nodes\n",
    "        for new_k in range(beam_width):\n",
    "            decoded_t = topk_indexes[0][0][new_k].view(1) # (1)\n",
    "            logp = topk_log_prob[0][0][new_k].item() # float log probability val\n",
    "\n",
    "            node = BeamSearchNode(prev_node=n,\n",
    "                                  wid=decoded_t,\n",
    "                                  logp=n.logp+logp,\n",
    "                                  length=n.length+1)\n",
    "            heappush(nodes, (-node.eval(), id(node), node))\n",
    "        n_dec_steps += beam_width\n",
    "        #print(n_dec_steps)\n",
    "    # if there are no end_nodes, retrieve best nodes (they are probably truncated)\n",
    "    if len(end_nodes) == 0:\n",
    "        end_nodes = [heappop(nodes) for _ in range(beam_width)]\n",
    "\n",
    "    # Construct sequences from end_nodes\n",
    "    n_best_seq_list = []\n",
    "    for score, _id, n in sorted(end_nodes, key=lambda x: x[0]):\n",
    "        sequence = [n.wid.item()]\n",
    "        # back trace from end node\n",
    "        while n.prev_node is not None:\n",
    "            n = n.prev_node\n",
    "            sequence.append(n.wid.item())\n",
    "        sequence = sequence[::-1] # reverse\n",
    "\n",
    "        n_best_seq_list.append(sequence)\n",
    "\n",
    "\n",
    "    # return n_best_seq_list\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in n_best_seq_list[0]]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocab(vocab, path):\n",
    "    output = open(path, 'wb')\n",
    "    pickle.dump(vocab, output)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vocab(intro_field.vocab, vocab + '/intro_vocab.pkl')\n",
    "save_vocab(solo_field.vocab, vocab + '/solo_vocab.pkl')\n",
    "save_vocab(outro_field.vocab, vocab + '/outro_vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_translate_sentence(model, sentence, german, english, device, max_length=1200):\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    #tokens = [token.lower() for token in sentence.split(' ')]\n",
    "    # print(tokens)\n",
    "\n",
    "    # sys.exit()\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    #tokens.insert(0, german.init_token)\n",
    "    #tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    #text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(sentence).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e97881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    print(len(data))\n",
    "    for example in data:\n",
    "        #print( vars(example))\n",
    "        src = vars(example)[\"intro\"]\n",
    "        trg = vars(example)[\"solo\"]\n",
    "        \n",
    "        src = [int(x) for x in src]\n",
    "        trg = [int(x) for x in trg]\n",
    "        \n",
    "        if len(trg) > 1200 or len(src) > 1200:\n",
    "            continue\n",
    "        \n",
    "        prediction = bleu_translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append(trg)\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running on entire test data takes a while\n",
    "score = bleu(test[1:10], model, intro_field, solo_field, device)\n",
    "print(f\"Bleu score {score * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
