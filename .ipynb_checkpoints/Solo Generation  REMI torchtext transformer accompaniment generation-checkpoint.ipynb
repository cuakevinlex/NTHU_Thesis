{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "022889aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator,ReversibleField\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import remi_utils as utils\n",
    "import twoencodertransformer as kk\n",
    "import pickle\n",
    "source_folder = \"solo_generation_dataset_augmented_mag\"\n",
    "folder = \"dynamic_mag_models/2enc_2nd\"\n",
    "destination_folder = folder + \"/solo_generation_weights\"\n",
    "generated_outputs = folder +  \"/generated_samples\"\n",
    "dissimilar_interpolation = folder + \"/interpolation\"\n",
    "vocab = folder + \"/vocab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "088348f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(destination_folder).mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs).mkdir(parents=True, exist_ok=True)\n",
    "Path(dissimilar_interpolation).mkdir(parents=True, exist_ok=True)\n",
    "Path(vocab).mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/main\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/piano\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/solo\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/piano_predict\").mkdir(parents=True, exist_ok=True)\n",
    "Path(dissimilar_interpolation+\"/intro\").mkdir(parents=True, exist_ok=True)\n",
    "Path(dissimilar_interpolation+\"/outro\").mkdir(parents=True, exist_ok=True)\n",
    "Path(dissimilar_interpolation+\"/predict\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d9b7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "event2word, word2event = pickle.load(open('dictionary_augmented.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "193a1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:1\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "print(dev)\n",
    "device = torch.device(dev)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc28e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields\n",
    "\n",
    "main_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "piano_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "fields = [('main', main_field), ('piano', piano_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='train_torchtext.csv', validation='val_torchtext.csv', test='test_torchtext.csv',\n",
    "                                           format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "BATCH_SIZE = 1\n",
    "train_iter = BucketIterator(train, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.main),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.main),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "test_iter = BucketIterator(test, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.main),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "\n",
    "# Vocabulary\n",
    "\n",
    "main_field.build_vocab(train, min_freq=1)\n",
    "piano_field.build_vocab(train, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300385ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823\n",
      "2171\n",
      "964\n",
      "1720\n",
      "1643\n",
      "906\n",
      "1580\n",
      "709\n",
      "1511\n",
      "1662\n",
      "1920\n",
      "1187\n",
      "1004\n",
      "631\n",
      "1520\n",
      "1442\n",
      "967\n",
      "606\n",
      "1095\n",
      "1828\n",
      "810\n",
      "819\n",
      "1180\n",
      "1284\n",
      "1187\n",
      "1999\n",
      "1420\n",
      "1644\n",
      "1508\n",
      "1026\n",
      "2006\n",
      "1199\n",
      "1252\n",
      "1319\n",
      "1447\n",
      "986\n",
      "2587\n",
      "828\n",
      "1960\n",
      "1798\n",
      "1434\n",
      "1020\n",
      "1026\n",
      "1321\n",
      "1389\n",
      "3668\n",
      "1846\n",
      "1284\n",
      "439\n",
      "1690\n",
      "2627\n",
      "1968\n",
      "1236\n",
      "1723\n",
      "1580\n",
      "1351\n",
      "355\n",
      "929\n",
      "939\n",
      "1502\n",
      "1948\n",
      "1304\n",
      "1763\n",
      "638\n",
      "439\n",
      "3023\n",
      "541\n",
      "1375\n",
      "2504\n",
      "1656\n",
      "1509\n",
      "1303\n",
      "1350\n",
      "1524\n",
      "1014\n",
      "1546\n",
      "940\n",
      "1319\n",
      "2120\n",
      "739\n",
      "1429\n",
      "1438\n",
      "638\n",
      "1447\n",
      "1113\n",
      "1250\n",
      "1309\n",
      "1070\n",
      "1558\n",
      "541\n",
      "577\n",
      "784\n",
      "1876\n",
      "1080\n",
      "858\n",
      "1750\n",
      "819\n",
      "2006\n",
      "739\n",
      "2639\n",
      "1684\n",
      "1111\n",
      "914\n",
      "2619\n",
      "1462\n",
      "1216\n",
      "2146\n",
      "2094\n",
      "672\n",
      "986\n",
      "1509\n",
      "1776\n",
      "1071\n",
      "868\n",
      "556\n",
      "3528\n",
      "1004\n",
      "1928\n",
      "979\n",
      "1856\n",
      "1855\n",
      "1598\n",
      "1502\n",
      "1166\n",
      "1264\n",
      "1520\n",
      "1993\n",
      "969\n",
      "1014\n",
      "1211\n",
      "858\n",
      "1720\n",
      "1442\n",
      "1789\n",
      "1743\n",
      "1960\n",
      "1111\n",
      "1082\n",
      "1322\n",
      "1439\n",
      "1558\n",
      "2627\n",
      "1059\n",
      "638\n",
      "3163\n",
      "1422\n",
      "891\n",
      "1631\n",
      "2023\n",
      "1374\n",
      "509\n",
      "726\n",
      "854\n",
      "1020\n",
      "1194\n",
      "868\n",
      "2293\n",
      "931\n",
      "1765\n",
      "1935\n",
      "1163\n",
      "800\n",
      "546\n",
      "1350\n",
      "2032\n",
      "1026\n",
      "1715\n",
      "1250\n",
      "2619\n",
      "1366\n",
      "1534\n",
      "1171\n",
      "1024\n",
      "1337\n",
      "467\n",
      "1443\n",
      "1379\n",
      "1014\n",
      "1303\n",
      "1765\n",
      "541\n",
      "898\n",
      "1026\n",
      "1765\n",
      "1802\n",
      "1731\n",
      "930\n",
      "657\n",
      "1935\n",
      "1343\n",
      "895\n",
      "1963\n",
      "2067\n",
      "509\n",
      "825\n",
      "637\n",
      "439\n",
      "1978\n",
      "1180\n",
      "1654\n",
      "1690\n",
      "1216\n",
      "546\n",
      "2278\n",
      "831\n",
      "1547\n",
      "1647\n",
      "1116\n",
      "2006\n",
      "946\n",
      "1569\n",
      "770\n",
      "1542\n",
      "1443\n",
      "1166\n",
      "657\n",
      "1314\n",
      "1720\n",
      "1545\n",
      "814\n",
      "1456\n",
      "1662\n",
      "1504\n",
      "1442\n",
      "1508\n",
      "1134\n",
      "1207\n",
      "657\n",
      "1774\n",
      "1503\n",
      "1084\n",
      "1001\n",
      "878\n",
      "1932\n",
      "1187\n",
      "633\n",
      "1434\n",
      "574\n",
      "562\n",
      "858\n",
      "1113\n",
      "2792\n",
      "2067\n",
      "709\n",
      "2000\n",
      "2639\n",
      "837\n",
      "836\n",
      "1684\n",
      "967\n",
      "1548\n",
      "2117\n",
      "1802\n",
      "1376\n",
      "1000\n",
      "1183\n",
      "2395\n",
      "1108\n",
      "1394\n",
      "1207\n",
      "1950\n",
      "804\n",
      "1122\n",
      "1374\n",
      "821\n",
      "973\n",
      "2879\n",
      "1334\n",
      "1676\n",
      "727\n",
      "546\n",
      "1389\n",
      "858\n",
      "1212\n",
      "1092\n",
      "1855\n",
      "932\n",
      "1817\n",
      "3038\n",
      "1524\n",
      "939\n",
      "1543\n",
      "1543\n",
      "1019\n",
      "1720\n",
      "1676\n",
      "825\n",
      "1176\n",
      "323\n",
      "1515\n",
      "1743\n",
      "1304\n",
      "2017\n",
      "1830\n",
      "1166\n",
      "1350\n",
      "1539\n",
      "789\n",
      "1033\n",
      "1059\n",
      "2026\n",
      "1084\n",
      "1304\n",
      "439\n",
      "816\n",
      "1353\n",
      "1252\n",
      "1020\n",
      "1783\n",
      "838\n",
      "1187\n",
      "1135\n",
      "798\n",
      "1278\n",
      "2627\n",
      "1673\n",
      "1956\n",
      "1020\n",
      "1353\n",
      "804\n",
      "1124\n",
      "828\n",
      "730\n",
      "754\n",
      "622\n",
      "1811\n",
      "1534\n",
      "1309\n",
      "1508\n",
      "2792\n",
      "1595\n",
      "1252\n",
      "1662\n",
      "1113\n",
      "1135\n",
      "1502\n",
      "1770\n",
      "1144\n",
      "1439\n",
      "682\n",
      "886\n",
      "1993\n",
      "1439\n",
      "967\n",
      "929\n",
      "1791\n",
      "1569\n",
      "3163\n",
      "828\n",
      "1037\n",
      "1284\n",
      "1595\n",
      "970\n",
      "705\n",
      "1543\n",
      "798\n",
      "979\n",
      "3783\n",
      "839\n",
      "878\n",
      "789\n",
      "2332\n",
      "834\n",
      "967\n",
      "1798\n",
      "2879\n",
      "1320\n",
      "1508\n",
      "891\n",
      "839\n",
      "1351\n",
      "1746\n",
      "898\n",
      "819\n",
      "825\n",
      "1383\n",
      "1284\n",
      "1846\n",
      "1545\n",
      "3783\n",
      "1542\n",
      "1789\n",
      "825\n",
      "1275\n",
      "1313\n",
      "2892\n",
      "1504\n",
      "993\n",
      "940\n",
      "789\n",
      "1543\n",
      "1029\n",
      "1047\n",
      "1030\n",
      "1603\n",
      "899\n",
      "2288\n",
      "509\n",
      "1443\n",
      "1831\n",
      "1250\n",
      "2193\n",
      "1478\n",
      "943\n",
      "828\n",
      "2120\n",
      "1070\n",
      "2171\n",
      "1174\n",
      "1141\n",
      "1284\n",
      "1817\n",
      "554\n",
      "1029\n",
      "2628\n",
      "1307\n",
      "1355\n",
      "1928\n",
      "1712\n",
      "1723\n",
      "1715\n",
      "853\n",
      "1529\n",
      "1542\n",
      "1322\n",
      "1511\n",
      "637\n",
      "942\n",
      "1932\n",
      "1548\n",
      "730\n",
      "974\n",
      "1967\n",
      "1547\n",
      "986\n",
      "2090\n",
      "1116\n",
      "1420\n",
      "1082\n",
      "905\n",
      "1630\n",
      "1566\n",
      "1470\n",
      "2067\n",
      "1580\n",
      "2146\n",
      "1134\n",
      "1383\n",
      "1091\n",
      "1047\n",
      "886\n",
      "1651\n",
      "1166\n",
      "1478\n",
      "1046\n",
      "1343\n",
      "821\n",
      "2293\n",
      "822\n",
      "1033\n",
      "754\n",
      "1296\n",
      "1496\n",
      "1919\n",
      "946\n",
      "1047\n",
      "1483\n",
      "1324\n",
      "1178\n",
      "874\n",
      "589\n",
      "574\n",
      "836\n",
      "1892\n",
      "1720\n",
      "2146\n",
      "1216\n",
      "1750\n",
      "1743\n",
      "1307\n",
      "1086\n",
      "1595\n",
      "1546\n",
      "2067\n",
      "682\n",
      "1095\n",
      "1691\n",
      "1543\n",
      "939\n",
      "1598\n",
      "1443\n",
      "1376\n",
      "1313\n",
      "906\n",
      "1039\n",
      "3827\n",
      "1935\n",
      "1580\n",
      "914\n",
      "1768\n",
      "1264\n",
      "1723\n",
      "633\n",
      "864\n",
      "943\n",
      "1927\n",
      "1422\n",
      "1422\n",
      "1890\n",
      "1830\n",
      "940\n",
      "657\n",
      "1543\n",
      "637\n",
      "556\n",
      "2026\n",
      "1317\n",
      "1039\n",
      "2151\n",
      "898\n",
      "986\n",
      "906\n",
      "1070\n",
      "1776\n",
      "1718\n",
      "1187\n",
      "878\n",
      "1039\n",
      "1404\n",
      "831\n",
      "1171\n",
      "638\n",
      "834\n",
      "549\n",
      "631\n",
      "1098\n",
      "1334\n",
      "1271\n",
      "1557\n",
      "1978\n",
      "1919\n",
      "1335\n",
      "1830\n",
      "1892\n",
      "739\n",
      "2000\n",
      "1799\n",
      "1724\n",
      "1248\n",
      "1001\n",
      "986\n",
      "864\n",
      "1207\n",
      "1105\n",
      "1033\n",
      "1456\n",
      "1351\n",
      "2395\n",
      "1439\n",
      "1307\n",
      "793\n",
      "1557\n",
      "589\n",
      "1355\n",
      "1511\n",
      "1594\n",
      "3005\n",
      "1508\n",
      "2288\n",
      "859\n",
      "1322\n",
      "1166\n",
      "2288\n",
      "836\n",
      "467\n",
      "2026\n",
      "1660\n",
      "1015\n",
      "1638\n",
      "2116\n",
      "1566\n",
      "1183\n",
      "1831\n",
      "3023\n",
      "1020\n",
      "2171\n",
      "1047\n",
      "1297\n",
      "1799\n",
      "2112\n",
      "2088\n",
      "1941\n",
      "1303\n",
      "802\n",
      "1010\n",
      "793\n",
      "1026\n",
      "1594\n",
      "1365\n",
      "592\n",
      "1546\n",
      "3023\n",
      "1030\n",
      "3827\n",
      "1335\n",
      "1638\n",
      "1572\n",
      "1059\n",
      "1061\n",
      "1037\n",
      "1542\n",
      "1543\n",
      "637\n",
      "1968\n",
      "1524\n",
      "1246\n",
      "1274\n",
      "1462\n",
      "1246\n",
      "858\n",
      "1746\n",
      "1496\n",
      "1634\n",
      "1534\n",
      "2151\n",
      "1443\n",
      "1920\n",
      "1010\n",
      "1095\n",
      "878\n",
      "1993\n",
      "1070\n",
      "631\n",
      "1283\n",
      "1941\n",
      "1420\n",
      "746\n",
      "1211\n",
      "1447\n",
      "2598\n",
      "758\n",
      "1937\n",
      "1319\n",
      "1543\n",
      "1419\n",
      "1502\n",
      "2075\n",
      "2112\n",
      "1545\n",
      "1644\n",
      "1644\n",
      "1264\n",
      "1633\n",
      "323\n",
      "709\n",
      "1920\n",
      "1061\n",
      "1543\n",
      "1183\n",
      "1020\n",
      "1978\n",
      "1004\n",
      "1998\n",
      "821\n",
      "1351\n",
      "606\n",
      "1046\n",
      "1307\n",
      "2379\n",
      "838\n",
      "953\n",
      "787\n",
      "1046\n",
      "1876\n",
      "1577\n",
      "1684\n",
      "1435\n",
      "1543\n",
      "1459\n",
      "986\n",
      "784\n",
      "1509\n",
      "1502\n",
      "2379\n",
      "2628\n",
      "687\n",
      "1459\n",
      "789\n",
      "1351\n",
      "355\n",
      "2379\n",
      "664\n",
      "1660\n",
      "1395\n",
      "1468\n",
      "1003\n",
      "3005\n",
      "906\n",
      "1296\n",
      "819\n",
      "1539\n",
      "1470\n",
      "1099\n",
      "1456\n",
      "843\n",
      "1673\n",
      "967\n",
      "1478\n",
      "323\n",
      "1850\n",
      "1478\n",
      "1763\n",
      "934\n",
      "1890\n",
      "1103\n",
      "1047\n",
      "709\n",
      "1529\n",
      "2193\n",
      "1443\n",
      "1536\n",
      "868\n",
      "1684\n",
      "1841\n",
      "1297\n",
      "1003\n",
      "1425\n",
      "2088\n",
      "1194\n",
      "1283\n",
      "1250\n",
      "1324\n",
      "1046\n",
      "592\n",
      "1080\n",
      "1178\n",
      "1536\n",
      "891\n",
      "1246\n",
      "1176\n",
      "1091\n",
      "1691\n",
      "955\n",
      "3044\n",
      "1468\n",
      "2041\n",
      "574\n",
      "1019\n",
      "1978\n",
      "1015\n",
      "1546\n",
      "637\n",
      "1572\n",
      "1200\n",
      "1724\n",
      "1030\n",
      "1751\n",
      "2087\n",
      "1572\n",
      "1395\n",
      "562\n",
      "1470\n",
      "1015\n",
      "1317\n",
      "1572\n",
      "1828\n",
      "1690\n",
      "1438\n",
      "1876\n",
      "914\n",
      "1010\n",
      "836\n",
      "588\n",
      "853\n",
      "1297\n",
      "970\n",
      "1033\n",
      "1647\n",
      "828\n",
      "934\n",
      "1538\n",
      "1798\n",
      "672\n",
      "953\n",
      "1543\n",
      "3163\n",
      "1135\n",
      "1250\n",
      "2628\n",
      "974\n",
      "2418\n",
      "606\n",
      "943\n",
      "949\n",
      "864\n",
      "1967\n",
      "1900\n",
      "1750\n",
      "1174\n",
      "1750\n",
      "1337\n",
      "2075\n",
      "1789\n",
      "964\n",
      "798\n",
      "1577\n",
      "2474\n",
      "969\n",
      "1275\n",
      "1313\n",
      "836\n",
      "2094\n",
      "2120\n",
      "664\n",
      "1113\n",
      "967\n",
      "1147\n",
      "784\n",
      "1099\n",
      "1459\n",
      "883\n",
      "355\n",
      "1443\n",
      "1566\n",
      "787\n",
      "831\n",
      "859\n",
      "2023\n",
      "730\n",
      "1250\n",
      "3668\n",
      "2307\n",
      "1950\n",
      "1307\n",
      "1817\n",
      "1799\n",
      "1768\n",
      "2456\n",
      "1765\n",
      "1366\n",
      "3668\n",
      "1631\n",
      "1275\n",
      "1296\n",
      "2418\n",
      "1607\n",
      "1343\n",
      "967\n",
      "845\n",
      "1798\n",
      "1943\n",
      "1509\n",
      "549\n",
      "1180\n",
      "822\n",
      "745\n",
      "1841\n",
      "1598\n",
      "899\n",
      "1509\n",
      "1712\n",
      "1607\n",
      "874\n",
      "1838\n",
      "1039\n",
      "931\n",
      "839\n",
      "1607\n",
      "923\n",
      "1046\n",
      "1274\n",
      "1046\n",
      "606\n",
      "2146\n",
      "1543\n",
      "602\n",
      "546\n",
      "2120\n",
      "1927\n",
      "1634\n",
      "2504\n",
      "745\n",
      "541\n",
      "2861\n",
      "1566\n",
      "1108\n",
      "1171\n",
      "1838\n",
      "1092\n",
      "1439\n",
      "1020\n",
      "942\n",
      "1010\n",
      "946\n",
      "1399\n",
      "2307\n",
      "1751\n",
      "1098\n",
      "2892\n",
      "1789\n",
      "1098\n",
      "2006\n",
      "1459\n",
      "589\n",
      "1456\n",
      "2504\n",
      "1086\n",
      "1811\n",
      "1419\n",
      "1890\n",
      "1395\n",
      "1830\n",
      "1059\n",
      "664\n",
      "1019\n",
      "754\n",
      "1524\n",
      "2627\n",
      "1307\n",
      "946\n",
      "646\n",
      "1297\n",
      "1075\n",
      "810\n",
      "1637\n",
      "1207\n",
      "906\n",
      "1919\n",
      "1473\n",
      "1937\n",
      "1086\n",
      "1374\n",
      "1637\n",
      "1462\n",
      "895\n",
      "3005\n",
      "1171\n",
      "986\n",
      "1337\n",
      "1647\n",
      "1483\n",
      "1166\n",
      "930\n",
      "1638\n",
      "1013\n",
      "1630\n",
      "323\n",
      "1425\n",
      "953\n",
      "914\n",
      "1183\n",
      "2026\n",
      "1456\n",
      "1439\n",
      "1098\n",
      "1817\n",
      "1246\n",
      "1484\n",
      "1960\n",
      "2395\n",
      "1422\n",
      "1003\n",
      "1061\n",
      "2278\n",
      "1644\n",
      "1557\n",
      "1673\n",
      "1093\n",
      "1841\n",
      "1542\n",
      "1141\n",
      "1026\n",
      "1237\n",
      "1456\n",
      "834\n",
      "1502\n",
      "1776\n",
      "2332\n",
      "1456\n",
      "986\n",
      "1999\n",
      "1322\n",
      "1235\n",
      "1086\n",
      "1004\n",
      "1763\n",
      "650\n",
      "1802\n",
      "1473\n",
      "1937\n",
      "1462\n",
      "1318\n",
      "1271\n",
      "784\n",
      "1643\n",
      "1932\n",
      "1673\n",
      "2000\n",
      "3023\n",
      "637\n",
      "2699\n",
      "602\n",
      "955\n",
      "3827\n",
      "1274\n",
      "745\n",
      "1134\n",
      "1718\n",
      "1092\n",
      "1723\n",
      "577\n",
      "1509\n",
      "754\n",
      "709\n",
      "1569\n",
      "1335\n",
      "549\n",
      "802\n",
      "1660\n",
      "1015\n",
      "2293\n",
      "323\n",
      "1417\n",
      "794\n",
      "1199\n",
      "928\n",
      "1799\n",
      "2090\n",
      "1199\n",
      "2379\n",
      "798\n",
      "1443\n",
      "1004\n",
      "1026\n",
      "1419\n",
      "1720\n",
      "1520\n",
      "1371\n",
      "1236\n",
      "1442\n",
      "1216\n",
      "745\n",
      "1167\n",
      "1030\n",
      "2087\n",
      "1447\n",
      "1099\n",
      "1435\n",
      "930\n",
      "1443\n",
      "883\n",
      "941\n",
      "1166\n",
      "2429\n",
      "1199\n",
      "852\n",
      "1823\n",
      "1383\n",
      "589\n",
      "1171\n",
      "814\n",
      "1323\n",
      "836\n",
      "1199\n",
      "1166\n",
      "986\n",
      "1935\n",
      "1835\n",
      "1609\n",
      "1799\n",
      "1303\n",
      "1321\n",
      "1320\n",
      "1329\n",
      "1144\n",
      "1061\n",
      "1366\n",
      "1434\n",
      "1920\n",
      "1828\n",
      "886\n",
      "396\n",
      "789\n",
      "1236\n",
      "1304\n",
      "1422\n",
      "3038\n",
      "930\n",
      "2699\n",
      "589\n",
      "1470\n",
      "633\n",
      "1264\n",
      "1447\n",
      "1171\n",
      "787\n",
      "1337\n",
      "1558\n",
      "1838\n",
      "1093\n",
      "1059\n",
      "845\n",
      "986\n",
      "964\n",
      "1296\n",
      "1380\n",
      "1542\n",
      "1538\n",
      "1350\n",
      "1004\n",
      "1103\n",
      "914\n",
      "1366\n",
      "1207\n",
      "1643\n",
      "727\n",
      "1166\n",
      "1324\n",
      "2117\n",
      "1026\n",
      "650\n",
      "828\n",
      "932\n",
      "1478\n",
      "2116\n",
      "1691\n",
      "606\n",
      "1799\n",
      "928\n",
      "1163\n",
      "705\n",
      "804\n",
      "854\n",
      "934\n",
      "1542\n",
      "1543\n",
      "1166\n",
      "843\n",
      "1509\n",
      "788\n",
      "1376\n",
      "2598\n",
      "1166\n",
      "726\n",
      "622\n",
      "637\n",
      "1508\n",
      "726\n",
      "2628\n",
      "1438\n",
      "1303\n",
      "1524\n",
      "1637\n",
      "3163\n",
      "1366\n",
      "1379\n",
      "1783\n",
      "1303\n",
      "2398\n",
      "1013\n",
      "1371\n",
      "2031\n",
      "550\n",
      "1307\n",
      "1091\n",
      "1558\n",
      "1539\n",
      "1503\n",
      "1776\n",
      "1379\n",
      "1743\n",
      "1890\n",
      "1941\n",
      "1013\n",
      "1059\n",
      "1001\n",
      "852\n",
      "931\n",
      "955\n",
      "1313\n",
      "1478\n",
      "554\n",
      "1135\n",
      "1059\n",
      "1631\n",
      "1731\n",
      "664\n",
      "1047\n",
      "1355\n",
      "2000\n",
      "1024\n",
      "1313\n",
      "1383\n",
      "577\n",
      "1919\n",
      "1545\n",
      "1399\n",
      "1099\n",
      "2112\n",
      "1171\n",
      "1439\n",
      "1968\n",
      "1978\n",
      "1468\n",
      "1503\n",
      "1456\n",
      "945\n",
      "864\n",
      "793\n",
      "1723\n",
      "1524\n",
      "1572\n",
      "1248\n",
      "1439\n",
      "1319\n",
      "1250\n",
      "1047\n",
      "1113\n",
      "1417\n",
      "973\n",
      "1108\n",
      "1380\n",
      "1456\n",
      "1004\n",
      "1468\n",
      "1199\n",
      "1237\n",
      "1543\n",
      "1387\n",
      "2031\n",
      "1376\n",
      "2332\n",
      "1059\n",
      "905\n",
      "1033\n",
      "1900\n",
      "1684\n",
      "636\n",
      "1320\n",
      "1174\n",
      "1660\n",
      "804\n",
      "1835\n",
      "637\n",
      "1420\n",
      "816\n",
      "1389\n",
      "1920\n",
      "1768\n",
      "1763\n",
      "1071\n",
      "1353\n",
      "967\n",
      "1116\n",
      "1765\n",
      "2288\n",
      "631\n",
      "1509\n",
      "804\n",
      "1520\n",
      "1166\n",
      "1039\n",
      "1892\n",
      "1375\n",
      "1355\n",
      "1313\n",
      "986\n",
      "1297\n",
      "1030\n",
      "945\n",
      "886\n",
      "1387\n",
      "1374\n",
      "1577\n",
      "2429\n",
      "739\n",
      "3005\n",
      "1547\n",
      "874\n",
      "2398\n",
      "1580\n",
      "1144\n",
      "1470\n",
      "843\n",
      "1855\n",
      "914\n",
      "1010\n",
      "974\n",
      "804\n",
      "2151\n",
      "1383\n",
      "2087\n",
      "1660\n",
      "1144\n",
      "1557\n",
      "1447\n",
      "945\n",
      "2094\n",
      "942\n",
      "2699\n",
      "1548\n",
      "788\n",
      "1558\n",
      "1770\n",
      "1030\n",
      "993\n",
      "2474\n",
      "1838\n",
      "1178\n",
      "1167\n",
      "2278\n",
      "1099\n",
      "1529\n",
      "1673\n",
      "3528\n",
      "934\n",
      "727\n",
      "1147\n",
      "2879\n",
      "1343\n",
      "1039\n",
      "899\n",
      "1387\n",
      "1323\n",
      "1284\n",
      "1317\n",
      "1435\n",
      "1026\n",
      "657\n",
      "1763\n",
      "682\n",
      "2429\n",
      "1375\n",
      "1548\n",
      "1084\n",
      "1010\n",
      "1656\n",
      "1236\n",
      "2193\n",
      "1278\n",
      "1216\n",
      "754\n",
      "1783\n",
      "949\n",
      "3528\n",
      "2307\n",
      "2278\n",
      "1447\n",
      "1322\n",
      "946\n",
      "1313\n",
      "355\n",
      "1422\n",
      "1956\n",
      "798\n",
      "2619\n",
      "1307\n",
      "1375\n",
      "2170\n",
      "1303\n",
      "1061\n",
      "2088\n",
      "906\n",
      "2087\n",
      "970\n",
      "650\n",
      "829\n",
      "770\n",
      "2628\n",
      "1817\n",
      "895\n",
      "1993\n",
      "1456\n",
      "1278\n",
      "1644\n",
      "577\n",
      "868\n",
      "1355\n",
      "2598\n",
      "923\n",
      "1547\n",
      "1811\n",
      "2000\n",
      "1284\n",
      "1956\n",
      "1838\n",
      "836\n",
      "931\n",
      "1470\n",
      "622\n",
      "1010\n",
      "646\n",
      "800\n",
      "1483\n",
      "1956\n",
      "1024\n",
      "1508\n",
      "546\n",
      "1447\n",
      "1534\n",
      "2418\n",
      "1846\n",
      "1395\n",
      "1084\n",
      "1937\n",
      "2026\n",
      "1594\n",
      "1250\n",
      "843\n",
      "973\n",
      "1376\n",
      "1919\n",
      "1566\n",
      "1543\n",
      "1093\n",
      "1948\n",
      "1798\n",
      "2193\n",
      "1071\n",
      "878\n",
      "1638\n",
      "970\n",
      "931\n",
      "1543\n",
      "1211\n",
      "1594\n",
      "530\n",
      "1376\n",
      "1633\n",
      "637\n",
      "986\n",
      "1941\n",
      "1462\n",
      "1509\n",
      "1751\n",
      "1838\n",
      "2504\n",
      "945\n",
      "1631\n",
      "930\n",
      "854\n",
      "650\n",
      "1351\n",
      "2120\n",
      "1470\n",
      "1014\n",
      "1046\n",
      "636\n",
      "1022\n",
      "1313\n",
      "1790\n",
      "1548\n",
      "1235\n",
      "1948\n",
      "1557\n",
      "1212\n",
      "1718\n",
      "682\n",
      "1638\n",
      "1105\n",
      "2395\n",
      "1731\n",
      "729\n",
      "1343\n",
      "1443\n",
      "730\n",
      "1046\n",
      "1124\n",
      "1546\n",
      "3452\n",
      "836\n",
      "1283\n",
      "1103\n",
      "1039\n",
      "1846\n",
      "1774\n",
      "1743\n",
      "1539\n",
      "1828\n",
      "814\n",
      "1774\n",
      "1047\n",
      "1763\n",
      "1509\n",
      "853\n",
      "1324\n",
      "837\n",
      "1960\n",
      "942\n",
      "1971\n",
      "592\n",
      "2398\n",
      "802\n",
      "1473\n",
      "895\n",
      "1720\n",
      "1459\n",
      "1998\n",
      "838\n",
      "672\n",
      "1496\n",
      "1019\n",
      "816\n",
      "940\n",
      "1724\n",
      "2041\n",
      "1309\n",
      "967\n",
      "2193\n",
      "1515\n",
      "810\n",
      "1429\n",
      "1092\n",
      "1718\n",
      "931\n",
      "1515\n",
      "993\n",
      "1841\n",
      "1746\n",
      "1690\n",
      "682\n",
      "914\n",
      "2031\n",
      "1383\n",
      "1122\n",
      "869\n",
      "793\n",
      "2067\n",
      "1439\n",
      "1113\n",
      "2619\n",
      "1927\n",
      "1855\n",
      "1654\n",
      "1404\n",
      "1374\n",
      "1557\n",
      "895\n",
      "837\n",
      "1978\n",
      "1194\n",
      "1379\n",
      "974\n",
      "794\n",
      "1039\n",
      "928\n",
      "3452\n",
      "1900\n",
      "1509\n",
      "1637\n",
      "1320\n",
      "1323\n",
      "1303\n",
      "705\n",
      "622\n",
      "636\n",
      "2000\n",
      "1144\n",
      "1856\n",
      "819\n",
      "1720\n",
      "1141\n",
      "1046\n",
      "770\n",
      "646\n",
      "1093\n",
      "1231\n",
      "1420\n",
      "1511\n",
      "1948\n",
      "967\n",
      "1774\n",
      "1319\n",
      "2075\n",
      "1383\n",
      "1927\n",
      "1856\n",
      "3452\n",
      "798\n",
      "1105\n",
      "858\n",
      "838\n",
      "1180\n",
      "967\n",
      "864\n",
      "2379\n",
      "829\n",
      "1484\n",
      "914\n",
      "1609\n",
      "1828\n",
      "1000\n",
      "828\n",
      "986\n",
      "1631\n",
      "1892\n",
      "1313\n",
      "1690\n",
      "1166\n",
      "574\n",
      "1609\n",
      "931\n",
      "759\n",
      "1543\n",
      "1187\n",
      "923\n",
      "788\n",
      "853\n",
      "829\n",
      "1799\n",
      "1960\n",
      "973\n",
      "1543\n",
      "2193\n",
      "1194\n",
      "864\n",
      "821\n",
      "1029\n",
      "746\n",
      "1496\n",
      "1113\n",
      "1644\n",
      "1318\n",
      "1725\n",
      "852\n",
      "2075\n",
      "2023\n",
      "1029\n",
      "923\n",
      "1374\n",
      "1998\n",
      "2307\n",
      "2116\n",
      "969\n",
      "549\n",
      "1831\n",
      "1389\n",
      "1003\n",
      "1183\n",
      "1116\n",
      "953\n",
      "1015\n",
      "886\n",
      "1004\n",
      "831\n",
      "672\n",
      "1802\n",
      "664\n",
      "906\n",
      "439\n",
      "1422\n",
      "941\n",
      "1798\n",
      "2120\n",
      "1194\n",
      "1557\n",
      "1395\n",
      "1284\n",
      "1321\n",
      "810\n",
      "1835\n",
      "853\n",
      "940\n",
      "899\n",
      "745\n",
      "1313\n",
      "858\n",
      "1633\n",
      "1425\n",
      "757\n",
      "1439\n",
      "1303\n",
      "1323\n",
      "1314\n",
      "2170\n",
      "869\n",
      "646\n",
      "1511\n",
      "1504\n",
      "1963\n",
      "1113\n",
      "1026\n",
      "1633\n",
      "1515\n",
      "969\n",
      "1124\n",
      "1374\n",
      "1429\n",
      "819\n",
      "1334\n",
      "1577\n",
      "1246\n",
      "986\n",
      "3038\n",
      "1376\n",
      "819\n",
      "1798\n",
      "931\n",
      "2032\n",
      "1039\n",
      "3783\n",
      "973\n",
      "784\n",
      "1404\n",
      "2088\n",
      "1718\n",
      "1656\n",
      "1246\n",
      "1237\n",
      "1095\n",
      "1725\n",
      "1770\n",
      "1399\n",
      "1013\n",
      "1509\n",
      "1609\n",
      "942\n",
      "1483\n",
      "1644\n",
      "1603\n",
      "1660\n",
      "1935\n",
      "1004\n",
      "1534\n",
      "1712\n",
      "1422\n",
      "800\n",
      "2288\n",
      "1743\n",
      "1187\n",
      "1275\n",
      "816\n",
      "859\n",
      "2193\n",
      "905\n",
      "672\n",
      "439\n",
      "1351\n",
      "1376\n",
      "1789\n",
      "838\n",
      "852\n",
      "687\n",
      "1463\n",
      "530\n",
      "1715\n",
      "2598\n",
      "759\n",
      "637\n",
      "1271\n",
      "1644\n",
      "800\n",
      "1609\n",
      "1059\n",
      "577\n",
      "905\n",
      "1278\n",
      "798\n",
      "1542\n",
      "2398\n",
      "730\n",
      "1447\n",
      "2023\n",
      "3044\n",
      "602\n",
      "1355\n",
      "3163\n",
      "819\n",
      "1296\n",
      "1483\n",
      "1389\n",
      "729\n",
      "1203\n",
      "932\n",
      "1135\n",
      "969\n",
      "1420\n",
      "1322\n",
      "1212\n",
      "979\n",
      "3668\n",
      "1075\n",
      "942\n",
      "562\n",
      "1470\n",
      "1768\n",
      "467\n",
      "1061\n",
      "1691\n",
      "1463\n",
      "682\n",
      "1183\n",
      "1000\n",
      "834\n",
      "1536\n",
      "1371\n",
      "1547\n",
      "1084\n",
      "973\n",
      "1725\n",
      "1774\n",
      "1108\n",
      "1802\n",
      "1543\n",
      "729\n",
      "2627\n",
      "1004\n",
      "1307\n",
      "1015\n",
      "1141\n",
      "3005\n",
      "1200\n",
      "794\n",
      "1235\n",
      "592\n",
      "1463\n",
      "810\n",
      "439\n",
      "2892\n",
      "1024\n",
      "1577\n",
      "2699\n",
      "1116\n",
      "979\n",
      "1103\n",
      "955\n",
      "868\n",
      "967\n",
      "1351\n",
      "1026\n",
      "854\n",
      "1943\n",
      "1529\n",
      "2456\n",
      "2379\n",
      "1248\n",
      "1024\n",
      "1566\n",
      "1013\n",
      "745\n",
      "1309\n",
      "2792\n",
      "1374\n",
      "1235\n",
      "1478\n",
      "1478\n",
      "1071\n",
      "556\n",
      "1015\n",
      "1956\n",
      "1660\n",
      "1691\n",
      "3023\n",
      "1116\n",
      "1187\n",
      "1371\n",
      "746\n",
      "759\n",
      "1841\n",
      "1447\n",
      "1504\n",
      "836\n",
      "1212\n",
      "1379\n",
      "1274\n",
      "1075\n",
      "1470\n",
      "1651\n",
      "1817\n",
      "1435\n",
      "1634\n",
      "1831\n",
      "828\n",
      "1538\n",
      "1380\n",
      "439\n",
      "986\n",
      "2861\n",
      "845\n",
      "2927\n",
      "845\n",
      "1180\n",
      "1542\n",
      "1203\n",
      "1447\n",
      "1971\n",
      "1515\n",
      "993\n",
      "973\n",
      "1020\n",
      "1004\n",
      "1250\n",
      "1383\n",
      "3528\n",
      "932\n",
      "1545\n",
      "1075\n",
      "931\n",
      "1542\n",
      "974\n",
      "2474\n",
      "530\n",
      "973\n",
      "1542\n",
      "1751\n",
      "1502\n",
      "3005\n",
      "1355\n",
      "1963\n",
      "3023\n",
      "2087\n",
      "1404\n",
      "1284\n",
      "1835\n",
      "1937\n",
      "1690\n",
      "1543\n",
      "822\n",
      "2087\n",
      "754\n",
      "1473\n",
      "1502\n",
      "2146\n",
      "1644\n",
      "3783\n",
      "1000\n",
      "1026\n",
      "1422\n",
      "1174\n",
      "1001\n",
      "993\n",
      "588\n",
      "1811\n",
      "2171\n",
      "986\n",
      "946\n",
      "2456\n",
      "1387\n",
      "798\n",
      "1774\n",
      "1647\n",
      "1607\n",
      "1971\n",
      "2171\n",
      "2332\n",
      "396\n",
      "1542\n",
      "1503\n",
      "1425\n",
      "1425\n",
      "1529\n",
      "770\n",
      "727\n",
      "1950\n",
      "2639\n",
      "1610\n",
      "1504\n",
      "1536\n",
      "2023\n",
      "787\n",
      "2117\n",
      "1167\n",
      "1082\n",
      "746\n",
      "1720\n",
      "1212\n",
      "556\n",
      "546\n",
      "2023\n",
      "1456\n",
      "1520\n",
      "843\n",
      "1374\n",
      "1644\n",
      "1603\n",
      "1928\n",
      "1920\n",
      "1211\n",
      "1998\n",
      "1634\n",
      "1271\n",
      "1943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "1654\n",
      "828\n",
      "825\n",
      "1442\n",
      "1176\n",
      "2892\n",
      "1580\n",
      "843\n",
      "979\n",
      "1098\n",
      "1420\n",
      "1776\n",
      "1371\n",
      "1086\n",
      "1559\n",
      "1180\n",
      "828\n",
      "1724\n",
      "589\n",
      "1690\n",
      "636\n",
      "1463\n",
      "1098\n",
      "1890\n",
      "530\n",
      "1799\n",
      "1509\n",
      "970\n",
      "970\n",
      "1798\n",
      "1643\n",
      "1799\n",
      "1022\n",
      "1746\n",
      "1429\n",
      "967\n",
      "838\n",
      "2000\n",
      "1558\n",
      "1468\n",
      "1956\n",
      "705\n",
      "1248\n",
      "1508\n",
      "939\n",
      "2017\n",
      "923\n",
      "1022\n",
      "931\n",
      "2171\n",
      "1731\n",
      "878\n",
      "550\n",
      "2031\n",
      "2792\n",
      "1751\n",
      "1383\n",
      "883\n",
      "1774\n",
      "1690\n",
      "1235\n",
      "1335\n",
      "1941\n",
      "869\n",
      "1314\n",
      "839\n",
      "1304\n",
      "1105\n",
      "931\n",
      "1543\n",
      "1321\n",
      "1791\n",
      "1313\n",
      "1113\n",
      "759\n",
      "1122\n",
      "633\n",
      "1070\n",
      "1968\n",
      "633\n",
      "949\n",
      "1603\n",
      "798\n",
      "1015\n",
      "1503\n",
      "804\n",
      "1422\n",
      "1846\n",
      "1211\n",
      "1098\n",
      "2429\n",
      "804\n",
      "837\n",
      "3827\n",
      "1569\n",
      "1791\n",
      "1355\n",
      "1511\n",
      "955\n",
      "2619\n",
      "1746\n",
      "1319\n",
      "1993\n",
      "1113\n",
      "1765\n",
      "928\n",
      "1520\n",
      "1932\n",
      "787\n",
      "1830\n",
      "2088\n",
      "1720\n",
      "837\n",
      "955\n",
      "1211\n",
      "1508\n",
      "2927\n",
      "1086\n",
      "2094\n",
      "804\n",
      "2151\n",
      "2120\n",
      "2379\n",
      "2429\n",
      "923\n",
      "1082\n",
      "2699\n",
      "1999\n",
      "1187\n",
      "1329\n",
      "606\n",
      "1765\n",
      "1080\n",
      "729\n",
      "714\n",
      "1383\n",
      "1439\n",
      "2429\n",
      "1434\n",
      "2146\n",
      "3044\n",
      "1030\n",
      "2398\n",
      "1538\n",
      "2067\n",
      "1376\n",
      "974\n",
      "1502\n",
      "589\n",
      "1463\n",
      "1539\n",
      "3783\n",
      "1690\n",
      "822\n",
      "1998\n",
      "1770\n",
      "1059\n",
      "1647\n",
      "757\n",
      "836\n",
      "2792\n",
      "814\n",
      "1835\n",
      "986\n",
      "1684\n",
      "1577\n",
      "396\n",
      "530\n",
      "1122\n",
      "845\n",
      "970\n",
      "1383\n",
      "822\n",
      "1376\n",
      "1776\n",
      "1439\n",
      "1236\n",
      "1594\n",
      "804\n",
      "986\n",
      "1174\n",
      "834\n",
      "1509\n",
      "1720\n",
      "530\n",
      "1750\n",
      "1422\n",
      "1978\n",
      "1231\n",
      "1770\n",
      "1166\n",
      "1799\n",
      "906\n",
      "2151\n",
      "637\n",
      "869\n",
      "1572\n",
      "1141\n",
      "1515\n",
      "2067\n",
      "1374\n",
      "2112\n",
      "1429\n",
      "1178\n",
      "2041\n",
      "1647\n",
      "886\n",
      "1610\n",
      "1967\n",
      "1116\n",
      "746\n",
      "943\n",
      "1093\n",
      "1394\n",
      "906\n",
      "914\n",
      "1937\n",
      "1654\n",
      "757\n",
      "1004\n",
      "1022\n",
      "1468\n",
      "1080\n",
      "1004\n",
      "1365\n",
      "1937\n",
      "1113\n",
      "1846\n",
      "1799\n",
      "1502\n",
      "1502\n",
      "1250\n",
      "1203\n",
      "1167\n",
      "906\n",
      "1319\n",
      "1086\n",
      "758\n",
      "1577\n",
      "1235\n",
      "1307\n",
      "1610\n",
      "1835\n",
      "2504\n",
      "1303\n",
      "2456\n",
      "757\n",
      "1543\n",
      "714\n",
      "1275\n",
      "530\n",
      "905\n",
      "2587\n",
      "1318\n",
      "1607\n",
      "1634\n",
      "1236\n",
      "1539\n",
      "943\n",
      "1296\n",
      "1651\n",
      "1113\n",
      "1111\n",
      "1322\n",
      "2017\n",
      "1900\n",
      "1856\n",
      "1438\n",
      "2293\n",
      "1783\n",
      "2120\n",
      "1231\n",
      "1595\n",
      "845\n",
      "874\n",
      "1610\n",
      "1303\n",
      "1059\n",
      "1644\n",
      "1319\n",
      "2117\n",
      "1630\n",
      "631\n",
      "1320\n",
      "1353\n",
      "1037\n",
      "878\n",
      "1799\n",
      "929\n",
      "1463\n",
      "874\n",
      "1250\n",
      "2332\n",
      "1662\n",
      "636\n",
      "1660\n",
      "1098\n",
      "1080\n",
      "1876\n",
      "1355\n",
      "1203\n",
      "1303\n",
      "3528\n",
      "1447\n",
      "3827\n",
      "964\n",
      "1135\n",
      "1095\n",
      "1176\n",
      "1447\n",
      "757\n",
      "1147\n",
      "1309\n",
      "759\n",
      "1180\n",
      "1791\n",
      "1324\n",
      "1015\n",
      "899\n",
      "1948\n",
      "1113\n",
      "1380\n",
      "550\n",
      "606\n",
      "802\n",
      "979\n",
      "1743\n",
      "1404\n",
      "631\n",
      "1850\n",
      "1817\n",
      "967\n",
      "1515\n",
      "1644\n",
      "891\n",
      "1098\n",
      "2075\n",
      "1502\n",
      "650\n",
      "556\n",
      "1324\n",
      "993\n",
      "1004\n",
      "1329\n",
      "1003\n",
      "1317\n",
      "727\n",
      "878\n",
      "3452\n",
      "1676\n",
      "1174\n",
      "2031\n",
      "878\n",
      "949\n",
      "1039\n",
      "1546\n",
      "1644\n",
      "1000\n",
      "1237\n",
      "1850\n",
      "541\n",
      "1790\n",
      "1284\n",
      "1751\n",
      "1029\n",
      "577\n",
      "1180\n",
      "1743\n",
      "1443\n",
      "895\n",
      "1971\n",
      "941\n",
      "1166\n",
      "1135\n",
      "739\n",
      "1135\n",
      "1789\n",
      "1343\n",
      "2474\n",
      "1725\n",
      "1502\n",
      "1417\n",
      "874\n",
      "1890\n",
      "1417\n",
      "467\n",
      "1631\n",
      "1283\n",
      "1691\n",
      "1967\n",
      "682\n",
      "1509\n",
      "1194\n",
      "2307\n",
      "1135\n",
      "869\n",
      "2193\n",
      "891\n",
      "1004\n",
      "1046\n",
      "1322\n",
      "2418\n",
      "2032\n",
      "682\n",
      "1176\n",
      "1799\n",
      "1248\n",
      "1111\n",
      "562\n",
      "1798\n",
      "757\n",
      "2031\n",
      "637\n",
      "1802\n",
      "1548\n",
      "1438\n",
      "1124\n",
      "934\n",
      "2171\n",
      "1111\n",
      "1394\n",
      "1763\n",
      "727\n",
      "789\n",
      "2026\n",
      "905\n",
      "831\n",
      "1248\n",
      "3668\n",
      "1442\n",
      "745\n",
      "1443\n",
      "2041\n",
      "556\n",
      "1365\n",
      "1174\n",
      "898\n",
      "819\n",
      "1166\n",
      "1950\n",
      "986\n",
      "1163\n",
      "2504\n",
      "852\n",
      "1456\n",
      "973\n",
      "2116\n",
      "891\n",
      "1508\n",
      "891\n",
      "1927\n",
      "1047\n",
      "2879\n",
      "1375\n",
      "770\n",
      "1329\n",
      "2861\n",
      "1264\n",
      "1111\n",
      "2861\n",
      "1046\n",
      "1015\n",
      "1337\n",
      "2041\n",
      "1823\n",
      "2278\n",
      "3668\n",
      "1746\n",
      "1246\n",
      "1941\n",
      "1212\n",
      "1383\n",
      "730\n",
      "1098\n",
      "770\n",
      "932\n",
      "562\n",
      "1447\n",
      "2120\n",
      "1318\n",
      "2395\n",
      "1322\n",
      "1484\n",
      "1322\n",
      "802\n",
      "1303\n",
      "1309\n",
      "1790\n",
      "828\n",
      "1546\n",
      "1831\n",
      "2041\n",
      "1231\n",
      "355\n",
      "509\n",
      "1971\n",
      "1375\n",
      "1082\n",
      "1319\n",
      "1380\n",
      "1321\n",
      "637\n",
      "2193\n",
      "1630\n",
      "1122\n",
      "1770\n",
      "1712\n",
      "1783\n",
      "1020\n",
      "1715\n",
      "574\n",
      "1419\n",
      "1999\n",
      "1515\n",
      "509\n",
      "1928\n",
      "1216\n",
      "1502\n",
      "1520\n",
      "967\n",
      "1019\n",
      "687\n",
      "1993\n",
      "1690\n",
      "1484\n",
      "1394\n",
      "439\n",
      "1178\n",
      "1663\n",
      "1047\n",
      "942\n",
      "1091\n",
      "1033\n",
      "1434\n",
      "810\n",
      "2120\n",
      "1033\n",
      "1660\n",
      "2587\n",
      "854\n",
      "1322\n",
      "1876\n",
      "1307\n",
      "1309\n",
      "650\n",
      "3668\n",
      "798\n",
      "1892\n",
      "2628\n",
      "1967\n",
      "1309\n",
      "1351\n",
      "1663\n",
      "396\n",
      "1478\n",
      "898\n",
      "2456\n",
      "646\n",
      "1676\n",
      "1900\n",
      "869\n",
      "1502\n",
      "794\n",
      "1539\n",
      "1334\n",
      "1660\n",
      "1892\n",
      "1447\n",
      "714\n",
      "1638\n",
      "1536\n",
      "1598\n",
      "2006\n",
      "1595\n",
      "878\n",
      "554\n",
      "928\n",
      "2017\n",
      "1783\n",
      "1075\n",
      "986\n",
      "588\n",
      "793\n",
      "1166\n",
      "1478\n",
      "800\n",
      "1322\n",
      "831\n",
      "1000\n",
      "793\n",
      "1212\n",
      "1376\n",
      "914\n",
      "646\n",
      "942\n",
      "1144\n",
      "727\n",
      "1724\n",
      "1180\n",
      "705\n",
      "788\n",
      "1654\n",
      "804\n",
      "2075\n",
      "825\n",
      "784\n",
      "1960\n",
      "2627\n",
      "1187\n",
      "2117\n",
      "1502\n",
      "1662\n",
      "878\n",
      "1022\n",
      "1147\n",
      "1547\n",
      "1015\n",
      "1633\n",
      "1303\n",
      "949\n",
      "1546\n",
      "939\n",
      "1447\n",
      "931\n",
      "1394\n",
      "1317\n",
      "1478\n",
      "1376\n",
      "1004\n",
      "1180\n",
      "1470\n",
      "1435\n",
      "1609\n",
      "1712\n",
      "816\n",
      "1320\n",
      "1676\n",
      "1637\n",
      "2041\n",
      "3163\n",
      "1180\n",
      "1303\n",
      "798\n",
      "905\n",
      "439\n",
      "1546\n",
      "1026\n",
      "1546\n",
      "1337\n",
      "1380\n",
      "664\n",
      "941\n",
      "1303\n",
      "1811\n",
      "1237\n",
      "2112\n",
      "1264\n",
      "1799\n",
      "898\n",
      "714\n",
      "810\n",
      "1275\n",
      "1353\n",
      "1318\n",
      "549\n",
      "1014\n",
      "1663\n",
      "1998\n",
      "949\n",
      "2170\n",
      "1022\n",
      "859\n",
      "1024\n",
      "906\n",
      "969\n",
      "1502\n",
      "2792\n",
      "1663\n",
      "1660\n",
      "1569\n",
      "949\n",
      "1105\n",
      "2116\n",
      "899\n",
      "2792\n",
      "3044\n",
      "2587\n",
      "1098\n",
      "1509\n",
      "2075\n",
      "1999\n",
      "969\n",
      "853\n",
      "1003\n",
      "1442\n",
      "839\n",
      "1750\n",
      "1539\n",
      "1278\n",
      "1447\n",
      "906\n",
      "2598\n",
      "549\n",
      "550\n",
      "836\n",
      "602\n",
      "1111\n",
      "1350\n",
      "1443\n",
      "1580\n",
      "1770\n",
      "1124\n",
      "964\n",
      "1134\n",
      "1577\n",
      "1047\n",
      "934\n",
      "2699\n",
      "1307\n",
      "1200\n",
      "1566\n",
      "942\n",
      "1314\n",
      "2398\n",
      "2026\n",
      "1850\n",
      "1830\n",
      "1309\n",
      "1176\n",
      "550\n",
      "2639\n",
      "3005\n",
      "589\n",
      "1383\n",
      "914\n",
      "1070\n",
      "1823\n",
      "836\n",
      "800\n",
      "939\n",
      "1791\n",
      "1303\n",
      "1365\n",
      "589\n",
      "1135\n",
      "1075\n",
      "929\n",
      "1071\n",
      "1559\n",
      "2193\n",
      "967\n",
      "789\n",
      "1496\n",
      "3528\n",
      "973\n",
      "758\n",
      "2456\n",
      "1355\n",
      "1603\n",
      "2032\n",
      "1335\n",
      "726\n",
      "1637\n",
      "1010\n",
      "839\n",
      "1720\n",
      "2418\n",
      "1447\n",
      "2116\n",
      "1610\n",
      "1236\n",
      "1004\n",
      "726\n",
      "1135\n",
      "943\n",
      "396\n",
      "1850\n",
      "1355\n",
      "1569\n",
      "1383\n",
      "804\n",
      "2288\n",
      "1320\n",
      "1004\n",
      "1948\n",
      "2628\n",
      "1082\n",
      "1216\n",
      "1935\n",
      "1823\n",
      "2146\n",
      "2429\n",
      "2090\n",
      "3044\n",
      "836\n",
      "973\n",
      "1577\n",
      "928\n",
      "730\n",
      "1663\n",
      "931\n",
      "1768\n",
      "1419\n",
      "804\n",
      "1019\n",
      "1439\n",
      "1456\n",
      "1278\n",
      "1967\n",
      "1317\n",
      "854\n",
      "726\n",
      "788\n",
      "2193\n",
      "1322\n",
      "1508\n",
      "1831\n",
      "1932\n",
      "1768\n",
      "843\n",
      "2112\n",
      "1603\n",
      "1237\n",
      "323\n",
      "1598\n",
      "2170\n",
      "1399\n",
      "2418\n",
      "878\n",
      "1543\n",
      "1919\n",
      "2288\n",
      "1335\n",
      "1374\n",
      "1515\n",
      "2117\n",
      "945\n",
      "1283\n",
      "1750\n",
      "1630\n",
      "1856\n",
      "1746\n",
      "1724\n",
      "1654\n",
      "1422\n",
      "1020\n",
      "1404\n",
      "1538\n",
      "1798\n",
      "2332\n",
      "622\n",
      "1751\n",
      "1318\n",
      "1399\n",
      "1304\n",
      "1026\n",
      "1718\n",
      "1350\n",
      "1419\n",
      "2474\n",
      "588\n",
      "1010\n",
      "1355\n",
      "1529\n",
      "1394\n",
      "1026\n",
      "1046\n",
      "439\n",
      "550\n",
      "1594\n",
      "914\n",
      "819\n",
      "1502\n",
      "1496\n",
      "1515\n",
      "2598\n",
      "714\n",
      "1099\n",
      "940\n",
      "2293\n",
      "1037\n",
      "1250\n",
      "821\n",
      "1387\n",
      "1943\n",
      "1098\n",
      "1010\n",
      "804\n",
      "672\n",
      "1283\n",
      "1943\n",
      "973\n",
      "2151\n",
      "1743\n",
      "859\n",
      "1548\n",
      "1435\n",
      "1559\n",
      "2619\n",
      "1141\n",
      "1334\n",
      "1998\n",
      "1723\n",
      "588\n",
      "1524\n",
      "592\n",
      "819\n",
      "837\n",
      "1309\n",
      "1387\n",
      "1546\n",
      "588\n",
      "1095\n",
      "602\n",
      "1235\n",
      "2627\n",
      "2017\n",
      "1577\n",
      "1080\n",
      "802\n",
      "1334\n",
      "1395\n",
      "1968\n",
      "1559\n",
      "657\n",
      "845\n",
      "1014\n",
      "1438\n",
      "1095\n",
      "1274\n",
      "1660\n",
      "1004\n",
      "1789\n",
      "793\n",
      "798\n",
      "1462\n",
      "964\n",
      "1231\n",
      "1743\n",
      "554\n",
      "788\n",
      "396\n",
      "1690\n",
      "1389\n",
      "1545\n",
      "1252\n",
      "3452\n",
      "1941\n",
      "638\n",
      "682\n",
      "1178\n",
      "1417\n",
      "1577\n",
      "1724\n",
      "1634\n",
      "1543\n",
      "1029\n",
      "1509\n",
      "439\n",
      "942\n",
      "819\n",
      "3038\n",
      "562\n",
      "758\n",
      "1790\n",
      "1855\n",
      "1595\n",
      "1515\n",
      "729\n",
      "2293\n",
      "1536\n",
      "2193\n",
      "1113\n",
      "1379\n",
      "1850\n",
      "1791\n",
      "1473\n",
      "1020\n",
      "1135\n",
      "554\n",
      "930\n",
      "1307\n",
      "1314\n",
      "1135\n",
      "2023\n",
      "1603\n",
      "895\n",
      "942\n",
      "1542\n",
      "1715\n",
      "1473\n",
      "964\n",
      "1543\n",
      "1319\n",
      "1303\n",
      "1309\n",
      "3783\n",
      "1071\n",
      "1676\n",
      "1855\n",
      "859\n",
      "1296\n",
      "1351\n",
      "1075\n",
      "439\n",
      "1484\n",
      "2456\n",
      "1483\n",
      "1039\n",
      "1538\n",
      "1502\n",
      "941\n",
      "1335\n",
      "986\n",
      "1166\n",
      "1351\n",
      "3827\n",
      "1768\n",
      "1473\n",
      "906\n",
      "1203\n",
      "1470\n",
      "1309\n",
      "1013\n",
      "3452\n",
      "1084\n",
      "1271\n",
      "1547\n",
      "1932\n",
      "1971\n",
      "726\n",
      "1010\n",
      "1093\n",
      "1167\n",
      "1543\n",
      "2332\n",
      "899\n",
      "1203\n",
      "1725\n",
      "1841\n",
      "2090\n",
      "1798\n",
      "638\n",
      "1380\n",
      "1037\n",
      "1231\n",
      "1319\n",
      "1676\n",
      "1720\n",
      "1855\n",
      "1010\n",
      "1673\n",
      "839\n",
      "1607\n",
      "1662\n",
      "1509\n",
      "1284\n",
      "2639\n",
      "1743\n",
      "1135\n",
      "819\n",
      "1252\n",
      "1207\n",
      "1004\n",
      "940\n",
      "1200\n",
      "1691\n",
      "1046\n",
      "1187\n",
      "883\n",
      "1376\n",
      "1534\n",
      "622\n",
      "1539\n",
      "770\n",
      "906\n",
      "1001\n",
      "1187\n",
      "1511\n",
      "3528\n",
      "1830\n",
      "1135\n",
      "1092\n",
      "2474\n",
      "1122\n",
      "1147\n",
      "1630\n",
      "1122\n",
      "1020\n",
      "2090\n",
      "1374\n",
      "1376\n",
      "1366\n",
      "1577\n",
      "1478\n",
      "1309\n",
      "1092\n",
      "2170\n",
      "1438\n",
      "467\n",
      "1264\n",
      "1515\n",
      "986\n",
      "687\n",
      "1351\n",
      "1539\n",
      "638\n",
      "1207\n",
      "1890\n",
      "1091\n",
      "554\n",
      "1313\n",
      "955\n",
      "914\n",
      "672\n",
      "729\n",
      "1429\n",
      "1365\n",
      "562\n",
      "646\n",
      "1059\n",
      "1141\n",
      "1496\n",
      "1237\n",
      "574\n",
      "1297\n",
      "1163\n",
      "838\n",
      "602\n",
      "1371\n",
      "943\n",
      "800\n",
      "1047\n",
      "1743\n",
      "1163\n",
      "973\n",
      "1715\n",
      "2117\n",
      "1943\n",
      "1463\n",
      "588\n",
      "1478\n",
      "1365\n",
      "1529\n",
      "1712\n",
      "1950\n",
      "1353\n",
      "1546\n",
      "883\n",
      "1539\n",
      "1004\n",
      "2087\n",
      "2879\n",
      "1283\n",
      "1199\n",
      "1425\n",
      "1059\n",
      "1099\n",
      "2861\n",
      "3163\n",
      "828\n",
      "1015\n",
      "3044\n",
      "883\n",
      "2598\n",
      "1039\n",
      "1643\n",
      "2170\n",
      "2639\n",
      "1200\n",
      "993\n",
      "1019\n",
      "852\n",
      "1355\n",
      "1631\n",
      "1394\n",
      "973\n",
      "1459\n",
      "1350\n",
      "864\n",
      "1200\n",
      "1010\n",
      "1543\n",
      "1252\n",
      "1178\n",
      "1447\n",
      "1610\n",
      "1684\n",
      "831\n",
      "1314\n",
      "967\n",
      "1968\n",
      "1900\n",
      "1366\n",
      "953\n",
      "1323\n",
      "1835\n",
      "1059\n",
      "1459\n",
      "1948\n",
      "1610\n",
      "1429\n",
      "682\n",
      "794\n",
      "1047\n",
      "1569\n",
      "1271\n",
      "1013\n",
      "914\n",
      "2088\n",
      "2861\n",
      "1504\n",
      "1180\n",
      "1660\n",
      "834\n",
      "939\n",
      "2017\n",
      "3038\n",
      "974\n",
      "829\n",
      "1124\n",
      "1927\n",
      "1731\n",
      "1609\n",
      "705\n",
      "986\n",
      "509\n",
      "1250\n",
      "1743\n",
      "1718\n",
      "967\n",
      "1651\n",
      "739\n",
      "1850\n",
      "967\n",
      "1187\n",
      "869\n",
      "1329\n",
      "1539\n",
      "1993\n",
      "986\n",
      "1351\n",
      "602\n",
      "687\n",
      "2892\n",
      "2032\n",
      "1798\n",
      "1271\n",
      "657\n",
      "682\n",
      "794\n",
      "1483\n",
      "929\n",
      "633\n",
      "2587\n",
      "1375\n",
      "1091\n",
      "1001\n",
      "1144\n",
      "1379\n",
      "1790\n",
      "898\n",
      "1509\n",
      "868\n",
      "834\n",
      "1147\n",
      "1020\n",
      "1644\n",
      "1545\n",
      "1015\n",
      "2879\n",
      "1319\n",
      "787\n",
      "828\n",
      "1841\n",
      "2151\n",
      "2278\n",
      "1039\n",
      "509\n",
      "1712\n",
      "1103\n",
      "822\n",
      "2094\n",
      "2639\n",
      "819\n",
      "709\n",
      "929\n",
      "816\n",
      "1654\n",
      "3452\n",
      "1321\n",
      "739\n",
      "1462\n",
      "746\n",
      "541\n",
      "1811\n",
      "1790\n",
      "1651\n",
      "1304\n",
      "1026\n",
      "2398\n",
      "754\n",
      "986\n",
      "1309\n",
      "1374\n",
      "682\n",
      "1503\n",
      "1971\n",
      "592\n",
      "1823\n",
      "2006\n",
      "2619\n",
      "1470\n",
      "1823\n",
      "757\n",
      "589\n",
      "2120\n",
      "1673\n",
      "1026\n",
      "1037\n",
      "1963\n",
      "1876\n",
      "1846\n",
      "1284\n",
      "1656\n",
      "2587\n",
      "589\n",
      "1324\n",
      "1504\n",
      "650\n",
      "1399\n",
      "814\n",
      "2699\n",
      "2112\n",
      "1091\n",
      "1633\n",
      "1594\n",
      "1478\n",
      "1651\n",
      "1322\n",
      "1248\n",
      "967\n",
      "802\n",
      "986\n",
      "1572\n",
      "1307\n",
      "1014\n",
      "1598\n",
      "1274\n",
      "2193\n",
      "1417\n",
      "1630\n",
      "1439\n",
      "1135\n",
      "2116\n",
      "355\n",
      "941\n",
      "1508\n",
      "1690\n",
      "1831\n",
      "1967\n",
      "1108\n",
      "3827\n",
      "1323\n",
      "1802\n",
      "1303\n",
      "1080\n",
      "1595\n",
      "2892\n",
      "1515\n",
      "1743\n",
      "1200\n",
      "589\n",
      "2587\n",
      "592\n",
      "1470\n",
      "829\n",
      "636\n",
      "798\n",
      "2892\n",
      "928\n",
      "1134\n",
      "1303\n",
      "2094\n",
      "2927\n",
      "1319\n",
      "1434\n",
      "1166\n",
      "1098\n",
      "1084\n",
      "1633\n",
      "467\n",
      "2395\n",
      "550\n",
      "829\n",
      "1323\n",
      "853\n",
      "1920\n",
      "1546\n",
      "816\n",
      "1956\n",
      "1163\n",
      "1147\n",
      "1609\n",
      "1538\n",
      "1098\n",
      "2032\n",
      "1999\n",
      "759\n",
      "1422\n",
      "2278\n",
      "1598\n",
      "825\n",
      "1135\n",
      "1656\n",
      "1935\n",
      "814\n",
      "1010\n",
      "1508\n",
      "1502\n",
      "1365\n",
      "1484\n",
      "631\n",
      "1876\n",
      "589\n",
      "2094\n",
      "1093\n",
      "1022\n",
      "1790\n",
      "788\n",
      "1176\n",
      "1070\n",
      "1092\n",
      "1963\n",
      "1656\n",
      "541\n",
      "633\n",
      "759\n",
      "854\n",
      "1509\n",
      "1443\n",
      "1419\n",
      "1838\n",
      "1791\n",
      "746\n",
      "1468\n",
      "636\n",
      "1351\n",
      "2032\n",
      "1811\n",
      "1108\n",
      "1638\n",
      "1609\n",
      "852\n",
      "1203\n",
      "821\n",
      "1026\n",
      "1231\n",
      "1536\n",
      "1399\n",
      "1731\n",
      "923\n",
      "1000\n",
      "549\n",
      "1690\n",
      "3044\n",
      "931\n",
      "2927\n",
      "2031\n",
      "1919\n",
      "929\n",
      "2120\n",
      "3038\n",
      "1166\n",
      "1968\n",
      "942\n",
      "1662\n",
      "1856\n",
      "986\n",
      "822\n",
      "2090\n",
      "868\n",
      "986\n",
      "1634\n",
      "1558\n",
      "2293\n",
      "2879\n",
      "953\n",
      "814\n",
      "1024\n",
      "1577\n",
      "2017\n",
      "682\n",
      "758\n",
      "1928\n",
      "945\n",
      "355\n",
      "1783\n",
      "1609\n",
      "1303\n",
      "1508\n",
      "836\n",
      "1211\n",
      "1731\n",
      "1134\n",
      "859\n",
      "729\n",
      "1928\n",
      "1135\n",
      "942\n",
      "1509\n",
      "637\n",
      "932\n",
      "682\n",
      "2170\n",
      "1546\n",
      "1329\n",
      "1725\n",
      "1539\n",
      "1963\n",
      "1715\n",
      "1105\n",
      "554\n",
      "3023\n",
      "467\n",
      "1663\n",
      "687\n",
      "1166\n",
      "1371\n",
      "1609\n",
      "953\n",
      "828\n",
      "784\n",
      "1353\n",
      "439\n",
      "1103\n",
      "1900\n",
      "1542\n",
      "1503\n",
      "878\n",
      "1319\n",
      "664\n",
      "758\n",
      "945\n",
      "1187\n",
      "1167\n",
      "714\n",
      "1559\n",
      "1029\n",
      "323\n",
      "1284\n",
      "798\n",
      "1026\n",
      "1003\n",
      "1001\n",
      "3783\n",
      "574\n",
      "1798\n",
      "1082\n",
      "1317\n",
      "1046\n",
      "2090\n",
      "1502\n",
      "1950\n",
      "1798\n",
      "2307\n",
      "967\n",
      "979\n",
      "709\n",
      "1167\n",
      "2193\n",
      "1663\n",
      "1135\n",
      "1447\n",
      "1329\n",
      "1456\n",
      "705\n",
      "1252\n",
      "2927\n",
      "396\n",
      "946\n",
      "1470\n",
      "1607\n",
      "2006\n",
      "3038\n",
      "2088\n",
      "556\n",
      "1963\n",
      "1720\n",
      "1723\n",
      "2418\n",
      "1484\n",
      "1321\n",
      "1927\n",
      "1314\n",
      "1828\n",
      "2395\n",
      "934\n",
      "1284\n",
      "1015\n",
      "1932\n",
      "886\n",
      "930\n",
      "1434\n",
      "1337\n",
      "837\n",
      "1651\n",
      "1776\n",
      "1543\n",
      "1047\n",
      "1124\n",
      "1194\n",
      "1404\n",
      "622\n",
      "758\n",
      "1020\n",
      "878\n",
      "1274\n",
      "1275\n",
      "1134\n",
      "1039\n",
      "1334\n",
      "1103\n",
      "1071\n",
      "1577\n",
      "1892\n",
      "821\n",
      "1037\n",
      "1374\n",
      "1609\n",
      "787\n",
      "883\n",
      "1609\n",
      "1389\n",
      "1950\n",
      "1960\n",
      "1108\n",
      "1539\n",
      "1135\n",
      "1943\n",
      "1928\n",
      "1609\n",
      "1278\n",
      "1559\n",
      "1387\n",
      "794\n",
      "1183\n",
      "1435\n",
      "714\n",
      "874\n",
      "1105\n",
      "546\n",
      "2504\n",
      "577\n",
      "829\n",
      "2927\n",
      "2474\n",
      "1643\n",
      "2927\n",
      "1343\n",
      "1515\n",
      "1355\n",
      "2120\n",
      "1690\n",
      "687\n",
      "932\n",
      "1643\n",
      "1447\n",
      "1297\n",
      "1395\n",
      "942\n",
      "2120\n",
      "1163\n",
      "1180\n",
      "1534\n",
      "1637\n",
      "1061\n",
      "2861\n",
      "941\n",
      "1318\n",
      "1026\n",
      "1313\n",
      "1417\n",
      "1647\n",
      "1856\n",
      "1656\n",
      "1828\n",
      "1725\n",
      "1250\n",
      "1425\n",
      "1180\n",
      "2307\n",
      "1559\n",
      "1999\n",
      "1660\n",
      "589\n",
      "1422\n",
      "1135\n",
      "1313\n"
     ]
    }
   ],
   "source": [
    "big = []\n",
    "for ((main, main_len), (piano, piano_len)), _ in (train_iter):\n",
    "    #print(intro.transpose(1,0).size(0))\n",
    "    print(piano_len.cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82eec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "torch.backends.cudnn.enabled=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9d9f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/seq2seq_transformer/seq2seq_transformer.py\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_len,\n",
    "        device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "\n",
    "        # (N, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(src_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(trg_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
    "        )\n",
    "        embed_trg = self.dropout(\n",
    "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
    "        )\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask,\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e4ad3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(main_field.vocab)\n",
    "trg_vocab_size = len(piano_field.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.10\n",
    "max_len = 3000\n",
    "forward_expansion = 4\n",
    "src_pad_idx = 1 #english.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3910013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 12,969,244 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5) #non augmented 3e-4\n",
    "\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "\n",
    "def save_best_checkpoint(state, nth,filename=\"_checkpoint.pt\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "#     torch.save(state, destination_folder + str(nth)+filename)\n",
    "    torch.save(state, destination_folder + '/metrics.pt')\n",
    "\n",
    "def save_final_checkpoint(state, nth,filename=\"_checkpoint.pt\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, destination_folder + \"/\" + str(nth)+filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43049c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoi input str get int\n",
    "# intro_field.vocab.stoi\n",
    "# itos input into get token/str\n",
    "# intro_field.vocab.itos[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d99045b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "#criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b08d03f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: torch.utils.data.DataLoader,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    #for _, (src, _,trg,_) in enumerate(iterator):\n",
    "    for ((main, main_len), (piano, piano_len)), _ in (iterator):\n",
    "        if piano_len.cpu().item()>=3000:\n",
    "            continue\n",
    "        src, trg = main.transpose(1,0), piano.transpose(1,0)\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg[:-1, :])\n",
    "        \n",
    "#         print(output.size())\n",
    "#         print(trg.size())\n",
    "        \n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        loss = criterion(output, trg)\n",
    "#         print(torch.isfinite(trg).all().cpu().item())\n",
    "#         print(torch.isfinite(output).all().cpu().item())\n",
    "#         print(torch.isfinite(loss).all().cpu().item())\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.cpu().detach().item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             iterator: torch.utils.data.DataLoader,\n",
    "             criterion: nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        #for _, (src, _,trg,_) in enumerate(iterator):\n",
    "        for ((main, main_len), (piano, piano_len)), _ in (iterator):\n",
    "            if piano_len.cpu().item()>=3000:\n",
    "                continue\n",
    "            src, trg = main.transpose(1,0), piano.transpose(1,0)\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "            output = model(src, trg[:-1, :]) #turn off teacher forcing\n",
    "\n",
    "            output = output.view(-1, output.shape[-1])\n",
    "            trg = trg[1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.cpu().detach().item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71aa22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, german, english, device, max_length=1200):\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    tokens = [token.lower() for token in sentence.split(' ')]\n",
    "    # print(tokens)\n",
    "\n",
    "    # sys.exit()\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "    # print(outputs)\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86887ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "df_intro = pd.read_csv(source_folder + '/val_torchtext.csv')\n",
    "val_main = df_intro['main'].values\n",
    "val_piano = df_intro['piano'].values\n",
    "val_data=[]\n",
    "for i in range(len(val_main)):\n",
    "    temp_dict = {}\n",
    "    temp_dict['main'] = val_main[i]\n",
    "    temp_dict['piano'] = val_piano[i]\n",
    "    val_data.append(temp_dict)\n",
    "print(len(val_piano))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ead0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mode_collapse(model):\n",
    "    count = 0\n",
    "    translations = []\n",
    "    for i in range(3):\n",
    "        main = val_main[i]\n",
    "        piano = val_piano[i]\n",
    "        #print(intro)\n",
    "        list_main = [int(x) for x in main.split(' ')]\n",
    "        list_piano = [int(x) for x in piano.split(' ')]\n",
    "        translated_sentence = translate_sentence(model, main, main_field, piano_field, device, max_length=1200)\n",
    "        \n",
    "        translated_sentence = [int(x) for x in translated_sentence if x != '<pad>' and x != '<sos>' and x != '<eos>' and x != '<unk>']\n",
    "        print(translated_sentence)\n",
    "        translations.append(translated_sentence)\n",
    "        if i > 0:\n",
    "            if translations[i-1] == translations[i]:\n",
    "                count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "894016c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1982 | Time: 5m 40s\n",
      "\tTrain Loss: 0.091 | Train PPL:   1.096\n",
      "\t Val. Loss: 8.081 |  Val. PPL: 3231.108\n",
      "=> Saving checkpoint\n",
      "Epoch: 1983 | Time: 5m 41s\n",
      "\tTrain Loss: 0.091 | Train PPL:   1.096\n",
      "\t Val. Loss: 8.037 |  Val. PPL: 3092.142\n",
      "=> Saving checkpoint\n",
      "Epoch: 1984 | Time: 5m 41s\n",
      "\tTrain Loss: 0.092 | Train PPL:   1.096\n",
      "\t Val. Loss: 8.047 |  Val. PPL: 3123.171\n",
      "Epoch: 1985 | Time: 5m 40s\n",
      "\tTrain Loss: 0.091 | Train PPL:   1.096\n",
      "\t Val. Loss: 8.065 |  Val. PPL: 3181.441\n",
      "Epoch: 1986 | Time: 5m 41s\n",
      "\tTrain Loss: 0.091 | Train PPL:   1.095\n",
      "\t Val. Loss: 8.093 |  Val. PPL: 3270.876\n",
      "Epoch: 1987 | Time: 5m 40s\n",
      "\tTrain Loss: 0.091 | Train PPL:   1.095\n",
      "\t Val. Loss: 8.084 |  Val. PPL: 3240.840\n",
      "Epoch: 1988 | Time: 5m 41s\n",
      "\tTrain Loss: 0.091 | Train PPL:   1.096\n",
      "\t Val. Loss: 8.035 |  Val. PPL: 3087.370\n",
      "=> Saving checkpoint\n",
      "Epoch: 1989 | Time: 5m 41s\n",
      "\tTrain Loss: 0.091 | Train PPL:   1.095\n",
      "\t Val. Loss: 8.058 |  Val. PPL: 3159.673\n",
      "Epoch: 1990 | Time: 5m 41s\n",
      "\tTrain Loss: 0.090 | Train PPL:   1.095\n",
      "\t Val. Loss: 8.072 |  Val. PPL: 3202.853\n",
      "Epoch: 1991 | Time: 5m 41s\n",
      "\tTrain Loss: 0.091 | Train PPL:   1.095\n",
      "\t Val. Loss: 8.071 |  Val. PPL: 3198.897\n",
      "Epoch: 1992 | Time: 5m 40s\n",
      "\tTrain Loss: 0.091 | Train PPL:   1.095\n",
      "\t Val. Loss: 8.046 |  Val. PPL: 3121.252\n",
      "Epoch: 1993 | Time: 5m 41s\n",
      "\tTrain Loss: 0.090 | Train PPL:   1.094\n",
      "\t Val. Loss: 8.066 |  Val. PPL: 3185.298\n",
      "Epoch: 1994 | Time: 5m 41s\n",
      "\tTrain Loss: 0.090 | Train PPL:   1.095\n",
      "\t Val. Loss: 8.064 |  Val. PPL: 3177.025\n",
      "Epoch: 1995 | Time: 5m 40s\n",
      "\tTrain Loss: 0.090 | Train PPL:   1.094\n",
      "\t Val. Loss: 8.054 |  Val. PPL: 3144.818\n",
      "Epoch: 1996 | Time: 5m 41s\n",
      "\tTrain Loss: 0.090 | Train PPL:   1.094\n",
      "\t Val. Loss: 8.075 |  Val. PPL: 3213.681\n",
      "Epoch: 1997 | Time: 5m 41s\n",
      "\tTrain Loss: 0.090 | Train PPL:   1.094\n",
      "\t Val. Loss: 8.066 |  Val. PPL: 3183.344\n",
      "Epoch: 1998 | Time: 5m 41s\n",
      "\tTrain Loss: 0.090 | Train PPL:   1.094\n",
      "\t Val. Loss: 8.068 |  Val. PPL: 3189.534\n",
      "Epoch: 1999 | Time: 5m 41s\n",
      "\tTrain Loss: 0.090 | Train PPL:   1.094\n",
      "\t Val. Loss: 8.067 |  Val. PPL: 3187.586\n",
      "Epoch: 2000 | Time: 5m 42s\n",
      "\tTrain Loss: 0.090 | Train PPL:   1.095\n",
      "\t Val. Loss: 8.044 |  Val. PPL: 3114.861\n",
      "=> Saving checkpoint\n",
      "[0, 1, 2, 95, 67, 32, 179, 52, 4, 38, 179, 31, 4, 64, 129, 52, 8, 38, 127, 31, 72, 32, 230, 77, 10, 32, 179, 41, 91, 11, 127, 41, 13, 11, 127, 19, 70, 38, 104, 31, 16, 38, 227, 28, 17, 32, 129, 52, 90, 32, 127, 7, 90, 38, 55, 31, 27, 38, 178, 47, 74, 38, 129, 7, 0, 1, 32, 129, 52, 67, 38, 122, 31, 67, 38, 230, 36, 4, 11, 179, 66, 23, 54, 129, 52, 8, 38, 104, 31, 10, 11, 55, 52, 91, 53, 179, 7, 13, 38, 199, 42, 70, 32, 129, 31, 16, 38, 127, 41, 78, 35, 230, 28, 17, 53, 179, 7, 90, 5, 104, 41, 27, 32, 55, 41, 74, 38, 46, 7, 0, 67, 38, 230, 47, 4, 54, 179, 52, 23, 38, 127, 41, 8, 11, 104, 41, 10, 5, 55, 31, 91, 24, 127, 7, 70, 38, 230, 47, 70, 64, 129, 41, 78, 51, 179, 52, 17, 11, 104, 34, 90, 79, 55, 31, 74, 11, 179, 15, 0, 67, 24, 129, 34, 4, 32, 230, 37, 23, 53, 179, 31, 8, 38, 129, 31, 72, 38, 55, 41, 10, 71, 199, 31, 13, 38, 127, 7, 70, 11, 104, 31, 16, 11, 230, 28, 78, 35, 179, 66, 90, 24, 179, 52, 74, 38, 127, 19, 0, 67, 38, 104, 7, 67, 65, 199, 36, 4, 38, 129, 7, 8, 25, 127, 19, 72, 11, 122, 52, 91, 53, 179, 7, 70, 11, 100, 41, 70, 38, 55, 41, 78, 38, 127, 52, 17, 38, 122, 7, 90, 38, 100, 7, 0, 67, 24, 185, 77, 4, 63, 129, 52, 72, 38, 128, 41, 72, 32, 55, 41, 10, 32, 129, 52, 91, 45, 104, 15, 13, 32, 128, 52, 70, 38, 104, 15, 70, 32, 55, 31, 78, 53, 129, 7, 90, 38, 230, 42, 17, 51, 127, 31, 27, 24, 104, 31, 74, 11, 55, 31, 0, 67, 11, 179, 15, 4, 64, 230, 28, 23, 64, 179, 52, 8, 49, 127, 19, 72, 51, 179, 7, 10, 64, 179, 15, 91, 53, 199, 52, 13, 53, 179, 47, 70, 53, 179, 7, 16, 71, 179, 42, 78, 65, 127, 66, 90, 53, 129, 7, 90, 64, 127, 52, 74, 32, 104, 31, 0, 67, 38, 179, 47, 4, 38, 179, 19, 23, 35, 127, 19, 72, 38, 129, 7, 72, 45, 132, 7, 10, 11, 185, 15, 16, 11, 129, 15, 78, 54, 128, 52, 90, 71, 104, 52, 74, 53, 55, 41, 0, 67, 64, 230, 136, 4, 64, 179, 52, 8, 35, 129, 52, 72, 45, 127, 31, 10, 45, 104, 7, 13, 49, 104, 41, 16, 53, 179, 52, 17, 49, 129, 41, 17, 64, 127, 31, 90, 53, 104, 31, 27, 123, 179, 15, 0, 67, 63, 179, 22, 4, 53, 129, 7, 4, 35, 127, 52, 8, 51, 127, 52, 10, 64, 230, 137, 10, 64, 129, 52, 13, 64, 127, 52, 70, 35, 230, 68, 16, 71, 179, 52, 78, 54, 127, 31, 90, 38, 104, 41, 27, 51, 230, 36, 0, 1, 51, 179, 52, 4, 53, 179, 66, 23, 51, 127, 52, 8, 32, 104, 7, 72, 45, 179, 42, 10, 49, 129, 19, 10, 63, 179, 7, 13, 35, 127, 52, 16, 45, 179, 7, 17, 35, 129, 22, 90, 53, 230, 77, 27, 38, 179, 52, 74, 53, 179, 7, 0, 67, 49, 127, 7, 4, 71, 199, 66, 23, 24, 100, 31, 8, 63, 179, 7, 72, 45, 132, 7, 10, 64, 256, 135, 10, 45, 179, 41, 13, 35, 129, 31, 70, 45, 179, 52, 16, 32, 127, 19, 78, 49, 227, 36, 17, 35, 179, 47, 27, 51, 129, 52, 74, 53, 127, 52, 0, 67, 71, 55, 41]\n",
      "[0, 1, 2, 202, 1, 54, 122, 7, 67, 24, 30, 66, 4, 51, 50, 41, 23, 71, 50, 52, 72, 35, 149, 103, 72, 35, 122, 37, 72, 49, 100, 52, 91, 54, 30, 15, 91, 54, 48, 19, 70, 51, 129, 59, 78, 53, 122, 15, 78, 51, 55, 52, 90, 35, 122, 31, 74, 51, 55, 22, 74, 53, 33, 22, 0, 67, 51, 185, 60, 23, 53, 128, 52, 72, 51, 55, 66, 72, 53, 128, 31, 91, 53, 55, 31, 91, 64, 48, 19, 70, 51, 55, 41, 78, 53, 128, 7, 78, 54, 111, 7, 90, 35, 55, 7, 90, 54, 48, 31, 74, 35, 6, 31, 0, 67, 35, 218, 60, 23, 54, 128, 37, 72, 35, 111, 7, 91, 53, 30, 41, 91, 53, 48, 19, 70, 35, 111, 31, 78, 54, 30, 28, 78, 51, 48, 66, 90, 53, 111, 7, 74, 35, 30, 31, 0, 67, 54, 180, 47, 23, 53, 111, 66, 91, 35, 55, 52, 91, 51, 33, 66, 91, 53, 111, 41, 70, 35, 55, 41, 78, 51, 185, 77, 78, 64, 55, 52, 90, 54, 128, 31, 74, 51, 111, 7, 0, 67, 54, 178, 102, 72, 49, 122, 42, 91, 35, 100, 66, 91, 53, 30, 34, 78, 53, 122, 66, 74, 54, 100, 52, 0, 67, 35, 100, 34, 23, 35, 30, 66, 23, 51, 50, 19, 72, 51, 50, 52, 91, 51, 100, 7, 91, 51, 30, 34, 70, 54, 227, 125, 78, 51, 129, 59, 78, 51, 55, 7, 90, 49, 122, 31, 74, 35, 55, 19, 74, 51, 46, 31, 0, 67, 63, 129, 125, 23, 51, 55, 66, 72, 35, 122, 87, 72, 51, 122, 36, 91, 35, 55, 47, 70, 54, 46, 41, 78, 51, 55, 52, 90, 54, 46, 34, 74, 35, 104, 15, 0, 67, 35, 128, 37, 23, 35, 100, 19, 72, 54, 55, 52, 72, 51, 48, 34, 70, 35, 100, 19, 78, 64, 30, 19, 90, 54, 48, 7, 0, 67, 54, 199, 60, 67, 54, 100, 19, 23, 51, 132, 52, 72, 35, 100, 19, 91, 54, 46, 41, 70, 51, 127, 66, 78, 54, 100, 66, 78, 51, 46, 52, 90, 35, 100, 52, 74, 51, 46, 15, 0, 67, 54, 185, 77, 23, 45, 128, 41, 23, 54, 104, 37, 72, 49, 55, 34, 91, 53, 55, 47, 70, 54, 104, 31, 70, 51, 55, 31, 78, 51, 48, 19, 90, 35, 129, 42, 90, 54, 55, 7, 74, 51, 46, 41, 0, 67, 51, 50, 41, 23, 51, 55, 7, 72, 51, 185, 87, 72, 51, 55, 66, 72, 51, 48, 7, 91, 51, 55, 31, 70, 53, 129, 36, 78, 64, 111, 66, 78, 51, 55, 41, 90, 64, 48, 52, 74, 51, 111, 31, 0, 67, 51, 199, 103, 23, 51, 132, 36, 23, 51, 100, 41, 72, 51, 30, 41, 72, 53, 100, 41, 91, 35, 149, 36, 70, 51, 122, 66, 78, 53, 100, 22, 90, 51, 55, 15, 90, 35, 46, 7, 74, 51, 50, 22, 0, 67, 54, 185, 68, 67, 54, 55, 34, 23, 51, 48, 22, 23, 35, 128, 42, 72, 51, 55, 19, 91, 51, 129, 85, 70, 51, 55, 19, 78, 54, 48, 31, 90, 54, 185, 59, 74, 51, 128, 31, 0, 67, 51, 129, 94, 1, 2, 69, 23, 54, 50, 28, 23, 51, 55, 41, 8, 35, 122, 52, 72, 51, 55, 7, 13, 64, 55, 7, 70, 35, 128, 19, 17, 64, 185, 28, 90, 51, 55, 34, 90, 53, 128, 19, 0, 1, 35, 55, 19, 1, 2, 69, 1, 51, 185, 102, 1, 54, 128, 34, 1, 54, 55, 41, 8, 51, 48, 34, 8, 54, 55, 34, 8, 51, 129, 31, 13, 51, 55, 66, 13, 51, 128, 66, 16, 54, 55, 31, 17, 51, 55, 52, 17, 64, 48, 52, 27, 54, 185, 102, 0, 1, 64, 128, 66, 1, 51, 55, 41, 4, 51, 129, 83, 8, 51, 128, 87, 8, 51, 55, 41, 10, 51, 48, 7, 13, 64, 55, 31, 16, 64, 129, 42, 17, 51, 55, 41, 27, 51, 55, 31, 0, 1, 64, 185, 83, 1, 64, 55, 31, 1, 51, 48, 66, 8, 51, 128, 42, 8, 51, 55, 34, 10, 54, 48, 31, 13, 35, 128, 52, 16, 54, 55, 66, 16, 53, 111, 7, 17, 51, 48, 7, 27, 54, 100, 31, 27, 35, 128, 7, 0, 1, 64, 55, 15, 1, 54, 48, 19, 4, 64, 178, 77, 8, 51, 149, 36, 8, 35, 122, 31, 10, 35, 100, 52, 13, 54, 30, 19, 16, 53, 122, 66, 17, 51, 100, 41, 17, 51, 30, 41, 27, 35, 122, 7, 0, 1, 35, 129, 68, 4, 51, 122, 37, 8, 54, 55, 52, 8, 54, 122, 34, 10, 54, 55, 41, 13, 51, 46, 15, 17, 51, 185, 108, 17, 51, 128, 34, 27, 35, 128, 52, 0, 1, 64, 129, 66, 1, 64, 128, 52, 1, 64, 55, 41, 4, 54, 128, 15, 8, 64, 55, 52, 10, 54, 128, 41, 13, 51, 185, 94, 16, 64, 111, 7, 17, 35, 55, 7, 27, 54, 128, 52, 0, 1, 35, 128, 7, 1, 64, 55, 7, 8, 51, 55, 7, 8, 51, 185, 68, 10, 53, 128, 42, 13, 54, 55, 7, 13, 54, 48, 15, 13, 54, 128, 19, 16, 53, 128, 22, 17, 51, 104, 41, 27, 54, 55, 7, 0, 1, 54, 199, 80, 1, 51, 122, 31, 1, 64, 132, 68, 1, 54, 100, 52, 8, 51, 30, 31, 8, 64, 100, 34, 8, 51, 100, 31, 10, 51, 30, 31, 13, 54, 100, 7, 13, 64, 46, 41, 16, 54, 132, 77, 78, 35, 128, 37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 162, 1, 54, 30, 7, 4, 54, 26, 7, 4, 64, 6, 31, 8, 53, 6, 31, 10, 35, 33, 31, 10, 64, 6, 7, 10, 64, 9, 7, 91, 63, 33, 31, 13, 53, 50, 31, 13, 32, 6, 7, 16, 54, 12, 7, 17, 53, 6, 7, 27, 54, 50, 7, 27, 51, 57, 31, 0, 1, 32, 30, 15, 1, 53, 50, 31, 23, 35, 6, 52, 8, 51, 57, 31, 8, 63, 30, 41, 10, 35, 33, 31, 10, 49, 50, 7, 13, 53, 6, 7, 13, 35, 33, 7, 16, 54, 6, 7, 78, 123, 48, 52, 17, 45, 6, 31, 90, 49, 33, 15, 27, 35, 6, 22, 27, 35, 57, 7, 0, 1, 53, 33, 15, 1, 53, 50, 7, 4, 71, 50, 31, 23, 54, 9, 15, 8, 51, 30, 31, 8, 63, 50, 15, 10, 49, 57, 7, 10, 54, 50, 7, 10, 54, 57, 7, 10, 53, 30, 15, 13, 35, 50, 15, 13, 63, 9, 7, 16, 53, 98, 7, 16, 53, 30, 7, 78, 71, 12, 7, 17, 65, 12, 7, 90, 51, 111, 15, 74, 35, 33, 15, 0, 1, 51, 21, 7, 1, 53, 33, 15, 1, 53, 6, 15, 4, 35, 57, 15, 23, 53, 33, 15, 23, 49, 6, 31, 8, 53, 57, 7, 10, 53, 33, 52, 10, 51, 6, 15, 91, 54, 21, 7, 13, 53, 50, 22, 16, 35, 6, 15, 16, 53, 21, 7, 78, 35, 111, 60, 17, 53, 33, 52, 90, 35, 6, 19, 90, 54, 33, 41, 27, 45, 6, 31, 0, 1, 53, 33, 52, 1, 45, 6, 52, 4, 65, 57, 52, 4, 49, 30, 52, 4, 54, 48, 52, 23, 49, 6, 41, 8, 51, 12, 41, 8, 51, 33, 31, 10, 51, 50, 7, 91, 51, 6, 7, 13, 53, 33, 7, 70, 35, 57, 7, 16, 51, 21, 7, 78, 35, 50, 31, 78, 51, 57, 7, 17, 35, 30, 15, 90, 35, 26, 22, 27, 54, 6, 15, 74, 35, 33, 7, 0, 1, 2, 162, 67, 53, 48, 19, 67, 54, 57, 19, 4, 71, 50, 19, 23, 45, 57, 41, 23, 54, 12, 41, 10, 54, 33, 19, 13, 53, 50, 41, 16, 71, 57, 7, 78, 51, 48, 15, 78, 54, 57, 7, 78, 35, 50, 31, 78, 51, 21, 7, 90, 51, 9, 15, 90, 51, 12, 15, 74, 51, 33, 15, 74, 63, 21, 22, 74, 64, 21, 15, 0, 67, 35, 33, 31, 67, 35, 50, 15, 23, 71, 57, 15, 23, 54, 21, 7, 8, 54, 50, 15, 72, 51, 6, 7, 91, 51, 21, 15, 91, 51, 33, 15, 13, 35, 6, 7, 70, 54, 57, 7, 16, 35, 21, 7, 78, 51, 50, 15, 78, 51, 111, 66, 17, 54, 6, 7, 90, 45, 33, 15, 74, 54, 21, 7, 74, 53, 57, 15, 0, 1, 2, 162, 1, 53, 33, 15, 67, 45, 33, 66, 4, 35, 50, 15, 23, 51, 57, 7, 8, 51, 21, 7, 10, 63, 57, 31, 10, 49, 33, 31, 13, 64, 57, 15, 91, 54, 21, 22, 70, 51, 96, 7, 78, 35, 33, 31, 17, 53, 6, 22, 78, 35, 33, 15, 90, 54, 57, 7, 90, 54, 21, 15, 27, 54, 57, 7, 74, 71, 50, 22, 0, 1, 43, 117, 1, 49, 30, 52, 1, 54, 12, 52, 1, 54, 33, 52, 1, 35, 57, 52, 4, 51, 21, 7, 8, 54, 33, 52, 8, 53, 50, 52, 8, 51, 6, 52, 13, 54, 9, 7, 13, 53, 21, 7, 16, 49, 33, 31, 17, 35, 50, 7, 17, 51, 9, 15, 17, 54, 21, 7, 17, 63, 33, 15, 27, 35, 50, 15, 0, 1, 35, 33, 31, 1, 35, 6, 15, 1, 35, 21, 31, 1, 49, 57, 15, 8, 35, 111, 42, 8, 71, 33, 52, 8, 53, 6, 41, 10, 123, 57, 31, 13, 35, 33, 31, 13, 51, 6, 31, 16, 35, 33, 7, 17, 35, 6, 7, 17, 51, 57, 31, 27, 49, 21, 7, 0, 1, 64, 111, 36, 1, 45, 55, 77, 1, 35, 33, 52, 1, 54, 6, 15, 1, 53, 57, 52, 4, 51, 33, 31, 8, 53, 6, 31, 8, 35, 57, 52, 10, 49, 21, 7, 13, 35, 57, 52, 13, 35, 33, 31, 16, 32, 21, 7, 17, 32, 118, 15, 17, 53, 57, 7, 90, 35, 33, 22, 27, 49, 12, 7, 74, 35, 48, 52, 0, 1, 54, 6, 22, 1, 2, 162, 1, 35, 57, 31, 1, 53, 33, 47, 1, 53, 57, 41, 4, 63, 57, 52, 8, 49, 57, 52, 10, 49, 21, 31, 10, 35, 57, 15, 13, 24, 21, 7, 13, 51, 50, 15, 13, 54, 57, 7, 13, 51, 96, 7, 16, 51, 96, 15, 17, 35, 21, 22, 27, 54, 57, 7, 0, 1, 54, 6, 31, 1, 54, 57, 52, 1, 32, 21, 31, 4, 35, 6, 31, 4, 35, 57, 7, 8, 32, 6, 22, 10, 64, 57, 22, 13, 35, 55, 47, 16, 35, 21, 22, 17, 49, 57, 7, 90, 54, 21, 7, 27, 51, 96, 15, 74, 35, 6, 31, 0, 1, 2, 162, 1, 35, 57, 15, 1, 54, 6, 15, 4, 54, 21, 15, 4, 49, 111, 52, 23, 64, 21, 7, 8, 35, 50, 22, 8, 54, 57, 15, 10, 49, 57, 15, 10, 35, 33, 15, 10, 35, 57, 15, 13, 35, 33, 42, 16, 35, 33, 47, 78, 51, 6, 15, 17, 53, 21, 7, 90, 35, 33, 52, 27, 51, 57, 31, 0, 1, 53, 96, 7, 4, 53, 50, 15, 8, 54, 6, 7, 8, 54, 57, 15, 10, 49, 12, 7, 91, 54, 122, 77, 16, 53, 33, 52, 78, 35, 50, 15, 17, 49, 9, 52, 17, 49, 57, 7, 0, 1, 51, 48, 52, 1, 51, 6, 41, 1, 53, 57, 15, 23, 35, 12, 31, 8, 35, 33, 41, 10, 53, 6, 15]\n",
      "=> Saving checkpoint\n",
      "| Test Loss: 8.125 | Test PPL: 3378.302 |\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 2000\n",
    "S_EPOCH = 0\n",
    "CLIP = 1\n",
    "\n",
    "train_loss_log = []\n",
    "valid_loss_log = []\n",
    "best_valid_loss = float('inf')\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "#model = nn.DataParallel(model, device_ids=[0,1]).to(device)\n",
    "for epoch in range(S_EPOCH, N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iter, criterion)\n",
    "    \n",
    "    \n",
    "    train_loss_log.append(train_loss)\n",
    "    valid_loss_log.append(valid_loss)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        checkpoint = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "        save_best_checkpoint(checkpoint,N_EPOCHS)\n",
    "    if (epoch+1) % 20 == 0 or (epoch) % 20 == 0:\n",
    "        save_final_checkpoint(checkpoint,epoch)\n",
    "    if (epoch+1) % 25 ==0:\n",
    "        if check_mode_collapse(model) > 1:\n",
    "            print(\"model is mode collapsing\")\n",
    "save_final_checkpoint(checkpoint,N_EPOCHS)\n",
    "test_loss = evaluate(model, test_iter, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce0fa416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = {'model_state_dict': model.state_dict(),\n",
    "#                   'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                   'valid_loss': valid_loss}\n",
    "# save_checkpoint(destination_folder + checkpoint,N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff4403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(folder + \"train_loss_log.pkl\", 'wb')\n",
    "pickle.dump(train_loss_log, output)\n",
    "output.close()\n",
    "\n",
    "output = open(folder + \"valid_loss_log.pkl\", 'wb')\n",
    "pickle.dump(valid_loss_log, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33caff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(destination_folder + '/1000_checkpoint.pt', map_location=device)\n",
    "load_checkpoint(state, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501467c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(model, test_iter, criterion)\n",
    "print(math.exp(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_outputs = folder +  \"/generated_samples_1000epochs\"\n",
    "Path(generated_outputs+\"/main\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/piano\").mkdir(parents=True, exist_ok=True)\n",
    "Path(generated_outputs+\"/piano_predict\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_intro = pd.read_csv(source_folder + '/test_torchtext.csv')\n",
    "test_main = df_intro['main'].values\n",
    "test_piano = df_intro['piano'].values\n",
    "test_data=[]\n",
    "for i in range(len(val_main)):\n",
    "    temp_dict = {}\n",
    "    temp_dict['main'] = test_main[i]\n",
    "    temp_dict['piano'] = test_piano[i]\n",
    "    test_data.append(temp_dict)\n",
    "print(len(test_piano))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caada925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(test_piano)):\n",
    "#     if len(test_intro) > 1200:\n",
    "#         continue\n",
    "    main = test_main[i]\n",
    "    piano = test_piano[i]\n",
    "    list_main = [int(x) for x in main.split(' ')]\n",
    "    list_piano = [int(x) for x in piano.split(' ')]\n",
    "    \n",
    "    translated_sentence = translate_sentence(model, main, main_field, piano_field, device, max_length=3000)\n",
    "        #print(translated_sentence)\n",
    "    translated_sentence = [int(x) for x in translated_sentence if x != '<pad>' and x != '<sos>' and x != '<eos>' and x != '<unk>']\n",
    "    print(translated_sentence)\n",
    "    utils.write_midi(list_main, word2event, generated_outputs + \"/main/\" + \"/main\" + str(i)  + \".mid\")\n",
    "    utils.write_midi(list_piano, word2event, generated_outputs  + \"/piano/\" + \"/piano\" + str(i)  + \".mid\")\n",
    "    utils.write_midi(translated_sentence, word2event, generated_outputs + \"/piano_predict/\" + \"/piano_predict\" + str(i)  + \".mid\")\n",
    "    print(i)\n",
    "#     if i == 10:\n",
    "#         break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b85e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "for i in range(11):\n",
    "    piano = mido.MidiFile(generated_outputs + \"/piano/\" + '/piano' + str(i) + '.mid')\n",
    "    main = mido.MidiFile(generated_outputs + \"/main/\" +'/main' + str(i) + '.mid')\n",
    "    predict = mido.MidiFile(generated_outputs + \"/piano_predict/\" +'/piano_predict' + str(i) + '.mid')\n",
    "\n",
    "    piano.tracks[1].name = \"piano\"\n",
    "    main.tracks[1].name = \"main\"\n",
    "    predict.tracks[1].name = \"piano_predict\"\n",
    "    merged_mid = mido.MidiFile()\n",
    "    merged_mid.ticks_per_beat = main.ticks_per_beat\n",
    "    merged_mid.tracks = piano.tracks + main.tracks \n",
    "    merged_mid.save(generated_outputs + '/merged' + str(i) + '.mid')\n",
    "    \n",
    "    merged_mid = mido.MidiFile()\n",
    "    merged_mid.ticks_per_beat = main.ticks_per_beat\n",
    "    merged_mid.tracks = predict.tracks + main.tracks \n",
    "    merged_mid.save(generated_outputs + '/merged_predict' + str(i) + '.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b29e021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_intro' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24393/483130940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# dissimilar_interpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_intro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#     if len(test_intro) > 1200:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#         continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mintro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_intro\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_intro' is not defined"
     ]
    }
   ],
   "source": [
    "# dissimilar_interpolation\n",
    "for i in range(0,len(test_intro)):\n",
    "#     if len(test_intro) > 1200:\n",
    "#         continue\n",
    "    intro = test_intro[i]\n",
    "    #solo = test_solo[i]\n",
    "    if i + 3 < (len(test_intro)):\n",
    "        outro = test_outro[i+3]\n",
    "    else:\n",
    "        outro = test_outro[i]\n",
    "    #print(intro)\n",
    "    #print(outro)\n",
    "    list_intro = [int(x) for x in intro.split(' ')]\n",
    "    #list_solo = [int(x) for x in solo.split(' ')]\n",
    "    list_outro = [int(x) for x in outro.split(' ')]\n",
    "    #print(list_sentence)\n",
    "    translated_sentence = translate_sentence(model, intro, outro, intro_field, outro_field, solo_field, device, max_length=1200)\n",
    "    #print(translated_sentence)\n",
    "    translated_sentence = [int(x) for x in translated_sentence if x != '<pad>' and x != '<sos>' and x != '<eos>' and x != '<unk>']\n",
    "    print(translated_sentence)\n",
    "    utils.write_midi(list_intro, word2event, dissimilar_interpolation + \"/intro/\" + \"/intro\" + str(i)  + \".mid\")\n",
    "    #utils.write_midi(list_solo, word2event, generated_outputs  + \"/solo/\" + \"/solo\" + str(i)  + \".mid\")\n",
    "    utils.write_midi(list_outro, word2event, dissimilar_interpolation + \"/outro/\" + \"/outro\" + str(i)  + \".mid\")\n",
    "    utils.write_midi(translated_sentence, word2event, dissimilar_interpolation + \"/predict/\" + \"/predict\" + str(i)  + \".mid\")\n",
    "    print(i)\n",
    "#     if i == 10:\n",
    "#         break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb2841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "for i in range(len(test_intro)):\n",
    "    intro = mido.MidiFile(dissimilar_interpolation + \"/intro/\" + '/intro' + str(i) + '.mid')\n",
    "    outro = mido.MidiFile(dissimilar_interpolation + \"/outro/\" +'/outro' + str(i) + '.mid')\n",
    "    predict = mido.MidiFile(dissimilar_interpolation + \"/predict/\" +'/predict' + str(i) + '.mid')\n",
    "    total_intro_time = 0\n",
    "    total_solo_time = 0\n",
    "    total_predict_time = 0\n",
    "    for msg in intro.tracks[1]:\n",
    "        if msg.type == \"note_on\":\n",
    "            total_intro_time += msg.time\n",
    "    for msg in predict.tracks[1]:\n",
    "        if msg.type == \"note_on\":\n",
    "            total_predict_time += msg.time\n",
    "            \n",
    "    original_outro_time = 0 + outro.tracks[1][1].time\n",
    "    \n",
    "    print(original_outro_time + total_predict_time + total_intro_time)\n",
    "    predict.tracks[1][1].time += total_intro_time\n",
    "    outro.tracks[1][1].time = original_outro_time + total_predict_time + total_intro_time\n",
    "    print(outro.tracks[1][1].time)\n",
    "    merged_mid = mido.MidiFile()\n",
    "    merged_mid.ticks_per_beat = intro.ticks_per_beat\n",
    "    merged_mid.tracks = intro.tracks + predict.tracks + outro.tracks\n",
    "    merged_mid.save(dissimilar_interpolation + '/merged_predict' + str(i) + '.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchNode(object):\n",
    "    def __init__(self, prev_node, wid, logp, length):\n",
    "        self.prev_node = prev_node\n",
    "        self.wid = wid\n",
    "        self.logp = logp\n",
    "        self.length = length\n",
    "\n",
    "    def eval(self):\n",
    "        return self.logp / float(self.length - 1 + 1e-6)\n",
    "# }}}\n",
    "import copy\n",
    "from heapq import heappush, heappop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2930460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence_beam(model, sentence, german, english, device, max_length=1200,beam_width=2,max_dec_steps=25000):\n",
    "    \n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    tokens = [token.lower() for token in sentence.split(' ')]\n",
    "    # print(tokens)\n",
    "\n",
    "    # sys.exit()\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    eos_token = english.vocab.stoi[\"<eos>\"]\n",
    "    sos_token = english.vocab.stoi[\"<sos>\"]\n",
    "    \n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "    \n",
    "    n_best_list = []\n",
    "    \n",
    "     \n",
    "    #trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "    #first token as input\n",
    "    trg_tensor = torch.LongTensor(outputs).to(device)\n",
    "    \n",
    "    end_nodes = []\n",
    "\n",
    "    #starting node\n",
    "    node = BeamSearchNode(prev_node=None, wid=trg_tensor, logp=0, length=1)\n",
    "\n",
    "    nodes = []\n",
    "\n",
    "    heappush(nodes, (-node.eval(), id(node), node))\n",
    "    n_dec_steps = 0\n",
    "\n",
    "    while True:\n",
    "        # Give up when decoding takes too long\n",
    "        if n_dec_steps > max_dec_steps:\n",
    "            break\n",
    "        \n",
    "        # Fetch the best node\n",
    "        #print([n[2].wid for n in nodes])\n",
    "        score, _, n = heappop(nodes)\n",
    "        decoder_input = n.wid\n",
    "        \n",
    "        if n.wid.item() == eos_token and n.prev_node is not None:\n",
    "            end_nodes.append((score, id(n), n))\n",
    "            # If we reached maximum # of sentences required\n",
    "            if len(end_nodes) >= beam_width:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "   \n",
    "        sequence = [n.wid.item()]\n",
    "        a = n\n",
    "        while a.prev_node is not None:\n",
    "            a = a.prev_node\n",
    "            sequence.append(a.wid.item())\n",
    "        sequence = sequence[::-1] # reverse\n",
    "        \n",
    "        #print(sequence)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, torch.LongTensor(sequence).unsqueeze(1).to(device))\n",
    "        \n",
    "        # Get top-k from this decoded result\n",
    "        topk_log_prob, topk_indexes = torch.topk(output, beam_width)\n",
    "        #print(topk_indexes)\n",
    "        #print(topk_log_prob)\n",
    "        # Then, register new top-k nodes\n",
    "        for new_k in range(beam_width):\n",
    "            decoded_t = topk_indexes[0][0][new_k].view(1) # (1)\n",
    "            logp = topk_log_prob[0][0][new_k].item() # float log probability val\n",
    "\n",
    "            node = BeamSearchNode(prev_node=n,\n",
    "                                  wid=decoded_t,\n",
    "                                  logp=n.logp+logp,\n",
    "                                  length=n.length+1)\n",
    "            heappush(nodes, (-node.eval(), id(node), node))\n",
    "        n_dec_steps += beam_width\n",
    "        #print(n_dec_steps)\n",
    "    # if there are no end_nodes, retrieve best nodes (they are probably truncated)\n",
    "    if len(end_nodes) == 0:\n",
    "        end_nodes = [heappop(nodes) for _ in range(beam_width)]\n",
    "\n",
    "    # Construct sequences from end_nodes\n",
    "    n_best_seq_list = []\n",
    "    for score, _id, n in sorted(end_nodes, key=lambda x: x[0]):\n",
    "        sequence = [n.wid.item()]\n",
    "        # back trace from end node\n",
    "        while n.prev_node is not None:\n",
    "            n = n.prev_node\n",
    "            sequence.append(n.wid.item())\n",
    "        sequence = sequence[::-1] # reverse\n",
    "\n",
    "        n_best_seq_list.append(sequence)\n",
    "\n",
    "\n",
    "    # return n_best_seq_list\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in n_best_seq_list[0]]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocab(vocab, path):\n",
    "    output = open(path, 'wb')\n",
    "    pickle.dump(vocab, output)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vocab(intro_field.vocab, vocab + '/intro_vocab.pkl')\n",
    "save_vocab(solo_field.vocab, vocab + '/solo_vocab.pkl')\n",
    "save_vocab(outro_field.vocab, vocab + '/outro_vocab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_translate_sentence(model, sentence, german, english, device, max_length=1200):\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    #tokens = [token.lower() for token in sentence.split(' ')]\n",
    "    # print(tokens)\n",
    "\n",
    "    # sys.exit()\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    #tokens.insert(0, german.init_token)\n",
    "    #tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    #text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(sentence).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e97881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    print(len(data))\n",
    "    for example in data:\n",
    "        #print( vars(example))\n",
    "        src = vars(example)[\"intro\"]\n",
    "        trg = vars(example)[\"solo\"]\n",
    "        \n",
    "        src = [int(x) for x in src]\n",
    "        trg = [int(x) for x in trg]\n",
    "        \n",
    "        if len(trg) > 1200 or len(src) > 1200:\n",
    "            continue\n",
    "        \n",
    "        prediction = bleu_translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append(trg)\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a9cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running on entire test data takes a while\n",
    "score = bleu(test[1:10], model, intro_field, solo_field, device)\n",
    "print(f\"Bleu score {score * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
