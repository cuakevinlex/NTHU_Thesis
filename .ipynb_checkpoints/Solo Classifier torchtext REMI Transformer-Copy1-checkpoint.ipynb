{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022889aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dataset folder\n",
    "source_folder = \"solo_classification_REMI_dataset_unbalanced\"\n",
    "# where it saves the weights\n",
    "destination_folder = \"solo_classification_transformer_REMI_weights_unaugmented_200epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193a1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "print(dev)\n",
    "device = torch.device(dev)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d8407f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True)\n",
    "fields = [('labels', label_field), ('notes', text_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='val.csv', test='test.csv',\n",
    "                                           format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "test_iter = BucketIterator(test, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "\n",
    "# Vocabulary\n",
    "\n",
    "text_field.build_vocab(train, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f967294",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(text_field.vocab)\n",
    "emsize = 200\n",
    "d_hid = 64\n",
    "nlayers = 2 \n",
    "nhead = 8\n",
    "dropout = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa477d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  7, 58,  ..., 32, 38, 69],\n",
      "        [ 4,  7, 30,  ...,  8, 63,  5],\n",
      "        [ 4,  7, 30,  ..., 43,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   8,  31,   5],\n",
      "        [  4,   7,  58,  ...,  41,  63,   3],\n",
      "        [  4,   7,  30,  ...,   8,  27, 115],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   8,  29, 118],\n",
      "        [  4,   7,  58,  ...,  32,  43,  46],\n",
      "        [  4,   7,  58,  ...,  35,  46,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 23,  6],\n",
      "        [ 4,  7, 30,  ..., 22, 27,  5],\n",
      "        [ 4,  7, 30,  ..., 15, 39,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 38, 84],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ...,  9, 23,  5],\n",
      "        [ 4,  7, 58,  ..., 67, 27,  3],\n",
      "        [ 4,  7, 30,  ..., 22, 52, 96],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 15, 47,  5],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 22, 44,  2],\n",
      "        [ 4,  7, 30,  ..., 17, 39,  6],\n",
      "        [ 4,  7, 30,  ..., 32, 23, 85],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  53,  35,  73],\n",
      "        [  4,   7,  30,  ...,   8,  55,  73],\n",
      "        [  4,   7,  30,  ...,  32,  70,   3],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  17,  52, 164],\n",
      "        [  4,   7,  30,  ...,  32,  23,  91],\n",
      "        [  4,   7,  30,  ...,  15,  55,  96]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  41,  52,   5],\n",
      "        [  4,   7,  30,  ...,  12,  57,   6],\n",
      "        [  4,   7,  58,  ...,  51,  43,   2],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  78,   1,   1],\n",
      "        [  4,   7,  30,  ...,  72,   1,   1],\n",
      "        [  4,   7,  30,  ..., 103,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 24, 82, 84],\n",
      "        [ 4,  7, 58,  ...,  3,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  15,  35, 105],\n",
      "        [  4,   7,  58,  ...,  41,  47,  46],\n",
      "        [  4,   7,  30,  ...,  51,  31, 172],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  12,  43,   3],\n",
      "        [  4,   7,  30,  ...,  24,  52,  49],\n",
      "        [  4,   7,  30,  ...,  22,  55, 138],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  17,  52,  89],\n",
      "        [  4,   7,  58,  ...,   8,  40,   5],\n",
      "        [  4,   7,  30,  ...,  32,  35, 119]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  22,  38,  72],\n",
      "        [  4,   7,  30,  ...,  40, 105,   1],\n",
      "        [  4,   7,  30,  ...,  75,  90,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 12, 55,  5],\n",
      "        [ 4,  7, 58,  ..., 41, 35, 45],\n",
      "        [ 4,  7, 30,  ..., 29,  2,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 24, 50,  6],\n",
      "        [ 4,  7, 30,  ..., 30, 87,  1],\n",
      "        [ 4,  7, 30,  ..., 47, 61,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  15,  35,  61],\n",
      "        [  4,   7, 186,  ...,  51,  29, 105],\n",
      "        [  4,   7, 186,  ...,  29,  46,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,  11,  17,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  12,  56,   2],\n",
      "        [  4,   7,  30,  ...,  15,  31,  45],\n",
      "        [  4,   7,  30,  ...,  12, 139,   2],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  27,   2,   1],\n",
      "        [  4,   7,  30,  ...,  38,  46,   1],\n",
      "        [  4,   7,  30,  ...,  43, 120,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   9,  39,   2],\n",
      "        [  4,   7,  30,  ...,  15,  35, 105],\n",
      "        [  4,   7,  30,  ...,  12,  23,  74],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ..., 180,   1,   1],\n",
      "        [  4,   7,  30,  ...,   2,   1,   1],\n",
      "        [  4,   7,  58,  ...,  84,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 12, 52,  2],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  59,  88,  89],\n",
      "        [  4,   7,  30,  ...,  16,  30, 132],\n",
      "        [  4,   7,  30,  ...,  40, 116,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 51, 70, 96],\n",
      "        [ 4,  7, 30,  ..., 32, 27,  3],\n",
      "        [ 4,  7, 30,  ..., 14, 97,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 12, 71,  6],\n",
      "        [ 4,  7, 30,  ..., 32, 40, 96],\n",
      "        [ 4,  7, 30,  ..., 24, 31,  6],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 24, 66,  3],\n",
      "        [ 4,  7, 58,  ..., 15, 56, 96],\n",
      "        [ 4,  7, 58,  ..., 24, 29, 46],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4, 16, 12,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  22,  83,   5],\n",
      "        [  4,   7,  58,  ...,  22,  55,  45],\n",
      "        [  4,   7,  30,  ...,  10,  27,   2],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  57,   3,   1],\n",
      "        [  4,   7,  30,  ...,  43,  61,   1],\n",
      "        [  4,   7,  58,  ...,  23, 105,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  53,  38,  84],\n",
      "        [  4,   7,  30,  ...,  16,  30, 102],\n",
      "        [  4,   7,  30,  ...,  15,  57,   5],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 22, 27, 61],\n",
      "        [ 4,  7, 30,  ..., 24, 44,  5],\n",
      "        [ 4,  7, 30,  ..., 12, 44,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  12,  63, 115],\n",
      "        [  4,   7,  58,  ...,  22,  55,  90],\n",
      "        [  4,   7,  30,  ...,  32,  43,  46],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ...,  8, 55, 45],\n",
      "        [ 4,  7, 30,  ..., 15, 35,  6],\n",
      "        [ 4,  7, 30,  ..., 22, 23, 90],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  22,  38,  45],\n",
      "        [  4,   7,  30,  ...,  44, 118,   1],\n",
      "        [  4,   7,  58,  ...,  44,  84,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,  52,   3,   1],\n",
      "        [  4,   7,  58,  ...,  29,  49,   1],\n",
      "        [  4,   7,  30,  ...,  27, 127,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  65,  55,   3],\n",
      "        [  4,   7,  58,  ...,  24,  62,   5],\n",
      "        [  4,   7,  58,  ...,  17,  92, 208],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  53,  29,   3],\n",
      "        [  4,   7,  30,  ...,  17,  82,   2],\n",
      "        [  4,   7,  30,  ...,   8,  92, 119],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  17,  55, 143],\n",
      "        [  4,   7,  30,  ...,   8,  29, 144],\n",
      "        [  4,   7,  58,  ...,   8,  38, 164]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  14,  48,  72],\n",
      "        [  4,   7,  30,  ...,  24,  31, 119],\n",
      "        [  4,   7,  30,  ...,   5,   1,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  14,  57,  90],\n",
      "        [  4,   7,  58,  ...,  23,   6,   1],\n",
      "        [  4,   7,  30,  ...,  48, 172,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  15,  44,   6],\n",
      "        [  4,   7,  58,  ...,   8,  52,  45],\n",
      "        [  4,   7,  30,  ...,  51,  29, 118],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  67,  40,   2],\n",
      "        [  4,   7,  30,  ...,  38,  84,   1],\n",
      "        [  4,   7, 186,  ...,  83,  46,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  22,  47,   5],\n",
      "        [  4,   7,  30,  ...,  15,  39,  45],\n",
      "        [  4,   7,  30,  ...,   8,  62,   2],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  44, 105,   1],\n",
      "        [  4,   7,  30,  ...,  63, 105,   1],\n",
      "        [  4,   7,  58,  ...,  27,  91,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   8,  31, 214],\n",
      "        [  4,   7,  58,  ...,  38, 171,   1],\n",
      "        [  4,   7,  58,  ...,  50,   3,   1],\n",
      "        ...,\n",
      "        [  4,  28,  15,  ...,   1,   1,   1],\n",
      "        [  4,   7, 186,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  14,  40, 116],\n",
      "        [  4,   7,  30,  ...,  15,  29,   5],\n",
      "        [  4,   7,  30,  ...,  53,  27, 116],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 10, 43, 96],\n",
      "        [ 4,  7, 30,  ..., 53, 44,  3],\n",
      "        [ 4,  7, 58,  ..., 32, 35,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 47,  2],\n",
      "        [ 4,  7, 30,  ..., 54,  3,  1],\n",
      "        [ 4,  7, 30,  ..., 82, 84,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  41,  57,   2],\n",
      "        [  4,   7,  58,  ...,  17, 128,   3],\n",
      "        [  4,   7,  30,  ...,  17,  29,   2],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  22,  29,  61],\n",
      "        [  4,   7,  58,  ...,  15,  63, 103],\n",
      "        [  4,   7,  58,  ...,  12,  39,   5],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 12, 63, 46],\n",
      "        [ 4,  7, 30,  ..., 23,  6,  1],\n",
      "        [ 4,  7, 58,  ..., 43,  2,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  2,  1,  1],\n",
      "        [ 4,  7, 30,  ..., 96,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  32,  62, 138],\n",
      "        [  4,   7,  30,  ...,  12,  35, 153],\n",
      "        [  4,   7,  58,  ...,  22,  39,   3],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 24, 38,  3],\n",
      "        [ 4,  7, 30,  ..., 12, 29, 85],\n",
      "        [ 4,  7, 30,  ..., 22, 31, 49],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  12,  44, 120],\n",
      "        [  4,   7,  30,  ...,  10,  48, 127],\n",
      "        [  4,   7,  30,  ...,   8,  70, 103],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  10,  39,   2],\n",
      "        [  4,   7,  58,  ...,  51,  23,  91],\n",
      "        [  4,   7,  30,  ...,  24,  44, 115],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  41,  52,   5],\n",
      "        [  4,   7,  58,  ...,  67,  54,   2],\n",
      "        [  4,   7,  58,  ...,  51,  63, 164],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  35,  45,   1],\n",
      "        [  4,   7,  58,  ...,  72,   1,   1],\n",
      "        [  4,   7,  30,  ...,  74,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 17, 44, 45],\n",
      "        [ 4,  7, 58,  ..., 52,  3,  1],\n",
      "        [ 4,  7, 58,  ..., 70, 61,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for (labels, (notes, notes_len)), _ in (train_iter):\n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82eec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4d0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, 2)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.mean(dim=1)\n",
    "        output = self.decoder(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32976625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load Functions https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0\n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c88beb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Step [50/25000], Train Loss: 0.6645, Valid Loss: 0.6447\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.632446134347275\n",
      "Epoch [2/500], Step [100/25000], Train Loss: 0.6461, Valid Loss: 0.6469\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [3/500], Step [150/25000], Train Loss: 0.6401, Valid Loss: 0.6492\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [4/500], Step [200/25000], Train Loss: 0.6387, Valid Loss: 0.6448\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [5/500], Step [250/25000], Train Loss: 0.6352, Valid Loss: 0.6351\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [6/500], Step [300/25000], Train Loss: 0.6323, Valid Loss: 0.6208\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [7/500], Step [350/25000], Train Loss: 0.6296, Valid Loss: 0.6042\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [8/500], Step [400/25000], Train Loss: 0.6256, Valid Loss: 0.5916\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [9/500], Step [450/25000], Train Loss: 0.6209, Valid Loss: 0.5699\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.670468948035488\n",
      "Epoch [10/500], Step [500/25000], Train Loss: 0.6111, Valid Loss: 0.5485\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6717363751584284\n",
      "Epoch [11/500], Step [550/25000], Train Loss: 0.5993, Valid Loss: 0.5341\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6711026615969582\n",
      "Epoch [12/500], Step [600/25000], Train Loss: 0.5783, Valid Loss: 0.5340\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.7129277566539924\n",
      "Epoch [13/500], Step [650/25000], Train Loss: 0.5575, Valid Loss: 0.5372\n",
      "Epoch Accuracy: 0.7636248415716096\n",
      "Epoch [14/500], Step [700/25000], Train Loss: 0.5449, Valid Loss: 0.5246\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.811787072243346\n",
      "Epoch [15/500], Step [750/25000], Train Loss: 0.5334, Valid Loss: 0.5164\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8136882129277566\n",
      "Epoch [16/500], Step [800/25000], Train Loss: 0.5266, Valid Loss: 0.5183\n",
      "Epoch Accuracy: 0.8200253485424588\n",
      "Epoch [17/500], Step [850/25000], Train Loss: 0.5245, Valid Loss: 0.5077\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8003802281368821\n",
      "Epoch [18/500], Step [900/25000], Train Loss: 0.5197, Valid Loss: 0.5136\n",
      "Epoch Accuracy: 0.8067173637515843\n",
      "Epoch [19/500], Step [950/25000], Train Loss: 0.5162, Valid Loss: 0.5131\n",
      "Epoch Accuracy: 0.8193916349809885\n",
      "Epoch [20/500], Step [1000/25000], Train Loss: 0.5136, Valid Loss: 0.5093\n",
      "Epoch Accuracy: 0.8149556400506971\n",
      "Epoch [21/500], Step [1050/25000], Train Loss: 0.5106, Valid Loss: 0.5137\n",
      "Epoch Accuracy: 0.8086185044359949\n",
      "Epoch [22/500], Step [1100/25000], Train Loss: 0.5085, Valid Loss: 0.5077\n",
      "Epoch Accuracy: 0.8092522179974652\n",
      "Epoch [23/500], Step [1150/25000], Train Loss: 0.5085, Valid Loss: 0.5085\n",
      "Epoch Accuracy: 0.8060836501901141\n",
      "Epoch [24/500], Step [1200/25000], Train Loss: 0.5073, Valid Loss: 0.5100\n",
      "Epoch Accuracy: 0.8130544993662865\n",
      "Epoch [25/500], Step [1250/25000], Train Loss: 0.5048, Valid Loss: 0.5073\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8067173637515843\n",
      "Epoch [26/500], Step [1300/25000], Train Loss: 0.5018, Valid Loss: 0.5101\n",
      "Epoch Accuracy: 0.8181242078580482\n",
      "Epoch [27/500], Step [1350/25000], Train Loss: 0.5009, Valid Loss: 0.5049\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.820659062103929\n",
      "Epoch [28/500], Step [1400/25000], Train Loss: 0.4993, Valid Loss: 0.5088\n",
      "Epoch Accuracy: 0.8181242078580482\n",
      "Epoch [29/500], Step [1450/25000], Train Loss: 0.4972, Valid Loss: 0.4971\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8219264892268695\n",
      "Epoch [30/500], Step [1500/25000], Train Loss: 0.4960, Valid Loss: 0.4900\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8174904942965779\n",
      "Epoch [31/500], Step [1550/25000], Train Loss: 0.4937, Valid Loss: 0.4790\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8326996197718631\n",
      "Epoch [32/500], Step [1600/25000], Train Loss: 0.4971, Valid Loss: 0.4942\n",
      "Epoch Accuracy: 0.8212927756653993\n",
      "Epoch [33/500], Step [1650/25000], Train Loss: 0.4888, Valid Loss: 0.4765\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8250950570342205\n",
      "Epoch [34/500], Step [1700/25000], Train Loss: 0.4891, Valid Loss: 0.4773\n",
      "Epoch Accuracy: 0.8269961977186312\n",
      "Epoch [35/500], Step [1750/25000], Train Loss: 0.4858, Valid Loss: 0.4749\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8346007604562737\n",
      "Epoch [36/500], Step [1800/25000], Train Loss: 0.4814, Valid Loss: 0.4823\n",
      "Epoch Accuracy: 0.8396704689480355\n",
      "Epoch [37/500], Step [1850/25000], Train Loss: 0.4796, Valid Loss: 0.4720\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8339670468948035\n",
      "Epoch [38/500], Step [1900/25000], Train Loss: 0.4801, Valid Loss: 0.4861\n",
      "Epoch Accuracy: 0.8365019011406845\n",
      "Epoch [39/500], Step [1950/25000], Train Loss: 0.4763, Valid Loss: 0.4810\n",
      "Epoch Accuracy: 0.8428390367553865\n",
      "Epoch [40/500], Step [2000/25000], Train Loss: 0.4752, Valid Loss: 0.4823\n",
      "Epoch Accuracy: 0.8422053231939164\n",
      "Epoch [41/500], Step [2050/25000], Train Loss: 0.4719, Valid Loss: 0.4666\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8536121673003803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/500], Step [2100/25000], Train Loss: 0.4716, Valid Loss: 0.4791\n",
      "Epoch Accuracy: 0.8479087452471483\n",
      "Epoch [43/500], Step [2150/25000], Train Loss: 0.4674, Valid Loss: 0.4663\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8466413181242078\n",
      "Epoch [44/500], Step [2200/25000], Train Loss: 0.4696, Valid Loss: 0.4720\n",
      "Epoch Accuracy: 0.8447401774397972\n",
      "Epoch [45/500], Step [2250/25000], Train Loss: 0.4667, Valid Loss: 0.4692\n",
      "Epoch Accuracy: 0.8567807351077313\n",
      "Epoch [46/500], Step [2300/25000], Train Loss: 0.4655, Valid Loss: 0.4624\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.85297845373891\n",
      "Epoch [47/500], Step [2350/25000], Train Loss: 0.4656, Valid Loss: 0.4678\n",
      "Epoch Accuracy: 0.8479087452471483\n",
      "Epoch [48/500], Step [2400/25000], Train Loss: 0.4610, Valid Loss: 0.4619\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.861850443599493\n",
      "Epoch [49/500], Step [2450/25000], Train Loss: 0.4635, Valid Loss: 0.4683\n",
      "Epoch Accuracy: 0.858681875792142\n",
      "Epoch [50/500], Step [2500/25000], Train Loss: 0.4601, Valid Loss: 0.4640\n",
      "Epoch Accuracy: 0.8542458808618505\n",
      "Epoch [51/500], Step [2550/25000], Train Loss: 0.4565, Valid Loss: 0.4672\n",
      "Epoch Accuracy: 0.861850443599493\n",
      "Epoch [52/500], Step [2600/25000], Train Loss: 0.4572, Valid Loss: 0.4663\n",
      "Epoch Accuracy: 0.861850443599493\n",
      "Epoch [53/500], Step [2650/25000], Train Loss: 0.4526, Valid Loss: 0.4766\n",
      "Epoch Accuracy: 0.861850443599493\n",
      "Epoch [54/500], Step [2700/25000], Train Loss: 0.4545, Valid Loss: 0.4626\n",
      "Epoch Accuracy: 0.8656527249683144\n",
      "Epoch [55/500], Step [2750/25000], Train Loss: 0.4520, Valid Loss: 0.4594\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8713561470215463\n",
      "Epoch [56/500], Step [2800/25000], Train Loss: 0.4509, Valid Loss: 0.4601\n",
      "Epoch Accuracy: 0.8681875792141952\n",
      "Epoch [57/500], Step [2850/25000], Train Loss: 0.4523, Valid Loss: 0.4594\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.870722433460076\n",
      "Epoch [58/500], Step [2900/25000], Train Loss: 0.4495, Valid Loss: 0.4671\n",
      "Epoch Accuracy: 0.867553865652725\n",
      "Epoch [59/500], Step [2950/25000], Train Loss: 0.4486, Valid Loss: 0.4553\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8694550063371356\n",
      "Epoch [60/500], Step [3000/25000], Train Loss: 0.4433, Valid Loss: 0.4502\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8814955640050697\n",
      "Epoch [61/500], Step [3050/25000], Train Loss: 0.4465, Valid Loss: 0.4591\n",
      "Epoch Accuracy: 0.8745247148288974\n",
      "Epoch [62/500], Step [3100/25000], Train Loss: 0.4410, Valid Loss: 0.4605\n",
      "Epoch Accuracy: 0.8795944233206591\n",
      "Epoch [63/500], Step [3150/25000], Train Loss: 0.4436, Valid Loss: 0.4419\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8738910012674271\n",
      "Epoch [64/500], Step [3200/25000], Train Loss: 0.4419, Valid Loss: 0.4550\n",
      "Epoch Accuracy: 0.8783269961977186\n",
      "Epoch [65/500], Step [3250/25000], Train Loss: 0.4398, Valid Loss: 0.4819\n",
      "Epoch Accuracy: 0.876425855513308\n",
      "Epoch [66/500], Step [3300/25000], Train Loss: 0.4385, Valid Loss: 0.4545\n",
      "Epoch Accuracy: 0.8840304182509505\n",
      "Epoch [67/500], Step [3350/25000], Train Loss: 0.4365, Valid Loss: 0.4509\n",
      "Epoch Accuracy: 0.8859315589353612\n",
      "Epoch [68/500], Step [3400/25000], Train Loss: 0.4336, Valid Loss: 0.4449\n",
      "Epoch Accuracy: 0.8891001267427123\n",
      "Epoch [69/500], Step [3450/25000], Train Loss: 0.4367, Valid Loss: 0.4419\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8878326996197718\n",
      "Epoch [70/500], Step [3500/25000], Train Loss: 0.4338, Valid Loss: 0.4492\n",
      "Epoch Accuracy: 0.8840304182509505\n",
      "Epoch [71/500], Step [3550/25000], Train Loss: 0.4289, Valid Loss: 0.4444\n",
      "Epoch Accuracy: 0.8884664131812421\n",
      "Epoch [72/500], Step [3600/25000], Train Loss: 0.4289, Valid Loss: 0.4418\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8986058301647655\n",
      "Epoch [73/500], Step [3650/25000], Train Loss: 0.4276, Valid Loss: 0.4441\n",
      "Epoch Accuracy: 0.9005069708491762\n",
      "Epoch [74/500], Step [3700/25000], Train Loss: 0.4268, Valid Loss: 0.4555\n",
      "Epoch Accuracy: 0.8884664131812421\n",
      "Epoch [75/500], Step [3750/25000], Train Loss: 0.4263, Valid Loss: 0.4386\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8916349809885932\n",
      "Epoch [76/500], Step [3800/25000], Train Loss: 0.4267, Valid Loss: 0.4467\n",
      "Epoch Accuracy: 0.8922686945500634\n",
      "Epoch [77/500], Step [3850/25000], Train Loss: 0.4231, Valid Loss: 0.4300\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.903041825095057\n",
      "Epoch [78/500], Step [3900/25000], Train Loss: 0.4243, Valid Loss: 0.4362\n",
      "Epoch Accuracy: 0.8948035487959443\n",
      "Epoch [79/500], Step [3950/25000], Train Loss: 0.4234, Valid Loss: 0.4349\n",
      "Epoch Accuracy: 0.9017743979721166\n",
      "Epoch [80/500], Step [4000/25000], Train Loss: 0.4240, Valid Loss: 0.4357\n",
      "Epoch Accuracy: 0.8979721166032953\n",
      "Epoch [81/500], Step [4050/25000], Train Loss: 0.4246, Valid Loss: 0.4381\n",
      "Epoch Accuracy: 0.8960709759188846\n",
      "Epoch [82/500], Step [4100/25000], Train Loss: 0.4216, Valid Loss: 0.4275\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.903041825095057\n",
      "Epoch [83/500], Step [4150/25000], Train Loss: 0.4211, Valid Loss: 0.4505\n",
      "Epoch Accuracy: 0.899873257287706\n",
      "Epoch [84/500], Step [4200/25000], Train Loss: 0.4203, Valid Loss: 0.4360\n",
      "Epoch Accuracy: 0.9017743979721166\n",
      "Epoch [85/500], Step [4250/25000], Train Loss: 0.4172, Valid Loss: 0.4380\n",
      "Epoch Accuracy: 0.9100126742712294\n",
      "Epoch [86/500], Step [4300/25000], Train Loss: 0.4212, Valid Loss: 0.4449\n",
      "Epoch Accuracy: 0.8992395437262357\n",
      "Epoch [87/500], Step [4350/25000], Train Loss: 0.4158, Valid Loss: 0.4397\n",
      "Epoch Accuracy: 0.9036755386565273\n",
      "Epoch [88/500], Step [4400/25000], Train Loss: 0.4167, Valid Loss: 0.4358\n",
      "Epoch Accuracy: 0.9055766793409379\n",
      "Epoch [89/500], Step [4450/25000], Train Loss: 0.4177, Valid Loss: 0.4398\n",
      "Epoch Accuracy: 0.9036755386565273\n",
      "Epoch [90/500], Step [4500/25000], Train Loss: 0.4145, Valid Loss: 0.4444\n",
      "Epoch Accuracy: 0.9074778200253485\n",
      "Epoch [91/500], Step [4550/25000], Train Loss: 0.4121, Valid Loss: 0.4296\n",
      "Epoch Accuracy: 0.9119138149556401\n",
      "Epoch [92/500], Step [4600/25000], Train Loss: 0.4170, Valid Loss: 0.4365\n",
      "Epoch Accuracy: 0.9011406844106464\n",
      "Epoch [93/500], Step [4650/25000], Train Loss: 0.4110, Valid Loss: 0.4316\n",
      "Epoch Accuracy: 0.9112801013941698\n",
      "Epoch [94/500], Step [4700/25000], Train Loss: 0.4128, Valid Loss: 0.4335\n",
      "Epoch Accuracy: 0.908745247148289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/500], Step [4750/25000], Train Loss: 0.4101, Valid Loss: 0.4323\n",
      "Epoch Accuracy: 0.9125475285171103\n",
      "Epoch [96/500], Step [4800/25000], Train Loss: 0.4167, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.9043092522179975\n",
      "Epoch [97/500], Step [4850/25000], Train Loss: 0.4109, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.9119138149556401\n",
      "Epoch [98/500], Step [4900/25000], Train Loss: 0.4137, Valid Loss: 0.4284\n",
      "Epoch Accuracy: 0.9049429657794676\n",
      "Epoch [99/500], Step [4950/25000], Train Loss: 0.4125, Valid Loss: 0.4284\n",
      "Epoch Accuracy: 0.9055766793409379\n",
      "Epoch [100/500], Step [5000/25000], Train Loss: 0.4100, Valid Loss: 0.4323\n",
      "Epoch Accuracy: 0.9112801013941698\n",
      "Epoch [101/500], Step [5050/25000], Train Loss: 0.4084, Valid Loss: 0.4356\n",
      "Epoch Accuracy: 0.9106463878326996\n",
      "Epoch [102/500], Step [5100/25000], Train Loss: 0.4109, Valid Loss: 0.4320\n",
      "Epoch Accuracy: 0.9068441064638784\n",
      "Epoch [103/500], Step [5150/25000], Train Loss: 0.4073, Valid Loss: 0.4325\n",
      "Epoch Accuracy: 0.9131812420785805\n",
      "Epoch [104/500], Step [5200/25000], Train Loss: 0.4095, Valid Loss: 0.4373\n",
      "Epoch Accuracy: 0.9074778200253485\n",
      "Epoch [105/500], Step [5250/25000], Train Loss: 0.4084, Valid Loss: 0.4347\n",
      "Epoch Accuracy: 0.9112801013941698\n",
      "Epoch [106/500], Step [5300/25000], Train Loss: 0.4047, Valid Loss: 0.4285\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [107/500], Step [5350/25000], Train Loss: 0.4066, Valid Loss: 0.4307\n",
      "Epoch Accuracy: 0.908745247148289\n",
      "Epoch [108/500], Step [5400/25000], Train Loss: 0.4047, Valid Loss: 0.4415\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [109/500], Step [5450/25000], Train Loss: 0.4039, Valid Loss: 0.4197\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [110/500], Step [5500/25000], Train Loss: 0.4036, Valid Loss: 0.4219\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [111/500], Step [5550/25000], Train Loss: 0.4052, Valid Loss: 0.4221\n",
      "Epoch Accuracy: 0.9157160963244614\n",
      "Epoch [112/500], Step [5600/25000], Train Loss: 0.4053, Valid Loss: 0.4192\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9157160963244614\n",
      "Epoch [113/500], Step [5650/25000], Train Loss: 0.4033, Valid Loss: 0.4314\n",
      "Epoch Accuracy: 0.9144486692015209\n",
      "Epoch [114/500], Step [5700/25000], Train Loss: 0.4041, Valid Loss: 0.4201\n",
      "Epoch Accuracy: 0.9150823827629911\n",
      "Epoch [115/500], Step [5750/25000], Train Loss: 0.4040, Valid Loss: 0.4233\n",
      "Epoch Accuracy: 0.9150823827629911\n",
      "Epoch [116/500], Step [5800/25000], Train Loss: 0.4011, Valid Loss: 0.4200\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [117/500], Step [5850/25000], Train Loss: 0.4048, Valid Loss: 0.4175\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9125475285171103\n",
      "Epoch [118/500], Step [5900/25000], Train Loss: 0.4013, Valid Loss: 0.4189\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [119/500], Step [5950/25000], Train Loss: 0.4027, Valid Loss: 0.4227\n",
      "Epoch Accuracy: 0.9144486692015209\n",
      "Epoch [120/500], Step [6000/25000], Train Loss: 0.4021, Valid Loss: 0.4297\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [121/500], Step [6050/25000], Train Loss: 0.4005, Valid Loss: 0.4138\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [122/500], Step [6100/25000], Train Loss: 0.4024, Valid Loss: 0.4172\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [123/500], Step [6150/25000], Train Loss: 0.4027, Valid Loss: 0.4139\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [124/500], Step [6200/25000], Train Loss: 0.3997, Valid Loss: 0.4197\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [125/500], Step [6250/25000], Train Loss: 0.4023, Valid Loss: 0.4245\n",
      "Epoch Accuracy: 0.9150823827629911\n",
      "Epoch [126/500], Step [6300/25000], Train Loss: 0.4015, Valid Loss: 0.4219\n",
      "Epoch Accuracy: 0.9195183776932826\n",
      "Epoch [127/500], Step [6350/25000], Train Loss: 0.4011, Valid Loss: 0.4179\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [128/500], Step [6400/25000], Train Loss: 0.3969, Valid Loss: 0.4212\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [129/500], Step [6450/25000], Train Loss: 0.3995, Valid Loss: 0.4274\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [130/500], Step [6500/25000], Train Loss: 0.4001, Valid Loss: 0.4281\n",
      "Epoch Accuracy: 0.9195183776932826\n",
      "Epoch [131/500], Step [6550/25000], Train Loss: 0.4008, Valid Loss: 0.4220\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [132/500], Step [6600/25000], Train Loss: 0.3978, Valid Loss: 0.4228\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [133/500], Step [6650/25000], Train Loss: 0.4012, Valid Loss: 0.4216\n",
      "Epoch Accuracy: 0.9157160963244614\n",
      "Epoch [134/500], Step [6700/25000], Train Loss: 0.3973, Valid Loss: 0.4205\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [135/500], Step [6750/25000], Train Loss: 0.3992, Valid Loss: 0.4222\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [136/500], Step [6800/25000], Train Loss: 0.4006, Valid Loss: 0.4165\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [137/500], Step [6850/25000], Train Loss: 0.3943, Valid Loss: 0.4237\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [138/500], Step [6900/25000], Train Loss: 0.3957, Valid Loss: 0.4162\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [139/500], Step [6950/25000], Train Loss: 0.3985, Valid Loss: 0.4221\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [140/500], Step [7000/25000], Train Loss: 0.3960, Valid Loss: 0.4312\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [141/500], Step [7050/25000], Train Loss: 0.3970, Valid Loss: 0.4189\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [142/500], Step [7100/25000], Train Loss: 0.3941, Valid Loss: 0.4297\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [143/500], Step [7150/25000], Train Loss: 0.3954, Valid Loss: 0.4165\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [144/500], Step [7200/25000], Train Loss: 0.3938, Valid Loss: 0.4329\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [145/500], Step [7250/25000], Train Loss: 0.3977, Valid Loss: 0.4196\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [146/500], Step [7300/25000], Train Loss: 0.3983, Valid Loss: 0.4376\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [147/500], Step [7350/25000], Train Loss: 0.3943, Valid Loss: 0.4151\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [148/500], Step [7400/25000], Train Loss: 0.3930, Valid Loss: 0.4185\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [149/500], Step [7450/25000], Train Loss: 0.3943, Valid Loss: 0.4150\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [150/500], Step [7500/25000], Train Loss: 0.3964, Valid Loss: 0.4190\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [151/500], Step [7550/25000], Train Loss: 0.3932, Valid Loss: 0.4237\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [152/500], Step [7600/25000], Train Loss: 0.3946, Valid Loss: 0.4292\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [153/500], Step [7650/25000], Train Loss: 0.3956, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [154/500], Step [7700/25000], Train Loss: 0.3924, Valid Loss: 0.4289\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [155/500], Step [7750/25000], Train Loss: 0.3975, Valid Loss: 0.4188\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [156/500], Step [7800/25000], Train Loss: 0.3936, Valid Loss: 0.4243\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [157/500], Step [7850/25000], Train Loss: 0.3914, Valid Loss: 0.4191\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [158/500], Step [7900/25000], Train Loss: 0.3928, Valid Loss: 0.4222\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [159/500], Step [7950/25000], Train Loss: 0.3960, Valid Loss: 0.4243\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [160/500], Step [8000/25000], Train Loss: 0.3923, Valid Loss: 0.4347\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [161/500], Step [8050/25000], Train Loss: 0.3929, Valid Loss: 0.4358\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [162/500], Step [8100/25000], Train Loss: 0.3932, Valid Loss: 0.4183\n",
      "Epoch Accuracy: 0.9258555133079848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [163/500], Step [8150/25000], Train Loss: 0.3925, Valid Loss: 0.4249\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [164/500], Step [8200/25000], Train Loss: 0.3932, Valid Loss: 0.4303\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [165/500], Step [8250/25000], Train Loss: 0.3925, Valid Loss: 0.4211\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [166/500], Step [8300/25000], Train Loss: 0.3925, Valid Loss: 0.4184\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [167/500], Step [8350/25000], Train Loss: 0.3943, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [168/500], Step [8400/25000], Train Loss: 0.3926, Valid Loss: 0.4268\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [169/500], Step [8450/25000], Train Loss: 0.3916, Valid Loss: 0.4312\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [170/500], Step [8500/25000], Train Loss: 0.3927, Valid Loss: 0.4250\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [171/500], Step [8550/25000], Train Loss: 0.3905, Valid Loss: 0.4243\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [172/500], Step [8600/25000], Train Loss: 0.3900, Valid Loss: 0.4386\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [173/500], Step [8650/25000], Train Loss: 0.3942, Valid Loss: 0.4238\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [174/500], Step [8700/25000], Train Loss: 0.3930, Valid Loss: 0.4198\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [175/500], Step [8750/25000], Train Loss: 0.3898, Valid Loss: 0.4224\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [176/500], Step [8800/25000], Train Loss: 0.3926, Valid Loss: 0.4176\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [177/500], Step [8850/25000], Train Loss: 0.3884, Valid Loss: 0.4141\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [178/500], Step [8900/25000], Train Loss: 0.3916, Valid Loss: 0.4233\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [179/500], Step [8950/25000], Train Loss: 0.3925, Valid Loss: 0.4289\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [180/500], Step [9000/25000], Train Loss: 0.3900, Valid Loss: 0.4257\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [181/500], Step [9050/25000], Train Loss: 0.3879, Valid Loss: 0.4269\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [182/500], Step [9100/25000], Train Loss: 0.3887, Valid Loss: 0.4300\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [183/500], Step [9150/25000], Train Loss: 0.3930, Valid Loss: 0.4272\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [184/500], Step [9200/25000], Train Loss: 0.3902, Valid Loss: 0.4188\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [185/500], Step [9250/25000], Train Loss: 0.3930, Valid Loss: 0.4396\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [186/500], Step [9300/25000], Train Loss: 0.3912, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [187/500], Step [9350/25000], Train Loss: 0.3896, Valid Loss: 0.4236\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [188/500], Step [9400/25000], Train Loss: 0.3921, Valid Loss: 0.4232\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [189/500], Step [9450/25000], Train Loss: 0.3880, Valid Loss: 0.4265\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [190/500], Step [9500/25000], Train Loss: 0.3876, Valid Loss: 0.4283\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [191/500], Step [9550/25000], Train Loss: 0.3890, Valid Loss: 0.4165\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [192/500], Step [9600/25000], Train Loss: 0.3890, Valid Loss: 0.4228\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [193/500], Step [9650/25000], Train Loss: 0.3871, Valid Loss: 0.4217\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [194/500], Step [9700/25000], Train Loss: 0.3901, Valid Loss: 0.4247\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [195/500], Step [9750/25000], Train Loss: 0.3887, Valid Loss: 0.4150\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [196/500], Step [9800/25000], Train Loss: 0.3884, Valid Loss: 0.4430\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [197/500], Step [9850/25000], Train Loss: 0.3882, Valid Loss: 0.4202\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [198/500], Step [9900/25000], Train Loss: 0.3884, Valid Loss: 0.4155\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [199/500], Step [9950/25000], Train Loss: 0.3906, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [200/500], Step [10000/25000], Train Loss: 0.3884, Valid Loss: 0.4216\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [201/500], Step [10050/25000], Train Loss: 0.3840, Valid Loss: 0.4233\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [202/500], Step [10100/25000], Train Loss: 0.3886, Valid Loss: 0.4184\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [203/500], Step [10150/25000], Train Loss: 0.3859, Valid Loss: 0.4339\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [204/500], Step [10200/25000], Train Loss: 0.3870, Valid Loss: 0.4294\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [205/500], Step [10250/25000], Train Loss: 0.3887, Valid Loss: 0.4131\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [206/500], Step [10300/25000], Train Loss: 0.3873, Valid Loss: 0.4209\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [207/500], Step [10350/25000], Train Loss: 0.3868, Valid Loss: 0.4127\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [208/500], Step [10400/25000], Train Loss: 0.3865, Valid Loss: 0.4165\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [209/500], Step [10450/25000], Train Loss: 0.3848, Valid Loss: 0.4178\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [210/500], Step [10500/25000], Train Loss: 0.3859, Valid Loss: 0.4261\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [211/500], Step [10550/25000], Train Loss: 0.3850, Valid Loss: 0.4220\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [212/500], Step [10600/25000], Train Loss: 0.3862, Valid Loss: 0.4272\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [213/500], Step [10650/25000], Train Loss: 0.3864, Valid Loss: 0.4308\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [214/500], Step [10700/25000], Train Loss: 0.3842, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [215/500], Step [10750/25000], Train Loss: 0.3853, Valid Loss: 0.4225\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [216/500], Step [10800/25000], Train Loss: 0.3840, Valid Loss: 0.4352\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [217/500], Step [10850/25000], Train Loss: 0.3864, Valid Loss: 0.4273\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [218/500], Step [10900/25000], Train Loss: 0.3884, Valid Loss: 0.4296\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [219/500], Step [10950/25000], Train Loss: 0.3862, Valid Loss: 0.4298\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [220/500], Step [11000/25000], Train Loss: 0.3881, Valid Loss: 0.4260\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [221/500], Step [11050/25000], Train Loss: 0.3881, Valid Loss: 0.4208\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [222/500], Step [11100/25000], Train Loss: 0.3855, Valid Loss: 0.4213\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [223/500], Step [11150/25000], Train Loss: 0.3850, Valid Loss: 0.4239\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [224/500], Step [11200/25000], Train Loss: 0.3830, Valid Loss: 0.4307\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [225/500], Step [11250/25000], Train Loss: 0.3853, Valid Loss: 0.4270\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [226/500], Step [11300/25000], Train Loss: 0.3865, Valid Loss: 0.4246\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [227/500], Step [11350/25000], Train Loss: 0.3817, Valid Loss: 0.4354\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [228/500], Step [11400/25000], Train Loss: 0.3867, Valid Loss: 0.4265\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [229/500], Step [11450/25000], Train Loss: 0.3837, Valid Loss: 0.4299\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [230/500], Step [11500/25000], Train Loss: 0.3866, Valid Loss: 0.4352\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [231/500], Step [11550/25000], Train Loss: 0.3851, Valid Loss: 0.4270\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [232/500], Step [11600/25000], Train Loss: 0.3861, Valid Loss: 0.4308\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [233/500], Step [11650/25000], Train Loss: 0.3799, Valid Loss: 0.4256\n",
      "Epoch Accuracy: 0.9397972116603295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [234/500], Step [11700/25000], Train Loss: 0.3848, Valid Loss: 0.4379\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [235/500], Step [11750/25000], Train Loss: 0.3850, Valid Loss: 0.4566\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [236/500], Step [11800/25000], Train Loss: 0.3873, Valid Loss: 0.4231\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [237/500], Step [11850/25000], Train Loss: 0.3830, Valid Loss: 0.4263\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [238/500], Step [11900/25000], Train Loss: 0.3855, Valid Loss: 0.4264\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [239/500], Step [11950/25000], Train Loss: 0.3810, Valid Loss: 0.4295\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [240/500], Step [12000/25000], Train Loss: 0.3846, Valid Loss: 0.4267\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [241/500], Step [12050/25000], Train Loss: 0.3853, Valid Loss: 0.4308\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [242/500], Step [12100/25000], Train Loss: 0.3852, Valid Loss: 0.4332\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [243/500], Step [12150/25000], Train Loss: 0.3854, Valid Loss: 0.4255\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [244/500], Step [12200/25000], Train Loss: 0.3826, Valid Loss: 0.4140\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [245/500], Step [12250/25000], Train Loss: 0.3852, Valid Loss: 0.4161\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [246/500], Step [12300/25000], Train Loss: 0.3822, Valid Loss: 0.4266\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [247/500], Step [12350/25000], Train Loss: 0.3851, Valid Loss: 0.4195\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [248/500], Step [12400/25000], Train Loss: 0.3836, Valid Loss: 0.4360\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [249/500], Step [12450/25000], Train Loss: 0.3821, Valid Loss: 0.4163\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [250/500], Step [12500/25000], Train Loss: 0.3829, Valid Loss: 0.4191\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [251/500], Step [12550/25000], Train Loss: 0.3848, Valid Loss: 0.4137\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [252/500], Step [12600/25000], Train Loss: 0.3836, Valid Loss: 0.4200\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [253/500], Step [12650/25000], Train Loss: 0.3833, Valid Loss: 0.4150\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [254/500], Step [12700/25000], Train Loss: 0.3831, Valid Loss: 0.4093\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [255/500], Step [12750/25000], Train Loss: 0.3817, Valid Loss: 0.4185\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [256/500], Step [12800/25000], Train Loss: 0.3824, Valid Loss: 0.4251\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [257/500], Step [12850/25000], Train Loss: 0.3805, Valid Loss: 0.4205\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [258/500], Step [12900/25000], Train Loss: 0.3855, Valid Loss: 0.4133\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [259/500], Step [12950/25000], Train Loss: 0.3819, Valid Loss: 0.4274\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [260/500], Step [13000/25000], Train Loss: 0.3814, Valid Loss: 0.4149\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [261/500], Step [13050/25000], Train Loss: 0.3824, Valid Loss: 0.4181\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [262/500], Step [13100/25000], Train Loss: 0.3801, Valid Loss: 0.4304\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [263/500], Step [13150/25000], Train Loss: 0.3794, Valid Loss: 0.4405\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [264/500], Step [13200/25000], Train Loss: 0.3814, Valid Loss: 0.4190\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [265/500], Step [13250/25000], Train Loss: 0.3854, Valid Loss: 0.4171\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [266/500], Step [13300/25000], Train Loss: 0.3813, Valid Loss: 0.4214\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [267/500], Step [13350/25000], Train Loss: 0.3835, Valid Loss: 0.4391\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [268/500], Step [13400/25000], Train Loss: 0.3792, Valid Loss: 0.4265\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [269/500], Step [13450/25000], Train Loss: 0.3810, Valid Loss: 0.4191\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [270/500], Step [13500/25000], Train Loss: 0.3833, Valid Loss: 0.4245\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [271/500], Step [13550/25000], Train Loss: 0.3825, Valid Loss: 0.4475\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [272/500], Step [13600/25000], Train Loss: 0.3796, Valid Loss: 0.4164\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [273/500], Step [13650/25000], Train Loss: 0.3836, Valid Loss: 0.4441\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [274/500], Step [13700/25000], Train Loss: 0.3852, Valid Loss: 0.4143\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [275/500], Step [13750/25000], Train Loss: 0.3826, Valid Loss: 0.4250\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [276/500], Step [13800/25000], Train Loss: 0.3838, Valid Loss: 0.4270\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [277/500], Step [13850/25000], Train Loss: 0.3809, Valid Loss: 0.4486\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [278/500], Step [13900/25000], Train Loss: 0.3834, Valid Loss: 0.4419\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [279/500], Step [13950/25000], Train Loss: 0.3819, Valid Loss: 0.4347\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [280/500], Step [14000/25000], Train Loss: 0.3861, Valid Loss: 0.4573\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [281/500], Step [14050/25000], Train Loss: 0.3795, Valid Loss: 0.4330\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [282/500], Step [14100/25000], Train Loss: 0.3821, Valid Loss: 0.4302\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [283/500], Step [14150/25000], Train Loss: 0.3799, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [284/500], Step [14200/25000], Train Loss: 0.3766, Valid Loss: 0.4317\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [285/500], Step [14250/25000], Train Loss: 0.3800, Valid Loss: 0.4207\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [286/500], Step [14300/25000], Train Loss: 0.3847, Valid Loss: 0.4436\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [287/500], Step [14350/25000], Train Loss: 0.3782, Valid Loss: 0.4337\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [288/500], Step [14400/25000], Train Loss: 0.3801, Valid Loss: 0.4167\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [289/500], Step [14450/25000], Train Loss: 0.3799, Valid Loss: 0.4251\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [290/500], Step [14500/25000], Train Loss: 0.3801, Valid Loss: 0.4229\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [291/500], Step [14550/25000], Train Loss: 0.3801, Valid Loss: 0.4217\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [292/500], Step [14600/25000], Train Loss: 0.3800, Valid Loss: 0.4509\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [293/500], Step [14650/25000], Train Loss: 0.3813, Valid Loss: 0.4333\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [294/500], Step [14700/25000], Train Loss: 0.3814, Valid Loss: 0.4388\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [295/500], Step [14750/25000], Train Loss: 0.3773, Valid Loss: 0.4319\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [296/500], Step [14800/25000], Train Loss: 0.3800, Valid Loss: 0.4188\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [297/500], Step [14850/25000], Train Loss: 0.3828, Valid Loss: 0.4172\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [298/500], Step [14900/25000], Train Loss: 0.3816, Valid Loss: 0.4159\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [299/500], Step [14950/25000], Train Loss: 0.3774, Valid Loss: 0.4271\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [300/500], Step [15000/25000], Train Loss: 0.3816, Valid Loss: 0.4324\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [301/500], Step [15050/25000], Train Loss: 0.3779, Valid Loss: 0.4308\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [302/500], Step [15100/25000], Train Loss: 0.3797, Valid Loss: 0.4204\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [303/500], Step [15150/25000], Train Loss: 0.3815, Valid Loss: 0.4183\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [304/500], Step [15200/25000], Train Loss: 0.3812, Valid Loss: 0.4272\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [305/500], Step [15250/25000], Train Loss: 0.3804, Valid Loss: 0.4195\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [306/500], Step [15300/25000], Train Loss: 0.3802, Valid Loss: 0.4357\n",
      "Epoch Accuracy: 0.9328263624841572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [307/500], Step [15350/25000], Train Loss: 0.3764, Valid Loss: 0.4218\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [308/500], Step [15400/25000], Train Loss: 0.3806, Valid Loss: 0.4244\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [309/500], Step [15450/25000], Train Loss: 0.3809, Valid Loss: 0.4305\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [310/500], Step [15500/25000], Train Loss: 0.3790, Valid Loss: 0.4189\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [311/500], Step [15550/25000], Train Loss: 0.3763, Valid Loss: 0.4219\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [312/500], Step [15600/25000], Train Loss: 0.3794, Valid Loss: 0.4230\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [313/500], Step [15650/25000], Train Loss: 0.3806, Valid Loss: 0.4362\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [314/500], Step [15700/25000], Train Loss: 0.3782, Valid Loss: 0.4366\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [315/500], Step [15750/25000], Train Loss: 0.3791, Valid Loss: 0.4402\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [316/500], Step [15800/25000], Train Loss: 0.3789, Valid Loss: 0.4242\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [317/500], Step [15850/25000], Train Loss: 0.3785, Valid Loss: 0.4156\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [318/500], Step [15900/25000], Train Loss: 0.3793, Valid Loss: 0.4211\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [319/500], Step [15950/25000], Train Loss: 0.3781, Valid Loss: 0.4238\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [320/500], Step [16000/25000], Train Loss: 0.3790, Valid Loss: 0.4142\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [321/500], Step [16050/25000], Train Loss: 0.3754, Valid Loss: 0.4175\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [322/500], Step [16100/25000], Train Loss: 0.3769, Valid Loss: 0.4182\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [323/500], Step [16150/25000], Train Loss: 0.3827, Valid Loss: 0.4253\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [324/500], Step [16200/25000], Train Loss: 0.3769, Valid Loss: 0.4333\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [325/500], Step [16250/25000], Train Loss: 0.3781, Valid Loss: 0.4145\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [326/500], Step [16300/25000], Train Loss: 0.3792, Valid Loss: 0.4454\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [327/500], Step [16350/25000], Train Loss: 0.3790, Valid Loss: 0.4215\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [328/500], Step [16400/25000], Train Loss: 0.3773, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [329/500], Step [16450/25000], Train Loss: 0.3768, Valid Loss: 0.4401\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [330/500], Step [16500/25000], Train Loss: 0.3769, Valid Loss: 0.4310\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [331/500], Step [16550/25000], Train Loss: 0.3779, Valid Loss: 0.4187\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [332/500], Step [16600/25000], Train Loss: 0.3784, Valid Loss: 0.4242\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [333/500], Step [16650/25000], Train Loss: 0.3788, Valid Loss: 0.4172\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [334/500], Step [16700/25000], Train Loss: 0.3796, Valid Loss: 0.4405\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [335/500], Step [16750/25000], Train Loss: 0.3797, Valid Loss: 0.4465\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [336/500], Step [16800/25000], Train Loss: 0.3777, Valid Loss: 0.4147\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [337/500], Step [16850/25000], Train Loss: 0.3805, Valid Loss: 0.4180\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [338/500], Step [16900/25000], Train Loss: 0.3765, Valid Loss: 0.4286\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [339/500], Step [16950/25000], Train Loss: 0.3767, Valid Loss: 0.4195\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [340/500], Step [17000/25000], Train Loss: 0.3794, Valid Loss: 0.4269\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [341/500], Step [17050/25000], Train Loss: 0.3766, Valid Loss: 0.4219\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [342/500], Step [17100/25000], Train Loss: 0.3794, Valid Loss: 0.4221\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [343/500], Step [17150/25000], Train Loss: 0.3752, Valid Loss: 0.4339\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [344/500], Step [17200/25000], Train Loss: 0.3778, Valid Loss: 0.4270\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [345/500], Step [17250/25000], Train Loss: 0.3798, Valid Loss: 0.4328\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [346/500], Step [17300/25000], Train Loss: 0.3786, Valid Loss: 0.4240\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [347/500], Step [17350/25000], Train Loss: 0.3757, Valid Loss: 0.4268\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [348/500], Step [17400/25000], Train Loss: 0.3778, Valid Loss: 0.4258\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [349/500], Step [17450/25000], Train Loss: 0.3741, Valid Loss: 0.4138\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [350/500], Step [17500/25000], Train Loss: 0.3801, Valid Loss: 0.4374\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [351/500], Step [17550/25000], Train Loss: 0.3771, Valid Loss: 0.4292\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [352/500], Step [17600/25000], Train Loss: 0.3760, Valid Loss: 0.4302\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [353/500], Step [17650/25000], Train Loss: 0.3745, Valid Loss: 0.4297\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [354/500], Step [17700/25000], Train Loss: 0.3806, Valid Loss: 0.4420\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [355/500], Step [17750/25000], Train Loss: 0.3764, Valid Loss: 0.4413\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [356/500], Step [17800/25000], Train Loss: 0.3788, Valid Loss: 0.4197\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [357/500], Step [17850/25000], Train Loss: 0.3753, Valid Loss: 0.4274\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [358/500], Step [17900/25000], Train Loss: 0.3748, Valid Loss: 0.4171\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [359/500], Step [17950/25000], Train Loss: 0.3751, Valid Loss: 0.4246\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [360/500], Step [18000/25000], Train Loss: 0.3789, Valid Loss: 0.4247\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [361/500], Step [18050/25000], Train Loss: 0.3749, Valid Loss: 0.4189\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [362/500], Step [18100/25000], Train Loss: 0.3783, Valid Loss: 0.4266\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [363/500], Step [18150/25000], Train Loss: 0.3793, Valid Loss: 0.4255\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [364/500], Step [18200/25000], Train Loss: 0.3781, Valid Loss: 0.4228\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [365/500], Step [18250/25000], Train Loss: 0.3755, Valid Loss: 0.4201\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [366/500], Step [18300/25000], Train Loss: 0.3749, Valid Loss: 0.4298\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [367/500], Step [18350/25000], Train Loss: 0.3750, Valid Loss: 0.4331\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [368/500], Step [18400/25000], Train Loss: 0.3747, Valid Loss: 0.4330\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [369/500], Step [18450/25000], Train Loss: 0.3728, Valid Loss: 0.4419\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [370/500], Step [18500/25000], Train Loss: 0.3770, Valid Loss: 0.4305\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [371/500], Step [18550/25000], Train Loss: 0.3743, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [372/500], Step [18600/25000], Train Loss: 0.3750, Valid Loss: 0.4166\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [373/500], Step [18650/25000], Train Loss: 0.3767, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [374/500], Step [18700/25000], Train Loss: 0.3749, Valid Loss: 0.4241\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [375/500], Step [18750/25000], Train Loss: 0.3761, Valid Loss: 0.4453\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [376/500], Step [18800/25000], Train Loss: 0.3777, Valid Loss: 0.4258\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [377/500], Step [18850/25000], Train Loss: 0.3758, Valid Loss: 0.4267\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [378/500], Step [18900/25000], Train Loss: 0.3715, Valid Loss: 0.4252\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [379/500], Step [18950/25000], Train Loss: 0.3781, Valid Loss: 0.4239\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [380/500], Step [19000/25000], Train Loss: 0.3740, Valid Loss: 0.4329\n",
      "Epoch Accuracy: 0.9416983523447402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [381/500], Step [19050/25000], Train Loss: 0.3758, Valid Loss: 0.4226\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [382/500], Step [19100/25000], Train Loss: 0.3773, Valid Loss: 0.4283\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [383/500], Step [19150/25000], Train Loss: 0.3765, Valid Loss: 0.4225\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [384/500], Step [19200/25000], Train Loss: 0.3767, Valid Loss: 0.4283\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [385/500], Step [19250/25000], Train Loss: 0.3764, Valid Loss: 0.4279\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [386/500], Step [19300/25000], Train Loss: 0.3746, Valid Loss: 0.4277\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [387/500], Step [19350/25000], Train Loss: 0.3755, Valid Loss: 0.4230\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [388/500], Step [19400/25000], Train Loss: 0.3753, Valid Loss: 0.4258\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [389/500], Step [19450/25000], Train Loss: 0.3736, Valid Loss: 0.4460\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [390/500], Step [19500/25000], Train Loss: 0.3734, Valid Loss: 0.4259\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [391/500], Step [19550/25000], Train Loss: 0.3758, Valid Loss: 0.4248\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [392/500], Step [19600/25000], Train Loss: 0.3745, Valid Loss: 0.4291\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [393/500], Step [19650/25000], Train Loss: 0.3790, Valid Loss: 0.4230\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [394/500], Step [19700/25000], Train Loss: 0.3733, Valid Loss: 0.4202\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [395/500], Step [19750/25000], Train Loss: 0.3741, Valid Loss: 0.4295\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [396/500], Step [19800/25000], Train Loss: 0.3758, Valid Loss: 0.4398\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [397/500], Step [19850/25000], Train Loss: 0.3731, Valid Loss: 0.4218\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [398/500], Step [19900/25000], Train Loss: 0.3730, Valid Loss: 0.4296\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [399/500], Step [19950/25000], Train Loss: 0.3754, Valid Loss: 0.4261\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [400/500], Step [20000/25000], Train Loss: 0.3737, Valid Loss: 0.4240\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [401/500], Step [20050/25000], Train Loss: 0.3731, Valid Loss: 0.4284\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [402/500], Step [20100/25000], Train Loss: 0.3732, Valid Loss: 0.4298\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [403/500], Step [20150/25000], Train Loss: 0.3760, Valid Loss: 0.4297\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [404/500], Step [20200/25000], Train Loss: 0.3783, Valid Loss: 0.4279\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [405/500], Step [20250/25000], Train Loss: 0.3743, Valid Loss: 0.4201\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [406/500], Step [20300/25000], Train Loss: 0.3726, Valid Loss: 0.4266\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [407/500], Step [20350/25000], Train Loss: 0.3740, Valid Loss: 0.4564\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [408/500], Step [20400/25000], Train Loss: 0.3755, Valid Loss: 0.4289\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [409/500], Step [20450/25000], Train Loss: 0.3754, Valid Loss: 0.4208\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [410/500], Step [20500/25000], Train Loss: 0.3743, Valid Loss: 0.4280\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [411/500], Step [20550/25000], Train Loss: 0.3760, Valid Loss: 0.4274\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [412/500], Step [20600/25000], Train Loss: 0.3752, Valid Loss: 0.4253\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [413/500], Step [20650/25000], Train Loss: 0.3741, Valid Loss: 0.4295\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [414/500], Step [20700/25000], Train Loss: 0.3731, Valid Loss: 0.4398\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [415/500], Step [20750/25000], Train Loss: 0.3745, Valid Loss: 0.4317\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [416/500], Step [20800/25000], Train Loss: 0.3756, Valid Loss: 0.4324\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [417/500], Step [20850/25000], Train Loss: 0.3738, Valid Loss: 0.4367\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [418/500], Step [20900/25000], Train Loss: 0.3741, Valid Loss: 0.4285\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [419/500], Step [20950/25000], Train Loss: 0.3755, Valid Loss: 0.4269\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [420/500], Step [21000/25000], Train Loss: 0.3770, Valid Loss: 0.4441\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [421/500], Step [21050/25000], Train Loss: 0.3748, Valid Loss: 0.4444\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [422/500], Step [21100/25000], Train Loss: 0.3743, Valid Loss: 0.4271\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [423/500], Step [21150/25000], Train Loss: 0.3724, Valid Loss: 0.4268\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [424/500], Step [21200/25000], Train Loss: 0.3731, Valid Loss: 0.4255\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [425/500], Step [21250/25000], Train Loss: 0.3727, Valid Loss: 0.4505\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [426/500], Step [21300/25000], Train Loss: 0.3730, Valid Loss: 0.4340\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [427/500], Step [21350/25000], Train Loss: 0.3721, Valid Loss: 0.4336\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [428/500], Step [21400/25000], Train Loss: 0.3734, Valid Loss: 0.4401\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [429/500], Step [21450/25000], Train Loss: 0.3743, Valid Loss: 0.4510\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [430/500], Step [21500/25000], Train Loss: 0.3714, Valid Loss: 0.4451\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [431/500], Step [21550/25000], Train Loss: 0.3744, Valid Loss: 0.4271\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [432/500], Step [21600/25000], Train Loss: 0.3739, Valid Loss: 0.4454\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [433/500], Step [21650/25000], Train Loss: 0.3743, Valid Loss: 0.4459\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [434/500], Step [21700/25000], Train Loss: 0.3697, Valid Loss: 0.4220\n",
      "Epoch Accuracy: 0.9474017743979721\n",
      "Epoch [435/500], Step [21750/25000], Train Loss: 0.3726, Valid Loss: 0.4348\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [436/500], Step [21800/25000], Train Loss: 0.3703, Valid Loss: 0.4323\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [437/500], Step [21850/25000], Train Loss: 0.3717, Valid Loss: 0.4296\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [438/500], Step [21900/25000], Train Loss: 0.3741, Valid Loss: 0.4300\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [439/500], Step [21950/25000], Train Loss: 0.3748, Valid Loss: 0.4325\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [440/500], Step [22000/25000], Train Loss: 0.3703, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [441/500], Step [22050/25000], Train Loss: 0.3728, Valid Loss: 0.4307\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [442/500], Step [22100/25000], Train Loss: 0.3719, Valid Loss: 0.4316\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [443/500], Step [22150/25000], Train Loss: 0.3738, Valid Loss: 0.4397\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [444/500], Step [22200/25000], Train Loss: 0.3727, Valid Loss: 0.4326\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [445/500], Step [22250/25000], Train Loss: 0.3760, Valid Loss: 0.4264\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [446/500], Step [22300/25000], Train Loss: 0.3729, Valid Loss: 0.4321\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [447/500], Step [22350/25000], Train Loss: 0.3714, Valid Loss: 0.4314\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [448/500], Step [22400/25000], Train Loss: 0.3709, Valid Loss: 0.4392\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [449/500], Step [22450/25000], Train Loss: 0.3742, Valid Loss: 0.4271\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [450/500], Step [22500/25000], Train Loss: 0.3696, Valid Loss: 0.4350\n",
      "Epoch Accuracy: 0.9480354879594424\n",
      "Epoch [451/500], Step [22550/25000], Train Loss: 0.3701, Valid Loss: 0.4345\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [452/500], Step [22600/25000], Train Loss: 0.3733, Valid Loss: 0.4267\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [453/500], Step [22650/25000], Train Loss: 0.3745, Valid Loss: 0.4386\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [454/500], Step [22700/25000], Train Loss: 0.3711, Valid Loss: 0.4347\n",
      "Epoch Accuracy: 0.9448669201520913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [455/500], Step [22750/25000], Train Loss: 0.3711, Valid Loss: 0.4356\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [456/500], Step [22800/25000], Train Loss: 0.3737, Valid Loss: 0.4275\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [457/500], Step [22850/25000], Train Loss: 0.3721, Valid Loss: 0.4454\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [458/500], Step [22900/25000], Train Loss: 0.3710, Valid Loss: 0.4354\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [459/500], Step [22950/25000], Train Loss: 0.3721, Valid Loss: 0.4289\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [460/500], Step [23000/25000], Train Loss: 0.3738, Valid Loss: 0.4368\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [461/500], Step [23050/25000], Train Loss: 0.3685, Valid Loss: 0.4406\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [462/500], Step [23100/25000], Train Loss: 0.3703, Valid Loss: 0.4332\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [463/500], Step [23150/25000], Train Loss: 0.3711, Valid Loss: 0.4362\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [464/500], Step [23200/25000], Train Loss: 0.3729, Valid Loss: 0.4265\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [465/500], Step [23250/25000], Train Loss: 0.3715, Valid Loss: 0.4269\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [466/500], Step [23300/25000], Train Loss: 0.3700, Valid Loss: 0.4322\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [467/500], Step [23350/25000], Train Loss: 0.3754, Valid Loss: 0.4316\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [468/500], Step [23400/25000], Train Loss: 0.3717, Valid Loss: 0.4341\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [469/500], Step [23450/25000], Train Loss: 0.3718, Valid Loss: 0.4375\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [470/500], Step [23500/25000], Train Loss: 0.3729, Valid Loss: 0.4286\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [471/500], Step [23550/25000], Train Loss: 0.3719, Valid Loss: 0.4374\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [472/500], Step [23600/25000], Train Loss: 0.3707, Valid Loss: 0.4388\n",
      "Epoch Accuracy: 0.9461343472750317\n",
      "Epoch [473/500], Step [23650/25000], Train Loss: 0.3708, Valid Loss: 0.4328\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [474/500], Step [23700/25000], Train Loss: 0.3728, Valid Loss: 0.4240\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [475/500], Step [23750/25000], Train Loss: 0.3729, Valid Loss: 0.4394\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [476/500], Step [23800/25000], Train Loss: 0.3720, Valid Loss: 0.4327\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [477/500], Step [23850/25000], Train Loss: 0.3715, Valid Loss: 0.4376\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [478/500], Step [23900/25000], Train Loss: 0.3699, Valid Loss: 0.4453\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [479/500], Step [23950/25000], Train Loss: 0.3701, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [480/500], Step [24000/25000], Train Loss: 0.3722, Valid Loss: 0.4523\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [481/500], Step [24050/25000], Train Loss: 0.3702, Valid Loss: 0.4343\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [482/500], Step [24100/25000], Train Loss: 0.3737, Valid Loss: 0.4206\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [483/500], Step [24150/25000], Train Loss: 0.3678, Valid Loss: 0.4288\n",
      "Epoch Accuracy: 0.9480354879594424\n",
      "Epoch [484/500], Step [24200/25000], Train Loss: 0.3707, Valid Loss: 0.4202\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [485/500], Step [24250/25000], Train Loss: 0.3745, Valid Loss: 0.4190\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [486/500], Step [24300/25000], Train Loss: 0.3676, Valid Loss: 0.4417\n",
      "Epoch Accuracy: 0.949936628643853\n",
      "Epoch [487/500], Step [24350/25000], Train Loss: 0.3717, Valid Loss: 0.4235\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [488/500], Step [24400/25000], Train Loss: 0.3712, Valid Loss: 0.4361\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [489/500], Step [24450/25000], Train Loss: 0.3698, Valid Loss: 0.4254\n",
      "Epoch Accuracy: 0.9486692015209125\n",
      "Epoch [490/500], Step [24500/25000], Train Loss: 0.3728, Valid Loss: 0.4215\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [491/500], Step [24550/25000], Train Loss: 0.3704, Valid Loss: 0.4307\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [492/500], Step [24600/25000], Train Loss: 0.3676, Valid Loss: 0.4224\n",
      "Epoch Accuracy: 0.9493029150823827\n",
      "Epoch [493/500], Step [24650/25000], Train Loss: 0.3705, Valid Loss: 0.4200\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [494/500], Step [24700/25000], Train Loss: 0.3694, Valid Loss: 0.4286\n",
      "Epoch Accuracy: 0.9461343472750317\n",
      "Epoch [495/500], Step [24750/25000], Train Loss: 0.3712, Valid Loss: 0.4347\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [496/500], Step [24800/25000], Train Loss: 0.3696, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [497/500], Step [24850/25000], Train Loss: 0.3700, Valid Loss: 0.4436\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [498/500], Step [24900/25000], Train Loss: 0.3742, Valid Loss: 0.4359\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [499/500], Step [24950/25000], Train Loss: 0.3721, Valid Loss: 0.4460\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [500/500], Step [25000/25000], Train Loss: 0.3707, Valid Loss: 0.4292\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.CrossEntropyLoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 10,\n",
    "          eval_every = len(train_iter),\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total = 0\n",
    "        total_correct = 0\n",
    "        for (labels, (notes, notes_len)), _ in (train_loader):   \n",
    "            labels = labels.to(device)\n",
    "            notes = notes.to(device)\n",
    "            notes_len = notes_len.cpu()\n",
    "            output = model(notes.long())\n",
    "            loss = criterion(output, labels.long())\n",
    "            #loss = criterion(output.view(-1,1),labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            labels_max = labels.detach().cpu()\n",
    "            output_max = np.argmax((output.detach().cpu()),axis=1)\n",
    "            for i in range(len(labels_max)):\n",
    "                total+=1\n",
    "                if labels_max[i] ==  output_max[i]:\n",
    "                    total_correct += 1\n",
    "            accuracy = accuracy_score(labels_max, output_max)\n",
    "            \n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                  # validation loop\n",
    "                    for (labels, (notes, notes_len)), _ in (valid_loader):        \n",
    "                        labels = labels.to(device)\n",
    "                        notes = notes.to(device)\n",
    "                        notes_len = notes_len.cpu()\n",
    "                        output = model(notes.long())\n",
    "                        loss = criterion(output, labels.long())\n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
    "                    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "        print(\"Epoch Accuracy: {}\".format(total_correct/total))\n",
    "    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')\n",
    "\n",
    "\n",
    "model = TransformerModel(ntokens,emsize,nhead,d_hid,nlayers,dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "train(model=model, optimizer=optimizer, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcbc3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b529535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "500\n",
      "500\n",
      "500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "epoch_train = []\n",
    "epoch_valid = []\n",
    "epochs = []\n",
    "\n",
    "for x in range(len(train_loss_list)):\n",
    "    epoch_train.append(sum(train_loss_list[x:x+2])/len(train_loss_list[x:x+2]))\n",
    "print(len(epoch_train))\n",
    "\n",
    "for x in range(len(valid_loss_list)):\n",
    "    epoch_valid.append(sum(valid_loss_list[x:x+2])/len(valid_loss_list[x:x+2]))\n",
    "print(len(epoch_valid))\n",
    "\n",
    "for x in range(500):\n",
    "    epochs.append(x)\n",
    "print(len(epochs))\n",
    "\n",
    "plt.plot(epochs, epoch_train, label='Train')\n",
    "plt.plot(epochs, epoch_valid, label='Valid')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"Transformer 500 epochs.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14827b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500, 525, 550, 575, 600, 625, 650, 675, 700, 725, 750, 775, 800, 825, 850, 875, 900, 925, 950, 975, 1000, 1025, 1050, 1075, 1100, 1125, 1150, 1175, 1200, 1225, 1250, 1275, 1300, 1325, 1350, 1375, 1400, 1425, 1450, 1475, 1500, 1525, 1550, 1575, 1600, 1625, 1650, 1675, 1700, 1725, 1750, 1775, 1800, 1825, 1850, 1875, 1900, 1925, 1950, 1975, 2000, 2025, 2050, 2075, 2100, 2125, 2150, 2175, 2200, 2225, 2250, 2275, 2300, 2325, 2350, 2375, 2400, 2425, 2450, 2475, 2500, 2525, 2550, 2575, 2600, 2625, 2650, 2675, 2700, 2725, 2750, 2775, 2800, 2825, 2850, 2875, 2900, 2925, 2950, 2975, 3000, 3025, 3050, 3075, 3100, 3125, 3150, 3175, 3200, 3225, 3250, 3275, 3300, 3325, 3350, 3375, 3400, 3425, 3450, 3475, 3500, 3525, 3550, 3575, 3600, 3625, 3650, 3675, 3700, 3725, 3750, 3775, 3800, 3825, 3850, 3875, 3900, 3925, 3950, 3975, 4000, 4025, 4050, 4075, 4100, 4125, 4150, 4175, 4200, 4225, 4250, 4275, 4300, 4325, 4350, 4375, 4400, 4425, 4450, 4475, 4500, 4525, 4550, 4575, 4600, 4625, 4650, 4675, 4700, 4725, 4750, 4775, 4800, 4825, 4850, 4875, 4900, 4925, 4950, 4975, 5000]\n"
     ]
    }
   ],
   "source": [
    "print(global_steps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfce53a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "epochs=[]\n",
    "for x in range(500):\n",
    "    epochs.append(x)\n",
    "plt.plot(epochs, train_loss_list, label='Train')\n",
    "plt.plot(epochs, valid_loss_list, label='Valid')\n",
    "\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"Transformer 500 epochs.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14b3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "974bdcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7561    0.8304    0.7915       112\n",
      "           0     0.9108    0.8661    0.8879       224\n",
      "\n",
      "    accuracy                         0.8542       336\n",
      "   macro avg     0.8334    0.8482    0.8397       336\n",
      "weighted avg     0.8592    0.8542    0.8557       336\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(model, test_loader, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (labels, (notes, notes_len)), _ in test_loader:           \n",
    "            labels = labels.to(device)\n",
    "            notes = notes.to(device)\n",
    "            notes_len = notes_len.cpu()\n",
    "            output = model(notes.long())\n",
    "\n",
    "            output = np.argmax(output.cpu().detach(), axis=1)\n",
    "            y_pred.extend(output.tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['INSTRUMENTAL SOLO', 'VOCAL'])\n",
    "    ax.yaxis.set_ticklabels(['INSTRUMENTAL SOLO', 'VOCAL'])\n",
    "    \n",
    "    \n",
    "best_model = TransformerModel(ntokens,emsize,nhead,d_hid,nlayers,dropout).to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)\n",
    "evaluate(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4b82444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intro = pd.read_csv(source_folder + '/test.csv')\n",
    "melodies = df_intro['melody'].values\n",
    "labels = df_intro['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac6cc563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '104', '28', '67', '73', '27', '7', '68', '43', '27', '29', '67', '73', '27', '10', '60', '43', '27', '37', '41', '43', '27', '11', '67', '43', '27', '30', '67', '73', '31', '32', '60', '43', '27', '33', '71', '73', '31', '18', '21', '43', '31', '24', '19', '42', '27', '20', '67', '43', '31', '0', '1', '19', '43', '27', '28', '21', '43', '27', '7', '16', '73', '27', '29', '67', '44', '31', '10', '66', '73', '27', '37', '67', '73', '27', '11', '71', '73', '27', '30', '67', '43', '25', '15', '16', '12', '27', '33', '41', '42', '77', '0', '29', '68', '44', '27', '10', '68', '73', '27', '37', '60', '73', '27', '11', '78', '73', '27', '30', '78', '73', '27', '32', '71', '73', '31', '33', '74', '43', '27', '18', '16', '42', '27', '24', '60', '42', '27', '20', '67', '42', '27', '0', '1', '21', '79', '27', '28', '4', '79', '27', '7', '19', '22', '27', '29', '4', '42', '25', '37', '78', '12', '31', '30', '67', '12', '89', '26', '16', '12', '27', '0', '1', '34', '42', '9', '32', '4', '79', '25', '15', '60', '22', '101']\n"
     ]
    }
   ],
   "source": [
    "test_instance = [x.lower() for x in melodies[0].split(' ')]\n",
    "print(test_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc272085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 30, 158, 20, 41, 47, 6, 18, 14, 40, 6, 25, 41, 47, 6, 11, 9, 40, 6, 34, 8, 40, 6, 19, 41, 40, 6, 26, 41, 47, 2, 36, 9, 40, 6, 37, 15, 47, 2, 16, 65, 40, 2, 42, 53, 23, 6, 28, 41, 40, 2, 4, 7, 53, 40, 6, 20, 65, 40, 6, 18, 12, 47, 6, 25, 41, 60, 2, 11, 17, 47, 6, 34, 41, 47, 6, 19, 15, 47, 6, 26, 41, 40, 5, 21, 12, 27, 6, 37, 8, 23, 69, 4, 25, 14, 60, 6, 11, 14, 47, 6, 34, 9, 47, 6, 19, 32, 47, 6, 26, 32, 47, 6, 36, 15, 47, 2, 37, 59, 40, 6, 16, 12, 23, 6, 42, 9, 23, 6, 28, 41, 23, 6, 4, 7, 65, 38, 6, 20, 24, 38, 6, 18, 53, 44, 6, 25, 24, 23, 5, 34, 32, 27, 2, 26, 41, 27, 84, 33, 12, 27, 6, 4, 7, 10, 23, 45, 36, 24, 38, 5, 21, 9, 44, 103]\n"
     ]
    }
   ],
   "source": [
    "tokens = [text_field.vocab.stoi[token] for token in test_instance]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c3d130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7095e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 3.1082e-20],\n",
      "        [1.0000e+00, 1.5642e-24],\n",
      "        [4.9197e-25, 1.0000e+00],\n",
      "        [3.2338e-24, 1.0000e+00],\n",
      "        [8.6531e-26, 1.0000e+00],\n",
      "        [9.0611e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 4.7799e-22],\n",
      "        [2.2345e-25, 1.0000e+00],\n",
      "        [1.9060e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0706e-19],\n",
      "        [1.0000e+00, 6.4574e-22],\n",
      "        [2.6405e-23, 1.0000e+00],\n",
      "        [8.8408e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 1.4071e-19],\n",
      "        [1.0000e+00, 6.3143e-22],\n",
      "        [1.0000e+00, 2.6471e-23],\n",
      "        [8.5144e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 8.6398e-19],\n",
      "        [1.0000e+00, 1.9478e-24],\n",
      "        [4.3017e-24, 1.0000e+00],\n",
      "        [8.6894e-22, 1.0000e+00],\n",
      "        [6.1413e-16, 1.0000e+00],\n",
      "        [1.0000e+00, 4.7866e-24],\n",
      "        [7.0811e-25, 1.0000e+00],\n",
      "        [3.9402e-23, 1.0000e+00],\n",
      "        [5.7394e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 1.1796e-21],\n",
      "        [6.6878e-16, 1.0000e+00],\n",
      "        [7.8062e-23, 1.0000e+00],\n",
      "        [7.2688e-15, 1.0000e+00],\n",
      "        [1.0000e+00, 2.5386e-21],\n",
      "        [8.1365e-25, 1.0000e+00],\n",
      "        [1.7223e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 3.4686e-08],\n",
      "        [1.0000e+00, 2.5082e-24],\n",
      "        [1.0000e+00, 4.0386e-10],\n",
      "        [1.5809e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 6.4766e-09],\n",
      "        [1.0000e+00, 1.3270e-20],\n",
      "        [7.8464e-25, 1.0000e+00],\n",
      "        [1.7424e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 2.9078e-08],\n",
      "        [1.0000e+00, 5.6173e-24],\n",
      "        [2.2786e-25, 1.0000e+00],\n",
      "        [2.6592e-14, 1.0000e+00],\n",
      "        [2.6643e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 1.2477e-24],\n",
      "        [2.5501e-25, 1.0000e+00],\n",
      "        [8.3241e-25, 1.0000e+00],\n",
      "        [1.9643e-21, 1.0000e+00],\n",
      "        [1.0000e+00, 5.3895e-24],\n",
      "        [2.1045e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 4.5832e-21],\n",
      "        [1.9536e-24, 1.0000e+00],\n",
      "        [9.9974e-01, 5.3109e-04],\n",
      "        [1.0000e+00, 6.6029e-20],\n",
      "        [7.4850e-20, 1.0000e+00],\n",
      "        [3.8885e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 1.0105e-11],\n",
      "        [1.0000e+00, 5.1600e-23],\n",
      "        [2.8230e-24, 1.0000e+00],\n",
      "        [2.4970e-24, 1.0000e+00],\n",
      "        [1.4173e-22, 1.0000e+00],\n",
      "        [1.0000e+00, 3.8397e-24],\n",
      "        [6.0345e-25, 1.0000e+00],\n",
      "        [4.6747e-25, 1.0000e+00],\n",
      "        [3.4870e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6735e-23],\n",
      "        [8.2370e-24, 1.0000e+00],\n",
      "        [1.9218e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 1.9042e-23],\n",
      "        [1.0000e+00, 3.9511e-23],\n",
      "        [3.0428e-23, 1.0000e+00],\n",
      "        [3.8840e-23, 1.0000e+00],\n",
      "        [1.6886e-18, 1.0000e+00],\n",
      "        [1.0000e+00, 1.4431e-22],\n",
      "        [9.7101e-25, 1.0000e+00],\n",
      "        [1.0497e-22, 1.0000e+00],\n",
      "        [1.0000e+00, 1.2770e-20],\n",
      "        [1.0000e+00, 3.5084e-23],\n",
      "        [4.0304e-20, 1.0000e+00],\n",
      "        [4.3962e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 1.1946e-18],\n",
      "        [1.0000e+00, 2.0237e-22],\n",
      "        [1.4003e-18, 1.0000e+00],\n",
      "        [7.5752e-24, 1.0000e+00],\n",
      "        [4.9695e-22, 1.0000e+00],\n",
      "        [1.0000e+00, 9.4009e-23],\n",
      "        [1.9897e-05, 9.9988e-01],\n",
      "        [1.6341e-24, 1.0000e+00],\n",
      "        [2.6963e-23, 1.0000e+00],\n",
      "        [3.6411e-24, 1.0000e+00],\n",
      "        [1.8054e-23, 1.0000e+00],\n",
      "        [3.8389e-24, 1.0000e+00],\n",
      "        [4.9344e-22, 1.0000e+00],\n",
      "        [9.5096e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 4.0125e-23],\n",
      "        [1.3649e-09, 1.0000e+00],\n",
      "        [1.8241e-25, 1.0000e+00],\n",
      "        [1.6530e-15, 1.0000e+00],\n",
      "        [1.0000e+00, 5.3197e-23],\n",
      "        [2.0711e-24, 1.0000e+00],\n",
      "        [1.1360e-23, 1.0000e+00],\n",
      "        [3.2094e-17, 1.0000e+00],\n",
      "        [1.0000e+00, 1.9357e-23],\n",
      "        [6.5224e-25, 1.0000e+00],\n",
      "        [4.0370e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 5.6493e-22],\n",
      "        [1.0000e+00, 1.4597e-24],\n",
      "        [9.9913e-01, 3.8872e-03],\n",
      "        [2.3018e-23, 1.0000e+00],\n",
      "        [1.8329e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 6.6082e-22],\n",
      "        [1.7520e-21, 1.0000e+00],\n",
      "        [6.7603e-22, 1.0000e+00],\n",
      "        [1.0000e+00, 6.4119e-16],\n",
      "        [1.0000e+00, 9.1874e-25],\n",
      "        [1.0000e+00, 2.5296e-20],\n",
      "        [2.4481e-22, 1.0000e+00],\n",
      "        [1.0000e+00, 4.2398e-20],\n",
      "        [1.0000e+00, 5.4441e-22],\n",
      "        [2.6412e-23, 1.0000e+00],\n",
      "        [2.2684e-24, 1.0000e+00],\n",
      "        [2.0196e-20, 1.0000e+00],\n",
      "        [1.0000e+00, 3.8670e-23],\n",
      "        [9.7145e-23, 1.0000e+00],\n",
      "        [1.1477e-23, 1.0000e+00],\n",
      "        [4.7240e-17, 1.0000e+00],\n",
      "        [1.0000e+00, 9.7629e-23],\n",
      "        [7.9462e-25, 1.0000e+00],\n",
      "        [7.1161e-26, 1.0000e+00],\n",
      "        [8.5858e-21, 1.0000e+00],\n",
      "        [1.0000e+00, 3.4280e-23],\n",
      "        [1.8051e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 1.5920e-22],\n",
      "        [1.5010e-25, 1.0000e+00],\n",
      "        [1.0408e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 2.2793e-23],\n",
      "        [8.6683e-24, 1.0000e+00],\n",
      "        [8.9439e-25, 1.0000e+00],\n",
      "        [1.3842e-05, 1.0000e+00],\n",
      "        [1.0000e+00, 4.3272e-22],\n",
      "        [2.6803e-24, 1.0000e+00],\n",
      "        [1.3306e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 1.2703e-19],\n",
      "        [1.0000e+00, 5.9403e-23],\n",
      "        [1.0167e-23, 1.0000e+00],\n",
      "        [7.4175e-25, 1.0000e+00],\n",
      "        [4.1940e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 2.0901e-14],\n",
      "        [4.0896e-23, 1.0000e+00],\n",
      "        [2.3606e-24, 1.0000e+00],\n",
      "        [3.1786e-23, 1.0000e+00],\n",
      "        [1.0000e+00, 1.6061e-24],\n",
      "        [2.9435e-15, 1.0000e+00],\n",
      "        [7.8066e-23, 1.0000e+00],\n",
      "        [7.0341e-22, 1.0000e+00],\n",
      "        [3.0958e-26, 1.0000e+00],\n",
      "        [3.6766e-25, 1.0000e+00],\n",
      "        [2.1298e-23, 1.0000e+00],\n",
      "        [3.6330e-24, 1.0000e+00],\n",
      "        [1.0000e+00, 5.2179e-22],\n",
      "        [1.0570e-25, 1.0000e+00],\n",
      "        [1.0000e+00, 3.8810e-23],\n",
      "        [2.4646e-24, 1.0000e+00],\n",
      "        [3.3922e-22, 1.0000e+00],\n",
      "        [3.0265e-23, 1.0000e+00],\n",
      "        [1.0081e-24, 1.0000e+00],\n",
      "        [7.9502e-24, 1.0000e+00],\n",
      "        [1.5745e-18, 1.0000e+00],\n",
      "        [1.0000e+00, 9.5047e-22],\n",
      "        [1.5464e-23, 1.0000e+00],\n",
      "        [2.3189e-24, 1.0000e+00],\n",
      "        [6.3876e-19, 1.0000e+00],\n",
      "        [2.4839e-24, 1.0000e+00]], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "tensor_tokens = torch.LongTensor(tokens).unsqueeze(1).to(device)\n",
    "outputs = model(tensor_tokens)\n",
    "attention = outputs\n",
    "print(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "063e23ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "dimension specified as 0 but tensor has no dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32542/786680558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbertviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/bertviz/model_view.py\u001b[0m in \u001b[0;36mmodel_view\u001b[0;34m(attention, tokens, sentence_b_start, prettify_tokens, display_mode, encoder_attention, decoder_attention, cross_attention, encoder_tokens, decoder_tokens, include_layers, include_heads)\u001b[0m\n\u001b[1;32m     56\u001b[0m             raise ValueError(\"If you specify 'attention' you may not specify any encoder-decoder arguments. This\"\n\u001b[1;32m     57\u001b[0m                              \" argument is only for self-attention models.\")\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mn_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude_layers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0minclude_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/bertviz/util.py\u001b[0m in \u001b[0;36mnum_heads\u001b[0;34m(attention)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: dimension specified as 0 but tensor has no dimensions"
     ]
    }
   ],
   "source": [
    "from bertviz import model_view, head_view\n",
    "\n",
    "model_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b477f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
