{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022889aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "import matplotlib.pyplot as plt\n",
    "source_folder = \"solo_classification_REMI_dataset\"\n",
    "destination_folder = \"solo_classification_REMI_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193a1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "print(dev)\n",
    "device = torch.device(dev)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d8407f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuakevinlex/miniconda3/lib/python3.8/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
     ]
    }
   ],
   "source": [
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(tokenize='spacy', lower=True, include_lengths=True, batch_first=True)\n",
    "fields = [('labels', label_field), ('notes', text_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='val.csv', test='test.csv',\n",
    "                                           format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=True, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "test_iter = BucketIterator(test, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "\n",
    "# Vocabulary\n",
    "\n",
    "text_field.build_vocab(train, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa477d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  4,   7,  55,  ...,  16,  40, 192],\n",
      "        [  4,   7,  55,  ...,  27, 184,   1],\n",
      "        [  4,   7,  55,  ...,  48,  90,   1],\n",
      "        ...,\n",
      "        [  4,  18,  26,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,  12,  17,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  35,  ...,   8,  40,  49],\n",
      "        [  4,   7,  55,  ..., 129,   1,   1],\n",
      "        [  4,   7,  55,  ..., 127,   1,   1],\n",
      "        ...,\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 55,  ..., 11, 59, 69],\n",
      "        [ 4,  7, 35,  ..., 21, 65,  3],\n",
      "        [ 4,  7, 55,  ..., 45, 54, 42],\n",
      "        ...,\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  55,  ...,  67,  28, 206],\n",
      "        [  4,   7,  55,  ...,  32,  47, 179],\n",
      "        [  4,   7,  35,  ...,  14,  34,   3],\n",
      "        ...,\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 55,  ...,  8, 46,  3],\n",
      "        [ 4, 23, 26,  ..., 17, 38, 88],\n",
      "        [ 4,  7, 55,  ..., 50,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  35,  ...,   9,  34, 129],\n",
      "        [  4,   7,  55,  ...,  17,  40,  78],\n",
      "        [  4,   7,  55,  ...,  11,  44,   2],\n",
      "        ...,\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  35,  ...,   8,  38, 125],\n",
      "        [  4,   7,  35,  ...,  11,  46,   3],\n",
      "        [  4,   7,  55,  ...,  11,  38,   2],\n",
      "        ...,\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 55,  ..., 11, 41,  3],\n",
      "        [ 4,  7, 55,  ..., 21, 38, 94],\n",
      "        [ 4,  7, 35,  ..., 14, 50, 74],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  35,  ...,  53,  36, 118],\n",
      "        [  4,   7,  35,  ...,  17,  43,  98],\n",
      "        [  4,   7,  55,  ...,   9,  27,  94],\n",
      "        ...,\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ..., 21, 70,  3],\n",
      "        [ 4,  7, 35,  ...,  9, 44,  3],\n",
      "        [ 4,  7, 35,  ..., 46,  2,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 26,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  35,  ...,   9,  57,  69],\n",
      "        [  4,  24,  26,  ...,   9,  47,  39],\n",
      "        [  4,   7,  35,  ...,  11,  62, 117],\n",
      "        ...,\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  35,  ...,  60,  58,   3],\n",
      "        [  4,   7,  55,  ...,  10,  43,  98],\n",
      "        [  4,   7,  55,  ...,  26,  59, 120],\n",
      "        ...,\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  35,  ...,  32,  46,   5],\n",
      "        [  4,   7,  35,  ...,  60,  46,  61],\n",
      "        [  4,  13,  60,  ...,  17,  47, 169],\n",
      "        ...,\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 55,  ..., 73, 58,  3],\n",
      "        [ 4,  7, 35,  ..., 10, 57, 39],\n",
      "        [ 4,  7, 35,  ..., 10, 46,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 55,  ...,  9, 27,  2],\n",
      "        [ 4,  7, 35,  ..., 38,  6,  1],\n",
      "        [ 4,  7, 35,  ..., 27,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ..., 21, 38,  5],\n",
      "        [ 4,  7, 35,  ..., 32, 43,  5],\n",
      "        [ 4,  7, 55,  ..., 45, 43,  6],\n",
      "        ...,\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 55,  ..., 45, 58, 49],\n",
      "        [ 4,  7, 55,  ...,  8, 50,  3],\n",
      "        [ 4,  7, 35,  ..., 16, 64, 74],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  55,  ...,   8,  63,   2],\n",
      "        [  4,   7,  55,  ...,   9,  34, 103],\n",
      "        [  4,   7,  55,  ...,  46,  39,   1],\n",
      "        ...,\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ..., 26, 58, 39],\n",
      "        [ 4,  7, 35,  ..., 36,  6,  1],\n",
      "        [ 4,  7, 35,  ..., 41, 42,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  35,  ...,   8,  38,  39],\n",
      "        [  4,   7,  35,  ..., 101,  47,   3],\n",
      "        [  4,   7,  55,  ...,  53,  44, 127],\n",
      "        ...,\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ..., 16, 50,  2],\n",
      "        [ 4,  7, 35,  ...,  9, 40,  6],\n",
      "        [ 4,  7, 55,  ...,  8, 81, 39],\n",
      "        ...,\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ..., 16, 48,  3],\n",
      "        [ 4,  7, 35,  ..., 26, 43,  2],\n",
      "        [ 4,  7, 35,  ...,  9, 27,  6],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ..., 15, 35, 96],\n",
      "        [ 4,  7, 35,  ..., 45, 47,  2],\n",
      "        [ 4,  7, 35,  ..., 48,  5,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 55,  ..., 32, 44, 69],\n",
      "        [ 4,  7, 35,  ...,  8, 62,  5],\n",
      "        [ 4,  7, 35,  ..., 46,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  35,  ...,  11,  41,   6],\n",
      "        [  4,   7,  35,  ...,  38, 103,   1],\n",
      "        [  4,   7,  35,  ...,  39,   1,   1],\n",
      "        ...,\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 55,  ..., 10, 81,  5],\n",
      "        [ 4,  7, 35,  ..., 28,  2,  1],\n",
      "        [ 4,  7, 35,  ..., 63, 69,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  55,  ...,   9,  63,   3],\n",
      "        [  4,   7,  35,  ...,  10,  34,   3],\n",
      "        [  4,   7,  35,  ...,  26, 116, 103],\n",
      "        ...,\n",
      "        [  4,   7,  35,  ...,   1,   1,   1],\n",
      "        [  4,   7,  55,  ...,   1,   1,   1],\n",
      "        [  4,   7,  35,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ..., 16, 68, 49],\n",
      "        [ 4,  7, 35,  ..., 11, 41,  6],\n",
      "        [ 4,  7, 35,  ..., 76,  2,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ..., 16, 43,  5],\n",
      "        [ 4,  7, 35,  ..., 34,  2,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ..., 17, 65,  2],\n",
      "        [ 4, 20, 32,  ..., 17, 46, 39],\n",
      "        [ 4,  7, 35,  ..., 49,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ..., 14, 38,  6],\n",
      "        [ 4,  7, 35,  ...,  3,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 35,  ...,  9, 36,  3],\n",
      "        [ 4,  7, 35,  ...,  6,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  3,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 55,  ..., 11, 52,  2],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 55,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for (labels, (notes, notes_len)), _ in (train_iter):\n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82eec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4d0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, dimension=64):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(len(text_field.vocab), 300)\n",
    "        self.dimension = dimension\n",
    "        self.lstm = nn.LSTM(input_size=300,\n",
    "                            hidden_size=dimension,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc = nn.Linear(2*dimension, 1)\n",
    "\n",
    "    def forward(self, notes, notes_len):\n",
    "        notes_emb = self.embedding(notes)\n",
    "        #print(notes_emb.size())\n",
    "        packed_input = pack_padded_sequence(notes_emb, notes_len, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        out_forward = output[range(len(output)), notes_len - 1, :self.dimension]\n",
    "        out_reverse = output[:, 0, self.dimension:]\n",
    "        out_reduced = torch.cat((out_forward, out_reverse), 1)\n",
    "        #print(out_reduced)\n",
    "        notes_fea = self.drop(out_reduced)\n",
    "\n",
    "        notes_fea = self.fc(notes_fea)\n",
    "        notes_fea = torch.squeeze(notes_fea, 1)\n",
    "        notes_out = torch.sigmoid(notes_fea)\n",
    "\n",
    "        return notes_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32976625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load Functions https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0\n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c88beb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [16/825], Train Loss: 0.5792, Valid Loss: 0.9600\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch [1/25], Step [32/825], Train Loss: 0.9959, Valid Loss: 0.6937\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.4990494296577947\n",
      "Epoch [2/25], Step [48/825], Train Loss: 0.6858, Valid Loss: 0.6854\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch [2/25], Step [64/825], Train Loss: 0.6988, Valid Loss: 0.6841\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.5066539923954373\n",
      "Epoch [3/25], Step [80/825], Train Loss: 0.6625, Valid Loss: 0.6804\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch [3/25], Step [96/825], Train Loss: 0.6774, Valid Loss: 0.6774\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.6083650190114068\n",
      "Epoch [4/25], Step [112/825], Train Loss: 0.6487, Valid Loss: 0.6710\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch [4/25], Step [128/825], Train Loss: 0.6518, Valid Loss: 0.6647\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.6577946768060836\n",
      "Epoch [5/25], Step [144/825], Train Loss: 0.6206, Valid Loss: 0.6556\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch [5/25], Step [160/825], Train Loss: 0.6242, Valid Loss: 0.6437\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.6958174904942965\n",
      "Epoch [6/25], Step [176/825], Train Loss: 0.5800, Valid Loss: 0.6337\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch [6/25], Step [192/825], Train Loss: 0.5821, Valid Loss: 0.6192\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.7452471482889734\n",
      "Epoch [7/25], Step [208/825], Train Loss: 0.5375, Valid Loss: 0.6080\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch [7/25], Step [224/825], Train Loss: 0.5299, Valid Loss: 0.5908\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.7728136882129277\n",
      "Epoch [8/25], Step [240/825], Train Loss: 0.4810, Valid Loss: 0.5835\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch [8/25], Step [256/825], Train Loss: 0.4822, Valid Loss: 0.5680\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.7956273764258555\n",
      "Epoch [9/25], Step [272/825], Train Loss: 0.4327, Valid Loss: 0.5600\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch [9/25], Step [288/825], Train Loss: 0.4180, Valid Loss: 0.5454\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.8384030418250951\n",
      "Epoch [10/25], Step [304/825], Train Loss: 0.3832, Valid Loss: 0.5440\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch [10/25], Step [320/825], Train Loss: 0.3612, Valid Loss: 0.5288\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.8650190114068441\n",
      "Epoch [11/25], Step [336/825], Train Loss: 0.3282, Valid Loss: 0.5393\n",
      "Epoch [11/25], Step [352/825], Train Loss: 0.3114, Valid Loss: 0.5172\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.905893536121673\n",
      "Epoch [12/25], Step [368/825], Train Loss: 0.2736, Valid Loss: 0.5294\n",
      "Epoch [12/25], Step [384/825], Train Loss: 0.2528, Valid Loss: 0.5065\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.9344106463878327\n",
      "Epoch [13/25], Step [400/825], Train Loss: 0.2318, Valid Loss: 0.5270\n",
      "Epoch [13/25], Step [416/825], Train Loss: 0.2010, Valid Loss: 0.5041\n",
      "Model saved to ==> solo_classification_REMI_weights/model.pt\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Epoch Accuracy: 0.9534220532319392\n",
      "Epoch [14/25], Step [432/825], Train Loss: 0.1764, Valid Loss: 0.5238\n",
      "Epoch [14/25], Step [448/825], Train Loss: 0.1508, Valid Loss: 0.5045\n",
      "Epoch Accuracy: 0.970532319391635\n",
      "Epoch [15/25], Step [464/825], Train Loss: 0.1497, Valid Loss: 0.5295\n",
      "Epoch [15/25], Step [480/825], Train Loss: 0.1305, Valid Loss: 0.5198\n",
      "Epoch Accuracy: 0.9762357414448669\n",
      "Epoch [16/25], Step [496/825], Train Loss: 0.1207, Valid Loss: 0.5399\n",
      "Epoch [16/25], Step [512/825], Train Loss: 0.0950, Valid Loss: 0.5343\n",
      "Epoch [16/25], Step [528/825], Train Loss: 0.0951, Valid Loss: 0.5547\n",
      "Epoch Accuracy: 0.9866920152091255\n",
      "Epoch [17/25], Step [544/825], Train Loss: 0.0757, Valid Loss: 0.5602\n",
      "Epoch [17/25], Step [560/825], Train Loss: 0.0738, Valid Loss: 0.5647\n",
      "Epoch Accuracy: 0.9838403041825095\n",
      "Epoch [18/25], Step [576/825], Train Loss: 0.0608, Valid Loss: 0.5875\n",
      "Epoch [18/25], Step [592/825], Train Loss: 0.0604, Valid Loss: 0.5851\n",
      "Epoch Accuracy: 0.9914448669201521\n",
      "Epoch [19/25], Step [608/825], Train Loss: 0.0514, Valid Loss: 0.5927\n",
      "Epoch [19/25], Step [624/825], Train Loss: 0.0545, Valid Loss: 0.5937\n",
      "Epoch Accuracy: 0.9923954372623575\n",
      "Epoch [20/25], Step [640/825], Train Loss: 0.0362, Valid Loss: 0.6027\n",
      "Epoch [20/25], Step [656/825], Train Loss: 0.0363, Valid Loss: 0.6287\n",
      "Epoch Accuracy: 0.997148288973384\n",
      "Epoch [21/25], Step [672/825], Train Loss: 0.0300, Valid Loss: 0.6439\n",
      "Epoch [21/25], Step [688/825], Train Loss: 0.0301, Valid Loss: 0.6528\n",
      "Epoch Accuracy: 0.9980988593155894\n",
      "Epoch [22/25], Step [704/825], Train Loss: 0.0249, Valid Loss: 0.6830\n",
      "Epoch [22/25], Step [720/825], Train Loss: 0.0258, Valid Loss: 0.6860\n",
      "Epoch Accuracy: 0.997148288973384\n",
      "Epoch [23/25], Step [736/825], Train Loss: 0.0275, Valid Loss: 0.6911\n",
      "Epoch [23/25], Step [752/825], Train Loss: 0.0212, Valid Loss: 0.7291\n",
      "Epoch Accuracy: 0.9980988593155894\n",
      "Epoch [24/25], Step [768/825], Train Loss: 0.0206, Valid Loss: 0.6990\n",
      "Epoch [24/25], Step [784/825], Train Loss: 0.0155, Valid Loss: 0.6755\n",
      "Epoch Accuracy: 1.0\n",
      "Epoch [25/25], Step [800/825], Train Loss: 0.0170, Valid Loss: 0.6998\n",
      "Epoch [25/25], Step [816/825], Train Loss: 0.0132, Valid Loss: 0.7069\n",
      "Epoch Accuracy: 0.9990494296577946\n",
      "Model saved to ==> solo_classification_REMI_weights/metrics.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 10,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total = 0\n",
    "        total_correct = 0\n",
    "        for (labels, (notes, notes_len)), _ in (train_loader):           \n",
    "            labels = labels.to(device)\n",
    "            notes = notes.to(device)\n",
    "            notes_len = notes_len.cpu()\n",
    "            output = model(notes.long(), notes_len.long())\n",
    "\n",
    "            loss = criterion(output, labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            labels_max = labels.detach().cpu()\n",
    "            output_max = torch.round(output.detach().cpu())\n",
    "\n",
    "            for i in range(len(labels_max)):\n",
    "                total+=1\n",
    "                if labels_max[i] ==  output_max[i]:\n",
    "                    total_correct += 1\n",
    "            accuracy = accuracy_score(labels_max, output_max)\n",
    "            \n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                  # validation loop\n",
    "                    for (labels, (notes, notes_len)), _ in (valid_loader):\n",
    "                        labels = labels.to(device)\n",
    "                        notes = notes.to(device)\n",
    "                        notes_len = notes_len.cpu()\n",
    "                        output = model(notes.long(), notes_len.long())\n",
    "                        loss = criterion(output, labels.float())\n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
    "                    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "        print(\"Epoch Accuracy: {}\".format(total_correct/total))\n",
    "    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')\n",
    "\n",
    "\n",
    "model = LSTM().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train(model=model, optimizer=optimizer, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcbc3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfce53a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_REMI_weights/metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5KUlEQVR4nO3dd3xUZdbA8d/JpPdCQkmAAFKklwBSROyKCrprQ1fFLura13V1VdT39V3LrmXVXRuyNhA7FiwoCCuKhN57CyWBkAZpM8nz/vHcQIAQEp3JJJnz/Xzmw51778w9SYY59+lijEEppVTgCvJ3AEoppfxLE4FSSgU4TQRKKRXgNBEopVSA00SglFIBLtjfAdRXixYtTHp6ur/DUEqpJmXBggV7jDHJNR1rcokgPT2dzMxMf4ehlFJNiohsOdoxrRpSSqkAp4lAKaUCnCYCpZQKcE2ujUApperL7XaTlZVFaWmpv0PxufDwcNLS0ggJCanza3yWCERkInAukGOM6VnDcQGeA0YBxcA4Y8xCX8WjlApcWVlZxMTEkJ6ejv3qaZ6MMeTm5pKVlUWHDh3q/DpfVg1NAs6q5fjZQGfncQPwLx/GopQKYKWlpSQlJTXrJAAgIiQlJdW75OOzRGCMmQ3sreWUMcCbxvoZiBeR1r6KRykV2Jp7Eqjya35OfzYWpwLbqj3PcvYdQURuEJFMEcncvXu3V4PYV+bho4VZ6HTcSqlA1SR6DRljXjHGZBhjMpKTaxwY96t9uXQnd01dwqY9+736vkopBZCbm0vfvn3p27cvrVq1IjU19cDz8vLyWl+bmZnJbbfd5vMY/dlraDvQttrzNGdfg8rdb/8QuwpL6Zgc3dCXV0o1c0lJSSxevBiACRMmEB0dzT333HPguMfjITi45q/ijIwMMjIyfB6jP0sE04ArxToBKDDG7GzoIPKLbSLYXVTW0JdWSgWocePGcdNNNzF48GDuvfdefvnlF4YMGUK/fv0YOnQoa9asAWDWrFmce+65gE0i11xzDSNHjqRjx448//zzXovHl91HJwMjgRYikgU8DIQAGGP+DXyJ7Tq6Htt99GpfxVKb/GI3ADmFmgiUCgSPfLaClTsKvfqe3dvE8vB5Per1mqysLObOnYvL5aKwsJA5c+YQHBzMjBkzuP/++/nwww+PeM3q1auZOXMmRUVFdO3alfHjx9drvMDR+CwRGGPGHuO4AW7x1fXrKs8pEeQUNf+BJkqpxuOiiy7C5XIBUFBQwFVXXcW6desQEdxud42vOeeccwgLCyMsLIyUlBSys7NJS0v7zbEE/MjiAyUCrRpSKiDU987dV6Kiog5sP/jgg5x88sl8/PHHbN68mZEjR9b4mrCwsAPbLpcLj8fjlViaRK8hryjIgjVfHbE7v8QpEWjVkFLKTwoKCkhNtb3nJ02a1ODXD5xEsOwDmHwJlBUdsjvvQIlAq4aUUv5x77338pe//IV+/fp57S6/PqSpDaTKyMgwv2phmmUfwIfXws3zIKUbYOfl6PrXryivqCQmPJhlE870crRKqcZg1apVHH/88f4Oo8HU9POKyAJjTI19UQOnRBDrDFouzDqwq7i8gvKKSmLDgykq9VDqrvBTcEop5T+BkwjinERQcHDMWn6JrRbq2ioG0HYCpVRgCpxEENMaECg8mAjynFHFXVo6iUDbCZRSAShwEoErBGJaHVoicBqKDyYCLREopQJP4CQCsO0E1doIqrqOHkgEhVoiUEoFnsBKBHFph5QIqrqOdkyOIjhItESglApIAZgIssDpMlvgTC+REBlKi+gwTQRKKZ84+eST+frrrw/Z9+yzzzJ+/Pgazx85ciRV3eRHjRpFfn7+EedMmDCBp59+2ivxBVYiiE0FTwmU5AG2RBAV6iI0OIiUWE0ESinfGDt2LFOmTDlk35QpUxg7ttYp2QD48ssviY+P91FkVmAlggNdSG07QV5xOfGRoQCkxIRpG4FSyicuvPBCvvjiiwML0WzevJkdO3YwefJkMjIy6NGjBw8//HCNr01PT2fPnj0A/O///i9dunRh+PDhB6aq9obAmnQu1pmlr3A7tO5NQbGb+Eg7hWtyTDiLtub7LzalVMOYfh/sWubd92zVC87+21EPJyYmMmjQIKZPn86YMWOYMmUKF198Mffffz+JiYlUVFRw6qmnsnTpUnr37l3jeyxYsIApU6awePFiPB4P/fv3Z8CAAV4JP+BLBAnVSgS5+8txV1T6KzqlVDNWvXqoqlpo6tSp9O/fn379+rFixQpWrlx51NfPmTOHCy64gMjISGJjYxk9erTXYgusEkFUCgSFHBhUll/ipnV8BAApsXZ61z37ymgdF+G3EJVSPlbLnbsvjRkzhjvvvJOFCxdSXFxMYmIiTz/9NPPnzychIYFx48ZRWuqf6unAKhEEBUFs6wNdSPOL3SQ4VUMpMeGATjOhlPKN6OhoTj75ZK655hrGjh1LYWEhUVFRxMXFkZ2dzfTp02t9/YgRI/jkk08oKSmhqKiIzz77zGuxBVaJAGw7QeF2KisN+cXlxEccrBoCHV2slPKdsWPHcsEFFzBlyhS6detGv3796NatG23btmXYsGG1vrZ///5ccskl9OnTh5SUFAYOHOi1uAIvEcSlwrZfKCrzUGk40FhcVTWk8w0ppXzl/PPPp/rU/0dbhGbWrFkHtjdv3nxg+4EHHuCBBx7welyBVTUEdlBZ4Q7y99sv/KrG4hbRYYho1ZBSKvAEXiKITYVKN/tydwIHSwQhriASI0O1akgpFXACLxHE2bEEpblbAQ4MKANIjgljt1YNKdUsNbXVGH+tX/NzBl4icFYqq8jbBhwsEQCkxIZriUCpZig8PJzc3NxmnwyMMeTm5hIeHl6v1wVgY7EzurggC0g50EYAtufQ2l1FNb9OKdVkpaWlkZWVxe7du/0dis+Fh4eTlpZWr9cEXiKISIDgCFz7dgD9iQ0/+CtIiQljz74yKisNQUHivxiVUl4VEhJChw4d/B1GoxV4VUMiEJdKePEuYsODCXYd/BWkxIThqTTsdaanVkqpQBB4iQAgNpXI0l0kRIUesjslVkcXK6UCT2Amgrg04tw5xEeEHLL74Ohi7TmklAocgZkIYlOJq9hLYoTrkN0H5hvSnkNKqQASmIkgLhUXlbQPLThkd9U0E7s1ESilAkiAJgLbtaqtK++Q3eEhLmLCg3WlMqVUQPFpIhCRs0RkjYisF5H7ajjeTkRmisgiEVkqIqN8GU8VT3QbAFqRe8SxlBhdu1gpFVh8lghExAW8CJwNdAfGikj3w077KzDVGNMPuBR4yVfxVFcY1gqAFHPk4JKUGB1drJQKLL4sEQwC1htjNhpjyoEpwJjDzjFArLMdB+zwYTwH5HlCKTSRJHlyjjiWEhumvYaUUgHFlyOLU4Ft1Z5nAYMPO2cC8I2I/BGIAk7zYTwH5BeX4zZJtCivIRHEhJFTWIYxBhEdXayUav783Vg8FphkjEkDRgFvicgRMYnIDSKSKSKZ3pgrJL/YzU6TSGTpriOOpcSEU+appKjM85uvo5RSTYEvE8F2oG2152nOvuquBaYCGGN+AsKBFoe/kTHmFWNMhjEmIzk5+TcHllfsZqdJIqx45xHHDqxUpqOLlVIBwpeJYD7QWUQ6iEgotjF42mHnbAVOBRCR47GJwOfTA+YXl7PDJOEqyQX3oe0ByTq6WCkVYHyWCIwxHuBW4GtgFbZ30AoReVRERjun3Q1cLyJLgMnAONMAE4bnF7vJliT7pPDQQkrV6GIdVKaUChQ+nYbaGPMl8OVh+x6qtr0SGObLGGqSX1JOYWhLqMQmgqROB45p1ZBSKtD4u7HYL/KK3RRH2LEEFBxaIogJCyY8JEirhpRSASMgE0F+cTnuSCcRFGYdckxEdFCZUiqgBGgicBMVFQORLY4oEcDBsQRKKRUIAjYRxEWGQFzqEY3FoKOLlVKBJUATQbldtD427SglAq0aUkoFjoBLBOWeSvaXV5BQVSIoyDrinOSYMIpKPZS6K/wQoVJKNayASwT5zsL0cZGhEJsKZQVQVnTIOQeWrNR2AqVUAAi8RFDiBnBKBHaBmsOrhw4sYq/tBEqpABBwiSBvvy0RxEc4JQI4ogvpwUXstUSglKqDNdPh7QtrbHNsCgIuEVSVCOKr2gjgyBLBgaohLREopY4heyV8cC2s/xYmndMkk0HgJQKnjSAhKhRiWgNyRBfShMhQgoNESwRKqdqV5MGUyyAsGi5+C/bvcZLBkZ1QGrMATAROiSAiBFwhENPqiAweFCQk69rFSqnaVFbAh9fbL/2L34Tuo+GKj6E41yaD/G3Hfo9GIuASQV6xm1BXEJGhLrsjLu2INgLQReyVUscw6/9sddDZT0C7E+y+tgPhik+gOM9JBlu9c62CLFj6PuRu8M77HSbgEkF+cTlxkSEHl6GMTa2xTi85JlzbCJRSNVv1Gcx+CvpdARnXHHosbQBc+TGU5NtkkLelfu9dWQnZK2D+a/DhdfBMT3imB3x0Haz58tiv/xUCMBG4bdfRKnFpto3gsGUQUmLDjliToMxTwUcLs7jprQWszT507IFSKkDsXgMf3wSpA2DU01DT2uapA+DKT6C0ACada7/Y62LNdPh7F/jXUPjibtg0B9Iy4Own4cbZMHi8V3+UKj5dj6Axyisut11Hq8SmgrsY5v4TOp8ByV1BhJSYMHL3l+OuqCSvuJx3ft7KO/O2smdfGUECy3cU8Oktw0iKDvPfD6OUajjGQOEO2zgcEmEbh0PCj35+an+4chq8ewm8eiqc9xz0uaTmcysrbQlj1uPQqjec/pitbkpIrznReFnAJYKCEjftEiMP7ug4EpI6w7cP2kdMG+h0MgNNb5KJ5o9vz+e7tbm4KwyndEvh6mHpRIcFc+krPzP+7YW8fd1gQoMDrmClVPNV4YH9OZC3GXJWQs5qyFllt0v2QlCw/YKv6n5emzZ97Z38B1fDxzdA1i9w5v9BcLWb0dJC+GQ8rP4cel8K5z1rE00DkgZYGdKrMjIyTGZm5q9+/eDHZzCySwpPXNj70AP5W2HDTNjwPWycBaX5Bw55JAQJjcIVFgUhkRAWzc7KBKZnhZKcdhznjhiMJLSHuLYQkdAgGVwp5QXrZsDKj6EoG4p2wb5dtgso1b4XQ2Mg5fiDj/Th0KpX/a5T4YbvHrE1D6kZcPF/bLX0nnW2hJG7Ac58HAbf6LPvDxFZYIzJqPFYICUCYwxdH/yKq4em85dRxx/9xMoKKrcvZsOi72gX6SHMlNnqo/JicO+3cxMVbKc8dzOhlSWHvjY43HZJjWkN0S3xRLdk7f5oWnfuT0LnEyCqxa+KXSnlZcs+gI+uh/B4iG974P+s/f/byt7YpRxvq4+99eW84hP49BYIDoOhf4Q5/7Dd2C/6D3Q40TvXOIraEkFAVQ2Vuisp91QSHxla+4lBLoLaDqBz2wG1nhZcUck9b89i7ZoV/O8p8fSKLICinbAvm4rCnezbvIjg4hy6UwJVbUXx7W1DUtWjdR8Ijaz1OkopL6tKAu2GwOXvQ2hUw1y3x/nQsge89weYMcH+/7/kHZuI/CigEkGeM6o4vnqvod8gyBXEo2NHcNG/Q7hsTjEf3Xw+aQmRvDNvCy+v3sjuojIGpScytnccX8z4ll6s45rEvcRkzYcVH9k3EZe960jtbxNDm/6Q0h1cAfWnUarh+CsJVGnRGa77znYFPf68Bm8PqElAfdtUjSpO8FIiAIgMDebVKzMY/cKPXDnxF9wVlezZV86Qjkk8f2k/hnRKAqBnp7b84fV5vLG5kjevGUTvuDLYsRC2L4TtC2DlNFj4pn3T4AhoNxi6nA1dz7I9B5RSv93S922jbbuhcPnUhk8CVcKioffF/rl2DQKqjWDu+j1c9to8Jl9/woEvaG9ZtDWPP7w2j37tErjt1M4M6pB4xDlbc4u57LWfyS92M3HcwEPPMQbyNh1MDOu/gz1r7LHk46HLmdD1bEgbCEEur8auVEBoLEnAT7Sx2PHF0p3c8u5CvrrjRLq1ivVyZOCpqCTYVXtX0p0FJVz+2jx25JfwyhUZjOiSfODY/jIPuwpL2V1UxvGtYokr3QZrvoK102HLXKj02O6t/f5gHwntvf4zKNXsFGXDsqnw7UMBmwRAG4sPyC9xZh49VmPxr3SsJADQOi6CqTcO4YrXf+G6/2QyoH0COUWlZBeWsa/Mc+C8tAR7XpshN8OQm+1w9fUzYMkUO/Bk9lPQ6WTofxV0HXVov2SlAlllJexYBOu+hrVfw87Fdn+Hk2Ds5IBMAscSUCWCF2eu56mv17D6sbMID/Fv9UpBsZv7PlpKdmEpreLCSYkJp2VsOK3iwnAFBfHAR8tIig5l6o1DDqyYdkD+Nlj8Dix8y06YF9kCel9ieySkZkCQDnBTAShvC/z4HKyaBvt3gwTZqtTOZ9iq1ZY9A3qMj1YNOf73i5W8/fNWVj12lpej8r4FW/K48vV5tI6PYMoNJ9CipqksKivsALgFk2DdN1BRbquOuo+G7mOg7WBtT1DNX/5WmP20vTmSINsTp8tZcNxpEHlkW12g0qohR16x22tdR31tQPsEJo4byFVv/MIfnAbuhKjDqn+CXND5dPsoLYS1X8HKTyHzDZj3bzs4pufv4YSb/d5PWSmvy98Kc/4Oi96xd/oDrobhd9Zt6gd1iICqQ8gvdh97MFkjMrhjEq9dOZCNe/ZzxcR5FDjLbNYoPNZ2R7v0Hbh3A1w40ZYIfnkVnu8Ln9xih7Mr1dR5yuDLe+H5/rD4XRgwDm5bDOc8rUngVwqoEkF+cblXxxA0hOGdW/DyFQO44c1Mrpr4Cy9c1o+8/W625xeTlVfC9vwStueV0K1VDHed0dW+KCzGlgR6/t62J8z9Jyz8jy069zgfht8FrXvXel2lGqXivXZunq0/2XUATrxHv/y9IKASQV5xOV1bxfg7jHo7uWsKL17Wn5vfWcjwJ2Yeciwy1EVCZCjfrMymW+tYRvVqfeiL49vCqCdhxJ/g55fsYhcrPrb1p/2usGMTgnUqbdUE5G6Ady6yq3VdONHe6CivCKhEUFDStKqGqjujRyum3HACS7MKSE2IIDU+grSECOIiQvBUGn730lwe+HgZGekJpMTUMEd6dDKc9jAMu91WF2W+Du9fZSfc6vk76HOZXQAjgHtVqEZsy0+2JABw1bSDS0Mqr/BpG4GInCUia0RkvYjcd5RzLhaRlSKyQkTe9VUsxhjbRhDRtKqGqstIT+Sa4R04s0creqbGER8ZiogQ4griHxf3YX95Bfd/tJxae4JFxMNJf4I7V8AfPrINzYsnw+unwQsD4b/PQvn+hvqRlDq2ZR/Am6NtD6DrZmgS8AGfJQIRcQEvAmcD3YGxItL9sHM6A38BhhljegB3+CqefWUePJXGZ4PJ/K1zyxjuPbMrM1Zl88GCrGO/IMgFx50Kv38N7lkLo1+A6BSY8TD8c4BNDpWVvg9cqaMpyobv/wc+vNaOj7n2W0jq5O+omiVflggGAeuNMRuNMeXAFGDMYedcD7xojMkDMMbk+CqYqgnn4ppYY3F9XDOsA4M6JPLoZyvZnl9y7BdUCY+F/lfA1V/CNd9AbBv45CZ47RTY+rPvAlaquqoRwbP+Bq+cbNfunf0U9LrYrv+rYwJ8xpdtBKnAtmrPs4DBh53TBUBEfgRcwARjzFeHv5GI3ADcANCuXbtfFUzVFNTNtUQAEBQk/P2iPpz17Gz+9P4S3r52MEFB9azzbzcYrp0By96386VPPBN6XACnPaJzG6lfzxi76Pv2TLuwk7vEdgP1lIC7FEryYNNsu0IYYturTvkrdD7TrgambVc+5e/G4mCgMzASSANmi0gvY0x+9ZOMMa8Ar4AdWfxrLuSLKagbo7aJkfz13O785aNlvPnTZsYN61D/NwkKsotsH3+u7Xr632ftNNlt+kH7odB+mE0YEQlej181IaWFdlnXsGiITDr4CIlwvvhXw+b/HnwU7znyPVxhdgH4kChb99/lTDjudNu5QTUYXyaC7UD14axpzr7qsoB5xhg3sElE1mITw3xvB+PtRWkas0sHtuXrFbv421erGdElmY7J0XgqKiks9ZBfXE5+iZvk6DDaJh5jZbTQKBh5n+1mmjkRtvxoRyzPfR4QO3dL+nAYeB20OK5BfjbVSOxcAlOvslOnHy4kyi7wXlZgn8em2e7K6cPtYjCRiTZZuMJ0XqxGwpeJYD7QWUQ6YBPApcBlh53zCTAWeENEWmCrijb6IpiqUblNtftofYgIT/y+N2c8M5sxL/wIAkWlnkPOCQ4SPrllGD1T4479hnGpcOqDdttdYtdL2DLXJoYFb8AvL0OfsXDSvbqITnNnjL0p+Oov9u7/sqkQFgvFuc5jjx305S62K+6lD7fLs2rVTqPms0RgjPGIyK3A19j6/4nGmBUi8iiQaYyZ5hw7Q0RWAhXAn4wxub6IJyLExXEp0cQ14e6j9dEyNpxXrhjAe5nbiA0PIT4yhPiIEOIjQ4kOC+b+j5dx99QlTPvjMMKC6zExXUiE/c+dPtw+35djq44yX4el79l1Ekb8CeLSfPJzKT8qK4LP7oDlH0CnU+F3r0BUC39HpbwgoGYfVQfNXJ3D1ZPmM35kJ/58Vrff/oaFO+0EYAsmOROAjbNTY7fuq+svNwfZK2DqlbB3I5x8Pwy/W6t1mhidhlrV6L4PlzI1cxvv3zSUAe291PCbv812+Vv8jl1RLSwW0k+EjidBx5HQootWEzR2xXvtdA656+1j7wZYMx3C4+D3r0OHE/0dofoVNBGoGhWVujnr2TmEBgfx5W0nEhHqxbUL9u+x3QE3zrKP/C12f0xrW300eDxEeXfdaFVP5fshZxXsWmbv+LNXwO5VtitnFXHZbsOpA+DMx+2gQ9UkaSJQRzV3/R4ue20e44amM2F0D99daO8m2PTDwTWYQyLt7JFDboXY1sd+vfIOT5ktsS3/0P5NcP7/h8ZAyx6Q0g2SOkPScXYUb3x7XQa1mdBEoGo1YdoKJs3dzLvXD2ZopwZo/MtZDf99xg5aC3JB38th+B3a48jXdiyCj8fbu/7OZ9hpG1r1tAkgrp3W+TdzmghUrUrKKxj1/BzKPZV8fecIosMaqHF37ya7xuzid+yym/FtITTaeUTZgUqh0dBhBPS8UBudfy1POcx52i7nGJ0C5z0PXc7wd1Sqgf3mRCAiUUCJMaZSRLoA3YDpzkCwBqWJwDcWbNnLRf/+ifP7pfLI6B7EhDdgN9vCHTD/dbv0YPk++yjbZ+uwS/bahcgTO9lxCrUlhJzVdq2FiAQYdH1grNe8fw98/5j9t2VP5w6/py1dicCu5XbeqF3LoPelcPbfdER4gPJGIlgAnAgkAD9iB4uVG2Mu92agdaGJwHee+Go1/5q1AVeQ0DM1jiEdkzihYyID0xOJaqhSwuGMgdVf2InIspfZuusR99pFSVzBtlSx4iNY9iHkrAAEMHYajN+92rxXr1rxMXxxD5QWQHw727Wzep1/SjfYsdhOPX7ec9DtHD8Gq/zNG4lgoTGmv4j8EYgwxjwpIouNMX29HOsxaSLwHWMMP23M5acNufy8MZfF2/JxVxhcQcKg9EReuKwfSdF+Ws2sshLWVCWE5TYhhMfbSczArs/c80LoPgY2zoTP77KNnGNePPoXYEkeLJliv0iH/tFWR9Uljv05ENPKaz/aIUoLbWNueCwcPxqSux55zr7d8OXdsPJTO07j/JdsPf8hvYCW215AiR3h9Me0h5bySiJYBNwMPANc64wQXmaM6eXdUI9NE0HDKS73sHBLPnM37OHVORs5r08b/nFxX/8GVVkJqz+3jc2VHru6Wo/fHTkzau4G+OBqOyfOoBvsl2FIuC1hbPvFTo2x4mPwlNrzk7vBRf+xd9FHk78NPr3F9n4adjuc8iC4jlGFtm83LHrLxnmsxvDcDTB5LOSuA+OsBZHUGY4/zz7a9LO9fb78k60+G3kfDL1d205UnXgjEZwE3A38aIx5QkQ6AncYY27zbqjHponAP57+eg0vzFzfcD2LvMFTBjMegZ9fhJa97Iyqi9+FnJW26qT3RTDgatsO8eF19o763Gegz6WHvo8xsOhtO78OBjqcZEsn7YbYtXNj2xx5bWNsr6jpf7bvHxJpR+QOHl/zF/fGH+zSoQAXv2lLPKu/gFWf2Zk7TQVEJNr3Sh0AY16qPWkpdRiv9hoSkSAg2hhT6I3g6ksTgX+Uuis445nZBLuE6befWL/5ifxt7Te2wbQ411alZFxtq5HCog+eU7jTJoMt/7WzrY56ys6rVLgTPrsN1n1jR0iPedGWPpZ9ANNus6WM371iZ9esUrAdPr8T1n1tu2ie8leY97IdP9G6L4x+Hlr3OXj+L6/ahNGiM4ydbKtzqiveC2u/gnXf2iQw+CYtBah680aJ4F3gJuzEcPOBWOA5Y8xT3gy0LjQR+M+sNTmMe2M+d5/ehT+e2tnf4dRPsdP7qKY69yoVHpj1uJ0zqWVP6H8lzHzclixOm2CrmKr3td+91t7F56yCEffASX+2JYdvH7LVVqc8CINvtL2XjIGVn8CX99qENPRWOPEeuzRo5kTocpZt3A6P9fVvQgUobySCxcaYviJyOdAfuA9YYIzp7d1Qj00TgX/d8u5Cvl2ZzTd3jCC9RR0aV5uidd/CR9fbxuS0gXD+v4++3kJ5sa2zX/w2RLaw0zB3GGH76ifWsChQSR5886BtNwgOt20Uw26HUx8OjO6uym+8kQhWAH2Bd4EXjDE/iMgSY0yf2l/pfZoI/Cu7sJRT//4D/drF8+Y1g5DmOoFcwXbY+pNdprMuX9CL37XTcQ+5xZYkjvV72TTH9oDqf8WRbRJK+UBtiaCuFY0vA5uBJdjlJNsDfmkjUP7VMjace87owoTPVvL50p2c16eGhtLmIC4Vel1Y9/P7XmYfddXhRJ3FUzUadZpcxBjzvDEm1RgzylhbgJN9HJtqpK4Ykk6v1Dge/XwlhaUNPrhcKeVldUoEIhInIv8QkUzn8XegmVYQq2NxBQmPX9CL3H1l/P3rNQBUVBr2lXnIKSpla24x2/YW+zlKpVRd1bVqaCKwHLjYeX4F8AbwO18EpRq/XmlxXDkknUlzNzN5/jbKPZVHnPPomB5cOSS94YNTStVLXRNBJ2PM76s9f0REFvsgHtWE/OnMriREhlLs9hAZEkxkqIvwUBeRIS4+WJDFk1+t4cwerWgZG+7vUJVStahrIigRkeHGmP8CiMgwoMR3YammICosmNtPq3k8QUZ6Aqc/M5vHPl/JC5f1b+DIlFL1UdeVKG4CXhSRzSKyGXgBuNFnUakmr31SFLeMPI7Pl+5kzrrd/g5HKVWLuvYaqhoz0BvobYzpB5zi08hUk3fjSR3p0CKKBz9ZTqm7wt/hKKWOol5r0xljCqvNMXSXD+JRzUh4iItHRvdgc24xr8ze6O9wlFJH8VsWKW2mQ0qVN43oksw5vVvzwsz1bMnd7+9wlFI1+C2JoGktdqz85qFzuxPqCuKhT1fQ1NbIVioQ1JoIRKRIRApreBQBzXRuAeVtLWPDufP0LvywdjdfLd/l73CUUoepNREYY2KMMbE1PGKMMTohuqqzq4a05/jWsTzy2Ur2lXn8HY5SqprfUjWkVJ0Fu4L4n/N7kl1Uyhn/+IH/zN2sPYmUaiQ0EagGM6B9Au9cO5g28RE8PG0FJz45k1dnb2S/lhCU8qt6L1Xpb7oeQdNnjOHnjXt5YeY6flyfS0JkCNcO78DVwzoQFaY1jkr5gjfWI1DKa0SEIZ2SGNIpiQVb8njh+3U8/c1aZq/bw1vXDmpa6yEr1Qz4tGpIRM4SkTUisl5E7qvlvN+LiBGRGrOVar4GtE/gjasH8ewlffll017u/WCpdjFVqoH5rEQgIi7gReB0IAuYLyLTjDErDzsvBrgdmOerWFTjd36/VLbnl/DU12tomxDJPWfWssi8UsqrfFkiGASsN8ZsNMaUA1OAMTWc9xjwBFDqw1hUE3DzyE5cOrAtL8xcz3vzt/o7HKUChi8TQSqwrdrzLGffASLSH2hrjPmitjcSkRuqVkfbvVtnsmyuRITHzu/JiC7J3P/xcmav1b+1Ug3Bb91HRSQI+Adw97HONca8YozJMMZkJCcn+z445TchriBevKwfnVOiufmdhazaWXjsFymlfhNfJoLtQNtqz9OcfVVigJ7ALGeNgxOAadpgrGLCQ3jj6oFEhwVz9Rvz2VmgayAp5Uu+TATzgc4i0kFEQoFLgWlVB40xBcaYFsaYdGNMOvAzMNoYo4MEFK3jIpg4biBFpW7Of/FH5m7Y4++QlGq2fJYIjDEe4Fbga2AVMNUYs0JEHhWR0b66rmo+ureJ5b0bhxAVGszlr83j6a/X4K6o9HdYSjU7OrJYNXr7yzw88tkKpmZm0b9dPM9d2o+2iZH+DkupJqW2kcU615Bq9KLCgnnywj48P7Yf67L3Mer5OXy+dIe/w1Kq2dBEoJqM0X3a8OXtJ3JcSjS3vruIRz9bqaOQlfICTQSqSWmbGMnUG4cwbmg6E3/cxDMz1vk7JKWaPJ10TjU5Ia4gHj6vO/vLPDz/3ToSI0MYN6yDv8NSqsnSRKCaJBHh/37Xi/wSNxM+W0lCVChj+qYe+4VKqSNo1ZBqsoJdQfxzbD8GdUjk7qlL+EGnpFDqV9FEoJq08BAXr12VQeeWMdz01gIWbs3zd0hKNTmaCFSTFxsewn+uGUhKbBjXTJrP2uwif4ekVJOiiUA1Cykx4bx1zWBCXEGc/+KPPDtjLcXluhayUnWhiUA1G+2SIvlo/FBGdk3m2RnrGPnULN6bv5WKSh1roFRtNBGoZqVtYiQvXT6AD8cPITUhgj9/uIxRz83RhmSlaqGJQDVLA9on8tH4obx0eX9K3BVcNfEXxr+9AI9OWqfUETQRqGZLRBjVqzXf3jWCu07vwvTlu3jiq9X+DkupRkcHlKlmLyzYxW2ndmbPvjJenbOJnqlxOvhMqWq0RKACxl/P6c7A9AT+/OFSVuwo8Hc4SjUamghUwAgNDuKlywcQHxHKjW8tIG9/ub9DUqpR0ESgAkpyTBj/vmIAOUVl3Dp5oTYeK4UmAhWA+raN53/O78mP63O18VgptLFYBaiLM9qyfHuBNh4rhZYIVAB78NzuDEq3M5c+N2Mdbq0mUgFKE4EKWCGuIF69KoNze7fmmRlrufBfc9mwe5+/w1KqwWkiUAEtLiKEZy/tx4uX9WfL3mJGPTeHST9uolLnJ1IBRBOBUsA5vVvzzR0jGNopiQmfreSKifPYkV/i77CUahCaCJRypMSGM3HcQP7vd71YtDWfM5+dzceLsjBGSweqedNEoFQ1IsLYQe346vYRdG0Zw53vLeGWdxfq4DPVrGkiUKoG7ZIiee/GIfz5rG58uzKbM56dzcw1Of4OSymf0ESg1FG4goTxIzvx6S3DSYwM5eo35nP/x8vYX6Yrn6nmRROBUsfQvU0sn946jBtGdGTyL1s55/k5bNtb7O+wlPIaTQRK1UF4iIv7Rx3P5OtPIK/YzaWv/ExWniYD1TxoIlCqHk7omMTb1w6msNTNZa/OY2eBdjFVTZ8mAqXqqVdaHG9dO5i8/eWMfeVnsgtL/R2SUr+JTxOBiJwlImtEZL2I3FfD8btEZKWILBWR70SkvS/jUcpb+raNZ9I1g9hdVMbYV38mp0iTgWq6fJYIRMQFvAicDXQHxopI98NOWwRkGGN6Ax8AT/oqHqW8bUD7BCZdM4hdBaVc/uo89uwr83dISv0qviwRDALWG2M2GmPKgSnAmOonGGNmGmOqWtx+BtJ8GI9SXjcwPZGJ4wayLa+YP7w2jxytJlJNkC8TQSqwrdrzLGff0VwLTK/pgIjcICKZIpK5e/duL4ao1G93QsckXr9qIFv3FnPeC/9l8bZ8f4ekVL00isZiEfkDkAE8VdNxY8wrxpgMY0xGcnJywwanVB0MO64FH908lNDgIC5++Sc+WJDl75CUqjNfJoLtQNtqz9OcfYcQkdOAB4DRxhitZFVNVrdWsUy7ZTgZ7RO45/0lPPrZSl0TWTUJvkwE84HOItJBREKBS4Fp1U8QkX7Ay9gkoBO5qCYvISqUN68ZxNXD0pn44yaueuMXnbBONXo+SwTGGA9wK/A1sAqYaoxZISKPisho57SngGjgfRFZLCLTjvJ2SjUZwa4gHj6vB09e2Jv5m/IY/eJ/WZtd5O+wlDoqaWpzrWdkZJjMzEx/h6FUnSzcmseNby2gtLyCFy7vz0ldtI1L+YeILDDGZNR0rFE0FivVXPVvl8AntwwjNSGCaybN562fNvs7JKWOoIlAKR9LjY/gg/FDGdklmQc/XcGEaSu0EVk1KpoIlGoA0WHBvHJlBtcO78CkuZu57s1Mikrd/g5LKQCC/R2AUoHCFSQ8eG53OiZH8dCnK/j9v+ZyTq82RIQGER7iIjzYRVhIEFGhwQzumEhMeIi/Q1YBQhOBUg3s8sHtaZ8YxR3vLeaZGWtrPKdlbBiPjO7JWT1bNXB0KhBpryGl/MhTUUmpp5JSdwUl5RWUeSrYWVDK41+uZtXOQs7o3pJHx/SkVVy4v0NVTVxtvYY0ESjVCLkrKnn9v5t45tu1hLqCuPfsblw+qB1BQeLv0FQTpd1HlWpiQlxB3HRSJ765cwS928bx4CfLuejln5i7YQ8VlU3r5k01floiUKqRM8bw0cLt/M8XK8krdpMUFcoZPVpxds9WDOmURIhL7+fUsWnVkFLNQHG5h1lrdvPlsp3MXJ3D/vIK4iJCOO34llw9LJ2eqXH+DlE1YpoIlGpmSt0VzFm3h+nLd/LtymzKPJU8fVEfRvdp4+/QVCNVWyLQ7qNKNUHhIS5O796S07u3ZO/+cm58K5PbJi9i8579/PGU4xDRRmVVd1q5qFQTlxgVytvXDeaCfqn849u13DV1CWWeCn+HpZoQLREo1QyEBbv4x8V96Ngiir9/u5Zte4t5+YoBJEWH+Ts01QRoIlCqmRAR/nhqZzokR3HX1CVc8NJc7h/VjdBgW/A3xj4AOiRH0Sk52o/RqsZEE4FSzcy5vdvQJj6CG97M5Ka3F9Z4jitIuG54B+44rQsRoa4GjlA1NpoIlGqG+rdL4Lu7RrJxzz5EBAGq2o+NgSnzt/Ly7I1MX76Lxy/oxfDOLfwar/Iv7T6qVID6aUMu93+8jE179nPhgDQeGHU8CVGh/g5L+YiOI1BK1ajUXcE/v1/Hyz9sJC4ihPEjO9E6LoK4iJBDHjHhwTrPUROniUApVatVOwu576NlLNmWX+Px2PBgLs5oy5VD0mmXFNmwwSmv0ESglDomYwy7CkspKHFTUOymoMRNYamHghI3i7bm8dXyXVQYw6nd7JQWQzsl6cC1JkRHFiuljklEaB0XQeu4iBqOdmBXQSnvzNvCu/O2MmNVNl1aRnPhgDRiw0MIChKCRHAFQZAIESEuBnVIJD5S2xyaAi0RKKXqpdRdwedLd/LGj5tYsaPwqOe5goQB7RM4tVsKpx6fQqfk6BpLEMXlttTRKjZcSxg+pFVDSimvM8awZ185nspKKioNxkBFpaHCGPL2l/PD2t18tyqHlTttsmiXGMmw41pQ5qkgu7CU7MIysgtLKSr1ADCkYxKPnd+D41Ji/PljNVuaCJRSfrMjv4TvV+fw/eoc5m/eS2x4CCmxYbSKDael86g0hpd/2ECJu4Jrh3fktlOPIzJUa669SROBUqrR27OvjL9NX80HC7JIjY/gwXO7c2aPllpd5CWaCJRSTcb8zXt58JPlrN5VxMiuyQzukITBHJgnqeo7q21iJH3S4mmfFKnJog40ESilmhRPRSWT5m7muRnrKCrz1HpuXEQIvdPi6JMWT++0OJJjwjAcnGAP7EZiVBjtEiNxBejAOE0ESqkmyVNRiafy4HeUCAhCpTFs3L2fJVn5LM3KZ8m2AtZkF1FRWfv3WVhwEJ1bRtMlJYYurWLo2jKGFtFhlHkqKPdUUuappMxTQZmnkuLyCopK3ewr9VBY6qGo1ENRqZtgl9AzNY6+afH0SosjJjzE178Gr9BEoJRq9krKK1i5s5DCUjeAM9Hewbv/nMJS1mYXsSZ7H2t3FbGrsLRO7ysC0WHBxIaHEB0WTKmngi25xQeOdUqOpk9aPN1axRAeEkSwK4jgICHEFUSwS4gMddGhRbTfSyM6oEwp1exFhLoY0D6hzucXFLtZk11EfnE54SEuwoKDCKv6NziIiFAXMeEhRIa4jphnKW9/OUu3F7BkWz5LtuUza00OHy7MqvV6YcFBdEqOpkvLaDq3jKFDiyjcFZXsL6tgf5mHfWUe9pd5KPVUkBwdTtvECNISIklLiKBlbLhPk4hPSwQichbwHOACXjPG/O2w42HAm8AAIBe4xBizubb31BKBUqqxMcZQWOKhvKIST2UlngqD26nWKir1sGH3PtZlF7E22/67o6Dm0khkqE1EecXuQ/YHBwlt4iO4+4wujOmb+qti9EuJQERcwIvA6UAWMF9EphljVlY77VogzxhznIhcCjwBXOKrmJRSyhdEhLjIo7cVHF5SKSp1s21vCWEhQUSFBhMV5iIyNPjAXX+pu4Id+SVk5VU9itmWV0JSlG+WHvVl1dAgYL0xZiOAiEwBxgDVE8EYYIKz/QHwgoiIaWoNF0opVQ8x4SF0b3P0xBEe4qJjcjQdG2g50SAfvncqsK3a8yxnX43nGGM8QAGQ5MOYlFJKHcaXicBrROQGEckUkczdu3f7OxyllGpWfJkItgNtqz1Pc/bVeI6IBANx2EbjQxhjXjHGZBhjMpKTk30UrlJKBSZfJoL5QGcR6SAiocClwLTDzpkGXOVsXwh8r+0DSinVsHzWWGyM8YjIrcDX2O6jE40xK0TkUSDTGDMNeB14S0TWA3uxyUIppVQD8umAMmPMl8CXh+17qNp2KXCRL2NQSilVuybRWKyUUsp3NBEopVSAa3KTzonIbmDLMU5rAexpgHDqS+OqH42rfjSu+mussfkirvbGmBq7XTa5RFAXIpJ5tDk1/Enjqh+Nq340rvprrLE1dFxaNaSUUgFOE4FSSgW45poIXvF3AEehcdWPxlU/Glf9NdbYGjSuZtlGoJRSqu6aa4lAKaVUHWkiUEqpANfsEoGInCUia0RkvYjc18DXnigiOSKyvNq+RBH5VkTWOf8mOPtFRJ534lwqIv19GFdbEZkpIitFZIWI3N4YYhORcBH5RUSWOHE94uzvICLznOu/50xaiIiEOc/XO8fTfRGXcy2XiCwSkc8bS0zO9TaLyDIRWSwimc6+xvAZixeRD0RktYisEpEh/o5LRLo6v6eqR6GI3OHvuJxr3el85peLyGTn/4L/PmPGmGbzwE5utwHoCIQCS4DuDXj9EUB/YHm1fU8C9znb9wFPONujgOmAACcA83wYV2ugv7MdA6wFuvs7Nuf9o53tEGCec72pwKXO/n8D453tm4F/O9uXAu/58Hd2F/Au8Lnz3O8xOdfYDLQ4bF9j+Iz9B7jO2Q4F4htDXNXicwG7gPb+jgu7INcmIKLaZ2ucPz9jPv3lN/QDGAJ8Xe35X4C/NHAM6RyaCNYArZ3t1sAaZ/tlYGxN5zVAjJ9i15JuNLEBkcBCYDB2RGXw4X9T7Ey2Q5ztYOc88UEsacB3wCnA584Xg19jqhbbZo5MBH79O2LXEdl0+M/t77gOi+UM4MfGEBcHV2ZMdD4znwNn+vMz1tyqhuqyPGZDa2mM2els7wJaOtt+idUpVvbD3n37PTanCmYxkAN8iy3R5Ru7dOnh126opU2fBe4FKp3nSY0gpioG+EZEFojIDc4+f/8dOwC7gTec6rTXRCSqEcRV3aXAZGfbr3EZY7YDTwNbgZ3Yz8wC/PgZa26JoFEzNqX7rb+uiEQDHwJ3GGMKqx/zV2zGmApjTF/sXfggoFtDx1CdiJwL5BhjFvgzjloMN8b0B84GbhGREdUP+unvGIytEv2XMaYfsB9b5eLvuABw6tpHA+8ffswfcTltEmOwCbQNEAWc1ZAxHK65JYK6LI/Z0LJFpDWA82+Os79BYxWREGwSeMcY81Fjig3AGJMPzMQWiePFLl16+LXrtLTpbzQMGC0im4Ep2Oqh5/wc0wHO3STGmBzgY2zy9PffMQvIMsbMc55/gE0M/o6rytnAQmNMtvPc33GdBmwyxuw2xriBj7CfO799xppbIqjL8pgNrfpynFdh6+er9l/p9FQ4ASioVlz1KhER7Gpwq4wx/2gssYlIsojEO9sR2HaLVdiEcOFR4vLp0qbGmL8YY9KMMenYz8/3xpjL/RlTFRGJEpGYqm1svfdy/Px3NMbsAraJSFdn16nASn/HVc1YDlYLVV3fn3FtBU4QkUjn/2bV78t/nzFfNtD444Ft+V+LrWt+oIGvPRlb5+fG3iVdi63L+w5YB8wAEp1zBXjRiXMZkOHDuIZji79LgcXOY5S/YwN6A4ucuJYDDzn7OwK/AOuxxfkwZ3+483y9c7yjj/+eIznYa8jvMTkxLHEeK6o+3/7+OzrX6gtkOn/LT4CERhJXFPbuOa7avsYQ1yPAaudz/xYQ5s/PmE4xoZRSAa65VQ0ppZSqJ00ESikV4DQRKKVUgNNEoJRSAU4TgVJKBThNBKrZEZGWIvKuiGx0pmL4SUQucI6NFGdG0VpeP0FE7qnnNfcdZf8DziyTS50ZMAc7++8Qkcj6XEMpX9FEoJoVZ4DOJ8BsY0xHY8wA7MCwND/EMgQ4Fzvza2/siNKquWzuwE60p5TfaSJQzc0pQLkx5t9VO4wxW4wx/zz8RGde+k+cu/WfRaR3tcN9nJLEOhG53jk/WkS+E5GFYtcEGHOMWFoDe4wxZU4ce4wxO0TkNuwcMzNFZKbz3mc411soIu8780JVrT/wpHO9X0TkOGf/RWLnsl8iIrN//a9LKU0EqvnpgZ3Oui4eARY5d+v3A29WO9Ybm1SGAA+JSBugFLjA2EnfTgb+7pRAjuYboK2IrBWRl0TkJABjzPPADuBkY8zJItIC+CtwmvPemdj1EKoUGGN6AS9gZ0YFeAg40xjTBzuhmlK/miYC1ayJyIvOXfP8Gg4Pxw7vxxjzPZAkIrHOsU+NMSXGmD3YOWAGYacgeFxElmKnJkjl4BTGRzDG7AMGADdgp2l+T0TG1XDqCdiFgn4UOyX3VdgFVKpMrvbvEGf7R2CSU1pxHf03oNSxBR/7FKWalBXA76ueGGNuce64M+v5PofPvWKAy4FkYIAxxu3MUBpe65sYUwHMAmaJyDLsl/ykw04T4FtjzNg6xGKc973JaXg+B1ggIgOMMT6b9VQ1b1oiUM3N90C4iIyvtu9ojbJzsF/uiMhIbH1+1ToNY8SuI5uEnXxuPnb63xwnCZzMoXftRxC7Zm7narv6Aluc7SLssqEAPwPDqtX/R4lIl2qvu6Tavz8553QyxswzxjyELW1Unz5ZqXrREoFqVowxRkTOB54RkXuxX5L7gT/XcPoEYKJT1VPMwal+wc6iORNoATzmNPK+A3zm3NlnYmePrE008E9nqm0PdvbIqlXFXgG+EpEdTjvBOGCyiIQ5x/+KnUUXIMGJsQw7pTLAU06SEexMmkuOEYtSR6WzjyrViDnVTxlOW4VSPqFVQ0opFeC0RKCUUgFOSwRKKRXgNBEopVSA00SglFIBThOBUkoFOE0ESikV4P4fi8cwNyTxj5AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14b3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "974bdcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_REMI_weights/model.pt\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7917    0.6786    0.7308       112\n",
      "           0     0.7188    0.8214    0.7667       112\n",
      "\n",
      "    accuracy                         0.7500       224\n",
      "   macro avg     0.7552    0.7500    0.7487       224\n",
      "weighted avg     0.7552    0.7500    0.7487       224\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(model, test_loader, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (labels, (notes, notes_len)), _ in test_loader:           \n",
    "            labels = labels.to(device)\n",
    "            notes = notes.to(device)\n",
    "            notes_len = notes_len.cpu()\n",
    "            output = model(notes.long(), notes_len.long())\n",
    "\n",
    "            output = (output > threshold).int()\n",
    "            y_pred.extend(output.tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['NON-SOLO', 'SOLO'])\n",
    "    ax.yaxis.set_ticklabels(['NON-SOLO', 'SOLO'])\n",
    "    \n",
    "    \n",
    "best_model = LSTM().to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)\n",
    "evaluate(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d0a62d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "544e09d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4,  7, 35,  ..., 26, 28, 42],\n",
       "         [ 4,  7, 35,  ..., 10, 50, 88],\n",
       "         [ 4,  7, 35,  ..., 26, 81, 85],\n",
       "         ...,\n",
       "         [ 4,  7, 35,  ...,  1,  1,  1],\n",
       "         [ 4,  7, 35,  ...,  1,  1,  1],\n",
       "         [ 4,  7, 35,  ...,  1,  1,  1]], device='cuda:0'),\n",
       " tensor([164, 164, 164, 163, 163, 161, 161, 159, 155, 154, 153, 153, 152, 151,\n",
       "         147, 147, 146, 145, 144, 144, 144, 143, 141, 140, 140, 140, 139, 137,\n",
       "         136, 136, 136, 136], device='cuda:0'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_iter)).notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d3005c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_REMI_weights/model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-304f365039f3>:24: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  out_forward = output[range(len(output)), notes_len - 1, :self.dimension]\n",
      "/home/cuakevinlex/miniconda3/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:2095: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\"Exporting a model to ONNX with a batch_size other than 1, \" +\n",
      "/home/cuakevinlex/miniconda3/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:2762: UserWarning: Exporting aten::index operator of advanced indexing in opset 9 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\"Exporting aten::index operator of advanced indexing in opset \" +\n",
      "/home/cuakevinlex/miniconda3/lib/python3.8/site-packages/torch/onnx/symbolic_helper.py:712: UserWarning: ONNX export mode is set to inference mode, but operator dropout is set to inference mode. The model will be exported in inference, as specified by the export mode.\n",
      "  warnings.warn(\"ONNX export mode is set to \" + training_mode +\n",
      "/home/cuakevinlex/miniconda3/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:711: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\"This model contains a squeeze operation on dimension \" + str(squeeze_dim) + \". If the model is \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hiddenlayer.graph.Graph object at 0x7fd7e2735fd0>\n"
     ]
    }
   ],
   "source": [
    "def print_architecture(model, test_loader, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    for (labels, (notes, notes_len)), _ in test_loader:           \n",
    "        labels = labels.to(device)\n",
    "        notes = notes.to(device)\n",
    "        notes_len = notes_len.cpu()\n",
    "        output = model(notes.long(), notes_len.long())\n",
    "        \n",
    "        \n",
    "        transforms = [ hl.transforms.Prune('Constant'),\n",
    "                     hl.transforms.Prune('Concat'),\n",
    "                     hl.transforms.Prune('Slice'),\n",
    "                     hl.transforms.Prune('Transpose'),\n",
    "                     hl.transforms.Prune('Cast'),\n",
    "                      hl.transforms.Prune('Expand')\n",
    "                      \n",
    "                     ] # Removes Constant nodes from graph.\n",
    "\n",
    "        graph = hl.build_graph(model, (notes,notes_len), transforms=transforms)\n",
    "        graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "        print(graph)\n",
    "        graph.save('rnn_hiddenlayer', format='png')\n",
    "\n",
    "        #output = (output > threshold).int()\n",
    "        #y_pred.extend(output.tolist())\n",
    "        #y_true.extend(labels.tolist())\n",
    "        #print(dict(model.named_parameters()))\n",
    "        #make_dot(output,params=dict(model.named_parameters())).render()\n",
    "        break\n",
    "\n",
    "    \n",
    "best_model = LSTM().to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)\n",
    "print_architecture(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b5f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
