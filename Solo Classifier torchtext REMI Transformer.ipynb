{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "022889aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dataset folder\n",
    "source_folder = \"solo_classification_REMI_dataset_unbalanced\"\n",
    "# where it saves the weights\n",
    "destination_folder = \"solo_classification_transformer_REMI_weights_unaugmented_200epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "193a1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "print(dev)\n",
    "device = torch.device(dev)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79d8407f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True)\n",
    "fields = [('labels', label_field), ('notes', text_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='val.csv', test='test.csv',\n",
    "                                           format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "test_iter = BucketIterator(test, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "\n",
    "# Vocabulary\n",
    "\n",
    "text_field.build_vocab(train, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "065e06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(text_field.vocab)\n",
    "emsize = 200\n",
    "d_hid = 64\n",
    "nlayers = 2 \n",
    "nhead = 8\n",
    "dropout = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aa477d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  7, 30,  ...,  8, 63,  5],\n",
      "        [ 4,  7, 30,  ..., 14, 56, 90],\n",
      "        [ 4,  7, 30,  ..., 43,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  67,  60,   2],\n",
      "        [  4,   7,  30,  ...,  16,  30, 132],\n",
      "        [  4,   7,  30,  ...,  15,  23,   6],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  59,  88,  89],\n",
      "        [  4,   7,  58,  ...,   9,  31, 105],\n",
      "        [  4,   7,  58,  ...,  47,  69,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  12,  68,   2],\n",
      "        [  4,   7,  58,  ...,  31,  89,   1],\n",
      "        [  4,   7,  30,  ...,  48, 127,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  75,   6,   1],\n",
      "        [  4,   7,  30,  ...,  68, 119,   1],\n",
      "        [  4,   7,  30,  ...,  75,   3,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 12, 27,  3],\n",
      "        [ 4,  7, 30,  ...,  8, 62,  2],\n",
      "        [ 4,  7, 30,  ..., 48, 61,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  22,  38,  72],\n",
      "        [  4,   7,  30,  ...,  43,  49,   1],\n",
      "        [  4,   7,  30,  ...,  40, 105,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  17, 128,   3],\n",
      "        [  4,   7,  30,  ...,  41,  57,   2],\n",
      "        [  4,   7,  30,  ...,  15,  44,   6],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 40,  3],\n",
      "        [ 4,  7, 30,  ..., 10, 27, 46],\n",
      "        [ 4,  7, 30,  ..., 22, 48,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ...,  9, 29,  6],\n",
      "        [ 4,  7, 30,  ..., 57,  5,  1],\n",
      "        [ 4,  7, 30,  ..., 54,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  15,  29,   5],\n",
      "        [  4,   7,  58,  ...,  14,  35,   5],\n",
      "        [  4,   7,  30,  ...,  53,  27, 116],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  12,  23,  74],\n",
      "        [  4,   7,  30,  ...,  14,  23,   6],\n",
      "        [  4,   7,  30,  ...,  53,  55,   5],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ..., 127,   1,   1],\n",
      "        [  4,   7,  58,  ..., 180,   1,   1],\n",
      "        [  4,   7,  58,  ...,  84,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 38, 84],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  17,  62, 188],\n",
      "        [  4,   7,  58,  ...,  38, 171,   1],\n",
      "        [  4,   7,  58,  ...,  50,   3,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7, 186,  ...,   1,   1,   1],\n",
      "        [  4,   7, 186,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 15, 47, 61],\n",
      "        [ 4,  7, 30,  ...,  8, 55, 45],\n",
      "        [ 4,  7, 30,  ..., 22, 31,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 17, 70, 85],\n",
      "        [ 4,  7, 30,  ..., 14, 38,  6],\n",
      "        [ 4,  7, 30,  ..., 15, 29,  2],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ..., 32, 23, 91],\n",
      "        [ 4,  7, 30,  ..., 12, 43,  3],\n",
      "        [ 4,  7, 30,  ...,  9, 39,  5]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  17,  92, 208],\n",
      "        [  4,   7,  58,  ...,   8,  31, 205],\n",
      "        [  4,   7,  30,  ...,  12,  57, 153],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   8,  40,  61],\n",
      "        [  4,   7,  30,  ...,  59,  43, 116],\n",
      "        [  4,   7,  30,  ...,   9,  54,  90],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4, 34, 53,  ..., 12, 23, 74],\n",
      "        [ 4,  7, 58,  ..., 32, 44,  3],\n",
      "        [ 4,  7, 30,  ..., 76, 40,  5],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  32,  35,   3],\n",
      "        [  4,   7,  58,  ...,  10,  43,  96],\n",
      "        [  4,   7,  58,  ...,  24,  38, 144],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 41, 44,  2],\n",
      "        [ 4,  7, 30,  ..., 22, 31, 49],\n",
      "        [ 4,  7, 30,  ..., 24, 38,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  53,  44, 130],\n",
      "        [  4,   7,  58,  ...,  24,  23,  78],\n",
      "        [  4,   7,  30,  ...,  24,  63, 130],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  63,   3],\n",
      "        [  4,   7,  58,  ...,   9,  29, 138],\n",
      "        [  4,   7,  58,  ...,  10,  44, 127],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  53,  29,   3],\n",
      "        [  4,   7,  30,  ...,   8,  92, 119],\n",
      "        [  4,   7,  30,  ...,   9,  27, 105]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 17, 39,  6],\n",
      "        [ 4,  7, 30,  ..., 15, 43, 45],\n",
      "        [ 4,  7, 30,  ..., 22, 44,  2],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  32,  23, 118],\n",
      "        [  4,   7,  30,  ...,  41,  47, 115],\n",
      "        [  4,   7,  30,  ...,  10,  43,   3],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  10,  40,   2],\n",
      "        [  4,   7,  30,  ...,  15,  39,  45],\n",
      "        [  4,   7,  22,  ...,   8,  27, 105],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,  43,  46,   1],\n",
      "        [  4,   7,  58,  ...,  39,  46,   1],\n",
      "        [  4,   7,  30,  ...,  63, 105,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 44,  2],\n",
      "        [ 4,  7, 30,  ..., 53, 38, 84],\n",
      "        [ 4,  7, 30,  ..., 15, 57,  5],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 10, 56, 84],\n",
      "        [ 4,  7, 58,  ...,  3,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  24,  50,   6],\n",
      "        [  4,   7,  30,  ...,  63,   2,   1],\n",
      "        [  4,   7,  58,  ...,  31, 105,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   9,  23, 120],\n",
      "        [  4,   7,  58,  ...,  32,  43,  46],\n",
      "        [  4,   7,  58,  ...,  35,  46,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  10,  62,   3],\n",
      "        [  4,   7,  58,  ...,   8,  31, 118],\n",
      "        [  4,   7,  30,  ...,  15,  27, 127],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,  28,  15,  ...,  22,  48,  96],\n",
      "        [  4,   7,  30,  ...,   8,  55, 153],\n",
      "        [  4,   7,  58,  ...,  54, 198,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,  11,  17,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   8,  29, 103],\n",
      "        [  4,   7,  30,  ...,  32,  35, 119],\n",
      "        [  4,   7,  30,  ...,  76,  23,   3],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,  10,  75, 225],\n",
      "        [  4,   7,  30,  ...,  24,  29,   3],\n",
      "        [  4,   7,  30,  ...,  22,  88,   3]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 12, 52,  2],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 10, 35, 49],\n",
      "        [ 4,  7, 30,  ...,  9, 82, 89],\n",
      "        [ 4,  7, 58,  ...,  8, 50,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ..., 35, 45,  1],\n",
      "        [ 4,  7, 58,  ..., 72,  1,  1],\n",
      "        [ 4,  7, 30,  ..., 74,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 14, 48, 72],\n",
      "        [ 4,  7, 30,  ..., 12, 44, 90],\n",
      "        [ 4,  7, 30,  ...,  5,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  14,  57,  90],\n",
      "        [  4,   7,  30,  ...,  48, 172,   1],\n",
      "        [  4,   7,  58,  ...,  23,   6,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 22, 35,  6],\n",
      "        [ 4,  7, 30,  ..., 51, 70, 96],\n",
      "        [ 4,  7, 30,  ..., 32, 27,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 12, 63, 46],\n",
      "        [ 4,  7, 30,  ..., 54,  2,  1],\n",
      "        [ 4,  7, 30,  ..., 75,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ..., 84,  1,  1],\n",
      "        [ 4,  7, 30,  ..., 96,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  17,  82,   2],\n",
      "        [  4,   7,  58,  ...,   8,  77, 105],\n",
      "        [  4,   7,  58,  ...,   8,  35,  46],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 15, 47,  5],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  17,  27, 143],\n",
      "        [  4,   7,  58,  ...,  12,  23,   3],\n",
      "        [  4,   7,  30,  ...,  15,  52,  89],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  31,   5],\n",
      "        [  4,   7,  58,  ...,  32,  44,  74],\n",
      "        [  4,   7,  58,  ...,  10,  48, 143],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  14,  31,   3],\n",
      "        [  4,   7,  30,  ...,  38,  84,   1],\n",
      "        [  4,   7, 186,  ...,  83,  46,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  10,  79,   3],\n",
      "        [  4,   7,  30,  ...,   8,  47, 119],\n",
      "        [  4,   7,  30,  ...,   9,  70,  74],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  22,  27,   3],\n",
      "        [  4,   7,  30,  ...,   8,  27,   2],\n",
      "        [  4,   7,  30,  ...,  15,  44,   2],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,  85,   1,   1],\n",
      "        [  4,   7,  30,  ...,  72,   1,   1],\n",
      "        [  4,   7,  30,  ..., 103,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   9,  35,   6],\n",
      "        [  4,   7,  30,  ...,  10,  40,   5],\n",
      "        [  4,   7,  30,  ...,  12, 139,   2],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  82, 116,   1],\n",
      "        [  4,   7,  30,  ...,  70,  46,   1],\n",
      "        [  4,   7,  30,  ...,  44,   5,   1]], device='cuda:0')\n",
      "tensor([[ 4, 26, 22,  ..., 17, 35, 90],\n",
      "        [ 4,  7, 58,  ..., 14, 23,  3],\n",
      "        [ 4,  7, 58,  ..., 12, 39,  5],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4, 28, 67,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 32, 40, 96],\n",
      "        [ 4,  7, 30,  ..., 12, 71,  6],\n",
      "        [ 4,  7, 30,  ..., 24, 31,  6],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  39,   5],\n",
      "        [  4,   7,  30,  ...,  17,  70,  49],\n",
      "        [  4,   7,  30,  ...,  22,  83,   5],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  38,  91,   1],\n",
      "        [  4,   7,  30,  ...,  57,   3,   1],\n",
      "        [  4,   7,  30,  ...,  40, 138,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 17, 44, 45],\n",
      "        [ 4,  7, 58,  ..., 70, 61,  1],\n",
      "        [ 4,  7, 58,  ..., 52,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for (labels, (notes, notes_len)), _ in (train_iter):\n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82eec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff4d0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, 2)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.mean(dim=1)\n",
    "        output = self.decoder(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32976625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load Functions https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0\n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c88beb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Step [25/25000], Train Loss: 0.6639, Valid Loss: 0.6558\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [1/500], Step [50/25000], Train Loss: 0.6670, Valid Loss: 0.6537\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6552598225602028\n",
      "Epoch [2/500], Step [75/25000], Train Loss: 0.6039, Valid Loss: 0.6565\n",
      "Epoch [2/500], Step [100/25000], Train Loss: 0.6875, Valid Loss: 0.6541\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [3/500], Step [125/25000], Train Loss: 0.6491, Valid Loss: 0.6516\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [3/500], Step [150/25000], Train Loss: 0.6361, Valid Loss: 0.6546\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [4/500], Step [175/25000], Train Loss: 0.6536, Valid Loss: 0.6473\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [4/500], Step [200/25000], Train Loss: 0.6251, Valid Loss: 0.6450\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [5/500], Step [225/25000], Train Loss: 0.6756, Valid Loss: 0.6356\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [5/500], Step [250/25000], Train Loss: 0.6021, Valid Loss: 0.6423\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [6/500], Step [275/25000], Train Loss: 0.6051, Valid Loss: 0.6480\n",
      "Epoch [6/500], Step [300/25000], Train Loss: 0.6692, Valid Loss: 0.6336\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [7/500], Step [325/25000], Train Loss: 0.6296, Valid Loss: 0.6311\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [7/500], Step [350/25000], Train Loss: 0.6346, Valid Loss: 0.6262\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [8/500], Step [375/25000], Train Loss: 0.6283, Valid Loss: 0.6076\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [8/500], Step [400/25000], Train Loss: 0.6349, Valid Loss: 0.6103\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [9/500], Step [425/25000], Train Loss: 0.6589, Valid Loss: 0.5908\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [9/500], Step [450/25000], Train Loss: 0.5955, Valid Loss: 0.5866\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6698352344740177\n",
      "Epoch [10/500], Step [475/25000], Train Loss: 0.6121, Valid Loss: 0.5874\n",
      "Epoch [10/500], Step [500/25000], Train Loss: 0.6277, Valid Loss: 0.5753\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6711026615969582\n",
      "Epoch [11/500], Step [525/25000], Train Loss: 0.5580, Valid Loss: 0.5796\n",
      "Epoch [11/500], Step [550/25000], Train Loss: 0.6681, Valid Loss: 0.5558\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6711026615969582\n",
      "Epoch [12/500], Step [575/25000], Train Loss: 0.6235, Valid Loss: 0.5521\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [12/500], Step [600/25000], Train Loss: 0.5883, Valid Loss: 0.5419\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6996197718631179\n",
      "Epoch [13/500], Step [625/25000], Train Loss: 0.5766, Valid Loss: 0.5328\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [13/500], Step [650/25000], Train Loss: 0.5867, Valid Loss: 0.5446\n",
      "Epoch Accuracy: 0.7053231939163498\n",
      "Epoch [14/500], Step [675/25000], Train Loss: 0.5666, Valid Loss: 0.5423\n",
      "Epoch [14/500], Step [700/25000], Train Loss: 0.5555, Valid Loss: 0.5406\n",
      "Epoch Accuracy: 0.785171102661597\n",
      "Epoch [15/500], Step [725/25000], Train Loss: 0.5266, Valid Loss: 0.5586\n",
      "Epoch [15/500], Step [750/25000], Train Loss: 0.5573, Valid Loss: 0.5277\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8168567807351077\n",
      "Epoch [16/500], Step [775/25000], Train Loss: 0.5162, Valid Loss: 0.5186\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [16/500], Step [800/25000], Train Loss: 0.5584, Valid Loss: 0.5596\n",
      "Epoch Accuracy: 0.7959442332065906\n",
      "Epoch [17/500], Step [825/25000], Train Loss: 0.5132, Valid Loss: 0.5222\n",
      "Epoch [17/500], Step [850/25000], Train Loss: 0.5457, Valid Loss: 0.5411\n",
      "Epoch Accuracy: 0.8181242078580482\n",
      "Epoch [18/500], Step [875/25000], Train Loss: 0.5117, Valid Loss: 0.5194\n",
      "Epoch [18/500], Step [900/25000], Train Loss: 0.5309, Valid Loss: 0.5323\n",
      "Epoch Accuracy: 0.8041825095057035\n",
      "Epoch [19/500], Step [925/25000], Train Loss: 0.5271, Valid Loss: 0.5369\n",
      "Epoch [19/500], Step [950/25000], Train Loss: 0.5230, Valid Loss: 0.5306\n",
      "Epoch Accuracy: 0.811787072243346\n",
      "Epoch [20/500], Step [975/25000], Train Loss: 0.5095, Valid Loss: 0.5306\n",
      "Epoch [20/500], Step [1000/25000], Train Loss: 0.5181, Valid Loss: 0.5316\n",
      "Epoch Accuracy: 0.8098859315589354\n",
      "Epoch [21/500], Step [1025/25000], Train Loss: 0.4977, Valid Loss: 0.5294\n",
      "Epoch [21/500], Step [1050/25000], Train Loss: 0.5205, Valid Loss: 0.5251\n",
      "Epoch Accuracy: 0.8149556400506971\n",
      "Epoch [22/500], Step [1075/25000], Train Loss: 0.5102, Valid Loss: 0.5206\n",
      "Epoch [22/500], Step [1100/25000], Train Loss: 0.5065, Valid Loss: 0.5420\n",
      "Epoch Accuracy: 0.8168567807351077\n",
      "Epoch [23/500], Step [1125/25000], Train Loss: 0.4915, Valid Loss: 0.5357\n",
      "Epoch [23/500], Step [1150/25000], Train Loss: 0.5198, Valid Loss: 0.5333\n",
      "Epoch Accuracy: 0.8193916349809885\n",
      "Epoch [24/500], Step [1175/25000], Train Loss: 0.4824, Valid Loss: 0.5388\n",
      "Epoch [24/500], Step [1200/25000], Train Loss: 0.5270, Valid Loss: 0.5194\n",
      "Epoch Accuracy: 0.8162230671736375\n",
      "Epoch [25/500], Step [1225/25000], Train Loss: 0.5171, Valid Loss: 0.5268\n",
      "Epoch [25/500], Step [1250/25000], Train Loss: 0.4873, Valid Loss: 0.5359\n",
      "Epoch Accuracy: 0.8143219264892269\n",
      "Epoch [26/500], Step [1275/25000], Train Loss: 0.4885, Valid Loss: 0.5428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/500], Step [1300/25000], Train Loss: 0.5173, Valid Loss: 0.5177\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.811787072243346\n",
      "Epoch [27/500], Step [1325/25000], Train Loss: 0.5022, Valid Loss: 0.5369\n",
      "Epoch [27/500], Step [1350/25000], Train Loss: 0.5024, Valid Loss: 0.5226\n",
      "Epoch Accuracy: 0.8193916349809885\n",
      "Epoch [28/500], Step [1375/25000], Train Loss: 0.4943, Valid Loss: 0.5371\n",
      "Epoch [28/500], Step [1400/25000], Train Loss: 0.5069, Valid Loss: 0.5182\n",
      "Epoch Accuracy: 0.820659062103929\n",
      "Epoch [29/500], Step [1425/25000], Train Loss: 0.4922, Valid Loss: 0.5232\n",
      "Epoch [29/500], Step [1450/25000], Train Loss: 0.4979, Valid Loss: 0.5274\n",
      "Epoch Accuracy: 0.8212927756653993\n",
      "Epoch [30/500], Step [1475/25000], Train Loss: 0.4869, Valid Loss: 0.5270\n",
      "Epoch [30/500], Step [1500/25000], Train Loss: 0.5012, Valid Loss: 0.5136\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8231939163498099\n",
      "Epoch [31/500], Step [1525/25000], Train Loss: 0.4795, Valid Loss: 0.5332\n",
      "Epoch [31/500], Step [1550/25000], Train Loss: 0.5057, Valid Loss: 0.5017\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8282636248415716\n",
      "Epoch [32/500], Step [1575/25000], Train Loss: 0.4906, Valid Loss: 0.4930\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [32/500], Step [1600/25000], Train Loss: 0.4904, Valid Loss: 0.5090\n",
      "Epoch Accuracy: 0.8269961977186312\n",
      "Epoch [33/500], Step [1625/25000], Train Loss: 0.4747, Valid Loss: 0.5057\n",
      "Epoch [33/500], Step [1650/25000], Train Loss: 0.5026, Valid Loss: 0.4914\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8301647655259823\n",
      "Epoch [34/500], Step [1675/25000], Train Loss: 0.5161, Valid Loss: 0.5034\n",
      "Epoch [34/500], Step [1700/25000], Train Loss: 0.4590, Valid Loss: 0.4959\n",
      "Epoch Accuracy: 0.8288973384030418\n",
      "Epoch [35/500], Step [1725/25000], Train Loss: 0.4778, Valid Loss: 0.5037\n",
      "Epoch [35/500], Step [1750/25000], Train Loss: 0.4929, Valid Loss: 0.4917\n",
      "Epoch Accuracy: 0.8314321926489227\n",
      "Epoch [36/500], Step [1775/25000], Train Loss: 0.4958, Valid Loss: 0.4925\n",
      "Epoch [36/500], Step [1800/25000], Train Loss: 0.4722, Valid Loss: 0.4998\n",
      "Epoch Accuracy: 0.8346007604562737\n",
      "Epoch [37/500], Step [1825/25000], Train Loss: 0.5006, Valid Loss: 0.5016\n",
      "Epoch [37/500], Step [1850/25000], Train Loss: 0.4615, Valid Loss: 0.4927\n",
      "Epoch Accuracy: 0.8409378960709759\n",
      "Epoch [38/500], Step [1875/25000], Train Loss: 0.4993, Valid Loss: 0.5005\n",
      "Epoch [38/500], Step [1900/25000], Train Loss: 0.4605, Valid Loss: 0.5075\n",
      "Epoch Accuracy: 0.8377693282636248\n",
      "Epoch [39/500], Step [1925/25000], Train Loss: 0.4669, Valid Loss: 0.4962\n",
      "Epoch [39/500], Step [1950/25000], Train Loss: 0.4926, Valid Loss: 0.4949\n",
      "Epoch Accuracy: 0.8365019011406845\n",
      "Epoch [40/500], Step [1975/25000], Train Loss: 0.4466, Valid Loss: 0.5039\n",
      "Epoch [40/500], Step [2000/25000], Train Loss: 0.5091, Valid Loss: 0.4956\n",
      "Epoch Accuracy: 0.8390367553865653\n",
      "Epoch [41/500], Step [2025/25000], Train Loss: 0.4657, Valid Loss: 0.5066\n",
      "Epoch [41/500], Step [2050/25000], Train Loss: 0.4861, Valid Loss: 0.4917\n",
      "Epoch Accuracy: 0.8453738910012675\n",
      "Epoch [42/500], Step [2075/25000], Train Loss: 0.4494, Valid Loss: 0.4989\n",
      "Epoch [42/500], Step [2100/25000], Train Loss: 0.5020, Valid Loss: 0.5086\n",
      "Epoch Accuracy: 0.8434727503168568\n",
      "Epoch [43/500], Step [2125/25000], Train Loss: 0.4770, Valid Loss: 0.4910\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [43/500], Step [2150/25000], Train Loss: 0.4675, Valid Loss: 0.5059\n",
      "Epoch Accuracy: 0.8510773130544994\n",
      "Epoch [44/500], Step [2175/25000], Train Loss: 0.4680, Valid Loss: 0.5032\n",
      "Epoch [44/500], Step [2200/25000], Train Loss: 0.4754, Valid Loss: 0.4986\n",
      "Epoch Accuracy: 0.8447401774397972\n",
      "Epoch [45/500], Step [2225/25000], Train Loss: 0.4753, Valid Loss: 0.5070\n",
      "Epoch [45/500], Step [2250/25000], Train Loss: 0.4653, Valid Loss: 0.4831\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8523447401774398\n",
      "Epoch [46/500], Step [2275/25000], Train Loss: 0.4874, Valid Loss: 0.5014\n",
      "Epoch [46/500], Step [2300/25000], Train Loss: 0.4516, Valid Loss: 0.5054\n",
      "Epoch Accuracy: 0.8409378960709759\n",
      "Epoch [47/500], Step [2325/25000], Train Loss: 0.4628, Valid Loss: 0.4947\n",
      "Epoch [47/500], Step [2350/25000], Train Loss: 0.4699, Valid Loss: 0.5047\n",
      "Epoch Accuracy: 0.8479087452471483\n",
      "Epoch [48/500], Step [2375/25000], Train Loss: 0.4746, Valid Loss: 0.4970\n",
      "Epoch [48/500], Step [2400/25000], Train Loss: 0.4569, Valid Loss: 0.4940\n",
      "Epoch Accuracy: 0.8523447401774398\n",
      "Epoch [49/500], Step [2425/25000], Train Loss: 0.4573, Valid Loss: 0.5041\n",
      "Epoch [49/500], Step [2450/25000], Train Loss: 0.4733, Valid Loss: 0.4888\n",
      "Epoch Accuracy: 0.8491761723700887\n",
      "Epoch [50/500], Step [2475/25000], Train Loss: 0.4624, Valid Loss: 0.4984\n",
      "Epoch [50/500], Step [2500/25000], Train Loss: 0.4686, Valid Loss: 0.4928\n",
      "Epoch Accuracy: 0.8517110266159695\n",
      "Epoch [51/500], Step [2525/25000], Train Loss: 0.4416, Valid Loss: 0.5027\n",
      "Epoch [51/500], Step [2550/25000], Train Loss: 0.4832, Valid Loss: 0.4816\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8542458808618505\n",
      "Epoch [52/500], Step [2575/25000], Train Loss: 0.4611, Valid Loss: 0.4937\n",
      "Epoch [52/500], Step [2600/25000], Train Loss: 0.4580, Valid Loss: 0.4845\n",
      "Epoch Accuracy: 0.8567807351077313\n",
      "Epoch [53/500], Step [2625/25000], Train Loss: 0.4675, Valid Loss: 0.4992\n",
      "Epoch [53/500], Step [2650/25000], Train Loss: 0.4582, Valid Loss: 0.4824\n",
      "Epoch Accuracy: 0.8485424588086184\n",
      "Epoch [54/500], Step [2675/25000], Train Loss: 0.4599, Valid Loss: 0.4946\n",
      "Epoch [54/500], Step [2700/25000], Train Loss: 0.4566, Valid Loss: 0.4899\n",
      "Epoch Accuracy: 0.8542458808618505\n",
      "Epoch [55/500], Step [2725/25000], Train Loss: 0.4730, Valid Loss: 0.4982\n",
      "Epoch [55/500], Step [2750/25000], Train Loss: 0.4486, Valid Loss: 0.4813\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8624841571609633\n",
      "Epoch [56/500], Step [2775/25000], Train Loss: 0.4509, Valid Loss: 0.4859\n",
      "Epoch [56/500], Step [2800/25000], Train Loss: 0.4626, Valid Loss: 0.4946\n",
      "Epoch Accuracy: 0.8631178707224335\n",
      "Epoch [57/500], Step [2825/25000], Train Loss: 0.4522, Valid Loss: 0.4935\n",
      "Epoch [57/500], Step [2850/25000], Train Loss: 0.4617, Valid Loss: 0.4886\n",
      "Epoch Accuracy: 0.8605830164765526\n",
      "Epoch [58/500], Step [2875/25000], Train Loss: 0.4646, Valid Loss: 0.4816\n",
      "Epoch [58/500], Step [2900/25000], Train Loss: 0.4411, Valid Loss: 0.4974\n",
      "Epoch Accuracy: 0.8631178707224335\n",
      "Epoch [59/500], Step [2925/25000], Train Loss: 0.4574, Valid Loss: 0.4788\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [59/500], Step [2950/25000], Train Loss: 0.4515, Valid Loss: 0.4827\n",
      "Epoch Accuracy: 0.8669201520912547\n",
      "Epoch [60/500], Step [2975/25000], Train Loss: 0.4352, Valid Loss: 0.4955\n",
      "Epoch [60/500], Step [3000/25000], Train Loss: 0.4730, Valid Loss: 0.4704\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8637515842839036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/500], Step [3025/25000], Train Loss: 0.4651, Valid Loss: 0.4894\n",
      "Epoch [61/500], Step [3050/25000], Train Loss: 0.4434, Valid Loss: 0.4803\n",
      "Epoch Accuracy: 0.8643852978453739\n",
      "Epoch [62/500], Step [3075/25000], Train Loss: 0.4378, Valid Loss: 0.4865\n",
      "Epoch [62/500], Step [3100/25000], Train Loss: 0.4639, Valid Loss: 0.4698\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8650190114068441\n",
      "Epoch [63/500], Step [3125/25000], Train Loss: 0.4381, Valid Loss: 0.4881\n",
      "Epoch [63/500], Step [3150/25000], Train Loss: 0.4617, Valid Loss: 0.4748\n",
      "Epoch Accuracy: 0.8662864385297845\n",
      "Epoch [64/500], Step [3175/25000], Train Loss: 0.4317, Valid Loss: 0.4775\n",
      "Epoch [64/500], Step [3200/25000], Train Loss: 0.4649, Valid Loss: 0.4972\n",
      "Epoch Accuracy: 0.870722433460076\n",
      "Epoch [65/500], Step [3225/25000], Train Loss: 0.4447, Valid Loss: 0.4756\n",
      "Epoch [65/500], Step [3250/25000], Train Loss: 0.4476, Valid Loss: 0.4829\n",
      "Epoch Accuracy: 0.8802281368821293\n",
      "Epoch [66/500], Step [3275/25000], Train Loss: 0.4640, Valid Loss: 0.4741\n",
      "Epoch [66/500], Step [3300/25000], Train Loss: 0.4342, Valid Loss: 0.4987\n",
      "Epoch Accuracy: 0.870722433460076\n",
      "Epoch [67/500], Step [3325/25000], Train Loss: 0.4517, Valid Loss: 0.4842\n",
      "Epoch [67/500], Step [3350/25000], Train Loss: 0.4330, Valid Loss: 0.4769\n",
      "Epoch Accuracy: 0.8802281368821293\n",
      "Epoch [68/500], Step [3375/25000], Train Loss: 0.4599, Valid Loss: 0.4770\n",
      "Epoch [68/500], Step [3400/25000], Train Loss: 0.4380, Valid Loss: 0.4759\n",
      "Epoch Accuracy: 0.8669201520912547\n",
      "Epoch [69/500], Step [3425/25000], Train Loss: 0.4367, Valid Loss: 0.4686\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [69/500], Step [3450/25000], Train Loss: 0.4493, Valid Loss: 0.4732\n",
      "Epoch Accuracy: 0.8783269961977186\n",
      "Epoch [70/500], Step [3475/25000], Train Loss: 0.4246, Valid Loss: 0.4739\n",
      "Epoch [70/500], Step [3500/25000], Train Loss: 0.4579, Valid Loss: 0.4930\n",
      "Epoch Accuracy: 0.8783269961977186\n",
      "Epoch [71/500], Step [3525/25000], Train Loss: 0.4392, Valid Loss: 0.4615\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [71/500], Step [3550/25000], Train Loss: 0.4409, Valid Loss: 0.4826\n",
      "Epoch Accuracy: 0.8859315589353612\n",
      "Epoch [72/500], Step [3575/25000], Train Loss: 0.4335, Valid Loss: 0.4624\n",
      "Epoch [72/500], Step [3600/25000], Train Loss: 0.4474, Valid Loss: 0.4831\n",
      "Epoch Accuracy: 0.8821292775665399\n",
      "Epoch [73/500], Step [3625/25000], Train Loss: 0.4397, Valid Loss: 0.4680\n",
      "Epoch [73/500], Step [3650/25000], Train Loss: 0.4364, Valid Loss: 0.4864\n",
      "Epoch Accuracy: 0.8871989860583016\n",
      "Epoch [74/500], Step [3675/25000], Train Loss: 0.4303, Valid Loss: 0.4797\n",
      "Epoch [74/500], Step [3700/25000], Train Loss: 0.4492, Valid Loss: 0.4739\n",
      "Epoch Accuracy: 0.8802281368821293\n",
      "Epoch [75/500], Step [3725/25000], Train Loss: 0.4144, Valid Loss: 0.4694\n",
      "Epoch [75/500], Step [3750/25000], Train Loss: 0.4598, Valid Loss: 0.4621\n",
      "Epoch Accuracy: 0.885297845373891\n",
      "Epoch [76/500], Step [3775/25000], Train Loss: 0.4526, Valid Loss: 0.4812\n",
      "Epoch [76/500], Step [3800/25000], Train Loss: 0.4116, Valid Loss: 0.4858\n",
      "Epoch Accuracy: 0.8922686945500634\n",
      "Epoch [77/500], Step [3825/25000], Train Loss: 0.4301, Valid Loss: 0.4542\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [77/500], Step [3850/25000], Train Loss: 0.4373, Valid Loss: 0.4812\n",
      "Epoch Accuracy: 0.8891001267427123\n",
      "Epoch [78/500], Step [3875/25000], Train Loss: 0.4405, Valid Loss: 0.4725\n",
      "Epoch [78/500], Step [3900/25000], Train Loss: 0.4249, Valid Loss: 0.4638\n",
      "Epoch Accuracy: 0.8897338403041825\n",
      "Epoch [79/500], Step [3925/25000], Train Loss: 0.4474, Valid Loss: 0.4629\n",
      "Epoch [79/500], Step [3950/25000], Train Loss: 0.4174, Valid Loss: 0.4674\n",
      "Epoch Accuracy: 0.8897338403041825\n",
      "Epoch [80/500], Step [3975/25000], Train Loss: 0.4231, Valid Loss: 0.4794\n",
      "Epoch [80/500], Step [4000/25000], Train Loss: 0.4338, Valid Loss: 0.4510\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8992395437262357\n",
      "Epoch [81/500], Step [4025/25000], Train Loss: 0.4339, Valid Loss: 0.4782\n",
      "Epoch [81/500], Step [4050/25000], Train Loss: 0.4239, Valid Loss: 0.4535\n",
      "Epoch Accuracy: 0.8916349809885932\n",
      "Epoch [82/500], Step [4075/25000], Train Loss: 0.4366, Valid Loss: 0.4922\n",
      "Epoch [82/500], Step [4100/25000], Train Loss: 0.4258, Valid Loss: 0.4633\n",
      "Epoch Accuracy: 0.8935361216730038\n",
      "Epoch [83/500], Step [4125/25000], Train Loss: 0.4206, Valid Loss: 0.4610\n",
      "Epoch [83/500], Step [4150/25000], Train Loss: 0.4283, Valid Loss: 0.4819\n",
      "Epoch Accuracy: 0.8992395437262357\n",
      "Epoch [84/500], Step [4175/25000], Train Loss: 0.4404, Valid Loss: 0.4556\n",
      "Epoch [84/500], Step [4200/25000], Train Loss: 0.4110, Valid Loss: 0.4616\n",
      "Epoch Accuracy: 0.899873257287706\n",
      "Epoch [85/500], Step [4225/25000], Train Loss: 0.4404, Valid Loss: 0.4651\n",
      "Epoch [85/500], Step [4250/25000], Train Loss: 0.4161, Valid Loss: 0.4552\n",
      "Epoch Accuracy: 0.8960709759188846\n",
      "Epoch [86/500], Step [4275/25000], Train Loss: 0.4280, Valid Loss: 0.4693\n",
      "Epoch [86/500], Step [4300/25000], Train Loss: 0.4139, Valid Loss: 0.4654\n",
      "Epoch Accuracy: 0.9049429657794676\n",
      "Epoch [87/500], Step [4325/25000], Train Loss: 0.4293, Valid Loss: 0.4481\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [87/500], Step [4350/25000], Train Loss: 0.4202, Valid Loss: 0.4551\n",
      "Epoch Accuracy: 0.8992395437262357\n",
      "Epoch [88/500], Step [4375/25000], Train Loss: 0.4157, Valid Loss: 0.4589\n",
      "Epoch [88/500], Step [4400/25000], Train Loss: 0.4289, Valid Loss: 0.4604\n",
      "Epoch Accuracy: 0.8973384030418251\n",
      "Epoch [89/500], Step [4425/25000], Train Loss: 0.4185, Valid Loss: 0.4623\n",
      "Epoch [89/500], Step [4450/25000], Train Loss: 0.4214, Valid Loss: 0.4481\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9017743979721166\n",
      "Epoch [90/500], Step [4475/25000], Train Loss: 0.4189, Valid Loss: 0.4650\n",
      "Epoch [90/500], Step [4500/25000], Train Loss: 0.4253, Valid Loss: 0.4621\n",
      "Epoch Accuracy: 0.8992395437262357\n",
      "Epoch [91/500], Step [4525/25000], Train Loss: 0.4268, Valid Loss: 0.4500\n",
      "Epoch [91/500], Step [4550/25000], Train Loss: 0.4112, Valid Loss: 0.4685\n",
      "Epoch Accuracy: 0.9024081115335868\n",
      "Epoch [92/500], Step [4575/25000], Train Loss: 0.4227, Valid Loss: 0.4511\n",
      "Epoch [92/500], Step [4600/25000], Train Loss: 0.4182, Valid Loss: 0.4476\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9068441064638784\n",
      "Epoch [93/500], Step [4625/25000], Train Loss: 0.4041, Valid Loss: 0.4702\n",
      "Epoch [93/500], Step [4650/25000], Train Loss: 0.4320, Valid Loss: 0.4367\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9036755386565273\n",
      "Epoch [94/500], Step [4675/25000], Train Loss: 0.4027, Valid Loss: 0.4706\n",
      "Epoch [94/500], Step [4700/25000], Train Loss: 0.4371, Valid Loss: 0.4450\n",
      "Epoch Accuracy: 0.9024081115335868\n",
      "Epoch [95/500], Step [4725/25000], Train Loss: 0.4092, Valid Loss: 0.4545\n",
      "Epoch [95/500], Step [4750/25000], Train Loss: 0.4251, Valid Loss: 0.4611\n",
      "Epoch Accuracy: 0.9017743979721166\n",
      "Epoch [96/500], Step [4775/25000], Train Loss: 0.4080, Valid Loss: 0.4534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/500], Step [4800/25000], Train Loss: 0.4194, Valid Loss: 0.4576\n",
      "Epoch Accuracy: 0.9112801013941698\n",
      "Epoch [97/500], Step [4825/25000], Train Loss: 0.4151, Valid Loss: 0.4446\n",
      "Epoch [97/500], Step [4850/25000], Train Loss: 0.4175, Valid Loss: 0.4583\n",
      "Epoch Accuracy: 0.9062103929024081\n",
      "Epoch [98/500], Step [4875/25000], Train Loss: 0.4124, Valid Loss: 0.4642\n",
      "Epoch [98/500], Step [4900/25000], Train Loss: 0.4139, Valid Loss: 0.4559\n",
      "Epoch Accuracy: 0.9106463878326996\n",
      "Epoch [99/500], Step [4925/25000], Train Loss: 0.4154, Valid Loss: 0.4419\n",
      "Epoch [99/500], Step [4950/25000], Train Loss: 0.4183, Valid Loss: 0.4627\n",
      "Epoch Accuracy: 0.9093789607097592\n",
      "Epoch [100/500], Step [4975/25000], Train Loss: 0.4165, Valid Loss: 0.4555\n",
      "Epoch [100/500], Step [5000/25000], Train Loss: 0.4088, Valid Loss: 0.4501\n",
      "Epoch Accuracy: 0.9106463878326996\n",
      "Epoch [101/500], Step [5025/25000], Train Loss: 0.4116, Valid Loss: 0.4578\n",
      "Epoch [101/500], Step [5050/25000], Train Loss: 0.4163, Valid Loss: 0.4613\n",
      "Epoch Accuracy: 0.9049429657794676\n",
      "Epoch [102/500], Step [5075/25000], Train Loss: 0.4187, Valid Loss: 0.4609\n",
      "Epoch [102/500], Step [5100/25000], Train Loss: 0.4114, Valid Loss: 0.4613\n",
      "Epoch Accuracy: 0.9036755386565273\n",
      "Epoch [103/500], Step [5125/25000], Train Loss: 0.4057, Valid Loss: 0.4464\n",
      "Epoch [103/500], Step [5150/25000], Train Loss: 0.4234, Valid Loss: 0.4478\n",
      "Epoch Accuracy: 0.9112801013941698\n",
      "Epoch [104/500], Step [5175/25000], Train Loss: 0.4036, Valid Loss: 0.4574\n",
      "Epoch [104/500], Step [5200/25000], Train Loss: 0.4216, Valid Loss: 0.4659\n",
      "Epoch Accuracy: 0.9093789607097592\n",
      "Epoch [105/500], Step [5225/25000], Train Loss: 0.4027, Valid Loss: 0.4445\n",
      "Epoch [105/500], Step [5250/25000], Train Loss: 0.4185, Valid Loss: 0.4445\n",
      "Epoch Accuracy: 0.908745247148289\n",
      "Epoch [106/500], Step [5275/25000], Train Loss: 0.4116, Valid Loss: 0.4503\n",
      "Epoch [106/500], Step [5300/25000], Train Loss: 0.4044, Valid Loss: 0.4431\n",
      "Epoch Accuracy: 0.9163498098859315\n",
      "Epoch [107/500], Step [5325/25000], Train Loss: 0.4107, Valid Loss: 0.4566\n",
      "Epoch [107/500], Step [5350/25000], Train Loss: 0.4065, Valid Loss: 0.4578\n",
      "Epoch Accuracy: 0.9150823827629911\n",
      "Epoch [108/500], Step [5375/25000], Train Loss: 0.4073, Valid Loss: 0.4406\n",
      "Epoch [108/500], Step [5400/25000], Train Loss: 0.4175, Valid Loss: 0.4425\n",
      "Epoch Accuracy: 0.9093789607097592\n",
      "Epoch [109/500], Step [5425/25000], Train Loss: 0.4132, Valid Loss: 0.4376\n",
      "Epoch [109/500], Step [5450/25000], Train Loss: 0.4072, Valid Loss: 0.4441\n",
      "Epoch Accuracy: 0.9093789607097592\n",
      "Epoch [110/500], Step [5475/25000], Train Loss: 0.4024, Valid Loss: 0.4399\n",
      "Epoch [110/500], Step [5500/25000], Train Loss: 0.4193, Valid Loss: 0.4522\n",
      "Epoch Accuracy: 0.9081115335868187\n",
      "Epoch [111/500], Step [5525/25000], Train Loss: 0.4056, Valid Loss: 0.4319\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [111/500], Step [5550/25000], Train Loss: 0.4170, Valid Loss: 0.4597\n",
      "Epoch Accuracy: 0.9125475285171103\n",
      "Epoch [112/500], Step [5575/25000], Train Loss: 0.4019, Valid Loss: 0.4393\n",
      "Epoch [112/500], Step [5600/25000], Train Loss: 0.4140, Valid Loss: 0.4459\n",
      "Epoch Accuracy: 0.9119138149556401\n",
      "Epoch [113/500], Step [5625/25000], Train Loss: 0.3917, Valid Loss: 0.4358\n",
      "Epoch [113/500], Step [5650/25000], Train Loss: 0.4166, Valid Loss: 0.4374\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [114/500], Step [5675/25000], Train Loss: 0.4012, Valid Loss: 0.4453\n",
      "Epoch [114/500], Step [5700/25000], Train Loss: 0.4085, Valid Loss: 0.4488\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [115/500], Step [5725/25000], Train Loss: 0.4175, Valid Loss: 0.4432\n",
      "Epoch [115/500], Step [5750/25000], Train Loss: 0.3899, Valid Loss: 0.4443\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [116/500], Step [5775/25000], Train Loss: 0.4055, Valid Loss: 0.4417\n",
      "Epoch [116/500], Step [5800/25000], Train Loss: 0.4060, Valid Loss: 0.4301\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [117/500], Step [5825/25000], Train Loss: 0.4091, Valid Loss: 0.4461\n",
      "Epoch [117/500], Step [5850/25000], Train Loss: 0.3957, Valid Loss: 0.4463\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [118/500], Step [5875/25000], Train Loss: 0.4063, Valid Loss: 0.4422\n",
      "Epoch [118/500], Step [5900/25000], Train Loss: 0.4057, Valid Loss: 0.4379\n",
      "Epoch Accuracy: 0.9150823827629911\n",
      "Epoch [119/500], Step [5925/25000], Train Loss: 0.4061, Valid Loss: 0.4425\n",
      "Epoch [119/500], Step [5950/25000], Train Loss: 0.4045, Valid Loss: 0.4429\n",
      "Epoch Accuracy: 0.9131812420785805\n",
      "Epoch [120/500], Step [5975/25000], Train Loss: 0.4043, Valid Loss: 0.4563\n",
      "Epoch [120/500], Step [6000/25000], Train Loss: 0.4038, Valid Loss: 0.4436\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [121/500], Step [6025/25000], Train Loss: 0.4062, Valid Loss: 0.4461\n",
      "Epoch [121/500], Step [6050/25000], Train Loss: 0.4008, Valid Loss: 0.4480\n",
      "Epoch Accuracy: 0.9119138149556401\n",
      "Epoch [122/500], Step [6075/25000], Train Loss: 0.3927, Valid Loss: 0.4416\n",
      "Epoch [122/500], Step [6100/25000], Train Loss: 0.4124, Valid Loss: 0.4485\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [123/500], Step [6125/25000], Train Loss: 0.4187, Valid Loss: 0.4332\n",
      "Epoch [123/500], Step [6150/25000], Train Loss: 0.3947, Valid Loss: 0.4503\n",
      "Epoch Accuracy: 0.9144486692015209\n",
      "Epoch [124/500], Step [6175/25000], Train Loss: 0.4000, Valid Loss: 0.4449\n",
      "Epoch [124/500], Step [6200/25000], Train Loss: 0.4020, Valid Loss: 0.4542\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [125/500], Step [6225/25000], Train Loss: 0.4044, Valid Loss: 0.4353\n",
      "Epoch [125/500], Step [6250/25000], Train Loss: 0.4006, Valid Loss: 0.4523\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [126/500], Step [6275/25000], Train Loss: 0.4046, Valid Loss: 0.4366\n",
      "Epoch [126/500], Step [6300/25000], Train Loss: 0.4001, Valid Loss: 0.4507\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [127/500], Step [6325/25000], Train Loss: 0.4214, Valid Loss: 0.4347\n",
      "Epoch [127/500], Step [6350/25000], Train Loss: 0.3840, Valid Loss: 0.4509\n",
      "Epoch Accuracy: 0.9163498098859315\n",
      "Epoch [128/500], Step [6375/25000], Train Loss: 0.4120, Valid Loss: 0.4384\n",
      "Epoch [128/500], Step [6400/25000], Train Loss: 0.3962, Valid Loss: 0.4332\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [129/500], Step [6425/25000], Train Loss: 0.3959, Valid Loss: 0.4549\n",
      "Epoch [129/500], Step [6450/25000], Train Loss: 0.4071, Valid Loss: 0.4358\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [130/500], Step [6475/25000], Train Loss: 0.4014, Valid Loss: 0.4369\n",
      "Epoch [130/500], Step [6500/25000], Train Loss: 0.3981, Valid Loss: 0.4429\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [131/500], Step [6525/25000], Train Loss: 0.3962, Valid Loss: 0.4584\n",
      "Epoch [131/500], Step [6550/25000], Train Loss: 0.4088, Valid Loss: 0.4545\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [132/500], Step [6575/25000], Train Loss: 0.3964, Valid Loss: 0.4321\n",
      "Epoch [132/500], Step [6600/25000], Train Loss: 0.4077, Valid Loss: 0.4599\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [133/500], Step [6625/25000], Train Loss: 0.4075, Valid Loss: 0.4335\n",
      "Epoch [133/500], Step [6650/25000], Train Loss: 0.3895, Valid Loss: 0.4592\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [134/500], Step [6675/25000], Train Loss: 0.3955, Valid Loss: 0.4390\n",
      "Epoch [134/500], Step [6700/25000], Train Loss: 0.4041, Valid Loss: 0.4544\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [135/500], Step [6725/25000], Train Loss: 0.4018, Valid Loss: 0.4420\n",
      "Epoch [135/500], Step [6750/25000], Train Loss: 0.3950, Valid Loss: 0.4388\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [136/500], Step [6775/25000], Train Loss: 0.3961, Valid Loss: 0.4432\n",
      "Epoch [136/500], Step [6800/25000], Train Loss: 0.3992, Valid Loss: 0.4516\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [137/500], Step [6825/25000], Train Loss: 0.4058, Valid Loss: 0.4298\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [137/500], Step [6850/25000], Train Loss: 0.3972, Valid Loss: 0.4486\n",
      "Epoch Accuracy: 0.9233206590621039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/500], Step [6875/25000], Train Loss: 0.4033, Valid Loss: 0.4445\n",
      "Epoch [138/500], Step [6900/25000], Train Loss: 0.3902, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [139/500], Step [6925/25000], Train Loss: 0.3883, Valid Loss: 0.4566\n",
      "Epoch [139/500], Step [6950/25000], Train Loss: 0.4072, Valid Loss: 0.4331\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [140/500], Step [6975/25000], Train Loss: 0.3965, Valid Loss: 0.4471\n",
      "Epoch [140/500], Step [7000/25000], Train Loss: 0.4000, Valid Loss: 0.4372\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [141/500], Step [7025/25000], Train Loss: 0.4071, Valid Loss: 0.4469\n",
      "Epoch [141/500], Step [7050/25000], Train Loss: 0.3933, Valid Loss: 0.4409\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [142/500], Step [7075/25000], Train Loss: 0.3924, Valid Loss: 0.4375\n",
      "Epoch [142/500], Step [7100/25000], Train Loss: 0.3993, Valid Loss: 0.4639\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [143/500], Step [7125/25000], Train Loss: 0.4011, Valid Loss: 0.4440\n",
      "Epoch [143/500], Step [7150/25000], Train Loss: 0.3948, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [144/500], Step [7175/25000], Train Loss: 0.3946, Valid Loss: 0.4293\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [144/500], Step [7200/25000], Train Loss: 0.3953, Valid Loss: 0.4445\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [145/500], Step [7225/25000], Train Loss: 0.3924, Valid Loss: 0.4395\n",
      "Epoch [145/500], Step [7250/25000], Train Loss: 0.4074, Valid Loss: 0.4461\n",
      "Epoch Accuracy: 0.9195183776932826\n",
      "Epoch [146/500], Step [7275/25000], Train Loss: 0.3888, Valid Loss: 0.4521\n",
      "Epoch [146/500], Step [7300/25000], Train Loss: 0.4005, Valid Loss: 0.4433\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [147/500], Step [7325/25000], Train Loss: 0.3908, Valid Loss: 0.4610\n",
      "Epoch [147/500], Step [7350/25000], Train Loss: 0.4031, Valid Loss: 0.4345\n",
      "Epoch Accuracy: 0.9195183776932826\n",
      "Epoch [148/500], Step [7375/25000], Train Loss: 0.4060, Valid Loss: 0.4540\n",
      "Epoch [148/500], Step [7400/25000], Train Loss: 0.3912, Valid Loss: 0.4469\n",
      "Epoch Accuracy: 0.9157160963244614\n",
      "Epoch [149/500], Step [7425/25000], Train Loss: 0.4043, Valid Loss: 0.4365\n",
      "Epoch [149/500], Step [7450/25000], Train Loss: 0.3863, Valid Loss: 0.4410\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [150/500], Step [7475/25000], Train Loss: 0.4037, Valid Loss: 0.4431\n",
      "Epoch [150/500], Step [7500/25000], Train Loss: 0.3896, Valid Loss: 0.4504\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [151/500], Step [7525/25000], Train Loss: 0.3775, Valid Loss: 0.4516\n",
      "Epoch [151/500], Step [7550/25000], Train Loss: 0.4132, Valid Loss: 0.4401\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [152/500], Step [7575/25000], Train Loss: 0.3982, Valid Loss: 0.4445\n",
      "Epoch [152/500], Step [7600/25000], Train Loss: 0.3977, Valid Loss: 0.4325\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [153/500], Step [7625/25000], Train Loss: 0.4033, Valid Loss: 0.4449\n",
      "Epoch [153/500], Step [7650/25000], Train Loss: 0.3890, Valid Loss: 0.4508\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [154/500], Step [7675/25000], Train Loss: 0.4013, Valid Loss: 0.4427\n",
      "Epoch [154/500], Step [7700/25000], Train Loss: 0.3944, Valid Loss: 0.4400\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [155/500], Step [7725/25000], Train Loss: 0.4124, Valid Loss: 0.4467\n",
      "Epoch [155/500], Step [7750/25000], Train Loss: 0.3808, Valid Loss: 0.4497\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [156/500], Step [7775/25000], Train Loss: 0.3892, Valid Loss: 0.4389\n",
      "Epoch [156/500], Step [7800/25000], Train Loss: 0.4009, Valid Loss: 0.4500\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [157/500], Step [7825/25000], Train Loss: 0.3838, Valid Loss: 0.4390\n",
      "Epoch [157/500], Step [7850/25000], Train Loss: 0.4044, Valid Loss: 0.4482\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [158/500], Step [7875/25000], Train Loss: 0.3775, Valid Loss: 0.4436\n",
      "Epoch [158/500], Step [7900/25000], Train Loss: 0.4065, Valid Loss: 0.4409\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [159/500], Step [7925/25000], Train Loss: 0.3932, Valid Loss: 0.4475\n",
      "Epoch [159/500], Step [7950/25000], Train Loss: 0.3938, Valid Loss: 0.4492\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [160/500], Step [7975/25000], Train Loss: 0.3918, Valid Loss: 0.4451\n",
      "Epoch [160/500], Step [8000/25000], Train Loss: 0.3946, Valid Loss: 0.4393\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [161/500], Step [8025/25000], Train Loss: 0.4027, Valid Loss: 0.4518\n",
      "Epoch [161/500], Step [8050/25000], Train Loss: 0.3852, Valid Loss: 0.4487\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [162/500], Step [8075/25000], Train Loss: 0.3931, Valid Loss: 0.4412\n",
      "Epoch [162/500], Step [8100/25000], Train Loss: 0.4014, Valid Loss: 0.4548\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [163/500], Step [8125/25000], Train Loss: 0.4060, Valid Loss: 0.4408\n",
      "Epoch [163/500], Step [8150/25000], Train Loss: 0.3836, Valid Loss: 0.4487\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [164/500], Step [8175/25000], Train Loss: 0.3883, Valid Loss: 0.4386\n",
      "Epoch [164/500], Step [8200/25000], Train Loss: 0.3973, Valid Loss: 0.4600\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [165/500], Step [8225/25000], Train Loss: 0.4025, Valid Loss: 0.4445\n",
      "Epoch [165/500], Step [8250/25000], Train Loss: 0.3820, Valid Loss: 0.4533\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [166/500], Step [8275/25000], Train Loss: 0.3962, Valid Loss: 0.4343\n",
      "Epoch [166/500], Step [8300/25000], Train Loss: 0.3888, Valid Loss: 0.4631\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [167/500], Step [8325/25000], Train Loss: 0.3864, Valid Loss: 0.4588\n",
      "Epoch [167/500], Step [8350/25000], Train Loss: 0.4009, Valid Loss: 0.4412\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [168/500], Step [8375/25000], Train Loss: 0.3946, Valid Loss: 0.4464\n",
      "Epoch [168/500], Step [8400/25000], Train Loss: 0.3912, Valid Loss: 0.4467\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [169/500], Step [8425/25000], Train Loss: 0.3913, Valid Loss: 0.4532\n",
      "Epoch [169/500], Step [8450/25000], Train Loss: 0.3892, Valid Loss: 0.4447\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [170/500], Step [8475/25000], Train Loss: 0.3802, Valid Loss: 0.4352\n",
      "Epoch [170/500], Step [8500/25000], Train Loss: 0.3990, Valid Loss: 0.4387\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [171/500], Step [8525/25000], Train Loss: 0.3874, Valid Loss: 0.4537\n",
      "Epoch [171/500], Step [8550/25000], Train Loss: 0.3985, Valid Loss: 0.4606\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [172/500], Step [8575/25000], Train Loss: 0.3895, Valid Loss: 0.4475\n",
      "Epoch [172/500], Step [8600/25000], Train Loss: 0.3960, Valid Loss: 0.4500\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [173/500], Step [8625/25000], Train Loss: 0.3927, Valid Loss: 0.4508\n",
      "Epoch [173/500], Step [8650/25000], Train Loss: 0.3988, Valid Loss: 0.4375\n",
      "Epoch Accuracy: 0.9195183776932826\n",
      "Epoch [174/500], Step [8675/25000], Train Loss: 0.3974, Valid Loss: 0.4441\n",
      "Epoch [174/500], Step [8700/25000], Train Loss: 0.3864, Valid Loss: 0.4655\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [175/500], Step [8725/25000], Train Loss: 0.3997, Valid Loss: 0.4478\n",
      "Epoch [175/500], Step [8750/25000], Train Loss: 0.3833, Valid Loss: 0.4367\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [176/500], Step [8775/25000], Train Loss: 0.3984, Valid Loss: 0.4529\n",
      "Epoch [176/500], Step [8800/25000], Train Loss: 0.3818, Valid Loss: 0.4420\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [177/500], Step [8825/25000], Train Loss: 0.3862, Valid Loss: 0.4423\n",
      "Epoch [177/500], Step [8850/25000], Train Loss: 0.4016, Valid Loss: 0.4384\n",
      "Epoch Accuracy: 0.9195183776932826\n",
      "Epoch [178/500], Step [8875/25000], Train Loss: 0.3791, Valid Loss: 0.4511\n",
      "Epoch [178/500], Step [8900/25000], Train Loss: 0.4093, Valid Loss: 0.4374\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [179/500], Step [8925/25000], Train Loss: 0.3883, Valid Loss: 0.4430\n",
      "Epoch [179/500], Step [8950/25000], Train Loss: 0.3952, Valid Loss: 0.4529\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [180/500], Step [8975/25000], Train Loss: 0.3858, Valid Loss: 0.4502\n",
      "Epoch [180/500], Step [9000/25000], Train Loss: 0.4010, Valid Loss: 0.4357\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [181/500], Step [9025/25000], Train Loss: 0.3956, Valid Loss: 0.4632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/500], Step [9050/25000], Train Loss: 0.3827, Valid Loss: 0.4450\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [182/500], Step [9075/25000], Train Loss: 0.3891, Valid Loss: 0.4579\n",
      "Epoch [182/500], Step [9100/25000], Train Loss: 0.3916, Valid Loss: 0.4413\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [183/500], Step [9125/25000], Train Loss: 0.3843, Valid Loss: 0.4521\n",
      "Epoch [183/500], Step [9150/25000], Train Loss: 0.3925, Valid Loss: 0.4388\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [184/500], Step [9175/25000], Train Loss: 0.3908, Valid Loss: 0.4399\n",
      "Epoch [184/500], Step [9200/25000], Train Loss: 0.3858, Valid Loss: 0.4550\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [185/500], Step [9225/25000], Train Loss: 0.3940, Valid Loss: 0.4362\n",
      "Epoch [185/500], Step [9250/25000], Train Loss: 0.3853, Valid Loss: 0.4676\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [186/500], Step [9275/25000], Train Loss: 0.4082, Valid Loss: 0.4543\n",
      "Epoch [186/500], Step [9300/25000], Train Loss: 0.3834, Valid Loss: 0.4483\n",
      "Epoch Accuracy: 0.9163498098859315\n",
      "Epoch [187/500], Step [9325/25000], Train Loss: 0.3879, Valid Loss: 0.4422\n",
      "Epoch [187/500], Step [9350/25000], Train Loss: 0.3942, Valid Loss: 0.4485\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [188/500], Step [9375/25000], Train Loss: 0.3896, Valid Loss: 0.4477\n",
      "Epoch [188/500], Step [9400/25000], Train Loss: 0.3888, Valid Loss: 0.4442\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [189/500], Step [9425/25000], Train Loss: 0.3859, Valid Loss: 0.4502\n",
      "Epoch [189/500], Step [9450/25000], Train Loss: 0.3906, Valid Loss: 0.4475\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [190/500], Step [9475/25000], Train Loss: 0.3917, Valid Loss: 0.4513\n",
      "Epoch [190/500], Step [9500/25000], Train Loss: 0.3904, Valid Loss: 0.4472\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [191/500], Step [9525/25000], Train Loss: 0.3926, Valid Loss: 0.4412\n",
      "Epoch [191/500], Step [9550/25000], Train Loss: 0.3871, Valid Loss: 0.4529\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [192/500], Step [9575/25000], Train Loss: 0.3930, Valid Loss: 0.4533\n",
      "Epoch [192/500], Step [9600/25000], Train Loss: 0.3834, Valid Loss: 0.4377\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [193/500], Step [9625/25000], Train Loss: 0.3878, Valid Loss: 0.4535\n",
      "Epoch [193/500], Step [9650/25000], Train Loss: 0.3943, Valid Loss: 0.4303\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [194/500], Step [9675/25000], Train Loss: 0.4014, Valid Loss: 0.4532\n",
      "Epoch [194/500], Step [9700/25000], Train Loss: 0.3810, Valid Loss: 0.4429\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [195/500], Step [9725/25000], Train Loss: 0.3941, Valid Loss: 0.4513\n",
      "Epoch [195/500], Step [9750/25000], Train Loss: 0.3838, Valid Loss: 0.4507\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [196/500], Step [9775/25000], Train Loss: 0.3870, Valid Loss: 0.4363\n",
      "Epoch [196/500], Step [9800/25000], Train Loss: 0.3990, Valid Loss: 0.4521\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [197/500], Step [9825/25000], Train Loss: 0.3903, Valid Loss: 0.4486\n",
      "Epoch [197/500], Step [9850/25000], Train Loss: 0.3841, Valid Loss: 0.4545\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [198/500], Step [9875/25000], Train Loss: 0.3829, Valid Loss: 0.4488\n",
      "Epoch [198/500], Step [9900/25000], Train Loss: 0.3918, Valid Loss: 0.4592\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [199/500], Step [9925/25000], Train Loss: 0.3884, Valid Loss: 0.4405\n",
      "Epoch [199/500], Step [9950/25000], Train Loss: 0.3915, Valid Loss: 0.4622\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [200/500], Step [9975/25000], Train Loss: 0.3931, Valid Loss: 0.4410\n",
      "Epoch [200/500], Step [10000/25000], Train Loss: 0.3806, Valid Loss: 0.4464\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [201/500], Step [10025/25000], Train Loss: 0.3835, Valid Loss: 0.4542\n",
      "Epoch [201/500], Step [10050/25000], Train Loss: 0.3937, Valid Loss: 0.4397\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [202/500], Step [10075/25000], Train Loss: 0.3841, Valid Loss: 0.4396\n",
      "Epoch [202/500], Step [10100/25000], Train Loss: 0.3936, Valid Loss: 0.4466\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [203/500], Step [10125/25000], Train Loss: 0.3866, Valid Loss: 0.4464\n",
      "Epoch [203/500], Step [10150/25000], Train Loss: 0.3910, Valid Loss: 0.4425\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [204/500], Step [10175/25000], Train Loss: 0.3757, Valid Loss: 0.4528\n",
      "Epoch [204/500], Step [10200/25000], Train Loss: 0.4001, Valid Loss: 0.4433\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [205/500], Step [10225/25000], Train Loss: 0.3903, Valid Loss: 0.4573\n",
      "Epoch [205/500], Step [10250/25000], Train Loss: 0.3817, Valid Loss: 0.4375\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [206/500], Step [10275/25000], Train Loss: 0.3860, Valid Loss: 0.4524\n",
      "Epoch [206/500], Step [10300/25000], Train Loss: 0.3934, Valid Loss: 0.4345\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [207/500], Step [10325/25000], Train Loss: 0.3774, Valid Loss: 0.4493\n",
      "Epoch [207/500], Step [10350/25000], Train Loss: 0.3980, Valid Loss: 0.4454\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [208/500], Step [10375/25000], Train Loss: 0.3816, Valid Loss: 0.4537\n",
      "Epoch [208/500], Step [10400/25000], Train Loss: 0.3935, Valid Loss: 0.4472\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [209/500], Step [10425/25000], Train Loss: 0.4056, Valid Loss: 0.4511\n",
      "Epoch [209/500], Step [10450/25000], Train Loss: 0.3709, Valid Loss: 0.4338\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [210/500], Step [10475/25000], Train Loss: 0.3732, Valid Loss: 0.4578\n",
      "Epoch [210/500], Step [10500/25000], Train Loss: 0.4038, Valid Loss: 0.4665\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [211/500], Step [10525/25000], Train Loss: 0.3929, Valid Loss: 0.4566\n",
      "Epoch [211/500], Step [10550/25000], Train Loss: 0.3822, Valid Loss: 0.4419\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [212/500], Step [10575/25000], Train Loss: 0.3897, Valid Loss: 0.4587\n",
      "Epoch [212/500], Step [10600/25000], Train Loss: 0.3890, Valid Loss: 0.4493\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [213/500], Step [10625/25000], Train Loss: 0.3998, Valid Loss: 0.4476\n",
      "Epoch [213/500], Step [10650/25000], Train Loss: 0.3762, Valid Loss: 0.4509\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [214/500], Step [10675/25000], Train Loss: 0.3790, Valid Loss: 0.4645\n",
      "Epoch [214/500], Step [10700/25000], Train Loss: 0.4019, Valid Loss: 0.4392\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [215/500], Step [10725/25000], Train Loss: 0.3914, Valid Loss: 0.4416\n",
      "Epoch [215/500], Step [10750/25000], Train Loss: 0.3895, Valid Loss: 0.4313\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [216/500], Step [10775/25000], Train Loss: 0.3893, Valid Loss: 0.4531\n",
      "Epoch [216/500], Step [10800/25000], Train Loss: 0.3842, Valid Loss: 0.4500\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [217/500], Step [10825/25000], Train Loss: 0.3880, Valid Loss: 0.4476\n",
      "Epoch [217/500], Step [10850/25000], Train Loss: 0.3869, Valid Loss: 0.4688\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [218/500], Step [10875/25000], Train Loss: 0.3958, Valid Loss: 0.4440\n",
      "Epoch [218/500], Step [10900/25000], Train Loss: 0.3866, Valid Loss: 0.4582\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [219/500], Step [10925/25000], Train Loss: 0.3852, Valid Loss: 0.4513\n",
      "Epoch [219/500], Step [10950/25000], Train Loss: 0.3873, Valid Loss: 0.4382\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [220/500], Step [10975/25000], Train Loss: 0.3965, Valid Loss: 0.4409\n",
      "Epoch [220/500], Step [11000/25000], Train Loss: 0.3810, Valid Loss: 0.4432\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [221/500], Step [11025/25000], Train Loss: 0.3858, Valid Loss: 0.4488\n",
      "Epoch [221/500], Step [11050/25000], Train Loss: 0.3847, Valid Loss: 0.4291\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [222/500], Step [11075/25000], Train Loss: 0.4084, Valid Loss: 0.4501\n",
      "Epoch [222/500], Step [11100/25000], Train Loss: 0.3704, Valid Loss: 0.4522\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [223/500], Step [11125/25000], Train Loss: 0.4025, Valid Loss: 0.4370\n",
      "Epoch [223/500], Step [11150/25000], Train Loss: 0.3782, Valid Loss: 0.4556\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [224/500], Step [11175/25000], Train Loss: 0.3903, Valid Loss: 0.4480\n",
      "Epoch [224/500], Step [11200/25000], Train Loss: 0.3773, Valid Loss: 0.4500\n",
      "Epoch Accuracy: 0.9340937896070975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [225/500], Step [11225/25000], Train Loss: 0.3848, Valid Loss: 0.4400\n",
      "Epoch [225/500], Step [11250/25000], Train Loss: 0.3896, Valid Loss: 0.4521\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [226/500], Step [11275/25000], Train Loss: 0.3930, Valid Loss: 0.4471\n",
      "Epoch [226/500], Step [11300/25000], Train Loss: 0.3772, Valid Loss: 0.4464\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [227/500], Step [11325/25000], Train Loss: 0.3844, Valid Loss: 0.4586\n",
      "Epoch [227/500], Step [11350/25000], Train Loss: 0.3882, Valid Loss: 0.4545\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [228/500], Step [11375/25000], Train Loss: 0.3875, Valid Loss: 0.4380\n",
      "Epoch [228/500], Step [11400/25000], Train Loss: 0.3896, Valid Loss: 0.4406\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [229/500], Step [11425/25000], Train Loss: 0.3901, Valid Loss: 0.4528\n",
      "Epoch [229/500], Step [11450/25000], Train Loss: 0.3817, Valid Loss: 0.4500\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [230/500], Step [11475/25000], Train Loss: 0.3903, Valid Loss: 0.4516\n",
      "Epoch [230/500], Step [11500/25000], Train Loss: 0.3860, Valid Loss: 0.4573\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [231/500], Step [11525/25000], Train Loss: 0.3934, Valid Loss: 0.4444\n",
      "Epoch [231/500], Step [11550/25000], Train Loss: 0.3803, Valid Loss: 0.4547\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [232/500], Step [11575/25000], Train Loss: 0.3852, Valid Loss: 0.4616\n",
      "Epoch [232/500], Step [11600/25000], Train Loss: 0.3876, Valid Loss: 0.4500\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [233/500], Step [11625/25000], Train Loss: 0.3855, Valid Loss: 0.4572\n",
      "Epoch [233/500], Step [11650/25000], Train Loss: 0.3910, Valid Loss: 0.4506\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [234/500], Step [11675/25000], Train Loss: 0.4025, Valid Loss: 0.4540\n",
      "Epoch [234/500], Step [11700/25000], Train Loss: 0.3722, Valid Loss: 0.4517\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [235/500], Step [11725/25000], Train Loss: 0.3832, Valid Loss: 0.4496\n",
      "Epoch [235/500], Step [11750/25000], Train Loss: 0.3929, Valid Loss: 0.4387\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [236/500], Step [11775/25000], Train Loss: 0.3837, Valid Loss: 0.4546\n",
      "Epoch [236/500], Step [11800/25000], Train Loss: 0.3824, Valid Loss: 0.4474\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [237/500], Step [11825/25000], Train Loss: 0.3974, Valid Loss: 0.4434\n",
      "Epoch [237/500], Step [11850/25000], Train Loss: 0.3783, Valid Loss: 0.4497\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [238/500], Step [11875/25000], Train Loss: 0.3898, Valid Loss: 0.4490\n",
      "Epoch [238/500], Step [11900/25000], Train Loss: 0.3797, Valid Loss: 0.4389\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [239/500], Step [11925/25000], Train Loss: 0.3870, Valid Loss: 0.4476\n",
      "Epoch [239/500], Step [11950/25000], Train Loss: 0.3821, Valid Loss: 0.4581\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [240/500], Step [11975/25000], Train Loss: 0.3911, Valid Loss: 0.4469\n",
      "Epoch [240/500], Step [12000/25000], Train Loss: 0.3789, Valid Loss: 0.4473\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [241/500], Step [12025/25000], Train Loss: 0.3845, Valid Loss: 0.4419\n",
      "Epoch [241/500], Step [12050/25000], Train Loss: 0.3838, Valid Loss: 0.4522\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [242/500], Step [12075/25000], Train Loss: 0.4088, Valid Loss: 0.4566\n",
      "Epoch [242/500], Step [12100/25000], Train Loss: 0.3653, Valid Loss: 0.4355\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [243/500], Step [12125/25000], Train Loss: 0.3824, Valid Loss: 0.4553\n",
      "Epoch [243/500], Step [12150/25000], Train Loss: 0.3964, Valid Loss: 0.4510\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [244/500], Step [12175/25000], Train Loss: 0.3824, Valid Loss: 0.4649\n",
      "Epoch [244/500], Step [12200/25000], Train Loss: 0.3929, Valid Loss: 0.4411\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [245/500], Step [12225/25000], Train Loss: 0.3889, Valid Loss: 0.4498\n",
      "Epoch [245/500], Step [12250/25000], Train Loss: 0.3785, Valid Loss: 0.4467\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [246/500], Step [12275/25000], Train Loss: 0.3846, Valid Loss: 0.4418\n",
      "Epoch [246/500], Step [12300/25000], Train Loss: 0.3778, Valid Loss: 0.4362\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [247/500], Step [12325/25000], Train Loss: 0.3687, Valid Loss: 0.4582\n",
      "Epoch [247/500], Step [12350/25000], Train Loss: 0.4008, Valid Loss: 0.4534\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [248/500], Step [12375/25000], Train Loss: 0.3881, Valid Loss: 0.4374\n",
      "Epoch [248/500], Step [12400/25000], Train Loss: 0.3839, Valid Loss: 0.4516\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [249/500], Step [12425/25000], Train Loss: 0.3832, Valid Loss: 0.4589\n",
      "Epoch [249/500], Step [12450/25000], Train Loss: 0.3812, Valid Loss: 0.4355\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [250/500], Step [12475/25000], Train Loss: 0.3765, Valid Loss: 0.4490\n",
      "Epoch [250/500], Step [12500/25000], Train Loss: 0.3886, Valid Loss: 0.4410\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [251/500], Step [12525/25000], Train Loss: 0.3891, Valid Loss: 0.4329\n",
      "Epoch [251/500], Step [12550/25000], Train Loss: 0.3843, Valid Loss: 0.4561\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [252/500], Step [12575/25000], Train Loss: 0.3949, Valid Loss: 0.4313\n",
      "Epoch [252/500], Step [12600/25000], Train Loss: 0.3783, Valid Loss: 0.4457\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [253/500], Step [12625/25000], Train Loss: 0.3899, Valid Loss: 0.4325\n",
      "Epoch [253/500], Step [12650/25000], Train Loss: 0.3744, Valid Loss: 0.4550\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [254/500], Step [12675/25000], Train Loss: 0.3849, Valid Loss: 0.4358\n",
      "Epoch [254/500], Step [12700/25000], Train Loss: 0.3835, Valid Loss: 0.4503\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [255/500], Step [12725/25000], Train Loss: 0.3845, Valid Loss: 0.4353\n",
      "Epoch [255/500], Step [12750/25000], Train Loss: 0.3932, Valid Loss: 0.4431\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [256/500], Step [12775/25000], Train Loss: 0.3821, Valid Loss: 0.4413\n",
      "Epoch [256/500], Step [12800/25000], Train Loss: 0.3808, Valid Loss: 0.4420\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [257/500], Step [12825/25000], Train Loss: 0.3662, Valid Loss: 0.4446\n",
      "Epoch [257/500], Step [12850/25000], Train Loss: 0.4001, Valid Loss: 0.4490\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [258/500], Step [12875/25000], Train Loss: 0.3706, Valid Loss: 0.4358\n",
      "Epoch [258/500], Step [12900/25000], Train Loss: 0.3962, Valid Loss: 0.4574\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [259/500], Step [12925/25000], Train Loss: 0.3744, Valid Loss: 0.4384\n",
      "Epoch [259/500], Step [12950/25000], Train Loss: 0.3890, Valid Loss: 0.4513\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [260/500], Step [12975/25000], Train Loss: 0.3850, Valid Loss: 0.4441\n",
      "Epoch [260/500], Step [13000/25000], Train Loss: 0.3752, Valid Loss: 0.4478\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [261/500], Step [13025/25000], Train Loss: 0.3813, Valid Loss: 0.4430\n",
      "Epoch [261/500], Step [13050/25000], Train Loss: 0.3796, Valid Loss: 0.4419\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [262/500], Step [13075/25000], Train Loss: 0.3782, Valid Loss: 0.4454\n",
      "Epoch [262/500], Step [13100/25000], Train Loss: 0.3843, Valid Loss: 0.4369\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [263/500], Step [13125/25000], Train Loss: 0.3880, Valid Loss: 0.4370\n",
      "Epoch [263/500], Step [13150/25000], Train Loss: 0.3801, Valid Loss: 0.4481\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [264/500], Step [13175/25000], Train Loss: 0.3885, Valid Loss: 0.4405\n",
      "Epoch [264/500], Step [13200/25000], Train Loss: 0.3798, Valid Loss: 0.4407\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [265/500], Step [13225/25000], Train Loss: 0.3830, Valid Loss: 0.4401\n",
      "Epoch [265/500], Step [13250/25000], Train Loss: 0.3792, Valid Loss: 0.4403\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [266/500], Step [13275/25000], Train Loss: 0.3976, Valid Loss: 0.4357\n",
      "Epoch [266/500], Step [13300/25000], Train Loss: 0.3706, Valid Loss: 0.4432\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [267/500], Step [13325/25000], Train Loss: 0.3797, Valid Loss: 0.4532\n",
      "Epoch [267/500], Step [13350/25000], Train Loss: 0.3827, Valid Loss: 0.4524\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [268/500], Step [13375/25000], Train Loss: 0.3981, Valid Loss: 0.4434\n",
      "Epoch [268/500], Step [13400/25000], Train Loss: 0.3713, Valid Loss: 0.4436\n",
      "Epoch Accuracy: 0.9328263624841572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [269/500], Step [13425/25000], Train Loss: 0.3818, Valid Loss: 0.4536\n",
      "Epoch [269/500], Step [13450/25000], Train Loss: 0.3872, Valid Loss: 0.4354\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [270/500], Step [13475/25000], Train Loss: 0.3755, Valid Loss: 0.4499\n",
      "Epoch [270/500], Step [13500/25000], Train Loss: 0.3879, Valid Loss: 0.4466\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [271/500], Step [13525/25000], Train Loss: 0.3801, Valid Loss: 0.4532\n",
      "Epoch [271/500], Step [13550/25000], Train Loss: 0.3800, Valid Loss: 0.4497\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [272/500], Step [13575/25000], Train Loss: 0.3803, Valid Loss: 0.4368\n",
      "Epoch [272/500], Step [13600/25000], Train Loss: 0.3874, Valid Loss: 0.4495\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [273/500], Step [13625/25000], Train Loss: 0.3800, Valid Loss: 0.4472\n",
      "Epoch [273/500], Step [13650/25000], Train Loss: 0.3815, Valid Loss: 0.4489\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [274/500], Step [13675/25000], Train Loss: 0.3781, Valid Loss: 0.4384\n",
      "Epoch [274/500], Step [13700/25000], Train Loss: 0.3838, Valid Loss: 0.4505\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [275/500], Step [13725/25000], Train Loss: 0.3830, Valid Loss: 0.4479\n",
      "Epoch [275/500], Step [13750/25000], Train Loss: 0.3885, Valid Loss: 0.4301\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [276/500], Step [13775/25000], Train Loss: 0.4004, Valid Loss: 0.4458\n",
      "Epoch [276/500], Step [13800/25000], Train Loss: 0.3752, Valid Loss: 0.4488\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [277/500], Step [13825/25000], Train Loss: 0.3783, Valid Loss: 0.4498\n",
      "Epoch [277/500], Step [13850/25000], Train Loss: 0.3865, Valid Loss: 0.4472\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [278/500], Step [13875/25000], Train Loss: 0.3914, Valid Loss: 0.4330\n",
      "Epoch [278/500], Step [13900/25000], Train Loss: 0.3703, Valid Loss: 0.4538\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [279/500], Step [13925/25000], Train Loss: 0.3709, Valid Loss: 0.4313\n",
      "Epoch [279/500], Step [13950/25000], Train Loss: 0.3935, Valid Loss: 0.4435\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [280/500], Step [13975/25000], Train Loss: 0.3769, Valid Loss: 0.4575\n",
      "Epoch [280/500], Step [14000/25000], Train Loss: 0.3860, Valid Loss: 0.4408\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [281/500], Step [14025/25000], Train Loss: 0.3739, Valid Loss: 0.4368\n",
      "Epoch [281/500], Step [14050/25000], Train Loss: 0.3955, Valid Loss: 0.4494\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [282/500], Step [14075/25000], Train Loss: 0.3824, Valid Loss: 0.4273\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [282/500], Step [14100/25000], Train Loss: 0.3875, Valid Loss: 0.4486\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [283/500], Step [14125/25000], Train Loss: 0.3835, Valid Loss: 0.4385\n",
      "Epoch [283/500], Step [14150/25000], Train Loss: 0.3797, Valid Loss: 0.4581\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [284/500], Step [14175/25000], Train Loss: 0.3812, Valid Loss: 0.4495\n",
      "Epoch [284/500], Step [14200/25000], Train Loss: 0.3809, Valid Loss: 0.4447\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [285/500], Step [14225/25000], Train Loss: 0.3852, Valid Loss: 0.4368\n",
      "Epoch [285/500], Step [14250/25000], Train Loss: 0.3770, Valid Loss: 0.4447\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [286/500], Step [14275/25000], Train Loss: 0.3759, Valid Loss: 0.4468\n",
      "Epoch [286/500], Step [14300/25000], Train Loss: 0.3826, Valid Loss: 0.4305\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [287/500], Step [14325/25000], Train Loss: 0.3813, Valid Loss: 0.4435\n",
      "Epoch [287/500], Step [14350/25000], Train Loss: 0.3812, Valid Loss: 0.4316\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [288/500], Step [14375/25000], Train Loss: 0.3909, Valid Loss: 0.4426\n",
      "Epoch [288/500], Step [14400/25000], Train Loss: 0.3703, Valid Loss: 0.4349\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [289/500], Step [14425/25000], Train Loss: 0.3815, Valid Loss: 0.4476\n",
      "Epoch [289/500], Step [14450/25000], Train Loss: 0.3866, Valid Loss: 0.4708\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [290/500], Step [14475/25000], Train Loss: 0.3793, Valid Loss: 0.4334\n",
      "Epoch [290/500], Step [14500/25000], Train Loss: 0.3832, Valid Loss: 0.4762\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [291/500], Step [14525/25000], Train Loss: 0.3763, Valid Loss: 0.4361\n",
      "Epoch [291/500], Step [14550/25000], Train Loss: 0.3867, Valid Loss: 0.4456\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [292/500], Step [14575/25000], Train Loss: 0.3854, Valid Loss: 0.4499\n",
      "Epoch [292/500], Step [14600/25000], Train Loss: 0.3774, Valid Loss: 0.4327\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [293/500], Step [14625/25000], Train Loss: 0.3961, Valid Loss: 0.4426\n",
      "Epoch [293/500], Step [14650/25000], Train Loss: 0.3678, Valid Loss: 0.4373\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [294/500], Step [14675/25000], Train Loss: 0.3813, Valid Loss: 0.4371\n",
      "Epoch [294/500], Step [14700/25000], Train Loss: 0.3770, Valid Loss: 0.4572\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [295/500], Step [14725/25000], Train Loss: 0.3699, Valid Loss: 0.4321\n",
      "Epoch [295/500], Step [14750/25000], Train Loss: 0.3874, Valid Loss: 0.4497\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [296/500], Step [14775/25000], Train Loss: 0.3816, Valid Loss: 0.4539\n",
      "Epoch [296/500], Step [14800/25000], Train Loss: 0.3759, Valid Loss: 0.4425\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [297/500], Step [14825/25000], Train Loss: 0.3781, Valid Loss: 0.4362\n",
      "Epoch [297/500], Step [14850/25000], Train Loss: 0.3806, Valid Loss: 0.4667\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [298/500], Step [14875/25000], Train Loss: 0.3767, Valid Loss: 0.4450\n",
      "Epoch [298/500], Step [14900/25000], Train Loss: 0.3912, Valid Loss: 0.4355\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [299/500], Step [14925/25000], Train Loss: 0.3824, Valid Loss: 0.4494\n",
      "Epoch [299/500], Step [14950/25000], Train Loss: 0.3749, Valid Loss: 0.4399\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [300/500], Step [14975/25000], Train Loss: 0.3678, Valid Loss: 0.4332\n",
      "Epoch [300/500], Step [15000/25000], Train Loss: 0.3980, Valid Loss: 0.4559\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [301/500], Step [15025/25000], Train Loss: 0.3914, Valid Loss: 0.4419\n",
      "Epoch [301/500], Step [15050/25000], Train Loss: 0.3750, Valid Loss: 0.4303\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [302/500], Step [15075/25000], Train Loss: 0.3772, Valid Loss: 0.4282\n",
      "Epoch [302/500], Step [15100/25000], Train Loss: 0.3856, Valid Loss: 0.4463\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [303/500], Step [15125/25000], Train Loss: 0.3842, Valid Loss: 0.4309\n",
      "Epoch [303/500], Step [15150/25000], Train Loss: 0.3752, Valid Loss: 0.4399\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [304/500], Step [15175/25000], Train Loss: 0.3721, Valid Loss: 0.4430\n",
      "Epoch [304/500], Step [15200/25000], Train Loss: 0.3972, Valid Loss: 0.4292\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [305/500], Step [15225/25000], Train Loss: 0.3932, Valid Loss: 0.4415\n",
      "Epoch [305/500], Step [15250/25000], Train Loss: 0.3675, Valid Loss: 0.4308\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [306/500], Step [15275/25000], Train Loss: 0.3796, Valid Loss: 0.4568\n",
      "Epoch [306/500], Step [15300/25000], Train Loss: 0.3834, Valid Loss: 0.4507\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [307/500], Step [15325/25000], Train Loss: 0.3896, Valid Loss: 0.4357\n",
      "Epoch [307/500], Step [15350/25000], Train Loss: 0.3740, Valid Loss: 0.4362\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [308/500], Step [15375/25000], Train Loss: 0.3821, Valid Loss: 0.4354\n",
      "Epoch [308/500], Step [15400/25000], Train Loss: 0.3738, Valid Loss: 0.4390\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [309/500], Step [15425/25000], Train Loss: 0.3730, Valid Loss: 0.4373\n",
      "Epoch [309/500], Step [15450/25000], Train Loss: 0.3843, Valid Loss: 0.4425\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [310/500], Step [15475/25000], Train Loss: 0.3946, Valid Loss: 0.4277\n",
      "Epoch [310/500], Step [15500/25000], Train Loss: 0.3708, Valid Loss: 0.4390\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [311/500], Step [15525/25000], Train Loss: 0.3943, Valid Loss: 0.4301\n",
      "Epoch [311/500], Step [15550/25000], Train Loss: 0.3668, Valid Loss: 0.4445\n",
      "Epoch Accuracy: 0.9334600760456274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [312/500], Step [15575/25000], Train Loss: 0.3883, Valid Loss: 0.4347\n",
      "Epoch [312/500], Step [15600/25000], Train Loss: 0.3622, Valid Loss: 0.4356\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [313/500], Step [15625/25000], Train Loss: 0.3800, Valid Loss: 0.4264\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [313/500], Step [15650/25000], Train Loss: 0.3810, Valid Loss: 0.4324\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [314/500], Step [15675/25000], Train Loss: 0.3870, Valid Loss: 0.4360\n",
      "Epoch [314/500], Step [15700/25000], Train Loss: 0.3741, Valid Loss: 0.4226\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [315/500], Step [15725/25000], Train Loss: 0.3749, Valid Loss: 0.4407\n",
      "Epoch [315/500], Step [15750/25000], Train Loss: 0.3866, Valid Loss: 0.4285\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [316/500], Step [15775/25000], Train Loss: 0.3707, Valid Loss: 0.4372\n",
      "Epoch [316/500], Step [15800/25000], Train Loss: 0.3834, Valid Loss: 0.4277\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [317/500], Step [15825/25000], Train Loss: 0.3804, Valid Loss: 0.4534\n",
      "Epoch [317/500], Step [15850/25000], Train Loss: 0.3885, Valid Loss: 0.4299\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [318/500], Step [15875/25000], Train Loss: 0.3842, Valid Loss: 0.4381\n",
      "Epoch [318/500], Step [15900/25000], Train Loss: 0.3734, Valid Loss: 0.4358\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [319/500], Step [15925/25000], Train Loss: 0.3777, Valid Loss: 0.4367\n",
      "Epoch [319/500], Step [15950/25000], Train Loss: 0.3802, Valid Loss: 0.4298\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [320/500], Step [15975/25000], Train Loss: 0.3895, Valid Loss: 0.4318\n",
      "Epoch [320/500], Step [16000/25000], Train Loss: 0.3745, Valid Loss: 0.4272\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [321/500], Step [16025/25000], Train Loss: 0.3815, Valid Loss: 0.4404\n",
      "Epoch [321/500], Step [16050/25000], Train Loss: 0.3846, Valid Loss: 0.4340\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [322/500], Step [16075/25000], Train Loss: 0.3850, Valid Loss: 0.4352\n",
      "Epoch [322/500], Step [16100/25000], Train Loss: 0.3732, Valid Loss: 0.4366\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [323/500], Step [16125/25000], Train Loss: 0.3755, Valid Loss: 0.4441\n",
      "Epoch [323/500], Step [16150/25000], Train Loss: 0.3870, Valid Loss: 0.4365\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [324/500], Step [16175/25000], Train Loss: 0.3700, Valid Loss: 0.4347\n",
      "Epoch [324/500], Step [16200/25000], Train Loss: 0.3837, Valid Loss: 0.4433\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [325/500], Step [16225/25000], Train Loss: 0.3745, Valid Loss: 0.4330\n",
      "Epoch [325/500], Step [16250/25000], Train Loss: 0.3815, Valid Loss: 0.4417\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [326/500], Step [16275/25000], Train Loss: 0.3741, Valid Loss: 0.4414\n",
      "Epoch [326/500], Step [16300/25000], Train Loss: 0.3787, Valid Loss: 0.4447\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [327/500], Step [16325/25000], Train Loss: 0.3725, Valid Loss: 0.4439\n",
      "Epoch [327/500], Step [16350/25000], Train Loss: 0.3832, Valid Loss: 0.4491\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [328/500], Step [16375/25000], Train Loss: 0.3780, Valid Loss: 0.4339\n",
      "Epoch [328/500], Step [16400/25000], Train Loss: 0.3823, Valid Loss: 0.4484\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [329/500], Step [16425/25000], Train Loss: 0.3933, Valid Loss: 0.4291\n",
      "Epoch [329/500], Step [16450/25000], Train Loss: 0.3664, Valid Loss: 0.4396\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [330/500], Step [16475/25000], Train Loss: 0.3964, Valid Loss: 0.4407\n",
      "Epoch [330/500], Step [16500/25000], Train Loss: 0.3642, Valid Loss: 0.4398\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [331/500], Step [16525/25000], Train Loss: 0.3788, Valid Loss: 0.4333\n",
      "Epoch [331/500], Step [16550/25000], Train Loss: 0.3793, Valid Loss: 0.4250\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [332/500], Step [16575/25000], Train Loss: 0.3900, Valid Loss: 0.4460\n",
      "Epoch [332/500], Step [16600/25000], Train Loss: 0.3672, Valid Loss: 0.4273\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [333/500], Step [16625/25000], Train Loss: 0.3732, Valid Loss: 0.4386\n",
      "Epoch [333/500], Step [16650/25000], Train Loss: 0.3826, Valid Loss: 0.4411\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [334/500], Step [16675/25000], Train Loss: 0.3664, Valid Loss: 0.4350\n",
      "Epoch [334/500], Step [16700/25000], Train Loss: 0.3873, Valid Loss: 0.4319\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [335/500], Step [16725/25000], Train Loss: 0.3749, Valid Loss: 0.4404\n",
      "Epoch [335/500], Step [16750/25000], Train Loss: 0.3791, Valid Loss: 0.4313\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [336/500], Step [16775/25000], Train Loss: 0.3803, Valid Loss: 0.4342\n",
      "Epoch [336/500], Step [16800/25000], Train Loss: 0.3816, Valid Loss: 0.4373\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [337/500], Step [16825/25000], Train Loss: 0.3688, Valid Loss: 0.4379\n",
      "Epoch [337/500], Step [16850/25000], Train Loss: 0.3884, Valid Loss: 0.4523\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [338/500], Step [16875/25000], Train Loss: 0.3920, Valid Loss: 0.4359\n",
      "Epoch [338/500], Step [16900/25000], Train Loss: 0.3688, Valid Loss: 0.4259\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [339/500], Step [16925/25000], Train Loss: 0.3765, Valid Loss: 0.4397\n",
      "Epoch [339/500], Step [16950/25000], Train Loss: 0.3793, Valid Loss: 0.4269\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [340/500], Step [16975/25000], Train Loss: 0.3804, Valid Loss: 0.4460\n",
      "Epoch [340/500], Step [17000/25000], Train Loss: 0.3738, Valid Loss: 0.4212\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [341/500], Step [17025/25000], Train Loss: 0.3678, Valid Loss: 0.4326\n",
      "Epoch [341/500], Step [17050/25000], Train Loss: 0.3808, Valid Loss: 0.4375\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [342/500], Step [17075/25000], Train Loss: 0.3736, Valid Loss: 0.4323\n",
      "Epoch [342/500], Step [17100/25000], Train Loss: 0.3769, Valid Loss: 0.4402\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [343/500], Step [17125/25000], Train Loss: 0.3711, Valid Loss: 0.4317\n",
      "Epoch [343/500], Step [17150/25000], Train Loss: 0.3791, Valid Loss: 0.4341\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [344/500], Step [17175/25000], Train Loss: 0.3728, Valid Loss: 0.4305\n",
      "Epoch [344/500], Step [17200/25000], Train Loss: 0.3810, Valid Loss: 0.4417\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [345/500], Step [17225/25000], Train Loss: 0.3845, Valid Loss: 0.4405\n",
      "Epoch [345/500], Step [17250/25000], Train Loss: 0.3836, Valid Loss: 0.4301\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [346/500], Step [17275/25000], Train Loss: 0.3721, Valid Loss: 0.4353\n",
      "Epoch [346/500], Step [17300/25000], Train Loss: 0.3829, Valid Loss: 0.4484\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [347/500], Step [17325/25000], Train Loss: 0.3889, Valid Loss: 0.4294\n",
      "Epoch [347/500], Step [17350/25000], Train Loss: 0.3708, Valid Loss: 0.4281\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [348/500], Step [17375/25000], Train Loss: 0.3814, Valid Loss: 0.4411\n",
      "Epoch [348/500], Step [17400/25000], Train Loss: 0.3735, Valid Loss: 0.4248\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [349/500], Step [17425/25000], Train Loss: 0.3913, Valid Loss: 0.4546\n",
      "Epoch [349/500], Step [17450/25000], Train Loss: 0.3691, Valid Loss: 0.4248\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [350/500], Step [17475/25000], Train Loss: 0.3730, Valid Loss: 0.4472\n",
      "Epoch [350/500], Step [17500/25000], Train Loss: 0.3866, Valid Loss: 0.4300\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [351/500], Step [17525/25000], Train Loss: 0.3813, Valid Loss: 0.4308\n",
      "Epoch [351/500], Step [17550/25000], Train Loss: 0.3676, Valid Loss: 0.4355\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [352/500], Step [17575/25000], Train Loss: 0.3821, Valid Loss: 0.4351\n",
      "Epoch [352/500], Step [17600/25000], Train Loss: 0.3754, Valid Loss: 0.4342\n",
      "Epoch Accuracy: 0.935361216730038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [353/500], Step [17625/25000], Train Loss: 0.3924, Valid Loss: 0.4359\n",
      "Epoch [353/500], Step [17650/25000], Train Loss: 0.3629, Valid Loss: 0.4400\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [354/500], Step [17675/25000], Train Loss: 0.3663, Valid Loss: 0.4517\n",
      "Epoch [354/500], Step [17700/25000], Train Loss: 0.3829, Valid Loss: 0.4443\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [355/500], Step [17725/25000], Train Loss: 0.3847, Valid Loss: 0.4280\n",
      "Epoch [355/500], Step [17750/25000], Train Loss: 0.3723, Valid Loss: 0.4382\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [356/500], Step [17775/25000], Train Loss: 0.3751, Valid Loss: 0.4463\n",
      "Epoch [356/500], Step [17800/25000], Train Loss: 0.3830, Valid Loss: 0.4288\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [357/500], Step [17825/25000], Train Loss: 0.3799, Valid Loss: 0.4491\n",
      "Epoch [357/500], Step [17850/25000], Train Loss: 0.3764, Valid Loss: 0.4391\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [358/500], Step [17875/25000], Train Loss: 0.3786, Valid Loss: 0.4448\n",
      "Epoch [358/500], Step [17900/25000], Train Loss: 0.3713, Valid Loss: 0.4306\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [359/500], Step [17925/25000], Train Loss: 0.3900, Valid Loss: 0.4416\n",
      "Epoch [359/500], Step [17950/25000], Train Loss: 0.3678, Valid Loss: 0.4343\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [360/500], Step [17975/25000], Train Loss: 0.3865, Valid Loss: 0.4332\n",
      "Epoch [360/500], Step [18000/25000], Train Loss: 0.3764, Valid Loss: 0.4425\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [361/500], Step [18025/25000], Train Loss: 0.3717, Valid Loss: 0.4492\n",
      "Epoch [361/500], Step [18050/25000], Train Loss: 0.3865, Valid Loss: 0.4335\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [362/500], Step [18075/25000], Train Loss: 0.3767, Valid Loss: 0.4372\n",
      "Epoch [362/500], Step [18100/25000], Train Loss: 0.3746, Valid Loss: 0.4299\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [363/500], Step [18125/25000], Train Loss: 0.3792, Valid Loss: 0.4421\n",
      "Epoch [363/500], Step [18150/25000], Train Loss: 0.3749, Valid Loss: 0.4339\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [364/500], Step [18175/25000], Train Loss: 0.3722, Valid Loss: 0.4338\n",
      "Epoch [364/500], Step [18200/25000], Train Loss: 0.3790, Valid Loss: 0.4463\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [365/500], Step [18225/25000], Train Loss: 0.3724, Valid Loss: 0.4277\n",
      "Epoch [365/500], Step [18250/25000], Train Loss: 0.3874, Valid Loss: 0.4458\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [366/500], Step [18275/25000], Train Loss: 0.3718, Valid Loss: 0.4334\n",
      "Epoch [366/500], Step [18300/25000], Train Loss: 0.3871, Valid Loss: 0.4443\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [367/500], Step [18325/25000], Train Loss: 0.3837, Valid Loss: 0.4314\n",
      "Epoch [367/500], Step [18350/25000], Train Loss: 0.3757, Valid Loss: 0.4221\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [368/500], Step [18375/25000], Train Loss: 0.3779, Valid Loss: 0.4467\n",
      "Epoch [368/500], Step [18400/25000], Train Loss: 0.3726, Valid Loss: 0.4304\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [369/500], Step [18425/25000], Train Loss: 0.3761, Valid Loss: 0.4162\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch [369/500], Step [18450/25000], Train Loss: 0.3859, Valid Loss: 0.4342\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [370/500], Step [18475/25000], Train Loss: 0.3623, Valid Loss: 0.4270\n",
      "Epoch [370/500], Step [18500/25000], Train Loss: 0.3879, Valid Loss: 0.4364\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [371/500], Step [18525/25000], Train Loss: 0.3825, Valid Loss: 0.4329\n",
      "Epoch [371/500], Step [18550/25000], Train Loss: 0.3704, Valid Loss: 0.4295\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [372/500], Step [18575/25000], Train Loss: 0.3704, Valid Loss: 0.4444\n",
      "Epoch [372/500], Step [18600/25000], Train Loss: 0.3832, Valid Loss: 0.4356\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [373/500], Step [18625/25000], Train Loss: 0.3748, Valid Loss: 0.4385\n",
      "Epoch [373/500], Step [18650/25000], Train Loss: 0.3805, Valid Loss: 0.4480\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [374/500], Step [18675/25000], Train Loss: 0.3802, Valid Loss: 0.4278\n",
      "Epoch [374/500], Step [18700/25000], Train Loss: 0.3771, Valid Loss: 0.4326\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [375/500], Step [18725/25000], Train Loss: 0.3891, Valid Loss: 0.4525\n",
      "Epoch [375/500], Step [18750/25000], Train Loss: 0.3697, Valid Loss: 0.4419\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [376/500], Step [18775/25000], Train Loss: 0.3662, Valid Loss: 0.4554\n",
      "Epoch [376/500], Step [18800/25000], Train Loss: 0.3843, Valid Loss: 0.4288\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [377/500], Step [18825/25000], Train Loss: 0.3865, Valid Loss: 0.4413\n",
      "Epoch [377/500], Step [18850/25000], Train Loss: 0.3663, Valid Loss: 0.4413\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [378/500], Step [18875/25000], Train Loss: 0.3753, Valid Loss: 0.4407\n",
      "Epoch [378/500], Step [18900/25000], Train Loss: 0.3784, Valid Loss: 0.4466\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [379/500], Step [18925/25000], Train Loss: 0.3786, Valid Loss: 0.4589\n",
      "Epoch [379/500], Step [18950/25000], Train Loss: 0.3838, Valid Loss: 0.4442\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [380/500], Step [18975/25000], Train Loss: 0.3799, Valid Loss: 0.4438\n",
      "Epoch [380/500], Step [19000/25000], Train Loss: 0.3698, Valid Loss: 0.4421\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [381/500], Step [19025/25000], Train Loss: 0.3560, Valid Loss: 0.4414\n",
      "Epoch [381/500], Step [19050/25000], Train Loss: 0.3971, Valid Loss: 0.4361\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [382/500], Step [19075/25000], Train Loss: 0.3823, Valid Loss: 0.4409\n",
      "Epoch [382/500], Step [19100/25000], Train Loss: 0.3673, Valid Loss: 0.4362\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [383/500], Step [19125/25000], Train Loss: 0.3668, Valid Loss: 0.4363\n",
      "Epoch [383/500], Step [19150/25000], Train Loss: 0.3855, Valid Loss: 0.4369\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [384/500], Step [19175/25000], Train Loss: 0.3769, Valid Loss: 0.4254\n",
      "Epoch [384/500], Step [19200/25000], Train Loss: 0.3754, Valid Loss: 0.4392\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [385/500], Step [19225/25000], Train Loss: 0.3772, Valid Loss: 0.4398\n",
      "Epoch [385/500], Step [19250/25000], Train Loss: 0.3731, Valid Loss: 0.4461\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [386/500], Step [19275/25000], Train Loss: 0.3756, Valid Loss: 0.4325\n",
      "Epoch [386/500], Step [19300/25000], Train Loss: 0.3763, Valid Loss: 0.4329\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [387/500], Step [19325/25000], Train Loss: 0.3722, Valid Loss: 0.4262\n",
      "Epoch [387/500], Step [19350/25000], Train Loss: 0.3745, Valid Loss: 0.4405\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [388/500], Step [19375/25000], Train Loss: 0.3733, Valid Loss: 0.4421\n",
      "Epoch [388/500], Step [19400/25000], Train Loss: 0.3784, Valid Loss: 0.4313\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [389/500], Step [19425/25000], Train Loss: 0.3891, Valid Loss: 0.4340\n",
      "Epoch [389/500], Step [19450/25000], Train Loss: 0.3605, Valid Loss: 0.4416\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [390/500], Step [19475/25000], Train Loss: 0.3696, Valid Loss: 0.4311\n",
      "Epoch [390/500], Step [19500/25000], Train Loss: 0.3779, Valid Loss: 0.4421\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [391/500], Step [19525/25000], Train Loss: 0.3768, Valid Loss: 0.4377\n",
      "Epoch [391/500], Step [19550/25000], Train Loss: 0.3737, Valid Loss: 0.4271\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [392/500], Step [19575/25000], Train Loss: 0.3791, Valid Loss: 0.4401\n",
      "Epoch [392/500], Step [19600/25000], Train Loss: 0.3722, Valid Loss: 0.4220\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [393/500], Step [19625/25000], Train Loss: 0.3838, Valid Loss: 0.4541\n",
      "Epoch [393/500], Step [19650/25000], Train Loss: 0.3658, Valid Loss: 0.4384\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [394/500], Step [19675/25000], Train Loss: 0.3749, Valid Loss: 0.4306\n",
      "Epoch [394/500], Step [19700/25000], Train Loss: 0.3732, Valid Loss: 0.4548\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [395/500], Step [19725/25000], Train Loss: 0.3801, Valid Loss: 0.4241\n",
      "Epoch [395/500], Step [19750/25000], Train Loss: 0.3703, Valid Loss: 0.4369\n",
      "Epoch Accuracy: 0.9429657794676806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [396/500], Step [19775/25000], Train Loss: 0.3767, Valid Loss: 0.4377\n",
      "Epoch [396/500], Step [19800/25000], Train Loss: 0.3768, Valid Loss: 0.4337\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [397/500], Step [19825/25000], Train Loss: 0.3885, Valid Loss: 0.4334\n",
      "Epoch [397/500], Step [19850/25000], Train Loss: 0.3623, Valid Loss: 0.4403\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [398/500], Step [19875/25000], Train Loss: 0.3706, Valid Loss: 0.4280\n",
      "Epoch [398/500], Step [19900/25000], Train Loss: 0.3768, Valid Loss: 0.4368\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [399/500], Step [19925/25000], Train Loss: 0.3791, Valid Loss: 0.4332\n",
      "Epoch [399/500], Step [19950/25000], Train Loss: 0.3691, Valid Loss: 0.4388\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [400/500], Step [19975/25000], Train Loss: 0.3730, Valid Loss: 0.4363\n",
      "Epoch [400/500], Step [20000/25000], Train Loss: 0.3796, Valid Loss: 0.4417\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [401/500], Step [20025/25000], Train Loss: 0.3767, Valid Loss: 0.4334\n",
      "Epoch [401/500], Step [20050/25000], Train Loss: 0.3732, Valid Loss: 0.4378\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [402/500], Step [20075/25000], Train Loss: 0.3606, Valid Loss: 0.4424\n",
      "Epoch [402/500], Step [20100/25000], Train Loss: 0.3886, Valid Loss: 0.4339\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [403/500], Step [20125/25000], Train Loss: 0.3800, Valid Loss: 0.4507\n",
      "Epoch [403/500], Step [20150/25000], Train Loss: 0.3684, Valid Loss: 0.4360\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [404/500], Step [20175/25000], Train Loss: 0.3777, Valid Loss: 0.4370\n",
      "Epoch [404/500], Step [20200/25000], Train Loss: 0.3730, Valid Loss: 0.4392\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [405/500], Step [20225/25000], Train Loss: 0.3807, Valid Loss: 0.4298\n",
      "Epoch [405/500], Step [20250/25000], Train Loss: 0.3662, Valid Loss: 0.4415\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [406/500], Step [20275/25000], Train Loss: 0.3680, Valid Loss: 0.4275\n",
      "Epoch [406/500], Step [20300/25000], Train Loss: 0.3845, Valid Loss: 0.4411\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [407/500], Step [20325/25000], Train Loss: 0.3702, Valid Loss: 0.4336\n",
      "Epoch [407/500], Step [20350/25000], Train Loss: 0.3764, Valid Loss: 0.4448\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [408/500], Step [20375/25000], Train Loss: 0.3720, Valid Loss: 0.4429\n",
      "Epoch [408/500], Step [20400/25000], Train Loss: 0.3721, Valid Loss: 0.4323\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [409/500], Step [20425/25000], Train Loss: 0.3705, Valid Loss: 0.4266\n",
      "Epoch [409/500], Step [20450/25000], Train Loss: 0.3818, Valid Loss: 0.4199\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [410/500], Step [20475/25000], Train Loss: 0.3785, Valid Loss: 0.4356\n",
      "Epoch [410/500], Step [20500/25000], Train Loss: 0.3678, Valid Loss: 0.4377\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [411/500], Step [20525/25000], Train Loss: 0.3643, Valid Loss: 0.4501\n",
      "Epoch [411/500], Step [20550/25000], Train Loss: 0.3765, Valid Loss: 0.4320\n",
      "Epoch Accuracy: 0.9474017743979721\n",
      "Epoch [412/500], Step [20575/25000], Train Loss: 0.3753, Valid Loss: 0.4359\n",
      "Epoch [412/500], Step [20600/25000], Train Loss: 0.3734, Valid Loss: 0.4305\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [413/500], Step [20625/25000], Train Loss: 0.3792, Valid Loss: 0.4484\n",
      "Epoch [413/500], Step [20650/25000], Train Loss: 0.3747, Valid Loss: 0.4217\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [414/500], Step [20675/25000], Train Loss: 0.3732, Valid Loss: 0.4293\n",
      "Epoch [414/500], Step [20700/25000], Train Loss: 0.3702, Valid Loss: 0.4463\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [415/500], Step [20725/25000], Train Loss: 0.3638, Valid Loss: 0.4383\n",
      "Epoch [415/500], Step [20750/25000], Train Loss: 0.3838, Valid Loss: 0.4454\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [416/500], Step [20775/25000], Train Loss: 0.3838, Valid Loss: 0.4302\n",
      "Epoch [416/500], Step [20800/25000], Train Loss: 0.3622, Valid Loss: 0.4397\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [417/500], Step [20825/25000], Train Loss: 0.3734, Valid Loss: 0.4435\n",
      "Epoch [417/500], Step [20850/25000], Train Loss: 0.3754, Valid Loss: 0.4289\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [418/500], Step [20875/25000], Train Loss: 0.3869, Valid Loss: 0.4414\n",
      "Epoch [418/500], Step [20900/25000], Train Loss: 0.3599, Valid Loss: 0.4396\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [419/500], Step [20925/25000], Train Loss: 0.3660, Valid Loss: 0.4317\n",
      "Epoch [419/500], Step [20950/25000], Train Loss: 0.3810, Valid Loss: 0.4314\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [420/500], Step [20975/25000], Train Loss: 0.3818, Valid Loss: 0.4327\n",
      "Epoch [420/500], Step [21000/25000], Train Loss: 0.3629, Valid Loss: 0.4353\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [421/500], Step [21025/25000], Train Loss: 0.3620, Valid Loss: 0.4366\n",
      "Epoch [421/500], Step [21050/25000], Train Loss: 0.3850, Valid Loss: 0.4255\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [422/500], Step [21075/25000], Train Loss: 0.3813, Valid Loss: 0.4337\n",
      "Epoch [422/500], Step [21100/25000], Train Loss: 0.3751, Valid Loss: 0.4591\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [423/500], Step [21125/25000], Train Loss: 0.3736, Valid Loss: 0.4331\n",
      "Epoch [423/500], Step [21150/25000], Train Loss: 0.3764, Valid Loss: 0.4411\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [424/500], Step [21175/25000], Train Loss: 0.3643, Valid Loss: 0.4302\n",
      "Epoch [424/500], Step [21200/25000], Train Loss: 0.3827, Valid Loss: 0.4370\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [425/500], Step [21225/25000], Train Loss: 0.3735, Valid Loss: 0.4411\n",
      "Epoch [425/500], Step [21250/25000], Train Loss: 0.3763, Valid Loss: 0.4332\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [426/500], Step [21275/25000], Train Loss: 0.3811, Valid Loss: 0.4325\n",
      "Epoch [426/500], Step [21300/25000], Train Loss: 0.3669, Valid Loss: 0.4289\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [427/500], Step [21325/25000], Train Loss: 0.3736, Valid Loss: 0.4414\n",
      "Epoch [427/500], Step [21350/25000], Train Loss: 0.3794, Valid Loss: 0.4436\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [428/500], Step [21375/25000], Train Loss: 0.3653, Valid Loss: 0.4329\n",
      "Epoch [428/500], Step [21400/25000], Train Loss: 0.3820, Valid Loss: 0.4322\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [429/500], Step [21425/25000], Train Loss: 0.3833, Valid Loss: 0.4325\n",
      "Epoch [429/500], Step [21450/25000], Train Loss: 0.3696, Valid Loss: 0.4403\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [430/500], Step [21475/25000], Train Loss: 0.3663, Valid Loss: 0.4316\n",
      "Epoch [430/500], Step [21500/25000], Train Loss: 0.3827, Valid Loss: 0.4403\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [431/500], Step [21525/25000], Train Loss: 0.3771, Valid Loss: 0.4324\n",
      "Epoch [431/500], Step [21550/25000], Train Loss: 0.3734, Valid Loss: 0.4398\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [432/500], Step [21575/25000], Train Loss: 0.3783, Valid Loss: 0.4386\n",
      "Epoch [432/500], Step [21600/25000], Train Loss: 0.3723, Valid Loss: 0.4344\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [433/500], Step [21625/25000], Train Loss: 0.3751, Valid Loss: 0.4378\n",
      "Epoch [433/500], Step [21650/25000], Train Loss: 0.3710, Valid Loss: 0.4378\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [434/500], Step [21675/25000], Train Loss: 0.3712, Valid Loss: 0.4383\n",
      "Epoch [434/500], Step [21700/25000], Train Loss: 0.3761, Valid Loss: 0.4427\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [435/500], Step [21725/25000], Train Loss: 0.3692, Valid Loss: 0.4356\n",
      "Epoch [435/500], Step [21750/25000], Train Loss: 0.3740, Valid Loss: 0.4338\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [436/500], Step [21775/25000], Train Loss: 0.3813, Valid Loss: 0.4388\n",
      "Epoch [436/500], Step [21800/25000], Train Loss: 0.3650, Valid Loss: 0.4294\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [437/500], Step [21825/25000], Train Loss: 0.3678, Valid Loss: 0.4321\n",
      "Epoch [437/500], Step [21850/25000], Train Loss: 0.3782, Valid Loss: 0.4391\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [438/500], Step [21875/25000], Train Loss: 0.3818, Valid Loss: 0.4380\n",
      "Epoch [438/500], Step [21900/25000], Train Loss: 0.3652, Valid Loss: 0.4378\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [439/500], Step [21925/25000], Train Loss: 0.3758, Valid Loss: 0.4260\n",
      "Epoch [439/500], Step [21950/25000], Train Loss: 0.3696, Valid Loss: 0.4432\n",
      "Epoch Accuracy: 0.94106463878327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [440/500], Step [21975/25000], Train Loss: 0.3757, Valid Loss: 0.4369\n",
      "Epoch [440/500], Step [22000/25000], Train Loss: 0.3713, Valid Loss: 0.4293\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [441/500], Step [22025/25000], Train Loss: 0.3678, Valid Loss: 0.4303\n",
      "Epoch [441/500], Step [22050/25000], Train Loss: 0.3838, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [442/500], Step [22075/25000], Train Loss: 0.3797, Valid Loss: 0.4443\n",
      "Epoch [442/500], Step [22100/25000], Train Loss: 0.3652, Valid Loss: 0.4326\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [443/500], Step [22125/25000], Train Loss: 0.3679, Valid Loss: 0.4347\n",
      "Epoch [443/500], Step [22150/25000], Train Loss: 0.3752, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [444/500], Step [22175/25000], Train Loss: 0.3676, Valid Loss: 0.4336\n",
      "Epoch [444/500], Step [22200/25000], Train Loss: 0.3777, Valid Loss: 0.4250\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [445/500], Step [22225/25000], Train Loss: 0.3741, Valid Loss: 0.4351\n",
      "Epoch [445/500], Step [22250/25000], Train Loss: 0.3780, Valid Loss: 0.4417\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [446/500], Step [22275/25000], Train Loss: 0.3684, Valid Loss: 0.4497\n",
      "Epoch [446/500], Step [22300/25000], Train Loss: 0.3848, Valid Loss: 0.4349\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [447/500], Step [22325/25000], Train Loss: 0.3716, Valid Loss: 0.4338\n",
      "Epoch [447/500], Step [22350/25000], Train Loss: 0.3762, Valid Loss: 0.4238\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [448/500], Step [22375/25000], Train Loss: 0.3725, Valid Loss: 0.4331\n",
      "Epoch [448/500], Step [22400/25000], Train Loss: 0.3705, Valid Loss: 0.4227\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [449/500], Step [22425/25000], Train Loss: 0.3686, Valid Loss: 0.4469\n",
      "Epoch [449/500], Step [22450/25000], Train Loss: 0.3844, Valid Loss: 0.4277\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [450/500], Step [22475/25000], Train Loss: 0.3776, Valid Loss: 0.4283\n",
      "Epoch [450/500], Step [22500/25000], Train Loss: 0.3690, Valid Loss: 0.4292\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [451/500], Step [22525/25000], Train Loss: 0.3802, Valid Loss: 0.4519\n",
      "Epoch [451/500], Step [22550/25000], Train Loss: 0.3792, Valid Loss: 0.4302\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [452/500], Step [22575/25000], Train Loss: 0.3659, Valid Loss: 0.4275\n",
      "Epoch [452/500], Step [22600/25000], Train Loss: 0.3761, Valid Loss: 0.4417\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [453/500], Step [22625/25000], Train Loss: 0.3623, Valid Loss: 0.4356\n",
      "Epoch [453/500], Step [22650/25000], Train Loss: 0.3856, Valid Loss: 0.4192\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [454/500], Step [22675/25000], Train Loss: 0.3752, Valid Loss: 0.4309\n",
      "Epoch [454/500], Step [22700/25000], Train Loss: 0.3703, Valid Loss: 0.4392\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [455/500], Step [22725/25000], Train Loss: 0.3674, Valid Loss: 0.4433\n",
      "Epoch [455/500], Step [22750/25000], Train Loss: 0.3801, Valid Loss: 0.4290\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [456/500], Step [22775/25000], Train Loss: 0.3659, Valid Loss: 0.4397\n",
      "Epoch [456/500], Step [22800/25000], Train Loss: 0.3764, Valid Loss: 0.4351\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [457/500], Step [22825/25000], Train Loss: 0.3776, Valid Loss: 0.4318\n",
      "Epoch [457/500], Step [22850/25000], Train Loss: 0.3652, Valid Loss: 0.4384\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [458/500], Step [22875/25000], Train Loss: 0.3675, Valid Loss: 0.4324\n",
      "Epoch [458/500], Step [22900/25000], Train Loss: 0.3753, Valid Loss: 0.4284\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [459/500], Step [22925/25000], Train Loss: 0.3736, Valid Loss: 0.4355\n",
      "Epoch [459/500], Step [22950/25000], Train Loss: 0.3693, Valid Loss: 0.4357\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [460/500], Step [22975/25000], Train Loss: 0.3652, Valid Loss: 0.4404\n",
      "Epoch [460/500], Step [23000/25000], Train Loss: 0.3788, Valid Loss: 0.4365\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [461/500], Step [23025/25000], Train Loss: 0.3781, Valid Loss: 0.4378\n",
      "Epoch [461/500], Step [23050/25000], Train Loss: 0.3636, Valid Loss: 0.4318\n",
      "Epoch Accuracy: 0.9461343472750317\n",
      "Epoch [462/500], Step [23075/25000], Train Loss: 0.3715, Valid Loss: 0.4244\n",
      "Epoch [462/500], Step [23100/25000], Train Loss: 0.3761, Valid Loss: 0.4360\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [463/500], Step [23125/25000], Train Loss: 0.3793, Valid Loss: 0.4318\n",
      "Epoch [463/500], Step [23150/25000], Train Loss: 0.3642, Valid Loss: 0.4361\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [464/500], Step [23175/25000], Train Loss: 0.3697, Valid Loss: 0.4316\n",
      "Epoch [464/500], Step [23200/25000], Train Loss: 0.3734, Valid Loss: 0.4410\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [465/500], Step [23225/25000], Train Loss: 0.3618, Valid Loss: 0.4446\n",
      "Epoch [465/500], Step [23250/25000], Train Loss: 0.3833, Valid Loss: 0.4341\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [466/500], Step [23275/25000], Train Loss: 0.3720, Valid Loss: 0.4403\n",
      "Epoch [466/500], Step [23300/25000], Train Loss: 0.3675, Valid Loss: 0.4401\n",
      "Epoch Accuracy: 0.9461343472750317\n",
      "Epoch [467/500], Step [23325/25000], Train Loss: 0.3689, Valid Loss: 0.4324\n",
      "Epoch [467/500], Step [23350/25000], Train Loss: 0.3791, Valid Loss: 0.4372\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [468/500], Step [23375/25000], Train Loss: 0.3724, Valid Loss: 0.4323\n",
      "Epoch [468/500], Step [23400/25000], Train Loss: 0.3642, Valid Loss: 0.4271\n",
      "Epoch Accuracy: 0.9486692015209125\n",
      "Epoch [469/500], Step [23425/25000], Train Loss: 0.3658, Valid Loss: 0.4390\n",
      "Epoch [469/500], Step [23450/25000], Train Loss: 0.3748, Valid Loss: 0.4376\n",
      "Epoch Accuracy: 0.9480354879594424\n",
      "Epoch [470/500], Step [23475/25000], Train Loss: 0.3736, Valid Loss: 0.4444\n",
      "Epoch [470/500], Step [23500/25000], Train Loss: 0.3681, Valid Loss: 0.4356\n",
      "Epoch Accuracy: 0.9461343472750317\n",
      "Epoch [471/500], Step [23525/25000], Train Loss: 0.3827, Valid Loss: 0.4325\n",
      "Epoch [471/500], Step [23550/25000], Train Loss: 0.3643, Valid Loss: 0.4358\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [472/500], Step [23575/25000], Train Loss: 0.3751, Valid Loss: 0.4372\n",
      "Epoch [472/500], Step [23600/25000], Train Loss: 0.3653, Valid Loss: 0.4304\n",
      "Epoch Accuracy: 0.9461343472750317\n",
      "Epoch [473/500], Step [23625/25000], Train Loss: 0.3665, Valid Loss: 0.4385\n",
      "Epoch [473/500], Step [23650/25000], Train Loss: 0.3772, Valid Loss: 0.4298\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [474/500], Step [23675/25000], Train Loss: 0.3632, Valid Loss: 0.4466\n",
      "Epoch [474/500], Step [23700/25000], Train Loss: 0.3822, Valid Loss: 0.4352\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [475/500], Step [23725/25000], Train Loss: 0.3712, Valid Loss: 0.4357\n",
      "Epoch [475/500], Step [23750/25000], Train Loss: 0.3722, Valid Loss: 0.4315\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [476/500], Step [23775/25000], Train Loss: 0.3776, Valid Loss: 0.4323\n",
      "Epoch [476/500], Step [23800/25000], Train Loss: 0.3707, Valid Loss: 0.4451\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [477/500], Step [23825/25000], Train Loss: 0.3609, Valid Loss: 0.4305\n",
      "Epoch [477/500], Step [23850/25000], Train Loss: 0.3854, Valid Loss: 0.4305\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [478/500], Step [23875/25000], Train Loss: 0.3737, Valid Loss: 0.4364\n",
      "Epoch [478/500], Step [23900/25000], Train Loss: 0.3727, Valid Loss: 0.4384\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [479/500], Step [23925/25000], Train Loss: 0.3715, Valid Loss: 0.4311\n",
      "Epoch [479/500], Step [23950/25000], Train Loss: 0.3732, Valid Loss: 0.4366\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [480/500], Step [23975/25000], Train Loss: 0.3613, Valid Loss: 0.4364\n",
      "Epoch [480/500], Step [24000/25000], Train Loss: 0.3834, Valid Loss: 0.4341\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [481/500], Step [24025/25000], Train Loss: 0.3663, Valid Loss: 0.4287\n",
      "Epoch [481/500], Step [24050/25000], Train Loss: 0.3822, Valid Loss: 0.4472\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [482/500], Step [24075/25000], Train Loss: 0.3611, Valid Loss: 0.4356\n",
      "Epoch [482/500], Step [24100/25000], Train Loss: 0.3787, Valid Loss: 0.4310\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [483/500], Step [24125/25000], Train Loss: 0.3816, Valid Loss: 0.4301\n",
      "Epoch [483/500], Step [24150/25000], Train Loss: 0.3701, Valid Loss: 0.4420\n",
      "Epoch Accuracy: 0.9385297845373891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [484/500], Step [24175/25000], Train Loss: 0.3701, Valid Loss: 0.4376\n",
      "Epoch [484/500], Step [24200/25000], Train Loss: 0.3687, Valid Loss: 0.4406\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [485/500], Step [24225/25000], Train Loss: 0.3758, Valid Loss: 0.4283\n",
      "Epoch [485/500], Step [24250/25000], Train Loss: 0.3712, Valid Loss: 0.4440\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [486/500], Step [24275/25000], Train Loss: 0.3768, Valid Loss: 0.4319\n",
      "Epoch [486/500], Step [24300/25000], Train Loss: 0.3623, Valid Loss: 0.4407\n",
      "Epoch Accuracy: 0.9474017743979721\n",
      "Epoch [487/500], Step [24325/25000], Train Loss: 0.3777, Valid Loss: 0.4309\n",
      "Epoch [487/500], Step [24350/25000], Train Loss: 0.3650, Valid Loss: 0.4390\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [488/500], Step [24375/25000], Train Loss: 0.3671, Valid Loss: 0.4407\n",
      "Epoch [488/500], Step [24400/25000], Train Loss: 0.3783, Valid Loss: 0.4419\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [489/500], Step [24425/25000], Train Loss: 0.3800, Valid Loss: 0.4336\n",
      "Epoch [489/500], Step [24450/25000], Train Loss: 0.3609, Valid Loss: 0.4311\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [490/500], Step [24475/25000], Train Loss: 0.3635, Valid Loss: 0.4316\n",
      "Epoch [490/500], Step [24500/25000], Train Loss: 0.3843, Valid Loss: 0.4326\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [491/500], Step [24525/25000], Train Loss: 0.3647, Valid Loss: 0.4295\n",
      "Epoch [491/500], Step [24550/25000], Train Loss: 0.3771, Valid Loss: 0.4357\n",
      "Epoch Accuracy: 0.9474017743979721\n",
      "Epoch [492/500], Step [24575/25000], Train Loss: 0.3646, Valid Loss: 0.4405\n",
      "Epoch [492/500], Step [24600/25000], Train Loss: 0.3774, Valid Loss: 0.4277\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [493/500], Step [24625/25000], Train Loss: 0.3744, Valid Loss: 0.4319\n",
      "Epoch [493/500], Step [24650/25000], Train Loss: 0.3691, Valid Loss: 0.4279\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [494/500], Step [24675/25000], Train Loss: 0.3696, Valid Loss: 0.4474\n",
      "Epoch [494/500], Step [24700/25000], Train Loss: 0.3724, Valid Loss: 0.4336\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [495/500], Step [24725/25000], Train Loss: 0.3628, Valid Loss: 0.4362\n",
      "Epoch [495/500], Step [24750/25000], Train Loss: 0.3796, Valid Loss: 0.4418\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [496/500], Step [24775/25000], Train Loss: 0.3818, Valid Loss: 0.4314\n",
      "Epoch [496/500], Step [24800/25000], Train Loss: 0.3566, Valid Loss: 0.4312\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [497/500], Step [24825/25000], Train Loss: 0.3702, Valid Loss: 0.4321\n",
      "Epoch [497/500], Step [24850/25000], Train Loss: 0.3687, Valid Loss: 0.4346\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [498/500], Step [24875/25000], Train Loss: 0.3763, Valid Loss: 0.4184\n",
      "Epoch [498/500], Step [24900/25000], Train Loss: 0.3674, Valid Loss: 0.4336\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [499/500], Step [24925/25000], Train Loss: 0.3734, Valid Loss: 0.4309\n",
      "Epoch [499/500], Step [24950/25000], Train Loss: 0.3697, Valid Loss: 0.4348\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [500/500], Step [24975/25000], Train Loss: 0.3692, Valid Loss: 0.4378\n",
      "Epoch [500/500], Step [25000/25000], Train Loss: 0.3735, Valid Loss: 0.4451\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.CrossEntropyLoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 10,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total = 0\n",
    "        total_correct = 0\n",
    "        for (labels, (notes, notes_len)), _ in (train_loader):   \n",
    "            labels = labels.to(device)\n",
    "            notes = notes.to(device)\n",
    "            notes_len = notes_len.cpu()\n",
    "            output = model(notes.long())\n",
    "            loss = criterion(output, labels.long())\n",
    "            #loss = criterion(output.view(-1,1),labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            labels_max = labels.detach().cpu()\n",
    "            output_max = np.argmax((output.detach().cpu()),axis=1)\n",
    "            for i in range(len(labels_max)):\n",
    "                total+=1\n",
    "                if labels_max[i] ==  output_max[i]:\n",
    "                    total_correct += 1\n",
    "            accuracy = accuracy_score(labels_max, output_max)\n",
    "            \n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                  # validation loop\n",
    "                    for (labels, (notes, notes_len)), _ in (valid_loader):        \n",
    "                        labels = labels.to(device)\n",
    "                        notes = notes.to(device)\n",
    "                        notes_len = notes_len.cpu()\n",
    "                        output = model(notes.long())\n",
    "                        loss = criterion(output, labels.long())\n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
    "                    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "        print(\"Epoch Accuracy: {}\".format(total_correct/total))\n",
    "    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')\n",
    "\n",
    "\n",
    "model = TransformerModel(ntokens,emsize,nhead,d_hid,nlayers,dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "train(model=model, optimizer=optimizer, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcbc3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe489733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "500\n",
      "500\n",
      "500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "epoch_train = []\n",
    "epoch_valid = []\n",
    "epochs = []\n",
    "\n",
    "for x in range(0, len(train_loss_list), 2):\n",
    "    epoch_train.append(sum(train_loss_list[x:x+2])/len(train_loss_list[x:x+2]))\n",
    "print(len(epoch_train))\n",
    "\n",
    "for x in range(0, len(valid_loss_list), 2):\n",
    "    epoch_valid.append(sum(valid_loss_list[x:x+2])/len(valid_loss_list[x:x+2]))\n",
    "print(len(epoch_valid))\n",
    "\n",
    "for x in range(500):\n",
    "    epochs.append(x)\n",
    "print(len(epochs))\n",
    "\n",
    "plt.plot(epochs, epoch_train, label='Train')\n",
    "plt.plot(epochs, epoch_valid, label='Valid')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"Transformer 500 epochs.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2773b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500, 525, 550, 575, 600, 625, 650, 675, 700, 725, 750, 775, 800, 825, 850, 875, 900, 925, 950, 975, 1000, 1025, 1050, 1075, 1100, 1125, 1150, 1175, 1200, 1225, 1250, 1275, 1300, 1325, 1350, 1375, 1400, 1425, 1450, 1475, 1500, 1525, 1550, 1575, 1600, 1625, 1650, 1675, 1700, 1725, 1750, 1775, 1800, 1825, 1850, 1875, 1900, 1925, 1950, 1975, 2000, 2025, 2050, 2075, 2100, 2125, 2150, 2175, 2200, 2225, 2250, 2275, 2300, 2325, 2350, 2375, 2400, 2425, 2450, 2475, 2500, 2525, 2550, 2575, 2600, 2625, 2650, 2675, 2700, 2725, 2750, 2775, 2800, 2825, 2850, 2875, 2900, 2925, 2950, 2975, 3000, 3025, 3050, 3075, 3100, 3125, 3150, 3175, 3200, 3225, 3250, 3275, 3300, 3325, 3350, 3375, 3400, 3425, 3450, 3475, 3500, 3525, 3550, 3575, 3600, 3625, 3650, 3675, 3700, 3725, 3750, 3775, 3800, 3825, 3850, 3875, 3900, 3925, 3950, 3975, 4000, 4025, 4050, 4075, 4100, 4125, 4150, 4175, 4200, 4225, 4250, 4275, 4300, 4325, 4350, 4375, 4400, 4425, 4450, 4475, 4500, 4525, 4550, 4575, 4600, 4625, 4650, 4675, 4700, 4725, 4750, 4775, 4800, 4825, 4850, 4875, 4900, 4925, 4950, 4975, 5000]\n"
     ]
    }
   ],
   "source": [
    "print(global_steps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfce53a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "#plt.savefig(\"Transformer 200 epochs.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14b3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "974bdcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7869    0.8571    0.8205       112\n",
      "           0     0.9252    0.8839    0.9041       224\n",
      "\n",
      "    accuracy                         0.8750       336\n",
      "   macro avg     0.8561    0.8705    0.8623       336\n",
      "weighted avg     0.8791    0.8750    0.8762       336\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(model, test_loader, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (labels, (notes, notes_len)), _ in test_loader:           \n",
    "            labels = labels.to(device)\n",
    "            notes = notes.to(device)\n",
    "            notes_len = notes_len.cpu()\n",
    "            output = model(notes.long())\n",
    "\n",
    "            output = np.argmax(output.cpu().detach(), axis=1)\n",
    "            y_pred.extend(output.tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['INSTRUMENTAL SOLO', 'VOCAL'])\n",
    "    ax.yaxis.set_ticklabels(['INSTRUMENTAL SOLO', 'VOCAL'])\n",
    "    \n",
    "    \n",
    "best_model = TransformerModel(ntokens,emsize,nhead,d_hid,nlayers,dropout).to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)\n",
    "evaluate(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d0a62d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4123/3001074312.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhiddenlayer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchviz'"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_iter)).notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3005c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_architecture(model, test_loader, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    for (labels, (notes, notes_len)), _ in test_loader:           \n",
    "        labels = labels.to(device)\n",
    "        notes = notes.to(device)\n",
    "        notes_len = notes_len.cpu()\n",
    "        output = model(notes.long(), notes_len.long())\n",
    "        \n",
    "        \n",
    "        transforms = [# hl.transforms.Prune('Constant'),\n",
    "                      #hl.transforms.FoldDuplicates()\n",
    "                     ] # Removes Constant nodes from graph.\n",
    "\n",
    "        graph = hl.build_graph(model, (notes,notes_len), transforms=transforms)\n",
    "        graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "        print(graph)\n",
    "        graph.save('rnn_hiddenlayer', format='png')\n",
    "\n",
    "        #output = (output > threshold).int()\n",
    "        #y_pred.extend(output.tolist())\n",
    "        #y_true.extend(labels.tolist())\n",
    "        #print(dict(model.named_parameters()))\n",
    "        #make_dot(output,params=dict(model.named_parameters())).render()\n",
    "        break\n",
    "\n",
    "    \n",
    "best_model = LSTM().to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)\n",
    "print_architecture(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
