{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "022889aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dataset folder\n",
    "source_folder = \"solo_classification_REMI_dataset_unbalanced\"\n",
    "# where it saves the weights\n",
    "destination_folder = \"solo_classification_transformer_REMI_weights_unaugmented_200epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "193a1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "print(dev)\n",
    "device = torch.device(dev)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79d8407f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(tokenize=None, lower=True, include_lengths=True, batch_first=True)\n",
    "fields = [('labels', label_field), ('notes', text_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='val.csv', test='test.csv',\n",
    "                                           format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "test_iter = BucketIterator(test, batch_size=32, sort_key=lambda x: len(x.notes),\n",
    "                            device=device, sort=False, sort_within_batch=True)\n",
    "\n",
    "# Vocabulary\n",
    "\n",
    "text_field.build_vocab(train, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99a1f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(text_field.vocab)\n",
    "emsize = 200\n",
    "d_hid = 64\n",
    "nlayers = 2 \n",
    "nhead = 8\n",
    "dropout = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aa477d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4,  7, 30,  ...,  8, 63,  5],\n",
      "        [ 4,  7, 30,  ..., 14, 56, 90],\n",
      "        [ 4,  7, 30,  ..., 43,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  67,  60,   2],\n",
      "        [  4,   7,  30,  ...,  16,  30, 132],\n",
      "        [  4,   7,  30,  ...,  15,  23,   6],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  59,  88,  89],\n",
      "        [  4,   7,  58,  ...,   9,  31, 105],\n",
      "        [  4,   7,  58,  ...,  47,  69,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  12,  68,   2],\n",
      "        [  4,   7,  58,  ...,  31,  89,   1],\n",
      "        [  4,   7,  30,  ...,  48, 127,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  75,   6,   1],\n",
      "        [  4,   7,  30,  ...,  68, 119,   1],\n",
      "        [  4,   7,  30,  ...,  75,   3,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 12, 27,  3],\n",
      "        [ 4,  7, 30,  ...,  8, 62,  2],\n",
      "        [ 4,  7, 30,  ..., 48, 61,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  22,  38,  72],\n",
      "        [  4,   7,  30,  ...,  43,  49,   1],\n",
      "        [  4,   7,  30,  ...,  40, 105,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  17, 128,   3],\n",
      "        [  4,   7,  30,  ...,  41,  57,   2],\n",
      "        [  4,   7,  30,  ...,  15,  44,   6],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 40,  3],\n",
      "        [ 4,  7, 30,  ..., 10, 27, 46],\n",
      "        [ 4,  7, 30,  ..., 22, 48,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ...,  9, 29,  6],\n",
      "        [ 4,  7, 30,  ..., 57,  5,  1],\n",
      "        [ 4,  7, 30,  ..., 54,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  15,  29,   5],\n",
      "        [  4,   7,  58,  ...,  14,  35,   5],\n",
      "        [  4,   7,  30,  ...,  53,  27, 116],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  12,  23,  74],\n",
      "        [  4,   7,  30,  ...,  14,  23,   6],\n",
      "        [  4,   7,  30,  ...,  53,  55,   5],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ..., 127,   1,   1],\n",
      "        [  4,   7,  58,  ..., 180,   1,   1],\n",
      "        [  4,   7,  58,  ...,  84,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 38, 84],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  17,  62, 188],\n",
      "        [  4,   7,  58,  ...,  38, 171,   1],\n",
      "        [  4,   7,  58,  ...,  50,   3,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7, 186,  ...,   1,   1,   1],\n",
      "        [  4,   7, 186,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 15, 47, 61],\n",
      "        [ 4,  7, 30,  ...,  8, 55, 45],\n",
      "        [ 4,  7, 30,  ..., 22, 31,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 17, 70, 85],\n",
      "        [ 4,  7, 30,  ..., 14, 38,  6],\n",
      "        [ 4,  7, 30,  ..., 15, 29,  2],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ..., 32, 23, 91],\n",
      "        [ 4,  7, 30,  ..., 12, 43,  3],\n",
      "        [ 4,  7, 30,  ...,  9, 39,  5]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  17,  92, 208],\n",
      "        [  4,   7,  58,  ...,   8,  31, 205],\n",
      "        [  4,   7,  30,  ...,  12,  57, 153],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   8,  40,  61],\n",
      "        [  4,   7,  30,  ...,  59,  43, 116],\n",
      "        [  4,   7,  30,  ...,   9,  54,  90],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4, 34, 53,  ..., 12, 23, 74],\n",
      "        [ 4,  7, 58,  ..., 32, 44,  3],\n",
      "        [ 4,  7, 30,  ..., 76, 40,  5],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  32,  35,   3],\n",
      "        [  4,   7,  58,  ...,  10,  43,  96],\n",
      "        [  4,   7,  58,  ...,  24,  38, 144],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 41, 44,  2],\n",
      "        [ 4,  7, 30,  ..., 22, 31, 49],\n",
      "        [ 4,  7, 30,  ..., 24, 38,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  53,  44, 130],\n",
      "        [  4,   7,  58,  ...,  24,  23,  78],\n",
      "        [  4,   7,  30,  ...,  24,  63, 130],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  63,   3],\n",
      "        [  4,   7,  58,  ...,   9,  29, 138],\n",
      "        [  4,   7,  58,  ...,  10,  44, 127],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  53,  29,   3],\n",
      "        [  4,   7,  30,  ...,   8,  92, 119],\n",
      "        [  4,   7,  30,  ...,   9,  27, 105]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 17, 39,  6],\n",
      "        [ 4,  7, 30,  ..., 15, 43, 45],\n",
      "        [ 4,  7, 30,  ..., 22, 44,  2],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  32,  23, 118],\n",
      "        [  4,   7,  30,  ...,  41,  47, 115],\n",
      "        [  4,   7,  30,  ...,  10,  43,   3],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  10,  40,   2],\n",
      "        [  4,   7,  30,  ...,  15,  39,  45],\n",
      "        [  4,   7,  22,  ...,   8,  27, 105],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,  43,  46,   1],\n",
      "        [  4,   7,  58,  ...,  39,  46,   1],\n",
      "        [  4,   7,  30,  ...,  63, 105,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 15, 44,  2],\n",
      "        [ 4,  7, 30,  ..., 53, 38, 84],\n",
      "        [ 4,  7, 30,  ..., 15, 57,  5],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 10, 56, 84],\n",
      "        [ 4,  7, 58,  ...,  3,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  24,  50,   6],\n",
      "        [  4,   7,  30,  ...,  63,   2,   1],\n",
      "        [  4,   7,  58,  ...,  31, 105,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   9,  23, 120],\n",
      "        [  4,   7,  58,  ...,  32,  43,  46],\n",
      "        [  4,   7,  58,  ...,  35,  46,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  10,  62,   3],\n",
      "        [  4,   7,  58,  ...,   8,  31, 118],\n",
      "        [  4,   7,  30,  ...,  15,  27, 127],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,  28,  15,  ...,  22,  48,  96],\n",
      "        [  4,   7,  30,  ...,   8,  55, 153],\n",
      "        [  4,   7,  58,  ...,  54, 198,   1],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,  11,  17,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   8,  29, 103],\n",
      "        [  4,   7,  30,  ...,  32,  35, 119],\n",
      "        [  4,   7,  30,  ...,  76,  23,   3],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,  10,  75, 225],\n",
      "        [  4,   7,  30,  ...,  24,  29,   3],\n",
      "        [  4,   7,  30,  ...,  22,  88,   3]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 12, 52,  2],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 10, 35, 49],\n",
      "        [ 4,  7, 30,  ...,  9, 82, 89],\n",
      "        [ 4,  7, 58,  ...,  8, 50,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ..., 35, 45,  1],\n",
      "        [ 4,  7, 58,  ..., 72,  1,  1],\n",
      "        [ 4,  7, 30,  ..., 74,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 14, 48, 72],\n",
      "        [ 4,  7, 30,  ..., 12, 44, 90],\n",
      "        [ 4,  7, 30,  ...,  5,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  14,  57,  90],\n",
      "        [  4,   7,  30,  ...,  48, 172,   1],\n",
      "        [  4,   7,  58,  ...,  23,   6,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 22, 35,  6],\n",
      "        [ 4,  7, 30,  ..., 51, 70, 96],\n",
      "        [ 4,  7, 30,  ..., 32, 27,  3],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 12, 63, 46],\n",
      "        [ 4,  7, 30,  ..., 54,  2,  1],\n",
      "        [ 4,  7, 30,  ..., 75,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ..., 84,  1,  1],\n",
      "        [ 4,  7, 30,  ..., 96,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  17,  82,   2],\n",
      "        [  4,   7,  58,  ...,   8,  77, 105],\n",
      "        [  4,   7,  58,  ...,   8,  35,  46],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 15, 47,  5],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  17,  27, 143],\n",
      "        [  4,   7,  58,  ...,  12,  23,   3],\n",
      "        [  4,   7,  30,  ...,  15,  52,  89],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  31,   5],\n",
      "        [  4,   7,  58,  ...,  32,  44,  74],\n",
      "        [  4,   7,  58,  ...,  10,  48, 143],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,  14,  31,   3],\n",
      "        [  4,   7,  30,  ...,  38,  84,   1],\n",
      "        [  4,   7, 186,  ...,  83,  46,   1],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  30,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  10,  79,   3],\n",
      "        [  4,   7,  30,  ...,   8,  47, 119],\n",
      "        [  4,   7,  30,  ...,   9,  70,  74],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1],\n",
      "        [  4,   7,  58,  ...,   1,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,  22,  27,   3],\n",
      "        [  4,   7,  30,  ...,   8,  27,   2],\n",
      "        [  4,   7,  30,  ...,  15,  44,   2],\n",
      "        ...,\n",
      "        [  4,   7,  58,  ...,  85,   1,   1],\n",
      "        [  4,   7,  30,  ...,  72,   1,   1],\n",
      "        [  4,   7,  30,  ..., 103,   1,   1]], device='cuda:0')\n",
      "tensor([[  4,   7,  58,  ...,   9,  35,   6],\n",
      "        [  4,   7,  30,  ...,  10,  40,   5],\n",
      "        [  4,   7,  30,  ...,  12, 139,   2],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  82, 116,   1],\n",
      "        [  4,   7,  30,  ...,  70,  46,   1],\n",
      "        [  4,   7,  30,  ...,  44,   5,   1]], device='cuda:0')\n",
      "tensor([[ 4, 26, 22,  ..., 17, 35, 90],\n",
      "        [ 4,  7, 58,  ..., 14, 23,  3],\n",
      "        [ 4,  7, 58,  ..., 12, 39,  5],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4, 28, 67,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 30,  ..., 32, 40, 96],\n",
      "        [ 4,  7, 30,  ..., 12, 71,  6],\n",
      "        [ 4,  7, 30,  ..., 24, 31,  6],\n",
      "        ...,\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1]], device='cuda:0')\n",
      "tensor([[  4,   7,  30,  ...,   9,  39,   5],\n",
      "        [  4,   7,  30,  ...,  17,  70,  49],\n",
      "        [  4,   7,  30,  ...,  22,  83,   5],\n",
      "        ...,\n",
      "        [  4,   7,  30,  ...,  38,  91,   1],\n",
      "        [  4,   7,  30,  ...,  57,   3,   1],\n",
      "        [  4,   7,  30,  ...,  40, 138,   1]], device='cuda:0')\n",
      "tensor([[ 4,  7, 58,  ..., 17, 44, 45],\n",
      "        [ 4,  7, 58,  ..., 70, 61,  1],\n",
      "        [ 4,  7, 58,  ..., 52,  3,  1],\n",
      "        ...,\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 58,  ...,  1,  1,  1],\n",
      "        [ 4,  7, 30,  ...,  1,  1,  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for (labels, (notes, notes_len)), _ in (train_iter):\n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82eec1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff4d0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, 2)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = output.mean(dim=1)\n",
    "        output = self.decoder(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        return output\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32976625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load Functions https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0\n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c88beb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Step [50/25000], Train Loss: 0.6766, Valid Loss: 0.6492\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.5773130544993663\n",
      "Epoch [2/500], Step [100/25000], Train Loss: 0.6431, Valid Loss: 0.6550\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [3/500], Step [150/25000], Train Loss: 0.6392, Valid Loss: 0.6478\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [4/500], Step [200/25000], Train Loss: 0.6385, Valid Loss: 0.6451\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [5/500], Step [250/25000], Train Loss: 0.6351, Valid Loss: 0.6316\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [6/500], Step [300/25000], Train Loss: 0.6329, Valid Loss: 0.6143\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [7/500], Step [350/25000], Train Loss: 0.6324, Valid Loss: 0.6063\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6666666666666666\n",
      "Epoch [8/500], Step [400/25000], Train Loss: 0.6249, Valid Loss: 0.5858\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.670468948035488\n",
      "Epoch [9/500], Step [450/25000], Train Loss: 0.6218, Valid Loss: 0.5690\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6717363751584284\n",
      "Epoch [10/500], Step [500/25000], Train Loss: 0.6149, Valid Loss: 0.5582\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6711026615969582\n",
      "Epoch [11/500], Step [550/25000], Train Loss: 0.6053, Valid Loss: 0.5479\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6717363751584284\n",
      "Epoch [12/500], Step [600/25000], Train Loss: 0.5896, Valid Loss: 0.5353\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.6945500633713562\n",
      "Epoch [13/500], Step [650/25000], Train Loss: 0.5661, Valid Loss: 0.6141\n",
      "Epoch Accuracy: 0.7547528517110266\n",
      "Epoch [14/500], Step [700/25000], Train Loss: 0.5583, Valid Loss: 0.5355\n",
      "Epoch Accuracy: 0.7693282636248415\n",
      "Epoch [15/500], Step [750/25000], Train Loss: 0.5438, Valid Loss: 0.5834\n",
      "Epoch Accuracy: 0.7839036755386565\n",
      "Epoch [16/500], Step [800/25000], Train Loss: 0.5345, Valid Loss: 0.5609\n",
      "Epoch Accuracy: 0.8010139416983524\n",
      "Epoch [17/500], Step [850/25000], Train Loss: 0.5256, Valid Loss: 0.5803\n",
      "Epoch Accuracy: 0.8060836501901141\n",
      "Epoch [18/500], Step [900/25000], Train Loss: 0.5201, Valid Loss: 0.5516\n",
      "Epoch Accuracy: 0.8098859315589354\n",
      "Epoch [19/500], Step [950/25000], Train Loss: 0.5217, Valid Loss: 0.5460\n",
      "Epoch Accuracy: 0.7984790874524715\n",
      "Epoch [20/500], Step [1000/25000], Train Loss: 0.5171, Valid Loss: 0.5648\n",
      "Epoch Accuracy: 0.8168567807351077\n",
      "Epoch [21/500], Step [1050/25000], Train Loss: 0.5128, Valid Loss: 0.5592\n",
      "Epoch Accuracy: 0.8086185044359949\n",
      "Epoch [22/500], Step [1100/25000], Train Loss: 0.5062, Valid Loss: 0.5279\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8003802281368821\n",
      "Epoch [23/500], Step [1150/25000], Train Loss: 0.5048, Valid Loss: 0.5552\n",
      "Epoch Accuracy: 0.8168567807351077\n",
      "Epoch [24/500], Step [1200/25000], Train Loss: 0.5006, Valid Loss: 0.5620\n",
      "Epoch Accuracy: 0.8219264892268695\n",
      "Epoch [25/500], Step [1250/25000], Train Loss: 0.5012, Valid Loss: 0.5554\n",
      "Epoch Accuracy: 0.8200253485424588\n",
      "Epoch [26/500], Step [1300/25000], Train Loss: 0.4978, Valid Loss: 0.5351\n",
      "Epoch Accuracy: 0.8212927756653993\n",
      "Epoch [27/500], Step [1350/25000], Train Loss: 0.4965, Valid Loss: 0.5498\n",
      "Epoch Accuracy: 0.8276299112801014\n",
      "Epoch [28/500], Step [1400/25000], Train Loss: 0.4901, Valid Loss: 0.5570\n",
      "Epoch Accuracy: 0.826362484157161\n",
      "Epoch [29/500], Step [1450/25000], Train Loss: 0.4943, Valid Loss: 0.5367\n",
      "Epoch Accuracy: 0.829531051964512\n",
      "Epoch [30/500], Step [1500/25000], Train Loss: 0.4881, Valid Loss: 0.5384\n",
      "Epoch Accuracy: 0.8276299112801014\n",
      "Epoch [31/500], Step [1550/25000], Train Loss: 0.4853, Valid Loss: 0.5219\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8390367553865653\n",
      "Epoch [32/500], Step [1600/25000], Train Loss: 0.4856, Valid Loss: 0.5254\n",
      "Epoch Accuracy: 0.835234474017744\n",
      "Epoch [33/500], Step [1650/25000], Train Loss: 0.4814, Valid Loss: 0.5287\n",
      "Epoch Accuracy: 0.8377693282636248\n",
      "Epoch [34/500], Step [1700/25000], Train Loss: 0.4797, Valid Loss: 0.5196\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8428390367553865\n",
      "Epoch [35/500], Step [1750/25000], Train Loss: 0.4761, Valid Loss: 0.5247\n",
      "Epoch Accuracy: 0.8396704689480355\n",
      "Epoch [36/500], Step [1800/25000], Train Loss: 0.4759, Valid Loss: 0.5228\n",
      "Epoch Accuracy: 0.8479087452471483\n",
      "Epoch [37/500], Step [1850/25000], Train Loss: 0.4743, Valid Loss: 0.5020\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8466413181242078\n",
      "Epoch [38/500], Step [1900/25000], Train Loss: 0.4729, Valid Loss: 0.5093\n",
      "Epoch Accuracy: 0.8460076045627376\n",
      "Epoch [39/500], Step [1950/25000], Train Loss: 0.4701, Valid Loss: 0.5168\n",
      "Epoch Accuracy: 0.8542458808618505\n",
      "Epoch [40/500], Step [2000/25000], Train Loss: 0.4711, Valid Loss: 0.5017\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8542458808618505\n",
      "Epoch [41/500], Step [2050/25000], Train Loss: 0.4686, Valid Loss: 0.4851\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8536121673003803\n",
      "Epoch [42/500], Step [2100/25000], Train Loss: 0.4668, Valid Loss: 0.5077\n",
      "Epoch Accuracy: 0.8504435994930292\n",
      "Epoch [43/500], Step [2150/25000], Train Loss: 0.4676, Valid Loss: 0.5055\n",
      "Epoch Accuracy: 0.85297845373891\n",
      "Epoch [44/500], Step [2200/25000], Train Loss: 0.4643, Valid Loss: 0.4987\n",
      "Epoch Accuracy: 0.8643852978453739\n",
      "Epoch [45/500], Step [2250/25000], Train Loss: 0.4618, Valid Loss: 0.4997\n",
      "Epoch Accuracy: 0.858681875792142\n",
      "Epoch [46/500], Step [2300/25000], Train Loss: 0.4612, Valid Loss: 0.5018\n",
      "Epoch Accuracy: 0.8599493029150824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/500], Step [2350/25000], Train Loss: 0.4626, Valid Loss: 0.5122\n",
      "Epoch Accuracy: 0.8624841571609633\n",
      "Epoch [48/500], Step [2400/25000], Train Loss: 0.4600, Valid Loss: 0.5097\n",
      "Epoch Accuracy: 0.8605830164765526\n",
      "Epoch [49/500], Step [2450/25000], Train Loss: 0.4603, Valid Loss: 0.4846\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8650190114068441\n",
      "Epoch [50/500], Step [2500/25000], Train Loss: 0.4597, Valid Loss: 0.5022\n",
      "Epoch Accuracy: 0.8612167300380228\n",
      "Epoch [51/500], Step [2550/25000], Train Loss: 0.4541, Valid Loss: 0.4826\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8656527249683144\n",
      "Epoch [52/500], Step [2600/25000], Train Loss: 0.4562, Valid Loss: 0.4994\n",
      "Epoch Accuracy: 0.8643852978453739\n",
      "Epoch [53/500], Step [2650/25000], Train Loss: 0.4562, Valid Loss: 0.4941\n",
      "Epoch Accuracy: 0.8650190114068441\n",
      "Epoch [54/500], Step [2700/25000], Train Loss: 0.4552, Valid Loss: 0.5038\n",
      "Epoch Accuracy: 0.8599493029150824\n",
      "Epoch [55/500], Step [2750/25000], Train Loss: 0.4530, Valid Loss: 0.4833\n",
      "Epoch Accuracy: 0.8688212927756654\n",
      "Epoch [56/500], Step [2800/25000], Train Loss: 0.4526, Valid Loss: 0.4996\n",
      "Epoch Accuracy: 0.8643852978453739\n",
      "Epoch [57/500], Step [2850/25000], Train Loss: 0.4498, Valid Loss: 0.4903\n",
      "Epoch Accuracy: 0.8719898605830165\n",
      "Epoch [58/500], Step [2900/25000], Train Loss: 0.4510, Valid Loss: 0.4990\n",
      "Epoch Accuracy: 0.870722433460076\n",
      "Epoch [59/500], Step [2950/25000], Train Loss: 0.4488, Valid Loss: 0.4801\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8650190114068441\n",
      "Epoch [60/500], Step [3000/25000], Train Loss: 0.4497, Valid Loss: 0.4938\n",
      "Epoch Accuracy: 0.8732572877059569\n",
      "Epoch [61/500], Step [3050/25000], Train Loss: 0.4474, Valid Loss: 0.4688\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8662864385297845\n",
      "Epoch [62/500], Step [3100/25000], Train Loss: 0.4462, Valid Loss: 0.4922\n",
      "Epoch Accuracy: 0.8757921419518377\n",
      "Epoch [63/500], Step [3150/25000], Train Loss: 0.4479, Valid Loss: 0.5019\n",
      "Epoch Accuracy: 0.8688212927756654\n",
      "Epoch [64/500], Step [3200/25000], Train Loss: 0.4419, Valid Loss: 0.4847\n",
      "Epoch Accuracy: 0.8795944233206591\n",
      "Epoch [65/500], Step [3250/25000], Train Loss: 0.4444, Valid Loss: 0.4878\n",
      "Epoch Accuracy: 0.8738910012674271\n",
      "Epoch [66/500], Step [3300/25000], Train Loss: 0.4431, Valid Loss: 0.4721\n",
      "Epoch Accuracy: 0.8776932826362485\n",
      "Epoch [67/500], Step [3350/25000], Train Loss: 0.4399, Valid Loss: 0.4679\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8821292775665399\n",
      "Epoch [68/500], Step [3400/25000], Train Loss: 0.4415, Valid Loss: 0.4554\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8846641318124208\n",
      "Epoch [69/500], Step [3450/25000], Train Loss: 0.4406, Valid Loss: 0.4744\n",
      "Epoch Accuracy: 0.8783269961977186\n",
      "Epoch [70/500], Step [3500/25000], Train Loss: 0.4377, Valid Loss: 0.4717\n",
      "Epoch Accuracy: 0.8884664131812421\n",
      "Epoch [71/500], Step [3550/25000], Train Loss: 0.4354, Valid Loss: 0.4952\n",
      "Epoch Accuracy: 0.8840304182509505\n",
      "Epoch [72/500], Step [3600/25000], Train Loss: 0.4351, Valid Loss: 0.4995\n",
      "Epoch Accuracy: 0.8859315589353612\n",
      "Epoch [73/500], Step [3650/25000], Train Loss: 0.4344, Valid Loss: 0.4830\n",
      "Epoch Accuracy: 0.8891001267427123\n",
      "Epoch [74/500], Step [3700/25000], Train Loss: 0.4347, Valid Loss: 0.4611\n",
      "Epoch Accuracy: 0.885297845373891\n",
      "Epoch [75/500], Step [3750/25000], Train Loss: 0.4299, Valid Loss: 0.4773\n",
      "Epoch Accuracy: 0.8903675538656527\n",
      "Epoch [76/500], Step [3800/25000], Train Loss: 0.4282, Valid Loss: 0.4601\n",
      "Epoch Accuracy: 0.8954372623574145\n",
      "Epoch [77/500], Step [3850/25000], Train Loss: 0.4295, Valid Loss: 0.4716\n",
      "Epoch Accuracy: 0.8897338403041825\n",
      "Epoch [78/500], Step [3900/25000], Train Loss: 0.4268, Valid Loss: 0.4804\n",
      "Epoch Accuracy: 0.8948035487959443\n",
      "Epoch [79/500], Step [3950/25000], Train Loss: 0.4273, Valid Loss: 0.4800\n",
      "Epoch Accuracy: 0.8992395437262357\n",
      "Epoch [80/500], Step [4000/25000], Train Loss: 0.4257, Valid Loss: 0.4522\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8967046894803549\n",
      "Epoch [81/500], Step [4050/25000], Train Loss: 0.4273, Valid Loss: 0.4503\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.894169835234474\n",
      "Epoch [82/500], Step [4100/25000], Train Loss: 0.4258, Valid Loss: 0.4860\n",
      "Epoch Accuracy: 0.894169835234474\n",
      "Epoch [83/500], Step [4150/25000], Train Loss: 0.4258, Valid Loss: 0.4793\n",
      "Epoch Accuracy: 0.8954372623574145\n",
      "Epoch [84/500], Step [4200/25000], Train Loss: 0.4249, Valid Loss: 0.4667\n",
      "Epoch Accuracy: 0.8967046894803549\n",
      "Epoch [85/500], Step [4250/25000], Train Loss: 0.4211, Valid Loss: 0.4640\n",
      "Epoch Accuracy: 0.9017743979721166\n",
      "Epoch [86/500], Step [4300/25000], Train Loss: 0.4226, Valid Loss: 0.4441\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.8967046894803549\n",
      "Epoch [87/500], Step [4350/25000], Train Loss: 0.4232, Valid Loss: 0.4455\n",
      "Epoch Accuracy: 0.8948035487959443\n",
      "Epoch [88/500], Step [4400/25000], Train Loss: 0.4192, Valid Loss: 0.4505\n",
      "Epoch Accuracy: 0.9017743979721166\n",
      "Epoch [89/500], Step [4450/25000], Train Loss: 0.4186, Valid Loss: 0.4875\n",
      "Epoch Accuracy: 0.903041825095057\n",
      "Epoch [90/500], Step [4500/25000], Train Loss: 0.4170, Valid Loss: 0.4763\n",
      "Epoch Accuracy: 0.9043092522179975\n",
      "Epoch [91/500], Step [4550/25000], Train Loss: 0.4161, Valid Loss: 0.4448\n",
      "Epoch Accuracy: 0.903041825095057\n",
      "Epoch [92/500], Step [4600/25000], Train Loss: 0.4153, Valid Loss: 0.4535\n",
      "Epoch Accuracy: 0.9043092522179975\n",
      "Epoch [93/500], Step [4650/25000], Train Loss: 0.4126, Valid Loss: 0.4554\n",
      "Epoch Accuracy: 0.9112801013941698\n",
      "Epoch [94/500], Step [4700/25000], Train Loss: 0.4142, Valid Loss: 0.4531\n",
      "Epoch Accuracy: 0.9131812420785805\n",
      "Epoch [95/500], Step [4750/25000], Train Loss: 0.4127, Valid Loss: 0.4379\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9081115335868187\n",
      "Epoch [96/500], Step [4800/25000], Train Loss: 0.4133, Valid Loss: 0.4275\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9093789607097592\n",
      "Epoch [97/500], Step [4850/25000], Train Loss: 0.4151, Valid Loss: 0.4478\n",
      "Epoch Accuracy: 0.9036755386565273\n",
      "Epoch [98/500], Step [4900/25000], Train Loss: 0.4113, Valid Loss: 0.4491\n",
      "Epoch Accuracy: 0.9100126742712294\n",
      "Epoch [99/500], Step [4950/25000], Train Loss: 0.4137, Valid Loss: 0.4479\n",
      "Epoch Accuracy: 0.9100126742712294\n",
      "Epoch [100/500], Step [5000/25000], Train Loss: 0.4086, Valid Loss: 0.4688\n",
      "Epoch Accuracy: 0.9157160963244614\n",
      "Epoch [101/500], Step [5050/25000], Train Loss: 0.4141, Valid Loss: 0.4588\n",
      "Epoch Accuracy: 0.9024081115335868\n",
      "Epoch [102/500], Step [5100/25000], Train Loss: 0.4075, Valid Loss: 0.4450\n",
      "Epoch Accuracy: 0.9163498098859315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/500], Step [5150/25000], Train Loss: 0.4100, Valid Loss: 0.4615\n",
      "Epoch Accuracy: 0.9131812420785805\n",
      "Epoch [104/500], Step [5200/25000], Train Loss: 0.4062, Valid Loss: 0.4404\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [105/500], Step [5250/25000], Train Loss: 0.4087, Valid Loss: 0.4331\n",
      "Epoch Accuracy: 0.9138149556400507\n",
      "Epoch [106/500], Step [5300/25000], Train Loss: 0.4106, Valid Loss: 0.4547\n",
      "Epoch Accuracy: 0.9112801013941698\n",
      "Epoch [107/500], Step [5350/25000], Train Loss: 0.4070, Valid Loss: 0.4672\n",
      "Epoch Accuracy: 0.9150823827629911\n",
      "Epoch [108/500], Step [5400/25000], Train Loss: 0.4052, Valid Loss: 0.4526\n",
      "Epoch Accuracy: 0.9144486692015209\n",
      "Epoch [109/500], Step [5450/25000], Train Loss: 0.4061, Valid Loss: 0.4430\n",
      "Epoch Accuracy: 0.9131812420785805\n",
      "Epoch [110/500], Step [5500/25000], Train Loss: 0.4057, Valid Loss: 0.4707\n",
      "Epoch Accuracy: 0.9131812420785805\n",
      "Epoch [111/500], Step [5550/25000], Train Loss: 0.4038, Valid Loss: 0.4409\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [112/500], Step [5600/25000], Train Loss: 0.4022, Valid Loss: 0.4553\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [113/500], Step [5650/25000], Train Loss: 0.4046, Valid Loss: 0.4390\n",
      "Epoch Accuracy: 0.9125475285171103\n",
      "Epoch [114/500], Step [5700/25000], Train Loss: 0.4039, Valid Loss: 0.4592\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [115/500], Step [5750/25000], Train Loss: 0.4031, Valid Loss: 0.4514\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [116/500], Step [5800/25000], Train Loss: 0.4024, Valid Loss: 0.4511\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [117/500], Step [5850/25000], Train Loss: 0.4055, Valid Loss: 0.4409\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [118/500], Step [5900/25000], Train Loss: 0.4028, Valid Loss: 0.4439\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [119/500], Step [5950/25000], Train Loss: 0.4032, Valid Loss: 0.4720\n",
      "Epoch Accuracy: 0.9163498098859315\n",
      "Epoch [120/500], Step [6000/25000], Train Loss: 0.4015, Valid Loss: 0.4442\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [121/500], Step [6050/25000], Train Loss: 0.4005, Valid Loss: 0.4395\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [122/500], Step [6100/25000], Train Loss: 0.4006, Valid Loss: 0.4627\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [123/500], Step [6150/25000], Train Loss: 0.3990, Valid Loss: 0.4622\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [124/500], Step [6200/25000], Train Loss: 0.4003, Valid Loss: 0.4649\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [125/500], Step [6250/25000], Train Loss: 0.4045, Valid Loss: 0.4431\n",
      "Epoch Accuracy: 0.9138149556400507\n",
      "Epoch [126/500], Step [6300/25000], Train Loss: 0.3986, Valid Loss: 0.4610\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [127/500], Step [6350/25000], Train Loss: 0.3987, Valid Loss: 0.4471\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [128/500], Step [6400/25000], Train Loss: 0.3987, Valid Loss: 0.4402\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [129/500], Step [6450/25000], Train Loss: 0.3989, Valid Loss: 0.4597\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [130/500], Step [6500/25000], Train Loss: 0.3988, Valid Loss: 0.4460\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [131/500], Step [6550/25000], Train Loss: 0.3982, Valid Loss: 0.4467\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [132/500], Step [6600/25000], Train Loss: 0.3986, Valid Loss: 0.4461\n",
      "Epoch Accuracy: 0.9195183776932826\n",
      "Epoch [133/500], Step [6650/25000], Train Loss: 0.3999, Valid Loss: 0.4478\n",
      "Epoch Accuracy: 0.917617237008872\n",
      "Epoch [134/500], Step [6700/25000], Train Loss: 0.3979, Valid Loss: 0.4496\n",
      "Epoch Accuracy: 0.9182509505703422\n",
      "Epoch [135/500], Step [6750/25000], Train Loss: 0.3971, Valid Loss: 0.4857\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [136/500], Step [6800/25000], Train Loss: 0.3974, Valid Loss: 0.4565\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [137/500], Step [6850/25000], Train Loss: 0.3960, Valid Loss: 0.4689\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [138/500], Step [6900/25000], Train Loss: 0.3980, Valid Loss: 0.4468\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [139/500], Step [6950/25000], Train Loss: 0.3987, Valid Loss: 0.4643\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [140/500], Step [7000/25000], Train Loss: 0.3953, Valid Loss: 0.4432\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [141/500], Step [7050/25000], Train Loss: 0.3970, Valid Loss: 0.4646\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [142/500], Step [7100/25000], Train Loss: 0.3972, Valid Loss: 0.4731\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [143/500], Step [7150/25000], Train Loss: 0.3971, Valid Loss: 0.4715\n",
      "Epoch Accuracy: 0.9195183776932826\n",
      "Epoch [144/500], Step [7200/25000], Train Loss: 0.3993, Valid Loss: 0.4867\n",
      "Epoch Accuracy: 0.9169835234474017\n",
      "Epoch [145/500], Step [7250/25000], Train Loss: 0.3950, Valid Loss: 0.4548\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [146/500], Step [7300/25000], Train Loss: 0.3949, Valid Loss: 0.4648\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [147/500], Step [7350/25000], Train Loss: 0.3952, Valid Loss: 0.4445\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [148/500], Step [7400/25000], Train Loss: 0.3939, Valid Loss: 0.4567\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [149/500], Step [7450/25000], Train Loss: 0.3924, Valid Loss: 0.4827\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [150/500], Step [7500/25000], Train Loss: 0.3967, Valid Loss: 0.4594\n",
      "Epoch Accuracy: 0.9188846641318125\n",
      "Epoch [151/500], Step [7550/25000], Train Loss: 0.3926, Valid Loss: 0.4833\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [152/500], Step [7600/25000], Train Loss: 0.3977, Valid Loss: 0.4498\n",
      "Epoch Accuracy: 0.9157160963244614\n",
      "Epoch [153/500], Step [7650/25000], Train Loss: 0.3948, Valid Loss: 0.4547\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [154/500], Step [7700/25000], Train Loss: 0.3958, Valid Loss: 0.4270\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [155/500], Step [7750/25000], Train Loss: 0.3951, Valid Loss: 0.4552\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [156/500], Step [7800/25000], Train Loss: 0.3944, Valid Loss: 0.4401\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [157/500], Step [7850/25000], Train Loss: 0.3955, Valid Loss: 0.4677\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [158/500], Step [7900/25000], Train Loss: 0.3945, Valid Loss: 0.4460\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [159/500], Step [7950/25000], Train Loss: 0.3956, Valid Loss: 0.4266\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [160/500], Step [8000/25000], Train Loss: 0.3932, Valid Loss: 0.4543\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [161/500], Step [8050/25000], Train Loss: 0.3932, Valid Loss: 0.4538\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [162/500], Step [8100/25000], Train Loss: 0.3952, Valid Loss: 0.4595\n",
      "Epoch Accuracy: 0.9214195183776933\n",
      "Epoch [163/500], Step [8150/25000], Train Loss: 0.3905, Valid Loss: 0.4718\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [164/500], Step [8200/25000], Train Loss: 0.3930, Valid Loss: 0.4488\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [165/500], Step [8250/25000], Train Loss: 0.3918, Valid Loss: 0.4420\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [166/500], Step [8300/25000], Train Loss: 0.3908, Valid Loss: 0.4626\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [167/500], Step [8350/25000], Train Loss: 0.3951, Valid Loss: 0.4368\n",
      "Epoch Accuracy: 0.9207858048162231\n",
      "Epoch [168/500], Step [8400/25000], Train Loss: 0.3938, Valid Loss: 0.4527\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [169/500], Step [8450/25000], Train Loss: 0.3934, Valid Loss: 0.4656\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [170/500], Step [8500/25000], Train Loss: 0.3935, Valid Loss: 0.4634\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [171/500], Step [8550/25000], Train Loss: 0.3934, Valid Loss: 0.4433\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [172/500], Step [8600/25000], Train Loss: 0.3916, Valid Loss: 0.4712\n",
      "Epoch Accuracy: 0.9220532319391636\n",
      "Epoch [173/500], Step [8650/25000], Train Loss: 0.3900, Valid Loss: 0.4518\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [174/500], Step [8700/25000], Train Loss: 0.3930, Valid Loss: 0.4784\n",
      "Epoch Accuracy: 0.9258555133079848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/500], Step [8750/25000], Train Loss: 0.3917, Valid Loss: 0.4412\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [176/500], Step [8800/25000], Train Loss: 0.3927, Valid Loss: 0.4448\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [177/500], Step [8850/25000], Train Loss: 0.3908, Valid Loss: 0.4699\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [178/500], Step [8900/25000], Train Loss: 0.3888, Valid Loss: 0.4579\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [179/500], Step [8950/25000], Train Loss: 0.3892, Valid Loss: 0.4759\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [180/500], Step [9000/25000], Train Loss: 0.3897, Valid Loss: 0.4541\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [181/500], Step [9050/25000], Train Loss: 0.3917, Valid Loss: 0.4465\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [182/500], Step [9100/25000], Train Loss: 0.3913, Valid Loss: 0.4492\n",
      "Epoch Accuracy: 0.9233206590621039\n",
      "Epoch [183/500], Step [9150/25000], Train Loss: 0.3931, Valid Loss: 0.4694\n",
      "Epoch Accuracy: 0.9201520912547528\n",
      "Epoch [184/500], Step [9200/25000], Train Loss: 0.3907, Valid Loss: 0.4668\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [185/500], Step [9250/25000], Train Loss: 0.3860, Valid Loss: 0.4472\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [186/500], Step [9300/25000], Train Loss: 0.3927, Valid Loss: 0.4478\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [187/500], Step [9350/25000], Train Loss: 0.3898, Valid Loss: 0.4604\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [188/500], Step [9400/25000], Train Loss: 0.3966, Valid Loss: 0.4658\n",
      "Epoch Accuracy: 0.9144486692015209\n",
      "Epoch [189/500], Step [9450/25000], Train Loss: 0.3896, Valid Loss: 0.4618\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [190/500], Step [9500/25000], Train Loss: 0.3880, Valid Loss: 0.4597\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [191/500], Step [9550/25000], Train Loss: 0.3889, Valid Loss: 0.4388\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [192/500], Step [9600/25000], Train Loss: 0.3890, Valid Loss: 0.4715\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [193/500], Step [9650/25000], Train Loss: 0.3874, Valid Loss: 0.4417\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [194/500], Step [9700/25000], Train Loss: 0.3883, Valid Loss: 0.4647\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [195/500], Step [9750/25000], Train Loss: 0.3894, Valid Loss: 0.4589\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [196/500], Step [9800/25000], Train Loss: 0.3892, Valid Loss: 0.4626\n",
      "Epoch Accuracy: 0.9258555133079848\n",
      "Epoch [197/500], Step [9850/25000], Train Loss: 0.3880, Valid Loss: 0.4582\n",
      "Epoch Accuracy: 0.9245880861850444\n",
      "Epoch [198/500], Step [9900/25000], Train Loss: 0.3909, Valid Loss: 0.4729\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [199/500], Step [9950/25000], Train Loss: 0.3878, Valid Loss: 0.4524\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [200/500], Step [10000/25000], Train Loss: 0.3897, Valid Loss: 0.4468\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [201/500], Step [10050/25000], Train Loss: 0.3893, Valid Loss: 0.4389\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [202/500], Step [10100/25000], Train Loss: 0.3888, Valid Loss: 0.4683\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [203/500], Step [10150/25000], Train Loss: 0.3901, Valid Loss: 0.4714\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [204/500], Step [10200/25000], Train Loss: 0.3866, Valid Loss: 0.4521\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [205/500], Step [10250/25000], Train Loss: 0.3869, Valid Loss: 0.4640\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [206/500], Step [10300/25000], Train Loss: 0.3876, Valid Loss: 0.4459\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [207/500], Step [10350/25000], Train Loss: 0.3909, Valid Loss: 0.4571\n",
      "Epoch Accuracy: 0.9226869455006337\n",
      "Epoch [208/500], Step [10400/25000], Train Loss: 0.3884, Valid Loss: 0.4735\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [209/500], Step [10450/25000], Train Loss: 0.3885, Valid Loss: 0.4552\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [210/500], Step [10500/25000], Train Loss: 0.3861, Valid Loss: 0.4717\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [211/500], Step [10550/25000], Train Loss: 0.3851, Valid Loss: 0.4579\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [212/500], Step [10600/25000], Train Loss: 0.3861, Valid Loss: 0.4640\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [213/500], Step [10650/25000], Train Loss: 0.3880, Valid Loss: 0.4604\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [214/500], Step [10700/25000], Train Loss: 0.3879, Valid Loss: 0.4593\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [215/500], Step [10750/25000], Train Loss: 0.3887, Valid Loss: 0.4691\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [216/500], Step [10800/25000], Train Loss: 0.3881, Valid Loss: 0.4558\n",
      "Epoch Accuracy: 0.9239543726235742\n",
      "Epoch [217/500], Step [10850/25000], Train Loss: 0.3860, Valid Loss: 0.4780\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [218/500], Step [10900/25000], Train Loss: 0.3831, Valid Loss: 0.4685\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [219/500], Step [10950/25000], Train Loss: 0.3846, Valid Loss: 0.4587\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [220/500], Step [11000/25000], Train Loss: 0.3860, Valid Loss: 0.4806\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [221/500], Step [11050/25000], Train Loss: 0.3871, Valid Loss: 0.4570\n",
      "Epoch Accuracy: 0.926489226869455\n",
      "Epoch [222/500], Step [11100/25000], Train Loss: 0.3818, Valid Loss: 0.4761\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [223/500], Step [11150/25000], Train Loss: 0.3828, Valid Loss: 0.4629\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [224/500], Step [11200/25000], Train Loss: 0.3850, Valid Loss: 0.4656\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [225/500], Step [11250/25000], Train Loss: 0.3826, Valid Loss: 0.4699\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [226/500], Step [11300/25000], Train Loss: 0.3867, Valid Loss: 0.4886\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [227/500], Step [11350/25000], Train Loss: 0.3827, Valid Loss: 0.4668\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [228/500], Step [11400/25000], Train Loss: 0.3870, Valid Loss: 0.4801\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [229/500], Step [11450/25000], Train Loss: 0.3893, Valid Loss: 0.4915\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [230/500], Step [11500/25000], Train Loss: 0.3828, Valid Loss: 0.4739\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [231/500], Step [11550/25000], Train Loss: 0.3883, Valid Loss: 0.4605\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [232/500], Step [11600/25000], Train Loss: 0.3873, Valid Loss: 0.4484\n",
      "Epoch Accuracy: 0.9283903675538656\n",
      "Epoch [233/500], Step [11650/25000], Train Loss: 0.3865, Valid Loss: 0.4542\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [234/500], Step [11700/25000], Train Loss: 0.3855, Valid Loss: 0.4620\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [235/500], Step [11750/25000], Train Loss: 0.3825, Valid Loss: 0.4514\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [236/500], Step [11800/25000], Train Loss: 0.3891, Valid Loss: 0.4503\n",
      "Epoch Accuracy: 0.9252217997465145\n",
      "Epoch [237/500], Step [11850/25000], Train Loss: 0.3835, Valid Loss: 0.4553\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [238/500], Step [11900/25000], Train Loss: 0.3858, Valid Loss: 0.4417\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [239/500], Step [11950/25000], Train Loss: 0.3836, Valid Loss: 0.4405\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [240/500], Step [12000/25000], Train Loss: 0.3845, Valid Loss: 0.4935\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [241/500], Step [12050/25000], Train Loss: 0.3869, Valid Loss: 0.4586\n",
      "Epoch Accuracy: 0.9290240811153359\n",
      "Epoch [242/500], Step [12100/25000], Train Loss: 0.3834, Valid Loss: 0.4724\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [243/500], Step [12150/25000], Train Loss: 0.3845, Valid Loss: 0.4553\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [244/500], Step [12200/25000], Train Loss: 0.3823, Valid Loss: 0.4622\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [245/500], Step [12250/25000], Train Loss: 0.3833, Valid Loss: 0.4664\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [246/500], Step [12300/25000], Train Loss: 0.3843, Valid Loss: 0.4622\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [247/500], Step [12350/25000], Train Loss: 0.3838, Valid Loss: 0.4749\n",
      "Epoch Accuracy: 0.9277566539923955\n",
      "Epoch [248/500], Step [12400/25000], Train Loss: 0.3816, Valid Loss: 0.4836\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [249/500], Step [12450/25000], Train Loss: 0.3805, Valid Loss: 0.4615\n",
      "Epoch Accuracy: 0.935361216730038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [250/500], Step [12500/25000], Train Loss: 0.3828, Valid Loss: 0.4543\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [251/500], Step [12550/25000], Train Loss: 0.3822, Valid Loss: 0.4611\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [252/500], Step [12600/25000], Train Loss: 0.3815, Valid Loss: 0.4621\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [253/500], Step [12650/25000], Train Loss: 0.3819, Valid Loss: 0.4574\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [254/500], Step [12700/25000], Train Loss: 0.3866, Valid Loss: 0.4762\n",
      "Epoch Accuracy: 0.9271229404309252\n",
      "Epoch [255/500], Step [12750/25000], Train Loss: 0.3845, Valid Loss: 0.4634\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [256/500], Step [12800/25000], Train Loss: 0.3844, Valid Loss: 0.4636\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [257/500], Step [12850/25000], Train Loss: 0.3830, Valid Loss: 0.4658\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [258/500], Step [12900/25000], Train Loss: 0.3831, Valid Loss: 0.4647\n",
      "Epoch Accuracy: 0.9296577946768061\n",
      "Epoch [259/500], Step [12950/25000], Train Loss: 0.3819, Valid Loss: 0.4697\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [260/500], Step [13000/25000], Train Loss: 0.3823, Valid Loss: 0.4748\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [261/500], Step [13050/25000], Train Loss: 0.3826, Valid Loss: 0.4613\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [262/500], Step [13100/25000], Train Loss: 0.3852, Valid Loss: 0.4615\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [263/500], Step [13150/25000], Train Loss: 0.3817, Valid Loss: 0.4696\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [264/500], Step [13200/25000], Train Loss: 0.3833, Valid Loss: 0.4831\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [265/500], Step [13250/25000], Train Loss: 0.3809, Valid Loss: 0.4678\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [266/500], Step [13300/25000], Train Loss: 0.3813, Valid Loss: 0.4504\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [267/500], Step [13350/25000], Train Loss: 0.3808, Valid Loss: 0.4634\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [268/500], Step [13400/25000], Train Loss: 0.3804, Valid Loss: 0.4541\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [269/500], Step [13450/25000], Train Loss: 0.3789, Valid Loss: 0.4674\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [270/500], Step [13500/25000], Train Loss: 0.3811, Valid Loss: 0.4683\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [271/500], Step [13550/25000], Train Loss: 0.3810, Valid Loss: 0.4750\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [272/500], Step [13600/25000], Train Loss: 0.3812, Valid Loss: 0.4461\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [273/500], Step [13650/25000], Train Loss: 0.3794, Valid Loss: 0.4718\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [274/500], Step [13700/25000], Train Loss: 0.3817, Valid Loss: 0.4633\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [275/500], Step [13750/25000], Train Loss: 0.3792, Valid Loss: 0.4411\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [276/500], Step [13800/25000], Train Loss: 0.3805, Valid Loss: 0.4651\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [277/500], Step [13850/25000], Train Loss: 0.3790, Valid Loss: 0.4905\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [278/500], Step [13900/25000], Train Loss: 0.3822, Valid Loss: 0.4568\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [279/500], Step [13950/25000], Train Loss: 0.3829, Valid Loss: 0.4493\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [280/500], Step [14000/25000], Train Loss: 0.3800, Valid Loss: 0.4553\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [281/500], Step [14050/25000], Train Loss: 0.3825, Valid Loss: 0.4568\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [282/500], Step [14100/25000], Train Loss: 0.3796, Valid Loss: 0.4489\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [283/500], Step [14150/25000], Train Loss: 0.3827, Valid Loss: 0.4555\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [284/500], Step [14200/25000], Train Loss: 0.3793, Valid Loss: 0.4691\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [285/500], Step [14250/25000], Train Loss: 0.3828, Valid Loss: 0.4649\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [286/500], Step [14300/25000], Train Loss: 0.3807, Valid Loss: 0.4575\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [287/500], Step [14350/25000], Train Loss: 0.3788, Valid Loss: 0.4560\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [288/500], Step [14400/25000], Train Loss: 0.3811, Valid Loss: 0.4571\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [289/500], Step [14450/25000], Train Loss: 0.3808, Valid Loss: 0.4486\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [290/500], Step [14500/25000], Train Loss: 0.3806, Valid Loss: 0.4317\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [291/500], Step [14550/25000], Train Loss: 0.3817, Valid Loss: 0.4507\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [292/500], Step [14600/25000], Train Loss: 0.3768, Valid Loss: 0.4690\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [293/500], Step [14650/25000], Train Loss: 0.3822, Valid Loss: 0.4751\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [294/500], Step [14700/25000], Train Loss: 0.3816, Valid Loss: 0.4584\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [295/500], Step [14750/25000], Train Loss: 0.3790, Valid Loss: 0.4630\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [296/500], Step [14800/25000], Train Loss: 0.3791, Valid Loss: 0.4647\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [297/500], Step [14850/25000], Train Loss: 0.3811, Valid Loss: 0.4478\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [298/500], Step [14900/25000], Train Loss: 0.3795, Valid Loss: 0.4563\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [299/500], Step [14950/25000], Train Loss: 0.3816, Valid Loss: 0.4538\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [300/500], Step [15000/25000], Train Loss: 0.3815, Valid Loss: 0.4416\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [301/500], Step [15050/25000], Train Loss: 0.3807, Valid Loss: 0.4711\n",
      "Epoch Accuracy: 0.9321926489226869\n",
      "Epoch [302/500], Step [15100/25000], Train Loss: 0.3816, Valid Loss: 0.4859\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [303/500], Step [15150/25000], Train Loss: 0.3803, Valid Loss: 0.4853\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [304/500], Step [15200/25000], Train Loss: 0.3805, Valid Loss: 0.4551\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [305/500], Step [15250/25000], Train Loss: 0.3815, Valid Loss: 0.4558\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [306/500], Step [15300/25000], Train Loss: 0.3806, Valid Loss: 0.4809\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [307/500], Step [15350/25000], Train Loss: 0.3774, Valid Loss: 0.4733\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [308/500], Step [15400/25000], Train Loss: 0.3804, Valid Loss: 0.4703\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [309/500], Step [15450/25000], Train Loss: 0.3778, Valid Loss: 0.4720\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [310/500], Step [15500/25000], Train Loss: 0.3781, Valid Loss: 0.4644\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [311/500], Step [15550/25000], Train Loss: 0.3796, Valid Loss: 0.4296\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [312/500], Step [15600/25000], Train Loss: 0.3787, Valid Loss: 0.4558\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [313/500], Step [15650/25000], Train Loss: 0.3799, Valid Loss: 0.4609\n",
      "Epoch Accuracy: 0.9328263624841572\n",
      "Epoch [314/500], Step [15700/25000], Train Loss: 0.3810, Valid Loss: 0.4545\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [315/500], Step [15750/25000], Train Loss: 0.3792, Valid Loss: 0.4708\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [316/500], Step [15800/25000], Train Loss: 0.3803, Valid Loss: 0.4523\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [317/500], Step [15850/25000], Train Loss: 0.3749, Valid Loss: 0.4459\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [318/500], Step [15900/25000], Train Loss: 0.3794, Valid Loss: 0.4799\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [319/500], Step [15950/25000], Train Loss: 0.3785, Valid Loss: 0.4625\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [320/500], Step [16000/25000], Train Loss: 0.3799, Valid Loss: 0.4835\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [321/500], Step [16050/25000], Train Loss: 0.3783, Valid Loss: 0.4442\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [322/500], Step [16100/25000], Train Loss: 0.3764, Valid Loss: 0.4666\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [323/500], Step [16150/25000], Train Loss: 0.3796, Valid Loss: 0.4466\n",
      "Epoch Accuracy: 0.9359949302915083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [324/500], Step [16200/25000], Train Loss: 0.3822, Valid Loss: 0.4560\n",
      "Epoch Accuracy: 0.9302915082382763\n",
      "Epoch [325/500], Step [16250/25000], Train Loss: 0.3794, Valid Loss: 0.4553\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [326/500], Step [16300/25000], Train Loss: 0.3785, Valid Loss: 0.4544\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [327/500], Step [16350/25000], Train Loss: 0.3763, Valid Loss: 0.4751\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [328/500], Step [16400/25000], Train Loss: 0.3790, Valid Loss: 0.4483\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [329/500], Step [16450/25000], Train Loss: 0.3807, Valid Loss: 0.4795\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [330/500], Step [16500/25000], Train Loss: 0.3762, Valid Loss: 0.4543\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [331/500], Step [16550/25000], Train Loss: 0.3797, Valid Loss: 0.4440\n",
      "Epoch Accuracy: 0.9315589353612167\n",
      "Epoch [332/500], Step [16600/25000], Train Loss: 0.3778, Valid Loss: 0.4417\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [333/500], Step [16650/25000], Train Loss: 0.3780, Valid Loss: 0.4424\n",
      "Epoch Accuracy: 0.9366286438529785\n",
      "Epoch [334/500], Step [16700/25000], Train Loss: 0.3770, Valid Loss: 0.4402\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [335/500], Step [16750/25000], Train Loss: 0.3816, Valid Loss: 0.4378\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [336/500], Step [16800/25000], Train Loss: 0.3788, Valid Loss: 0.4537\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [337/500], Step [16850/25000], Train Loss: 0.3795, Valid Loss: 0.4479\n",
      "Epoch Accuracy: 0.9347275031685678\n",
      "Epoch [338/500], Step [16900/25000], Train Loss: 0.3769, Valid Loss: 0.4654\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [339/500], Step [16950/25000], Train Loss: 0.3798, Valid Loss: 0.4671\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [340/500], Step [17000/25000], Train Loss: 0.3803, Valid Loss: 0.4408\n",
      "Epoch Accuracy: 0.9334600760456274\n",
      "Epoch [341/500], Step [17050/25000], Train Loss: 0.3779, Valid Loss: 0.4476\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [342/500], Step [17100/25000], Train Loss: 0.3767, Valid Loss: 0.4432\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [343/500], Step [17150/25000], Train Loss: 0.3805, Valid Loss: 0.4596\n",
      "Epoch Accuracy: 0.9309252217997465\n",
      "Epoch [344/500], Step [17200/25000], Train Loss: 0.3767, Valid Loss: 0.4437\n",
      "Epoch Accuracy: 0.9372623574144486\n",
      "Epoch [345/500], Step [17250/25000], Train Loss: 0.3754, Valid Loss: 0.4506\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [346/500], Step [17300/25000], Train Loss: 0.3801, Valid Loss: 0.4656\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [347/500], Step [17350/25000], Train Loss: 0.3760, Valid Loss: 0.4537\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [348/500], Step [17400/25000], Train Loss: 0.3754, Valid Loss: 0.4651\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [349/500], Step [17450/25000], Train Loss: 0.3767, Valid Loss: 0.4521\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [350/500], Step [17500/25000], Train Loss: 0.3769, Valid Loss: 0.4663\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [351/500], Step [17550/25000], Train Loss: 0.3765, Valid Loss: 0.4726\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [352/500], Step [17600/25000], Train Loss: 0.3793, Valid Loss: 0.4416\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [353/500], Step [17650/25000], Train Loss: 0.3756, Valid Loss: 0.4580\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [354/500], Step [17700/25000], Train Loss: 0.3781, Valid Loss: 0.4575\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [355/500], Step [17750/25000], Train Loss: 0.3782, Valid Loss: 0.4742\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [356/500], Step [17800/25000], Train Loss: 0.3793, Valid Loss: 0.4589\n",
      "Epoch Accuracy: 0.9359949302915083\n",
      "Epoch [357/500], Step [17850/25000], Train Loss: 0.3739, Valid Loss: 0.4662\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [358/500], Step [17900/25000], Train Loss: 0.3749, Valid Loss: 0.4592\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [359/500], Step [17950/25000], Train Loss: 0.3770, Valid Loss: 0.4555\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [360/500], Step [18000/25000], Train Loss: 0.3753, Valid Loss: 0.4448\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [361/500], Step [18050/25000], Train Loss: 0.3753, Valid Loss: 0.4427\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [362/500], Step [18100/25000], Train Loss: 0.3741, Valid Loss: 0.4653\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [363/500], Step [18150/25000], Train Loss: 0.3767, Valid Loss: 0.4560\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [364/500], Step [18200/25000], Train Loss: 0.3758, Valid Loss: 0.4439\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [365/500], Step [18250/25000], Train Loss: 0.3763, Valid Loss: 0.4548\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [366/500], Step [18300/25000], Train Loss: 0.3753, Valid Loss: 0.4456\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [367/500], Step [18350/25000], Train Loss: 0.3770, Valid Loss: 0.4541\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [368/500], Step [18400/25000], Train Loss: 0.3763, Valid Loss: 0.4491\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [369/500], Step [18450/25000], Train Loss: 0.3760, Valid Loss: 0.4488\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [370/500], Step [18500/25000], Train Loss: 0.3752, Valid Loss: 0.4575\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [371/500], Step [18550/25000], Train Loss: 0.3756, Valid Loss: 0.4663\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [372/500], Step [18600/25000], Train Loss: 0.3760, Valid Loss: 0.4675\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [373/500], Step [18650/25000], Train Loss: 0.3734, Valid Loss: 0.4640\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [374/500], Step [18700/25000], Train Loss: 0.3773, Valid Loss: 0.4611\n",
      "Epoch Accuracy: 0.935361216730038\n",
      "Epoch [375/500], Step [18750/25000], Train Loss: 0.3761, Valid Loss: 0.4409\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [376/500], Step [18800/25000], Train Loss: 0.3734, Valid Loss: 0.4541\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [377/500], Step [18850/25000], Train Loss: 0.3740, Valid Loss: 0.4614\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [378/500], Step [18900/25000], Train Loss: 0.3749, Valid Loss: 0.4613\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [379/500], Step [18950/25000], Train Loss: 0.3752, Valid Loss: 0.4513\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [380/500], Step [19000/25000], Train Loss: 0.3741, Valid Loss: 0.4500\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [381/500], Step [19050/25000], Train Loss: 0.3772, Valid Loss: 0.4450\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [382/500], Step [19100/25000], Train Loss: 0.3741, Valid Loss: 0.4603\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [383/500], Step [19150/25000], Train Loss: 0.3754, Valid Loss: 0.4451\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [384/500], Step [19200/25000], Train Loss: 0.3765, Valid Loss: 0.4478\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [385/500], Step [19250/25000], Train Loss: 0.3744, Valid Loss: 0.4518\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [386/500], Step [19300/25000], Train Loss: 0.3769, Valid Loss: 0.4459\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [387/500], Step [19350/25000], Train Loss: 0.3747, Valid Loss: 0.4564\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [388/500], Step [19400/25000], Train Loss: 0.3749, Valid Loss: 0.4531\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [389/500], Step [19450/25000], Train Loss: 0.3726, Valid Loss: 0.4470\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [390/500], Step [19500/25000], Train Loss: 0.3758, Valid Loss: 0.4504\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [391/500], Step [19550/25000], Train Loss: 0.3770, Valid Loss: 0.4388\n",
      "Epoch Accuracy: 0.9385297845373891\n",
      "Epoch [392/500], Step [19600/25000], Train Loss: 0.3747, Valid Loss: 0.4516\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [393/500], Step [19650/25000], Train Loss: 0.3740, Valid Loss: 0.4582\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [394/500], Step [19700/25000], Train Loss: 0.3739, Valid Loss: 0.4511\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [395/500], Step [19750/25000], Train Loss: 0.3738, Valid Loss: 0.4561\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [396/500], Step [19800/25000], Train Loss: 0.3755, Valid Loss: 0.4416\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [397/500], Step [19850/25000], Train Loss: 0.3750, Valid Loss: 0.4558\n",
      "Epoch Accuracy: 0.9404309252217997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [398/500], Step [19900/25000], Train Loss: 0.3740, Valid Loss: 0.4451\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [399/500], Step [19950/25000], Train Loss: 0.3731, Valid Loss: 0.4542\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [400/500], Step [20000/25000], Train Loss: 0.3756, Valid Loss: 0.4680\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [401/500], Step [20050/25000], Train Loss: 0.3736, Valid Loss: 0.4504\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [402/500], Step [20100/25000], Train Loss: 0.3769, Valid Loss: 0.4415\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [403/500], Step [20150/25000], Train Loss: 0.3728, Valid Loss: 0.4440\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [404/500], Step [20200/25000], Train Loss: 0.3738, Valid Loss: 0.4496\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [405/500], Step [20250/25000], Train Loss: 0.3726, Valid Loss: 0.4541\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [406/500], Step [20300/25000], Train Loss: 0.3732, Valid Loss: 0.4407\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [407/500], Step [20350/25000], Train Loss: 0.3747, Valid Loss: 0.4556\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [408/500], Step [20400/25000], Train Loss: 0.3729, Valid Loss: 0.4587\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [409/500], Step [20450/25000], Train Loss: 0.3756, Valid Loss: 0.4567\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [410/500], Step [20500/25000], Train Loss: 0.3748, Valid Loss: 0.4656\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [411/500], Step [20550/25000], Train Loss: 0.3760, Valid Loss: 0.4911\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [412/500], Step [20600/25000], Train Loss: 0.3739, Valid Loss: 0.4427\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [413/500], Step [20650/25000], Train Loss: 0.3724, Valid Loss: 0.4514\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [414/500], Step [20700/25000], Train Loss: 0.3791, Valid Loss: 0.4575\n",
      "Epoch Accuracy: 0.9340937896070975\n",
      "Epoch [415/500], Step [20750/25000], Train Loss: 0.3738, Valid Loss: 0.4551\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [416/500], Step [20800/25000], Train Loss: 0.3748, Valid Loss: 0.4545\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [417/500], Step [20850/25000], Train Loss: 0.3735, Valid Loss: 0.4490\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [418/500], Step [20900/25000], Train Loss: 0.3736, Valid Loss: 0.4659\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [419/500], Step [20950/25000], Train Loss: 0.3730, Valid Loss: 0.4395\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [420/500], Step [21000/25000], Train Loss: 0.3744, Valid Loss: 0.4572\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [421/500], Step [21050/25000], Train Loss: 0.3728, Valid Loss: 0.4541\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [422/500], Step [21100/25000], Train Loss: 0.3724, Valid Loss: 0.4596\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [423/500], Step [21150/25000], Train Loss: 0.3753, Valid Loss: 0.4687\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [424/500], Step [21200/25000], Train Loss: 0.3748, Valid Loss: 0.4480\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [425/500], Step [21250/25000], Train Loss: 0.3714, Valid Loss: 0.4630\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [426/500], Step [21300/25000], Train Loss: 0.3730, Valid Loss: 0.4418\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [427/500], Step [21350/25000], Train Loss: 0.3745, Valid Loss: 0.4474\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [428/500], Step [21400/25000], Train Loss: 0.3747, Valid Loss: 0.4557\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [429/500], Step [21450/25000], Train Loss: 0.3755, Valid Loss: 0.4573\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [430/500], Step [21500/25000], Train Loss: 0.3714, Valid Loss: 0.4568\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [431/500], Step [21550/25000], Train Loss: 0.3726, Valid Loss: 0.4448\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [432/500], Step [21600/25000], Train Loss: 0.3724, Valid Loss: 0.4427\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [433/500], Step [21650/25000], Train Loss: 0.3729, Valid Loss: 0.4491\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [434/500], Step [21700/25000], Train Loss: 0.3727, Valid Loss: 0.4472\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [435/500], Step [21750/25000], Train Loss: 0.3721, Valid Loss: 0.4426\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [436/500], Step [21800/25000], Train Loss: 0.3717, Valid Loss: 0.4519\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [437/500], Step [21850/25000], Train Loss: 0.3725, Valid Loss: 0.4578\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [438/500], Step [21900/25000], Train Loss: 0.3718, Valid Loss: 0.4562\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [439/500], Step [21950/25000], Train Loss: 0.3721, Valid Loss: 0.4461\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [440/500], Step [22000/25000], Train Loss: 0.3718, Valid Loss: 0.4601\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [441/500], Step [22050/25000], Train Loss: 0.3733, Valid Loss: 0.4504\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [442/500], Step [22100/25000], Train Loss: 0.3738, Valid Loss: 0.4443\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [443/500], Step [22150/25000], Train Loss: 0.3743, Valid Loss: 0.4506\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [444/500], Step [22200/25000], Train Loss: 0.3739, Valid Loss: 0.4698\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [445/500], Step [22250/25000], Train Loss: 0.3706, Valid Loss: 0.4655\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [446/500], Step [22300/25000], Train Loss: 0.3721, Valid Loss: 0.4582\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [447/500], Step [22350/25000], Train Loss: 0.3735, Valid Loss: 0.4521\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [448/500], Step [22400/25000], Train Loss: 0.3727, Valid Loss: 0.4445\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [449/500], Step [22450/25000], Train Loss: 0.3748, Valid Loss: 0.4714\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [450/500], Step [22500/25000], Train Loss: 0.3738, Valid Loss: 0.4496\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [451/500], Step [22550/25000], Train Loss: 0.3738, Valid Loss: 0.4723\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [452/500], Step [22600/25000], Train Loss: 0.3742, Valid Loss: 0.4669\n",
      "Epoch Accuracy: 0.9397972116603295\n",
      "Epoch [453/500], Step [22650/25000], Train Loss: 0.3733, Valid Loss: 0.4595\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [454/500], Step [22700/25000], Train Loss: 0.3731, Valid Loss: 0.4486\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [455/500], Step [22750/25000], Train Loss: 0.3711, Valid Loss: 0.4498\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [456/500], Step [22800/25000], Train Loss: 0.3695, Valid Loss: 0.4581\n",
      "Epoch Accuracy: 0.9474017743979721\n",
      "Epoch [457/500], Step [22850/25000], Train Loss: 0.3735, Valid Loss: 0.4441\n",
      "Epoch Accuracy: 0.9404309252217997\n",
      "Epoch [458/500], Step [22900/25000], Train Loss: 0.3716, Valid Loss: 0.4574\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [459/500], Step [22950/25000], Train Loss: 0.3727, Valid Loss: 0.4416\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [460/500], Step [23000/25000], Train Loss: 0.3704, Valid Loss: 0.4481\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [461/500], Step [23050/25000], Train Loss: 0.3717, Valid Loss: 0.4581\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [462/500], Step [23100/25000], Train Loss: 0.3720, Valid Loss: 0.4483\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [463/500], Step [23150/25000], Train Loss: 0.3696, Valid Loss: 0.4548\n",
      "Epoch Accuracy: 0.9474017743979721\n",
      "Epoch [464/500], Step [23200/25000], Train Loss: 0.3710, Valid Loss: 0.4405\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [465/500], Step [23250/25000], Train Loss: 0.3715, Valid Loss: 0.4402\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [466/500], Step [23300/25000], Train Loss: 0.3724, Valid Loss: 0.4462\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [467/500], Step [23350/25000], Train Loss: 0.3704, Valid Loss: 0.4440\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [468/500], Step [23400/25000], Train Loss: 0.3717, Valid Loss: 0.4627\n",
      "Epoch Accuracy: 0.9461343472750317\n",
      "Epoch [469/500], Step [23450/25000], Train Loss: 0.3741, Valid Loss: 0.4584\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [470/500], Step [23500/25000], Train Loss: 0.3728, Valid Loss: 0.4592\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [471/500], Step [23550/25000], Train Loss: 0.3718, Valid Loss: 0.4591\n",
      "Epoch Accuracy: 0.944233206590621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [472/500], Step [23600/25000], Train Loss: 0.3710, Valid Loss: 0.4778\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [473/500], Step [23650/25000], Train Loss: 0.3739, Valid Loss: 0.4550\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [474/500], Step [23700/25000], Train Loss: 0.3711, Valid Loss: 0.4509\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [475/500], Step [23750/25000], Train Loss: 0.3715, Valid Loss: 0.4523\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [476/500], Step [23800/25000], Train Loss: 0.3705, Valid Loss: 0.4558\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [477/500], Step [23850/25000], Train Loss: 0.3727, Valid Loss: 0.4635\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [478/500], Step [23900/25000], Train Loss: 0.3696, Valid Loss: 0.4477\n",
      "Epoch Accuracy: 0.9474017743979721\n",
      "Epoch [479/500], Step [23950/25000], Train Loss: 0.3718, Valid Loss: 0.4523\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [480/500], Step [24000/25000], Train Loss: 0.3714, Valid Loss: 0.4526\n",
      "Epoch Accuracy: 0.944233206590621\n",
      "Epoch [481/500], Step [24050/25000], Train Loss: 0.3689, Valid Loss: 0.4492\n",
      "Epoch Accuracy: 0.9480354879594424\n",
      "Epoch [482/500], Step [24100/25000], Train Loss: 0.3708, Valid Loss: 0.4561\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [483/500], Step [24150/25000], Train Loss: 0.3731, Valid Loss: 0.4392\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [484/500], Step [24200/25000], Train Loss: 0.3743, Valid Loss: 0.4511\n",
      "Epoch Accuracy: 0.9378960709759189\n",
      "Epoch [485/500], Step [24250/25000], Train Loss: 0.3728, Valid Loss: 0.4503\n",
      "Epoch Accuracy: 0.9416983523447402\n",
      "Epoch [486/500], Step [24300/25000], Train Loss: 0.3699, Valid Loss: 0.4483\n",
      "Epoch Accuracy: 0.9474017743979721\n",
      "Epoch [487/500], Step [24350/25000], Train Loss: 0.3694, Valid Loss: 0.4502\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [488/500], Step [24400/25000], Train Loss: 0.3683, Valid Loss: 0.4457\n",
      "Epoch Accuracy: 0.9486692015209125\n",
      "Epoch [489/500], Step [24450/25000], Train Loss: 0.3710, Valid Loss: 0.4540\n",
      "Epoch Accuracy: 0.9435994930291508\n",
      "Epoch [490/500], Step [24500/25000], Train Loss: 0.3688, Valid Loss: 0.4394\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [491/500], Step [24550/25000], Train Loss: 0.3721, Valid Loss: 0.4575\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [492/500], Step [24600/25000], Train Loss: 0.3695, Valid Loss: 0.4402\n",
      "Epoch Accuracy: 0.9486692015209125\n",
      "Epoch [493/500], Step [24650/25000], Train Loss: 0.3698, Valid Loss: 0.4453\n",
      "Epoch Accuracy: 0.9455006337135615\n",
      "Epoch [494/500], Step [24700/25000], Train Loss: 0.3685, Valid Loss: 0.4575\n",
      "Epoch Accuracy: 0.9467680608365019\n",
      "Epoch [495/500], Step [24750/25000], Train Loss: 0.3721, Valid Loss: 0.4490\n",
      "Epoch Accuracy: 0.9429657794676806\n",
      "Epoch [496/500], Step [24800/25000], Train Loss: 0.3736, Valid Loss: 0.4430\n",
      "Epoch Accuracy: 0.94106463878327\n",
      "Epoch [497/500], Step [24850/25000], Train Loss: 0.3701, Valid Loss: 0.4530\n",
      "Epoch Accuracy: 0.9448669201520913\n",
      "Epoch [498/500], Step [24900/25000], Train Loss: 0.3721, Valid Loss: 0.4573\n",
      "Epoch Accuracy: 0.9423320659062104\n",
      "Epoch [499/500], Step [24950/25000], Train Loss: 0.3763, Valid Loss: 0.4393\n",
      "Epoch Accuracy: 0.9391634980988594\n",
      "Epoch [500/500], Step [25000/25000], Train Loss: 0.3693, Valid Loss: 0.4452\n",
      "Epoch Accuracy: 0.9461343472750317\n",
      "Model saved to ==> solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.CrossEntropyLoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 10,\n",
    "          eval_every = len(train_iter),\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total = 0\n",
    "        total_correct = 0\n",
    "        for (labels, (notes, notes_len)), _ in (train_loader):   \n",
    "            labels = labels.to(device)\n",
    "            notes = notes.to(device)\n",
    "            notes_len = notes_len.cpu()\n",
    "            output = model(notes.long())\n",
    "            loss = criterion(output, labels.long())\n",
    "            #loss = criterion(output.view(-1,1),labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            labels_max = labels.detach().cpu()\n",
    "            output_max = np.argmax((output.detach().cpu()),axis=1)\n",
    "            for i in range(len(labels_max)):\n",
    "                total+=1\n",
    "                if labels_max[i] ==  output_max[i]:\n",
    "                    total_correct += 1\n",
    "            accuracy = accuracy_score(labels_max, output_max)\n",
    "            \n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                  # validation loop\n",
    "                    for (labels, (notes, notes_len)), _ in (valid_loader):        \n",
    "                        labels = labels.to(device)\n",
    "                        notes = notes.to(device)\n",
    "                        notes_len = notes_len.cpu()\n",
    "                        output = model(notes.long())\n",
    "                        loss = criterion(output, labels.long())\n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
    "                    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "        print(\"Epoch Accuracy: {}\".format(total_correct/total))\n",
    "    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')\n",
    "\n",
    "\n",
    "model = TransformerModel(ntokens,emsize,nhead,d_hid,nlayers,dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
    "\n",
    "train(model=model, optimizer=optimizer, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcbc3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8a2bbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n",
      "500\n",
      "500\n",
      "500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "epoch_train = []\n",
    "epoch_valid = []\n",
    "epochs = []\n",
    "\n",
    "for x in range(len(train_loss_list)):\n",
    "    epoch_train.append(sum(train_loss_list[x:x+2])/len(train_loss_list[x:x+2]))\n",
    "print(len(epoch_train))\n",
    "\n",
    "for x in range(len(valid_loss_list)):\n",
    "    epoch_valid.append(sum(valid_loss_list[x:x+2])/len(valid_loss_list[x:x+2]))\n",
    "print(len(epoch_valid))\n",
    "\n",
    "for x in range(500):\n",
    "    epochs.append(x)\n",
    "print(len(epochs))\n",
    "\n",
    "plt.plot(epochs, epoch_train, label='Train')\n",
    "plt.plot(epochs, epoch_valid, label='Valid')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"Transformer 500 epochs.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d8529e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2795a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500, 525, 550, 575, 600, 625, 650, 675, 700, 725, 750, 775, 800, 825, 850, 875, 900, 925, 950, 975, 1000, 1025, 1050, 1075, 1100, 1125, 1150, 1175, 1200, 1225, 1250, 1275, 1300, 1325, 1350, 1375, 1400, 1425, 1450, 1475, 1500, 1525, 1550, 1575, 1600, 1625, 1650, 1675, 1700, 1725, 1750, 1775, 1800, 1825, 1850, 1875, 1900, 1925, 1950, 1975, 2000, 2025, 2050, 2075, 2100, 2125, 2150, 2175, 2200, 2225, 2250, 2275, 2300, 2325, 2350, 2375, 2400, 2425, 2450, 2475, 2500, 2525, 2550, 2575, 2600, 2625, 2650, 2675, 2700, 2725, 2750, 2775, 2800, 2825, 2850, 2875, 2900, 2925, 2950, 2975, 3000, 3025, 3050, 3075, 3100, 3125, 3150, 3175, 3200, 3225, 3250, 3275, 3300, 3325, 3350, 3375, 3400, 3425, 3450, 3475, 3500, 3525, 3550, 3575, 3600, 3625, 3650, 3675, 3700, 3725, 3750, 3775, 3800, 3825, 3850, 3875, 3900, 3925, 3950, 3975, 4000, 4025, 4050, 4075, 4100, 4125, 4150, 4175, 4200, 4225, 4250, 4275, 4300, 4325, 4350, 4375, 4400, 4425, 4450, 4475, 4500, 4525, 4550, 4575, 4600, 4625, 4650, 4675, 4700, 4725, 4750, 4775, 4800, 4825, 4850, 4875, 4900, 4925, 4950, 4975, 5000]\n"
     ]
    }
   ],
   "source": [
    "print(global_steps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfce53a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/metrics.pt\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1000,) and (500,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22715/2464486282.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   3020\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1000,) and (500,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
    "for x in range(500):\n",
    "    epochs.append(x)\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"Transformer 500 epochs.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14b3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "974bdcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== solo_classification_transformer_REMI_weights_unaugmented_200epochs/model.pt\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7869    0.8571    0.8205       112\n",
      "           0     0.9252    0.8839    0.9041       224\n",
      "\n",
      "    accuracy                         0.8750       336\n",
      "   macro avg     0.8561    0.8705    0.8623       336\n",
      "weighted avg     0.8791    0.8750    0.8762       336\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(model, test_loader, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (labels, (notes, notes_len)), _ in test_loader:           \n",
    "            labels = labels.to(device)\n",
    "            notes = notes.to(device)\n",
    "            notes_len = notes_len.cpu()\n",
    "            output = model(notes.long())\n",
    "\n",
    "            output = np.argmax(output.cpu().detach(), axis=1)\n",
    "            y_pred.extend(output.tolist())\n",
    "            y_true.extend(labels.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['INSTRUMENTAL SOLO', 'VOCAL'])\n",
    "    ax.yaxis.set_ticklabels(['INSTRUMENTAL SOLO', 'VOCAL'])\n",
    "    \n",
    "    \n",
    "best_model = TransformerModel(ntokens,emsize,nhead,d_hid,nlayers,dropout).to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)\n",
    "evaluate(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d0a62d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4123/3001074312.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhiddenlayer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchviz'"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_iter)).notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3005c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_architecture(model, test_loader, version='title', threshold=0.5):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    for (labels, (notes, notes_len)), _ in test_loader:           \n",
    "        labels = labels.to(device)\n",
    "        notes = notes.to(device)\n",
    "        notes_len = notes_len.cpu()\n",
    "        output = model(notes.long(), notes_len.long())\n",
    "        \n",
    "        \n",
    "        transforms = [# hl.transforms.Prune('Constant'),\n",
    "                      #hl.transforms.FoldDuplicates()\n",
    "                     ] # Removes Constant nodes from graph.\n",
    "\n",
    "        graph = hl.build_graph(model, (notes,notes_len), transforms=transforms)\n",
    "        graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "        print(graph)\n",
    "        graph.save('rnn_hiddenlayer', format='png')\n",
    "\n",
    "        #output = (output > threshold).int()\n",
    "        #y_pred.extend(output.tolist())\n",
    "        #y_true.extend(labels.tolist())\n",
    "        #print(dict(model.named_parameters()))\n",
    "        #make_dot(output,params=dict(model.named_parameters())).render()\n",
    "        break\n",
    "\n",
    "    \n",
    "best_model = LSTM().to(device)\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "load_checkpoint(destination_folder + '/model.pt', best_model, optimizer)\n",
    "print_architecture(best_model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
