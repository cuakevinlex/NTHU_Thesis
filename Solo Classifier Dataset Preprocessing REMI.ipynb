{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2ca29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import miditoolkit\n",
    "import remi_utils as utils\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517f8832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create pickle file based on dataset\n",
    "\n",
    "def extract_events(input_path, chord=False):\n",
    "    note_items, tempo_items = utils.read_items(input_path)\n",
    "    note_items = utils.quantize_items(note_items)\n",
    "    max_time = note_items[-1].end\n",
    "    if chord:\n",
    "        chord_items = utils.extract_chords(note_items)\n",
    "        items = chord_items + tempo_items + note_items\n",
    "    else:\n",
    "        items = tempo_items + note_items\n",
    "    groups = utils.group_items(items, max_time)\n",
    "    events = utils.item2event(groups)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_elements= []\n",
    "for midi_file in glob.glob(\"./data/melody/*/*.mid*\", recursive=True):\n",
    "    #print(midi_file)\n",
    "    events = extract_events(midi_file) # If you're analyzing chords, use `extract_events(midi_file, chord=True)`\n",
    "    for event in events:\n",
    "        element = '{}_{}'.format(event.name, event.value)\n",
    "        all_elements.append(element)\n",
    "\n",
    "for midi_file in glob.glob(\"./data/piano/*/*.mid*\", recursive=True):\n",
    "    #print(midi_file)\n",
    "    try:\n",
    "        events = extract_events(midi_file) # If you're analyzing chords, use `extract_events(midi_file, chord=True)`\n",
    "    except:\n",
    "        print(midi_file)\n",
    "    for event in events:\n",
    "        element = '{}_{}'.format(event.name, event.value)\n",
    "        all_elements.append(element)        \n",
    "\n",
    "counts = Counter(all_elements)\n",
    "event2word = {c: i for i, c in enumerate(counts.keys())}\n",
    "word2event = {i: c for i, c in enumerate(counts.keys())}\n",
    "pickle.dump((event2word, word2event), open('dictionary.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8f5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "event2word, word2event = pickle.load(open('dictionary.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98f87116",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "intros = []\n",
    "outros = []\n",
    "solos = []\n",
    "with open('solos.json') as json_file: \n",
    "    data = json.load(json_file) \n",
    "for i in range(1,910):\n",
    "    filename = str(i).zfill(3)\n",
    "    if filename not in data:\n",
    "        continue\n",
    "    for j in range(len(data[filename])):\n",
    "        count += 1\n",
    "        # extract intro\n",
    "        intro = extract_events(\"./data/melody/intro/\" + str(i).zfill(3) + \"_solo_\" + str(j) + \".mid\")\n",
    "        w_intro = utils.event_to_word(intro, event2word)\n",
    "        intros.append(w_intro)\n",
    "        # extract outro\n",
    "        outro = extract_events(\"./data/melody/outro/\" + str(i).zfill(3) + \"_solo_\" + str(j) + \".mid\")\n",
    "        w_outro = utils.event_to_word(outro, event2word)\n",
    "        outros.append(w_outro)\n",
    "        # extract solo\n",
    "        solo = extract_events(\"./data/melody/middle/\" + str(i).zfill(3) + \"_solo_\" + str(j) + \".mid\")\n",
    "        w_solo = utils.event_to_word(solo, event2word)\n",
    "        solos.append(w_solo)\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "08da5814",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef8b9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 75, 103, 1, 71, 86, 25, 7, 71, 36, 31, 10, 71, 8, 13, 14, 71, 38, 31, 15, 71, 8, 31, 18, 69, 22, 88, 0, 15, 71, 38, 27, 33, 67, 36, 27, 18, 69, 86, 27, 24, 71, 8, 27, 20, 71, 22, 27, 0, 1, 71, 86, 31, 7, 69, 36, 25, 10, 71, 8, 77, 20, 71, 8, 25, 0, 1, 71, 35, 31, 7, 71, 38, 31, 10, 69, 86, 64, 15, 71, 38, 27, 33, 71, 36, 27, 18, 71, 86, 27, 24, 71, 8, 27, 20, 67, 22, 27, 0, 1, 71, 86, 25, 7, 71, 36, 31, 10, 71, 8, 13, 14, 71, 38, 31, 15, 71, 8, 31, 18, 69, 86, 88]\n",
      "['Bar_None', 'Position_1/16', 'Tempo Class_mid', 'Tempo Value_0', 'Position_1/16', 'Note Velocity_28', 'Note On_66', 'Note Duration_2', 'Position_3/16', 'Note Velocity_28', 'Note On_63', 'Note Duration_1', 'Position_5/16', 'Note Velocity_28', 'Note On_68', 'Note Duration_5', 'Position_9/16', 'Note Velocity_28', 'Note On_61', 'Note Duration_1', 'Position_11/16', 'Note Velocity_28', 'Note On_68', 'Note Duration_1', 'Position_13/16', 'Note Velocity_29', 'Note On_70', 'Note Duration_14', 'Bar_None', 'Position_11/16', 'Note Velocity_28', 'Note On_61', 'Note Duration_0', 'Position_12/16', 'Note Velocity_27', 'Note On_63', 'Note Duration_0', 'Position_13/16', 'Note Velocity_29', 'Note On_66', 'Note Duration_0', 'Position_14/16', 'Note Velocity_28', 'Note On_68', 'Note Duration_0', 'Position_15/16', 'Note Velocity_28', 'Note On_70', 'Note Duration_0', 'Bar_None', 'Position_1/16', 'Note Velocity_28', 'Note On_66', 'Note Duration_1', 'Position_3/16', 'Note Velocity_29', 'Note On_63', 'Note Duration_2', 'Position_5/16', 'Note Velocity_28', 'Note On_68', 'Note Duration_11', 'Position_15/16', 'Note Velocity_28', 'Note On_68', 'Note Duration_2', 'Bar_None', 'Position_1/16', 'Note Velocity_28', 'Note On_65', 'Note Duration_1', 'Position_3/16', 'Note Velocity_28', 'Note On_61', 'Note Duration_1', 'Position_5/16', 'Note Velocity_29', 'Note On_66', 'Note Duration_8', 'Position_11/16', 'Note Velocity_28', 'Note On_61', 'Note Duration_0', 'Position_12/16', 'Note Velocity_28', 'Note On_63', 'Note Duration_0', 'Position_13/16', 'Note Velocity_28', 'Note On_66', 'Note Duration_0', 'Position_14/16', 'Note Velocity_28', 'Note On_68', 'Note Duration_0', 'Position_15/16', 'Note Velocity_27', 'Note On_70', 'Note Duration_0', 'Bar_None', 'Position_1/16', 'Note Velocity_28', 'Note On_66', 'Note Duration_2', 'Position_3/16', 'Note Velocity_28', 'Note On_63', 'Note Duration_1', 'Position_5/16', 'Note Velocity_28', 'Note On_68', 'Note Duration_5', 'Position_9/16', 'Note Velocity_28', 'Note On_61', 'Note Duration_1', 'Position_11/16', 'Note Velocity_28', 'Note On_68', 'Note Duration_1', 'Position_13/16', 'Note Velocity_29', 'Note On_66', 'Note Duration_14']\n"
     ]
    }
   ],
   "source": [
    "print(intros[0])\n",
    "print([word2event[x] for x in intros[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a054de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "intros_piano = []\n",
    "outros_piano = []\n",
    "solos_piano = []\n",
    "with open('solos.json') as json_file: \n",
    "    data = json.load(json_file) \n",
    "for i in range(1,910):\n",
    "    filename = str(i).zfill(3)\n",
    "    if filename not in data:\n",
    "        continue\n",
    "    for j in range(len(data[filename])):\n",
    "        count += 1\n",
    "        # extract intro\n",
    "        intro = extract_events(\"./data/piano/intro/\" + str(i).zfill(3) + \"_solo_\" + str(j) + \".mid\")\n",
    "        w_intro = utils.event_to_word(intro, event2word)\n",
    "        intros_piano.append(w_intro)\n",
    "        # extract outro\n",
    "        outro = extract_events(\"./data/piano/outro/\" + str(i).zfill(3) + \"_solo_\" + str(j) + \".mid\")\n",
    "        w_outro = utils.event_to_word(outro, event2word)\n",
    "        outros_piano.append(w_outro)\n",
    "        # extract solo\n",
    "        solo = extract_events(\"./data/piano/middle/\" + str(i).zfill(3) + \"_solo_\" + str(j) + \".mid\")\n",
    "        w_solo = utils.event_to_word(solo, event2word)\n",
    "        solos_piano.append(w_solo)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "52e52f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [intros, intros_piano, outros, outros_piano, solos, solos_piano]\n",
    "pickle.dump(data, open('./solo_generation_dataset/solo_generation_dataset.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54250ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('./solo_generation_dataset/solo_generation_dataset.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ca4494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_length(series):\n",
    "    max_length=0\n",
    "    for i in range(len(series)):\n",
    "        if max_length < len(series[i]):\n",
    "            max_length = len(series[i])\n",
    "    return max_length\n",
    "\n",
    "def pad_dataset(dataset, word2event):\n",
    "    pad_value = len(word2event)\n",
    "    max_length = 0\n",
    "    for i in range(len(dataset)):\n",
    "        if max_length < find_max_length(dataset[i]):\n",
    "            max_length = find_max_length(dataset[i])\n",
    "    print(max_length)\n",
    "    for i in range(len(dataset)):\n",
    "        for j in range(len(dataset[i])):\n",
    "            while len(dataset[i][j]) < max_length:\n",
    "                dataset[i][j].append(pad_value)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c572bb26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637\n"
     ]
    }
   ],
   "source": [
    "data_padded = pad_dataset(data,word2event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83c2666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_padded, open('./solo_generation_dataset/solo_generation_dataset_padded.pkl', 'wb'))\n",
    "data_padded = pickle.load(open('./solo_generation_dataset/solo_generation_dataset_padded.pkl', 'rb'))\n",
    "data = data_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd89f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "        string_array = [str(num) for num in data[i][j]]\n",
    "        data_text[i][j] = ' '.join(string_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0af70b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "intros_t, intros_piano_t, outros_t, outros_piano_t, solos_t, solos_piano_t = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c6ecdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "intros_train, intros_t_subset, intros_piano_train, intros_piano_t_subset, outros_train, outros_t_subset, outros_piano_train, outros_piano_t_subset, solos_train, solos_t_subset, solos_piano_train, solos_piano_t_subset = train_test_split(intros_t, intros_piano_t, outros_t, outros_piano_t, solos_t, solos_piano_t, test_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b6d3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "intros_test, intros_valid, intros_piano_test, intros_piano_valid, outros_test, outros_valid, outros_piano_test, outros_piano_valid, solos_test, solos_valid, solos_piano_test, solos_piano_valid = train_test_split(intros_t_subset, intros_piano_t_subset, outros_t_subset, outros_piano_t_subset, solos_t_subset, solos_piano_t_subset, test_size=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07761dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "valid = []\n",
    "test = []\n",
    "\n",
    "for i in range(len(intros_train)):\n",
    "    train.append([0,intros_train[i]])\n",
    "    train.append([0,outros_train[i]])\n",
    "    train.append([1,solos_train[i]])\n",
    "    \n",
    "for i in range(len(intros_valid)):\n",
    "    valid.append([0,intros_valid[i]])\n",
    "    valid.append([0,outros_valid[i]])\n",
    "    valid.append([1,solos_valid[i]])\n",
    "\n",
    "    \n",
    "for i in range(len(intros_test)):\n",
    "    test.append([0,intros_test[i]])\n",
    "    test.append([0,outros_test[i]])\n",
    "    test.append([1,solos_test[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "valid = []\n",
    "test = []\n",
    "\n",
    "vocal_train = []\n",
    "vocal_valid = []\n",
    "vocal_test = []\n",
    "\n",
    "for i in range(len(intros_train)):\n",
    "    vocal_train.append([0,intros_train[i]])\n",
    "    vocal_train.append([0,outros_train[i]])\n",
    "    train.append([1,solos_train[i]])\n",
    "\n",
    "vocal_train, _ = train_test_split(vocal_train, test_size=int(len(vocal_train)/2))\n",
    "\n",
    "for i in range(len(vocal_train)):\n",
    "    train.append(vocal_train[i])\n",
    "    \n",
    "    \n",
    "for i in range(len(intros_valid)):\n",
    "    vocal_valid.append([0,intros_valid[i]])\n",
    "    vocal_valid.append([0,outros_valid[i]])\n",
    "    valid.append([1,solos_valid[i]])\n",
    "\n",
    "vocal_valid, _ = train_test_split(vocal_valid, test_size=int(len(vocal_valid)/2))\n",
    "\n",
    "for i in range(len(vocal_valid)):\n",
    "    valid.append(vocal_valid[i])\n",
    "    \n",
    "    \n",
    "for i in range(len(intros_test)):\n",
    "    vocal_test.append([0,intros_test[i]])\n",
    "    vocal_test.append([0,outros_test[i]])\n",
    "    test.append([1,solos_test[i]])\n",
    "\n",
    "vocal_test, _ = train_test_split(vocal_test, test_size=int(len(vocal_test)/2))\n",
    "\n",
    "for i in range(len(vocal_test)):\n",
    "    test.append(vocal_test[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a39a460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train,columns=['label','melody'])\n",
    "df_val = pd.DataFrame(test,columns=['label','melody'])\n",
    "df_test = pd.DataFrame(valid,columns=['label','melody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a1d1466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "195a318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_folder=\"solo_classification_REMI_dataset_unbalanced\"\n",
    "df_train.to_csv(destination_folder + '/train.csv', index=False)\n",
    "df_val.to_csv(destination_folder + '/val.csv', index=False)\n",
    "df_test.to_csv(destination_folder + '/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "13a39866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_padding(series, word2event):\n",
    "    return [value for value in series if value != len(word2event)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b96b61ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst_int = [int(x) for x in df_train.values[0][0].split(' ')]\n",
    "utils.write_midi(remove_padding(lst_int, word2event), word2event, 'test.midi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
